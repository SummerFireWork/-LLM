{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 设置环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['http_proxy'] = '127.0.0.1:7890'\n",
    "os.environ['https_proxy'] = '127.0.0.1:7890'\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"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\"\n",
    "\n",
    "os.environ[\"DASHSCOPE_API_KEY\"] = \"sk-62396f4eadf94b50acc7161cfd4b0b0e\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 导入数据\n",
    "## 2.1 导入数据方法1：通过TextLoader导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "home_path = os.getcwd()\n",
    "data_path = os.path.join(home_path, 'data')\n",
    "documents = []\n",
    "for file_name in os.listdir(data_path):\n",
    "    if file_name.endswith(\".txt\"):\n",
    "        file_path = os.path.join(data_path, file_name)\n",
    "        documents.append(file_path)\n",
    "\n",
    "for i in range(len(documents)):\n",
    "    docs = TextLoader(documents[i]).load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 导入数据方法2：通过DirectoryLoader导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 1674.37it/s]\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import TextLoader, DirectoryLoader\n",
    "\n",
    "home_path = os.getcwd()\n",
    "data_path = os.path.join(home_path, 'data')\n",
    "text_loader_kwargs ={'autodetect_encoding': True}\n",
    "loader = DirectoryLoader(data_path, glob=\"**/*.txt\", loader_cls=TextLoader, loader_kwargs=text_loader_kwargs, show_progress=True)\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 文本分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1134\n",
      "========================================================================================================================================================================================================\n",
      "440\n",
      "998\n",
      "543\n",
      "14\n",
      "996\n",
      "239\n",
      "876\n",
      "489\n",
      "993\n",
      "492\n",
      "999\n",
      "323\n",
      "801\n",
      "982\n",
      "612\n",
      "995\n",
      "433\n",
      "842\n",
      "995\n",
      "558\n",
      "987\n",
      "757\n",
      "873\n",
      "991\n",
      "709\n",
      "760\n",
      "951\n",
      "424\n",
      "918\n",
      "992\n",
      "994\n",
      "619\n",
      "495\n",
      "894\n",
      "977\n",
      "961\n",
      "890\n",
      "727\n",
      "979\n",
      "466\n",
      "831\n",
      "632\n",
      "896\n",
      "611\n",
      "970\n",
      "71\n",
      "932\n",
      "995\n",
      "383\n",
      "646\n",
      "557\n",
      "916\n",
      "793\n",
      "997\n",
      "790\n",
      "774\n",
      "670\n",
      "696\n",
      "804\n",
      "974\n",
      "506\n",
      "972\n",
      "997\n",
      "654\n",
      "723\n",
      "951\n",
      "999\n",
      "904\n",
      "686\n",
      "728\n",
      "742\n",
      "850\n",
      "862\n",
      "887\n",
      "967\n",
      "790\n",
      "776\n",
      "758\n",
      "837\n",
      "518\n",
      "194\n",
      "998\n",
      "896\n",
      "979\n",
      "976\n",
      "981\n",
      "847\n",
      "993\n",
      "591\n",
      "995\n",
      "374\n",
      "786\n",
      "933\n",
      "624\n",
      "999\n",
      "884\n",
      "999\n",
      "550\n",
      "632\n",
      "929\n",
      "997\n",
      "837\n",
      "207\n",
      "999\n",
      "495\n",
      "963\n",
      "402\n",
      "927\n",
      "891\n",
      "574\n",
      "530\n",
      "622\n",
      "996\n",
      "812\n",
      "696\n",
      "480\n",
      "994\n",
      "214\n",
      "777\n",
      "998\n",
      "474\n",
      "870\n",
      "313\n",
      "827\n",
      "851\n",
      "874\n",
      "997\n",
      "289\n",
      "717\n",
      "969\n",
      "45\n",
      "999\n",
      "438\n",
      "288\n",
      "995\n",
      "518\n",
      "553\n",
      "972\n",
      "857\n",
      "436\n",
      "862\n",
      "896\n",
      "953\n",
      "994\n",
      "816\n",
      "759\n",
      "991\n",
      "395\n",
      "919\n",
      "918\n",
      "727\n",
      "993\n",
      "230\n",
      "794\n",
      "996\n",
      "202\n",
      "691\n",
      "936\n",
      "595\n",
      "947\n",
      "936\n",
      "920\n",
      "990\n",
      "279\n",
      "50\n",
      "997\n",
      "317\n",
      "997\n",
      "314\n",
      "992\n",
      "216\n",
      "821\n",
      "994\n",
      "792\n",
      "977\n",
      "912\n",
      "949\n",
      "910\n",
      "980\n",
      "930\n",
      "935\n",
      "937\n",
      "978\n",
      "183\n",
      "961\n",
      "996\n",
      "995\n",
      "367\n",
      "995\n",
      "986\n",
      "588\n",
      "999\n",
      "875\n",
      "995\n",
      "995\n",
      "501\n",
      "984\n",
      "998\n",
      "604\n",
      "780\n",
      "958\n",
      "925\n",
      "634\n",
      "924\n",
      "520\n",
      "735\n",
      "692\n",
      "997\n",
      "663\n",
      "990\n",
      "872\n",
      "996\n",
      "319\n",
      "638\n",
      "607\n",
      "930\n",
      "823\n",
      "902\n",
      "738\n",
      "456\n",
      "987\n",
      "459\n",
      "915\n",
      "901\n",
      "965\n",
      "832\n",
      "999\n",
      "386\n",
      "972\n",
      "649\n",
      "990\n",
      "481\n",
      "496\n",
      "606\n",
      "765\n",
      "962\n",
      "972\n",
      "656\n",
      "999\n",
      "220\n",
      "638\n",
      "851\n",
      "978\n",
      "996\n",
      "557\n",
      "833\n",
      "806\n",
      "993\n",
      "999\n",
      "325\n",
      "998\n",
      "908\n",
      "857\n",
      "678\n",
      "544\n",
      "621\n",
      "427\n",
      "996\n",
      "272\n",
      "895\n",
      "970\n",
      "263\n",
      "875\n",
      "508\n",
      "936\n",
      "980\n",
      "972\n",
      "754\n",
      "715\n",
      "756\n",
      "980\n",
      "955\n",
      "906\n",
      "974\n",
      "728\n",
      "766\n",
      "998\n",
      "703\n",
      "856\n",
      "999\n",
      "680\n",
      "999\n",
      "442\n",
      "796\n",
      "874\n",
      "998\n",
      "298\n",
      "818\n",
      "427\n",
      "911\n",
      "933\n",
      "430\n",
      "761\n",
      "747\n",
      "456\n",
      "704\n",
      "992\n",
      "222\n",
      "887\n",
      "957\n",
      "719\n",
      "998\n",
      "225\n",
      "925\n",
      "990\n",
      "974\n",
      "662\n",
      "991\n",
      "156\n",
      "996\n",
      "274\n",
      "934\n",
      "998\n",
      "827\n",
      "683\n",
      "324\n",
      "994\n",
      "708\n",
      "806\n",
      "981\n",
      "476\n",
      "914\n",
      "660\n",
      "629\n",
      "751\n",
      "823\n",
      "952\n",
      "994\n",
      "443\n",
      "999\n",
      "212\n",
      "266\n",
      "994\n",
      "243\n",
      "846\n",
      "995\n",
      "708\n",
      "959\n",
      "664\n",
      "442\n",
      "743\n",
      "997\n",
      "509\n",
      "964\n",
      "890\n",
      "949\n",
      "837\n",
      "994\n",
      "997\n",
      "631\n",
      "811\n",
      "210\n",
      "995\n",
      "313\n",
      "738\n",
      "971\n",
      "832\n",
      "355\n",
      "996\n",
      "599\n",
      "691\n",
      "896\n",
      "904\n",
      "692\n",
      "792\n",
      "994\n",
      "664\n",
      "805\n",
      "995\n",
      "312\n",
      "993\n",
      "251\n",
      "935\n",
      "918\n",
      "996\n",
      "748\n",
      "931\n",
      "208\n",
      "941\n",
      "998\n",
      "613\n",
      "525\n",
      "997\n",
      "423\n",
      "980\n",
      "563\n",
      "770\n",
      "996\n",
      "264\n",
      "959\n",
      "737\n",
      "996\n",
      "363\n",
      "966\n",
      "159\n",
      "995\n",
      "280\n",
      "26\n",
      "998\n",
      "506\n",
      "806\n",
      "897\n",
      "757\n",
      "811\n",
      "911\n",
      "981\n",
      "963\n",
      "980\n",
      "969\n",
      "986\n",
      "942\n",
      "922\n",
      "911\n",
      "927\n",
      "967\n",
      "889\n",
      "935\n",
      "872\n",
      "686\n",
      "924\n",
      "786\n",
      "759\n",
      "771\n",
      "755\n",
      "778\n",
      "849\n",
      "848\n",
      "984\n",
      "854\n",
      "982\n",
      "895\n",
      "975\n",
      "968\n",
      "977\n",
      "820\n",
      "993\n",
      "833\n",
      "843\n",
      "903\n",
      "948\n",
      "983\n",
      "958\n",
      "913\n",
      "941\n",
      "758\n",
      "981\n",
      "717\n",
      "970\n",
      "939\n",
      "819\n",
      "815\n",
      "989\n",
      "971\n",
      "896\n",
      "883\n",
      "965\n",
      "806\n",
      "912\n",
      "892\n",
      "730\n",
      "758\n",
      "903\n",
      "981\n",
      "893\n",
      "902\n",
      "858\n",
      "841\n",
      "840\n",
      "862\n",
      "932\n",
      "874\n",
      "839\n",
      "807\n",
      "745\n",
      "910\n",
      "907\n",
      "812\n",
      "977\n",
      "983\n",
      "990\n",
      "927\n",
      "984\n",
      "971\n",
      "875\n",
      "966\n",
      "910\n",
      "831\n",
      "807\n",
      "958\n",
      "767\n",
      "865\n",
      "977\n",
      "874\n",
      "736\n",
      "742\n",
      "997\n",
      "995\n",
      "956\n",
      "848\n",
      "765\n",
      "884\n",
      "888\n",
      "905\n",
      "950\n",
      "916\n",
      "768\n",
      "927\n",
      "994\n",
      "899\n",
      "995\n",
      "938\n",
      "836\n",
      "933\n",
      "925\n",
      "951\n",
      "979\n",
      "960\n",
      "769\n",
      "848\n",
      "842\n",
      "846\n",
      "957\n",
      "974\n",
      "910\n",
      "948\n",
      "752\n",
      "858\n",
      "894\n",
      "878\n",
      "791\n",
      "954\n",
      "848\n",
      "969\n",
      "774\n",
      "546\n",
      "995\n",
      "255\n",
      "908\n",
      "838\n",
      "947\n",
      "851\n",
      "885\n",
      "949\n",
      "958\n",
      "607\n",
      "991\n",
      "978\n",
      "924\n",
      "994\n",
      "985\n",
      "707\n",
      "892\n",
      "772\n",
      "586\n",
      "661\n",
      "980\n",
      "907\n",
      "876\n",
      "808\n",
      "578\n",
      "685\n",
      "847\n",
      "996\n",
      "593\n",
      "818\n",
      "957\n",
      "551\n",
      "997\n",
      "951\n",
      "982\n",
      "888\n",
      "891\n",
      "946\n",
      "899\n",
      "306\n",
      "994\n",
      "921\n",
      "796\n",
      "999\n",
      "288\n",
      "992\n",
      "295\n",
      "983\n",
      "932\n",
      "990\n",
      "275\n",
      "868\n",
      "707\n",
      "894\n",
      "553\n",
      "997\n",
      "759\n",
      "705\n",
      "734\n",
      "985\n",
      "644\n",
      "978\n",
      "715\n",
      "671\n",
      "881\n",
      "610\n",
      "838\n",
      "761\n",
      "533\n",
      "768\n",
      "725\n",
      "989\n",
      "345\n",
      "988\n",
      "978\n",
      "971\n",
      "955\n",
      "372\n",
      "766\n",
      "398\n",
      "674\n",
      "836\n",
      "801\n",
      "459\n",
      "996\n",
      "375\n",
      "965\n",
      "973\n",
      "983\n",
      "647\n",
      "763\n",
      "843\n",
      "856\n",
      "928\n",
      "893\n",
      "896\n",
      "650\n",
      "970\n",
      "944\n",
      "523\n",
      "856\n",
      "889\n",
      "888\n",
      "994\n",
      "602\n",
      "576\n",
      "633\n",
      "809\n",
      "816\n",
      "931\n",
      "522\n",
      "973\n",
      "988\n",
      "110\n",
      "995\n",
      "319\n",
      "999\n",
      "289\n",
      "759\n",
      "790\n",
      "908\n",
      "973\n",
      "999\n",
      "338\n",
      "731\n",
      "759\n",
      "579\n",
      "929\n",
      "958\n",
      "982\n",
      "939\n",
      "810\n",
      "529\n",
      "569\n",
      "774\n",
      "317\n",
      "781\n",
      "988\n",
      "615\n",
      "655\n",
      "873\n",
      "890\n",
      "614\n",
      "956\n",
      "998\n",
      "878\n",
      "796\n",
      "968\n",
      "952\n",
      "564\n",
      "573\n",
      "691\n",
      "770\n",
      "940\n",
      "965\n",
      "941\n",
      "920\n",
      "994\n",
      "510\n",
      "837\n",
      "749\n",
      "875\n",
      "683\n",
      "814\n",
      "999\n",
      "915\n",
      "353\n",
      "773\n",
      "673\n",
      "917\n",
      "566\n",
      "873\n",
      "636\n",
      "839\n",
      "406\n",
      "890\n",
      "760\n",
      "942\n",
      "553\n",
      "997\n",
      "287\n",
      "823\n",
      "953\n",
      "973\n",
      "272\n",
      "888\n",
      "974\n",
      "963\n",
      "936\n",
      "964\n",
      "989\n",
      "807\n",
      "936\n",
      "993\n",
      "972\n",
      "846\n",
      "612\n",
      "581\n",
      "996\n",
      "283\n",
      "966\n",
      "968\n",
      "989\n",
      "986\n",
      "927\n",
      "895\n",
      "992\n",
      "966\n",
      "968\n",
      "520\n",
      "968\n",
      "999\n",
      "983\n",
      "644\n",
      "933\n",
      "447\n",
      "939\n",
      "704\n",
      "878\n",
      "888\n",
      "983\n",
      "987\n",
      "979\n",
      "881\n",
      "935\n",
      "973\n",
      "874\n",
      "936\n",
      "949\n",
      "876\n",
      "878\n",
      "850\n",
      "893\n",
      "932\n",
      "985\n",
      "908\n",
      "861\n",
      "957\n",
      "864\n",
      "984\n",
      "857\n",
      "994\n",
      "975\n",
      "845\n",
      "831\n",
      "442\n",
      "996\n",
      "354\n",
      "94\n",
      "995\n",
      "555\n",
      "96\n",
      "995\n",
      "451\n",
      "971\n",
      "558\n",
      "990\n",
      "483\n",
      "579\n",
      "991\n",
      "757\n",
      "90\n",
      "995\n",
      "707\n",
      "999\n",
      "509\n",
      "721\n",
      "928\n",
      "992\n",
      "494\n",
      "805\n",
      "951\n",
      "717\n",
      "730\n",
      "421\n",
      "715\n",
      "938\n",
      "986\n",
      "911\n",
      "976\n",
      "938\n",
      "593\n",
      "995\n",
      "407\n",
      "884\n",
      "970\n",
      "888\n",
      "442\n",
      "969\n",
      "994\n",
      "351\n",
      "915\n",
      "906\n",
      "978\n",
      "669\n",
      "505\n",
      "985\n",
      "663\n",
      "623\n",
      "783\n",
      "722\n",
      "828\n",
      "961\n",
      "913\n",
      "999\n",
      "993\n",
      "799\n",
      "788\n",
      "895\n",
      "725\n",
      "229\n",
      "998\n",
      "849\n",
      "132\n",
      "998\n",
      "399\n",
      "639\n",
      "998\n",
      "762\n",
      "789\n",
      "997\n",
      "580\n",
      "829\n",
      "452\n",
      "684\n",
      "976\n",
      "528\n",
      "719\n",
      "481\n",
      "997\n",
      "407\n",
      "701\n",
      "778\n",
      "869\n",
      "870\n",
      "851\n",
      "402\n",
      "995\n",
      "810\n",
      "997\n",
      "466\n",
      "528\n",
      "790\n",
      "814\n",
      "964\n",
      "625\n",
      "989\n",
      "843\n",
      "939\n",
      "946\n",
      "828\n",
      "725\n",
      "872\n",
      "938\n",
      "869\n",
      "785\n",
      "443\n",
      "854\n",
      "922\n",
      "690\n",
      "522\n",
      "787\n",
      "989\n",
      "413\n",
      "576\n",
      "721\n",
      "816\n",
      "988\n",
      "213\n",
      "844\n",
      "575\n",
      "997\n",
      "713\n",
      "995\n",
      "328\n",
      "872\n",
      "809\n",
      "950\n",
      "675\n",
      "608\n",
      "933\n",
      "880\n",
      "950\n",
      "751\n",
      "944\n",
      "999\n",
      "237\n",
      "863\n",
      "997\n",
      "687\n",
      "26\n",
      "995\n",
      "248\n",
      "102\n",
      "987\n",
      "998\n",
      "215\n",
      "379\n",
      "886\n",
      "727\n",
      "972\n",
      "740\n",
      "998\n",
      "766\n",
      "746\n",
      "995\n",
      "369\n",
      "311\n",
      "863\n",
      "995\n",
      "995\n",
      "264\n",
      "665\n",
      "825\n",
      "654\n",
      "657\n",
      "510\n",
      "996\n",
      "222\n",
      "665\n",
      "614\n",
      "997\n",
      "630\n",
      "547\n",
      "961\n",
      "834\n",
      "729\n",
      "677\n",
      "970\n",
      "718\n",
      "986\n",
      "989\n",
      "781\n",
      "997\n",
      "447\n",
      "966\n",
      "989\n",
      "27\n",
      "994\n",
      "943\n",
      "924\n",
      "990\n",
      "700\n",
      "997\n",
      "442\n",
      "32\n",
      "998\n",
      "456\n",
      "604\n",
      "992\n",
      "294\n",
      "686\n",
      "991\n",
      "292\n",
      "711\n",
      "956\n",
      "225\n",
      "997\n",
      "226\n",
      "916\n",
      "540\n",
      "719\n",
      "542\n",
      "518\n",
      "759\n",
      "355\n",
      "996\n",
      "998\n",
      "604\n",
      "660\n",
      "998\n",
      "232\n",
      "26\n",
      "990\n",
      "990\n",
      "474\n",
      "909\n",
      "727\n",
      "761\n",
      "803\n",
      "949\n",
      "850\n",
      "483\n",
      "931\n",
      "983\n",
      "633\n",
      "923\n",
      "582\n",
      "496\n",
      "682\n",
      "437\n",
      "620\n",
      "950\n",
      "955\n",
      "995\n",
      "712\n",
      "982\n",
      "991\n",
      "597\n",
      "816\n",
      "749\n",
      "431\n",
      "638\n",
      "967\n",
      "880\n",
      "875\n",
      "791\n",
      "845\n",
      "774\n",
      "738\n",
      "352\n",
      "981\n",
      "832\n",
      "751\n",
      "637\n",
      "780\n",
      "847\n",
      "858\n",
      "906\n",
      "746\n",
      "831\n",
      "628\n",
      "897\n",
      "895\n",
      "846\n",
      "777\n",
      "968\n",
      "819\n",
      "961\n",
      "902\n",
      "913\n",
      "706\n",
      "853\n",
      "988\n",
      "749\n",
      "977\n",
      "725\n",
      "903\n",
      "840\n",
      "931\n",
      "691\n",
      "815\n",
      "843\n",
      "695\n",
      "828\n",
      "895\n",
      "736\n",
      "923\n",
      "848\n",
      "551\n",
      "891\n",
      "974\n",
      "946\n",
      "930\n",
      "815\n",
      "977\n",
      "900\n",
      "947\n",
      "834\n",
      "985\n",
      "934\n",
      "903\n",
      "880\n",
      "957\n",
      "944\n",
      "719\n",
      "999\n",
      "944\n",
      "864\n",
      "932\n",
      "833\n",
      "611\n",
      "922\n",
      "990\n",
      "737\n",
      "994\n",
      "863\n",
      "962\n",
      "994\n",
      "842\n",
      "806\n",
      "942\n",
      "886\n",
      "957\n",
      "978\n",
      "800\n",
      "982\n",
      "964\n",
      "852\n",
      "623\n",
      "544\n",
      "825\n",
      "848\n",
      "831\n",
      "914\n",
      "728\n",
      "804\n",
      "997\n",
      "574\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import DashScopeEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "documents = text_splitter.split_documents(docs)\n",
    "\n",
    "print(len(documents))\n",
    "print(\"=\"*200)\n",
    "for doc in documents:\n",
    "    print(len(doc.page_content))\n",
    "\n",
    "db = Chroma.from_documents(documents, DashScopeEmbeddings())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.运行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1运行方法1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}, page_content='The performance of prompt learning relies on whether the PLMs can fill in the correct label word'), Document(metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}, page_content='Few-shot prompt\\nExample 1:\\nDocument: …If you are pregnant, limit caffeine to 200 milligrams each day. This is about the amount in 1½ 8-ou nce cups of coffee or one 12-ounce cup of coffee. Relevant Query: Is a little caffeine ok during pregnancy?\\nExample N:\\nDocument: Passiflora herbertiana. A rare passion fruit native to Australia...\\nRelevant Query: What fruit is native to Australia?\\nExample N +1:\\nDocument: {#Document}\\nRelevant Query:\\nZero-shot prompt\\nWrite a Question answered by the given passage.\\nPassage: {#Passage}\\nQuery:\\nBrainstorm prompt\\nBrainstorm a list of potentially useful text retrieval tasks. Please adhere to the following guidelines: - Specify what the query is, and what the desired documents are.\\n-\\tEach retrieval task should cover a wide range of queries, and should not be too specific.'), Document(metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}, page_content='3.2\\tPrompt Construction\\nThe prompt xprompt, which is constructed based on x, consists of the following three components:\\n(1)\\tTask description xdesc generally describes the task. For different classification tasks, e..g, sentiment classification, topic classification, etc, descriptions are different. Take the sentiment classification task as an example, the task description is given as follows:\\nClassify the overall sentiment of the input as positive or negative\\n(2)\\tDemonstration consists of a sequence of annotated examples:\\n{(xdemo, ydemo), ..., (xdemo, ydemo)}'), Document(metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}, page_content='3.3.1\\tPrompting\\nPrompting in LLMs refers to the technique of providing a specific instruction or context to guide the model’s generation of text. The prompt serves as a conditioning signal and influences the language generation process of the model. Existing prompting strategies can be roughly categorized into three groups: zero-shot prompting, few-shot prompting, and chain-of-thought (CoT) prompting [97].\\n•\\tZero-shot prompting. Zero-shot prompting involves instructing the model to generate texts on a specific topic without any prior exposure to training examples in that domain or topic. The model relies on its pre-existing knowledge and language understanding to generate coherent and\\ncontextually relevant expanded terms for original queries. Experiments show that zero-shot prompting is a simple yet effective method for query rewriter [76, 78, 82, 84, 85, 98].')]\n"
     ]
    }
   ],
   "source": [
    "retriever = db.as_retriever()\n",
    "retrieved_docs = retriever.invoke(\"What is prompt?\")\n",
    "print(retrieved_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================================================================================================\n",
      "page_content='The performance of prompt learning relies on whether the PLMs can fill in the correct label word' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "page_content='Few-shot prompt\n",
      "Example 1:\n",
      "Document: …If you are pregnant, limit caffeine to 200 milligrams each day. This is about the amount in 1½ 8-ou nce cups of coffee or one 12-ounce cup of coffee. Relevant Query: Is a little caffeine ok during pregnancy?\n",
      "Example N:\n",
      "Document: Passiflora herbertiana. A rare passion fruit native to Australia...\n",
      "Relevant Query: What fruit is native to Australia?\n",
      "Example N +1:\n",
      "Document: {#Document}\n",
      "Relevant Query:\n",
      "Zero-shot prompt\n",
      "Write a Question answered by the given passage.\n",
      "Passage: {#Passage}\n",
      "Query:\n",
      "Brainstorm prompt\n",
      "Brainstorm a list of potentially useful text retrieval tasks. Please adhere to the following guidelines: - Specify what the query is, and what the desired documents are.\n",
      "-\tEach retrieval task should cover a wide range of queries, and should not be too specific.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "page_content='3.2\tPrompt Construction\n",
      "The prompt xprompt, which is constructed based on x, consists of the following three components:\n",
      "(1)\tTask description xdesc generally describes the task. For different classification tasks, e..g, sentiment classification, topic classification, etc, descriptions are different. Take the sentiment classification task as an example, the task description is given as follows:\n",
      "Classify the overall sentiment of the input as positive or negative\n",
      "(2)\tDemonstration consists of a sequence of annotated examples:\n",
      "{(xdemo, ydemo), ..., (xdemo, ydemo)}' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "page_content='3.3.1\tPrompting\n",
      "Prompting in LLMs refers to the technique of providing a specific instruction or context to guide the model’s generation of text. The prompt serves as a conditioning signal and influences the language generation process of the model. Existing prompting strategies can be roughly categorized into three groups: zero-shot prompting, few-shot prompting, and chain-of-thought (CoT) prompting [97].\n",
      "•\tZero-shot prompting. Zero-shot prompting involves instructing the model to generate texts on a specific topic without any prior exposure to training examples in that domain or topic. The model relies on its pre-existing knowledge and language understanding to generate coherent and\n",
      "contextually relevant expanded terms for original queries. Experiments show that zero-shot prompting is a simple yet effective method for query rewriter [76, 78, 82, 84, 85, 98].' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n"
     ]
    }
   ],
   "source": [
    "for docs in retrieved_docs:\n",
    "    print(\"=\"*200)\n",
    "    print(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2运行方法2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}, page_content='The performance of prompt learning relies on whether the PLMs can fill in the correct label word'), Document(metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}, page_content='The performance of prompt learning relies on whether the PLMs can fill in the correct label word'), Document(metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}, page_content='Few-shot prompt\\nExample 1:\\nDocument: …If you are pregnant, limit caffeine to 200 milligrams each day. This is about the amount in 1½ 8-ou nce cups of coffee or one 12-ounce cup of coffee. Relevant Query: Is a little caffeine ok during pregnancy?\\nExample N:\\nDocument: Passiflora herbertiana. A rare passion fruit native to Australia...\\nRelevant Query: What fruit is native to Australia?\\nExample N +1:\\nDocument: {#Document}\\nRelevant Query:\\nZero-shot prompt\\nWrite a Question answered by the given passage.\\nPassage: {#Passage}\\nQuery:\\nBrainstorm prompt\\nBrainstorm a list of potentially useful text retrieval tasks. Please adhere to the following guidelines: - Specify what the query is, and what the desired documents are.\\n-\\tEach retrieval task should cover a wide range of queries, and should not be too specific.'), Document(metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}, page_content='Few-shot prompt\\nExample 1:\\nDocument: …If you are pregnant, limit caffeine to 200 milligrams each day. This is about the amount in 1½ 8-ou nce cups of coffee or one 12-ounce cup of coffee. Relevant Query: Is a little caffeine ok during pregnancy?\\nExample N:\\nDocument: Passiflora herbertiana. A rare passion fruit native to Australia...\\nRelevant Query: What fruit is native to Australia?\\nExample N +1:\\nDocument: {#Document}\\nRelevant Query:\\nZero-shot prompt\\nWrite a Question answered by the given passage.\\nPassage: {#Passage}\\nQuery:\\nBrainstorm prompt\\nBrainstorm a list of potentially useful text retrieval tasks. Please adhere to the following guidelines: - Specify what the query is, and what the desired documents are.\\n-\\tEach retrieval task should cover a wide range of queries, and should not be too specific.')]\n"
     ]
    }
   ],
   "source": [
    "query = \"What is prompt?\"\n",
    "retrieved_docs = db.similarity_search(query)\n",
    "print(retrieved_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================================================================================================\n",
      "page_content='The performance of prompt learning relies on whether the PLMs can fill in the correct label word' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "page_content='The performance of prompt learning relies on whether the PLMs can fill in the correct label word' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "page_content='Few-shot prompt\n",
      "Example 1:\n",
      "Document: …If you are pregnant, limit caffeine to 200 milligrams each day. This is about the amount in 1½ 8-ou nce cups of coffee or one 12-ounce cup of coffee. Relevant Query: Is a little caffeine ok during pregnancy?\n",
      "Example N:\n",
      "Document: Passiflora herbertiana. A rare passion fruit native to Australia...\n",
      "Relevant Query: What fruit is native to Australia?\n",
      "Example N +1:\n",
      "Document: {#Document}\n",
      "Relevant Query:\n",
      "Zero-shot prompt\n",
      "Write a Question answered by the given passage.\n",
      "Passage: {#Passage}\n",
      "Query:\n",
      "Brainstorm prompt\n",
      "Brainstorm a list of potentially useful text retrieval tasks. Please adhere to the following guidelines: - Specify what the query is, and what the desired documents are.\n",
      "-\tEach retrieval task should cover a wide range of queries, and should not be too specific.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "page_content='Few-shot prompt\n",
      "Example 1:\n",
      "Document: …If you are pregnant, limit caffeine to 200 milligrams each day. This is about the amount in 1½ 8-ou nce cups of coffee or one 12-ounce cup of coffee. Relevant Query: Is a little caffeine ok during pregnancy?\n",
      "Example N:\n",
      "Document: Passiflora herbertiana. A rare passion fruit native to Australia...\n",
      "Relevant Query: What fruit is native to Australia?\n",
      "Example N +1:\n",
      "Document: {#Document}\n",
      "Relevant Query:\n",
      "Zero-shot prompt\n",
      "Write a Question answered by the given passage.\n",
      "Passage: {#Passage}\n",
      "Query:\n",
      "Brainstorm prompt\n",
      "Brainstorm a list of potentially useful text retrieval tasks. Please adhere to the following guidelines: - Specify what the query is, and what the desired documents are.\n",
      "-\tEach retrieval task should cover a wide range of queries, and should not be too specific.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n"
     ]
    }
   ],
   "source": [
    "for docs in retrieved_docs:\n",
    "    print(\"=\"*200)\n",
    "    print(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 运行方法3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 8397.134765625\n",
      "page_content='The performance of prompt learning relies on whether the PLMs can fill in the correct label word' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 8397.134765625\n",
      "page_content='The performance of prompt learning relies on whether the PLMs can fill in the correct label word' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 9335.20703125\n",
      "page_content='Few-shot prompt\n",
      "Example 1:\n",
      "Document: …If you are pregnant, limit caffeine to 200 milligrams each day. This is about the amount in 1½ 8-ou nce cups of coffee or one 12-ounce cup of coffee. Relevant Query: Is a little caffeine ok during pregnancy?\n",
      "Example N:\n",
      "Document: Passiflora herbertiana. A rare passion fruit native to Australia...\n",
      "Relevant Query: What fruit is native to Australia?\n",
      "Example N +1:\n",
      "Document: {#Document}\n",
      "Relevant Query:\n",
      "Zero-shot prompt\n",
      "Write a Question answered by the given passage.\n",
      "Passage: {#Passage}\n",
      "Query:\n",
      "Brainstorm prompt\n",
      "Brainstorm a list of potentially useful text retrieval tasks. Please adhere to the following guidelines: - Specify what the query is, and what the desired documents are.\n",
      "-\tEach retrieval task should cover a wide range of queries, and should not be too specific.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 9335.20703125\n",
      "page_content='Few-shot prompt\n",
      "Example 1:\n",
      "Document: …If you are pregnant, limit caffeine to 200 milligrams each day. This is about the amount in 1½ 8-ou nce cups of coffee or one 12-ounce cup of coffee. Relevant Query: Is a little caffeine ok during pregnancy?\n",
      "Example N:\n",
      "Document: Passiflora herbertiana. A rare passion fruit native to Australia...\n",
      "Relevant Query: What fruit is native to Australia?\n",
      "Example N +1:\n",
      "Document: {#Document}\n",
      "Relevant Query:\n",
      "Zero-shot prompt\n",
      "Write a Question answered by the given passage.\n",
      "Passage: {#Passage}\n",
      "Query:\n",
      "Brainstorm prompt\n",
      "Brainstorm a list of potentially useful text retrieval tasks. Please adhere to the following guidelines: - Specify what the query is, and what the desired documents are.\n",
      "-\tEach retrieval task should cover a wide range of queries, and should not be too specific.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 9349.6220703125\n",
      "page_content='3.2\tPrompt Construction\n",
      "The prompt xprompt, which is constructed based on x, consists of the following three components:\n",
      "(1)\tTask description xdesc generally describes the task. For different classification tasks, e..g, sentiment classification, topic classification, etc, descriptions are different. Take the sentiment classification task as an example, the task description is given as follows:\n",
      "Classify the overall sentiment of the input as positive or negative\n",
      "(2)\tDemonstration consists of a sequence of annotated examples:\n",
      "{(xdemo, ydemo), ..., (xdemo, ydemo)}' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 9349.6220703125\n",
      "page_content='3.2\tPrompt Construction\n",
      "The prompt xprompt, which is constructed based on x, consists of the following three components:\n",
      "(1)\tTask description xdesc generally describes the task. For different classification tasks, e..g, sentiment classification, topic classification, etc, descriptions are different. Take the sentiment classification task as an example, the task description is given as follows:\n",
      "Classify the overall sentiment of the input as positive or negative\n",
      "(2)\tDemonstration consists of a sequence of annotated examples:\n",
      "{(xdemo, ydemo), ..., (xdemo, ydemo)}' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 10106.099609375\n",
      "page_content='3.3.1\tPrompting\n",
      "Prompting in LLMs refers to the technique of providing a specific instruction or context to guide the model’s generation of text. The prompt serves as a conditioning signal and influences the language generation process of the model. Existing prompting strategies can be roughly categorized into three groups: zero-shot prompting, few-shot prompting, and chain-of-thought (CoT) prompting [97].\n",
      "•\tZero-shot prompting. Zero-shot prompting involves instructing the model to generate texts on a specific topic without any prior exposure to training examples in that domain or topic. The model relies on its pre-existing knowledge and language understanding to generate coherent and\n",
      "contextually relevant expanded terms for original queries. Experiments show that zero-shot prompting is a simple yet effective method for query rewriter [76, 78, 82, 84, 85, 98].' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 10106.099609375\n",
      "page_content='3.3.1\tPrompting\n",
      "Prompting in LLMs refers to the technique of providing a specific instruction or context to guide the model’s generation of text. The prompt serves as a conditioning signal and influences the language generation process of the model. Existing prompting strategies can be roughly categorized into three groups: zero-shot prompting, few-shot prompting, and chain-of-thought (CoT) prompting [97].\n",
      "•\tZero-shot prompting. Zero-shot prompting involves instructing the model to generate texts on a specific topic without any prior exposure to training examples in that domain or topic. The model relies on its pre-existing knowledge and language understanding to generate coherent and\n",
      "contextually relevant expanded terms for original queries. Experiments show that zero-shot prompting is a simple yet effective method for query rewriter [76, 78, 82, 84, 85, 98].' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 10277.49609375\n",
      "page_content='Unlike the above-discussed research works, which used direct prompting, some of the works explored advanced prompting to offer better guidance and context for the GLLM evaluator. Zhuo et al. [470] developed a' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 10277.49609375\n",
      "page_content='Unlike the above-discussed research works, which used direct prompting, some of the works explored advanced prompting to offer better guidance and context for the GLLM evaluator. Zhuo et al. [470] developed a' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 10468.853515625\n",
      "page_content='•\tFew-shot prompting. Few-shot prompting, also known as in-context learning, involves providing the model with a limited set of examples or demonstrations related to the desired task or domain [65, 76, 78, 98]. These examples serve as a form of explicit instruction, allowing the model to adapt its language generation to specific tasks or domains. Query2Doc [65] prompts LLMs to write a document that answers the query with some demo query-document pairs provided by the ranking dataset, such as MSMARCO [99] and NQ [100]. This work experiments with a single prompt. To further study the impact of different prompt designing, recent works [76] have explored eight different prompts, such as prompting LLMs to generate query expansion terms instead of entire pseudo documents and CoT prompting. Some illustrative prompts are shown in Table 2. The experiments validate that Query2Doc is more effective than many other prompt-based methods.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 10468.853515625\n",
      "page_content='•\tFew-shot prompting. Few-shot prompting, also known as in-context learning, involves providing the model with a limited set of examples or demonstrations related to the desired task or domain [65, 76, 78, 98]. These examples serve as a form of explicit instruction, allowing the model to adapt its language generation to specific tasks or domains. Query2Doc [65] prompts LLMs to write a document that answers the query with some demo query-document pairs provided by the ranking dataset, such as MSMARCO [99] and NQ [100]. This work experiments with a single prompt. To further study the impact of different prompt designing, recent works [76] have explored eight different prompts, such as prompting LLMs to generate query expansion terms instead of entire pseudo documents and CoT prompting. Some illustrative prompts are shown in Table 2. The experiments validate that Query2Doc is more effective than many other prompt-based methods.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 10961.2822265625\n",
      "page_content='Instability in Prompt Tuning. Recent work shows that the effectiveness of prompt tuning is' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 10961.2822265625\n",
      "page_content='Instability in Prompt Tuning. Recent work shows that the effectiveness of prompt tuning is' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 11485.47265625\n",
      "page_content='assistant-level prompt is the desired input from the LLM (this is used when fine-tuning to inform the model of the expected output).\n",
      "To create the prompts, we wrote Python code to iterate through the annotated CSV-based dataset and convert each (observation, label) pair into a prompt as shown in Listing 1. The same system-level prompt is used for each input to the model, and describes the task to perform (failure mode classification). We use the user-level prompt to provide the model with the observation that we want it to label. During the fine-tuning of the GPT-3.5 (Fine-tuned), we include an assistant-level prompt that informs the model of the desired output for each observation (i.e. the failure mode). The design behind these prompts were based on the best practices listed in the OpenAI Documentation7.\n",
      "In our experiments we also investigate the necessity to add the following two texts to the system-level prompt:' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Stewart 等 - 2023 - Large Language Models for Failure Mode Classification An Investigation.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 11485.47265625\n",
      "page_content='assistant-level prompt is the desired input from the LLM (this is used when fine-tuning to inform the model of the expected output).\n",
      "To create the prompts, we wrote Python code to iterate through the annotated CSV-based dataset and convert each (observation, label) pair into a prompt as shown in Listing 1. The same system-level prompt is used for each input to the model, and describes the task to perform (failure mode classification). We use the user-level prompt to provide the model with the observation that we want it to label. During the fine-tuning of the GPT-3.5 (Fine-tuned), we include an assistant-level prompt that informs the model of the desired output for each observation (i.e. the failure mode). The design behind these prompts were based on the best practices listed in the OpenAI Documentation7.\n",
      "In our experiments we also investigate the necessity to add the following two texts to the system-level prompt:' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Stewart 等 - 2023 - Large Language Models for Failure Mode Classification An Investigation.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 11491.140625\n",
      "page_content='The latest versions of the GPT-based models require a three-part prompt. The system-level prompt dictates the desired response format of the model. For example, one can use this prompt to ask the model to reply in a sarcastic tone, or to reply with a one-word answer, and so on. The user-level prompt is the input from the user. Finally, the\n",
      "5GPT-4.0 was not available for fine-tuning as of the time of writing, hence the decision to use GPT-3.5.\n",
      "6https://chat.openai.com/\n",
      "Observation\tLLM output\n",
      "runs for a while and trip\tThe failure mode of the observation \"runs for a while and trips\" suggests an electrical failure. This could be due to an overload, short circuit, or other electrical issue that causes the equipment to shut down or trip a circuit breaker.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Stewart 等 - 2023 - Large Language Models for Failure Mode Classification An Investigation.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 11491.140625\n",
      "page_content='The latest versions of the GPT-based models require a three-part prompt. The system-level prompt dictates the desired response format of the model. For example, one can use this prompt to ask the model to reply in a sarcastic tone, or to reply with a one-word answer, and so on. The user-level prompt is the input from the user. Finally, the\n",
      "5GPT-4.0 was not available for fine-tuning as of the time of writing, hence the decision to use GPT-3.5.\n",
      "6https://chat.openai.com/\n",
      "Observation\tLLM output\n",
      "runs for a while and trip\tThe failure mode of the observation \"runs for a while and trips\" suggests an electrical failure. This could be due to an overload, short circuit, or other electrical issue that causes the equipment to shut down or trip a circuit breaker.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Stewart 等 - 2023 - Large Language Models for Failure Mode Classification An Investigation.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 11851.208984375\n",
      "page_content='Although effective, these methods primarily rely on a handcrafted prompt (e.g., “Please write a query based on this document”), which may not be optimal. Previous study [155] has shown that prompt has a significant impact on the performance of LLM reranker. Thus, how to design appropriate prompts for ranking task is an important problem. Along this line, a discrete prompt optimization method Co-Prompt [156] is proposed for better prompt generation in reranking tasks. Besides, PaRaDe [158] proposes a difficulty-based method to select the most difficult k incontext demonstrations to include in the prompt, proving improvements compared with zero-shot performance. Nevertheless, the experiments in the paper indicate that such difficulty-based selection does not even show a significant advantage compared to random selection, showing that the demonstration selection in ranking task is a very challenging problem. The main challenge lies in the complex nature of query-document relationship,' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 11851.208984375\n",
      "page_content='Although effective, these methods primarily rely on a handcrafted prompt (e.g., “Please write a query based on this document”), which may not be optimal. Previous study [155] has shown that prompt has a significant impact on the performance of LLM reranker. Thus, how to design appropriate prompts for ranking task is an important problem. Along this line, a discrete prompt optimization method Co-Prompt [156] is proposed for better prompt generation in reranking tasks. Besides, PaRaDe [158] proposes a difficulty-based method to select the most difficult k incontext demonstrations to include in the prompt, proving improvements compared with zero-shot performance. Nevertheless, the experiments in the paper indicate that such difficulty-based selection does not even show a significant advantage compared to random selection, showing that the demonstration selection in ranking task is a very challenging problem. The main challenge lies in the complex nature of query-document relationship,' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 11894.404296875\n",
      "page_content='direct prompting, advanced prompting strategies help the model to achieve better results. This is because advanced prompting involves generating intermediate outputs, which in turn guide the model in generating the correct final output. Zhang et al. [125] explored the ChatGPT model with direct and chain-of-thought prompting for stance detection in tweets in zero and few-shot settings. Experiment results on three datasets showed that one-shot chain of thought prompting outperforms zero-shot direct prompting and also achieves near state-of-the-art results. Yang et al. [127] designed emotion-enhanced CoT prompting to combine emotion information with the power of CoT prompting for mental health analysis tasks. Experiments on five different mental health analysis tasks showed that ChatGPT with emotion-enhanced CoT outperforms other prompting strategies. Overall, ChatGPT outperforms traditional deep learning models like CNN and RNN but still lags behind task-specific fine-tuned models. Wu' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 11894.404296875\n",
      "page_content='direct prompting, advanced prompting strategies help the model to achieve better results. This is because advanced prompting involves generating intermediate outputs, which in turn guide the model in generating the correct final output. Zhang et al. [125] explored the ChatGPT model with direct and chain-of-thought prompting for stance detection in tweets in zero and few-shot settings. Experiment results on three datasets showed that one-shot chain of thought prompting outperforms zero-shot direct prompting and also achieves near state-of-the-art results. Yang et al. [127] designed emotion-enhanced CoT prompting to combine emotion information with the power of CoT prompting for mental health analysis tasks. Experiments on five different mental health analysis tasks showed that ChatGPT with emotion-enhanced CoT outperforms other prompting strategies. Overall, ChatGPT outperforms traditional deep learning models like CNN and RNN but still lags behind task-specific fine-tuned models. Wu' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 11930.5888671875\n",
      "page_content='6.\tConclusion\n",
      "In this paper, we first show that model bias on label words can impact the performance of prompt learning and that different templates lead to instability in prompt learning by affecting the model bias. Then, we propose a data annotation and filtering method that incorporates model bias in true zeroshot settings. Finally, we use unlabeled data to select the least biased model during training. The experiments demonstrate that our approach can calibrate model bias on label words and thus can improve the accuracy of text classification tasks. In the future, we intend to incorporate continuous prompts and multi-verbalizers into our approach to further reduce the impact of model bias on prompt learning.\n",
      "Acknowledgment\n",
      "This work was supported in part by the National Key R&D Program of China under Grant 2023YFF0905503, National Natural Science Foundation of China under Grants No.62072203, and Malaysia MOHE FRGS Funding No. FRGS2023-1.\n",
      "7.\tBibliographical References' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 11930.5888671875\n",
      "page_content='6.\tConclusion\n",
      "In this paper, we first show that model bias on label words can impact the performance of prompt learning and that different templates lead to instability in prompt learning by affecting the model bias. Then, we propose a data annotation and filtering method that incorporates model bias in true zeroshot settings. Finally, we use unlabeled data to select the least biased model during training. The experiments demonstrate that our approach can calibrate model bias on label words and thus can improve the accuracy of text classification tasks. In the future, we intend to incorporate continuous prompts and multi-verbalizers into our approach to further reduce the impact of model bias on prompt learning.\n",
      "Acknowledgment\n",
      "This work was supported in part by the National Key R&D Program of China under Grant 2023YFF0905503, National Natural Science Foundation of China under Grants No.62072203, and Malaysia MOHE FRGS Funding No. FRGS2023-1.\n",
      "7.\tBibliographical References' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 12156.921875\n",
      "page_content='(Brown et al., 2020) and PET (Schick and Schütze, 2021a), prompt tuning has shown effectiveness in low-resource scenarios by incorporating human prior knowledge into the PLM’s input. Prompt tuning does not need to introduce additional parameters compared to fine-tuning because it transforms the downstream task into masked language modeling, a common task in pre-training. Thus, prompt tuning utilizes the knowledge stored in PLMs in a more direct manner, which is beneficial when sufficient training data are unavailable to provide additional knowledge.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 12156.921875\n",
      "page_content='(Brown et al., 2020) and PET (Schick and Schütze, 2021a), prompt tuning has shown effectiveness in low-resource scenarios by incorporating human prior knowledge into the PLM’s input. Prompt tuning does not need to introduce additional parameters compared to fine-tuning because it transforms the downstream task into masked language modeling, a common task in pre-training. Thus, prompt tuning utilizes the knowledge stored in PLMs in a more direct manner, which is beneficial when sufficient training data are unavailable to provide additional knowledge.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 12332.92578125\n",
      "page_content='Li and Liang (2021); Zhong et al. (2021); Qin and Eisner (2021) propose to optimize prompts in the continuous space. Rubin et al. (2021); Das et al. (2021); Liu et al. (2021); Su et al. (2022) introduce different strategies for selecting in-context examples. Lampinen et al. (2022) show that explanations of examples in a few-shot prompt lead to a performance boost. Marasovic´ et al. (2021) find that GPT-3 outperforms other models by a large margin in the explanation generation task. Wei et al. (2022b) propose chain-of-thought reasoning and utilized <input, chain-of-thought, output> triples as the prompt for LLMs. Wiegreffe et al. (2021) traine a supervised filter to select explanations generated by GPT-3 on the SNLI and CommonsenseQA tasks.\n",
      "2.3\tText Classification' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 12332.92578125\n",
      "page_content='Li and Liang (2021); Zhong et al. (2021); Qin and Eisner (2021) propose to optimize prompts in the continuous space. Rubin et al. (2021); Das et al. (2021); Liu et al. (2021); Su et al. (2022) introduce different strategies for selecting in-context examples. Lampinen et al. (2022) show that explanations of examples in a few-shot prompt lead to a performance boost. Marasovic´ et al. (2021) find that GPT-3 outperforms other models by a large margin in the explanation generation task. Wei et al. (2022b) propose chain-of-thought reasoning and utilized <input, chain-of-thought, output> triples as the prompt for LLMs. Wiegreffe et al. (2021) traine a supervised filter to select explanations generated by GPT-3 on the SNLI and CommonsenseQA tasks.\n",
      "2.3\tText Classification' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 12533.8427734375\n",
      "page_content='Prompt Learning. GPT-3 (Brown et al., 2020) demonstrates that large-scale PLMs can perform well in low-data scenarios by in-context learning. Specifically, instead of tuning any parameters, incontext learning concatenates the task description, a few demonstration examples and the original task input as a prompt to guide GPT-3 to predict the next word. To apply prompts on models smaller than GPT-3, such as BERT (Devlin et al., 2019) and RoBERTa (Liu et al., 2019), PET (Schick and Schütze, 2021a) converts input examples into cloze questions and finetunes the model on these reformulated examples. However, manually designing good templates is laborious and requires domain knowledge. To reduce human labor in template engineering, Shin et al. (2020) proposes AUTOPROMPT to create templates automatically based on a gradient-guided search. Gao et al. (2021) proposes LM-BFF, which leverages T5 to automate the search process of templates. Searching templates over the entire vocabulary is' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 12533.8427734375\n",
      "page_content='Prompt Learning. GPT-3 (Brown et al., 2020) demonstrates that large-scale PLMs can perform well in low-data scenarios by in-context learning. Specifically, instead of tuning any parameters, incontext learning concatenates the task description, a few demonstration examples and the original task input as a prompt to guide GPT-3 to predict the next word. To apply prompts on models smaller than GPT-3, such as BERT (Devlin et al., 2019) and RoBERTa (Liu et al., 2019), PET (Schick and Schütze, 2021a) converts input examples into cloze questions and finetunes the model on these reformulated examples. However, manually designing good templates is laborious and requires domain knowledge. To reduce human labor in template engineering, Shin et al. (2020) proposes AUTOPROMPT to create templates automatically based on a gradient-guided search. Gao et al. (2021) proposes LM-BFF, which leverages T5 to automate the search process of templates. Searching templates over the entire vocabulary is' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 12573.1103515625\n",
      "page_content='LLM + Corpora\tPrompting\tK\tGRF+PRF [82]\n",
      "\tLLM + Corpora\tPrompting\tA\tGRM [83]\n",
      "\tLLM + Corpora\tPrompting\tA\tInteR [84]\n",
      "\tLLM + Corpora\tPrompting\tA\tLameR [85]\n",
      "\tLLM + Corpora\tPrompting\tA\tCSQE [86]\n",
      "\tLLM + Corpora\tPrompting\tQ\tCAR [87]\n",
      "\tLLM + Corpora\tSFT & RL\tQ\tRaFe [88]\n",
      "C onvpr-onver\tLLM\tPrompting\tQ\tLLMCS [89]\n",
      "sational\tLLM\tPrompting\tQ\tCONVERSER [90]\n",
      "\tLLM\tPrompting\tQ\tYe et al. [91]\n",
      "versational search. Ad-hoc retrieval aims to bridge the semantic gap between a user ’s query and the potential documents. LLMs, with their extensive inherent knowledge, have proven effective in replacing traditional lexical knowledge databases [67–71].' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 12573.1103515625\n",
      "page_content='LLM + Corpora\tPrompting\tK\tGRF+PRF [82]\n",
      "\tLLM + Corpora\tPrompting\tA\tGRM [83]\n",
      "\tLLM + Corpora\tPrompting\tA\tInteR [84]\n",
      "\tLLM + Corpora\tPrompting\tA\tLameR [85]\n",
      "\tLLM + Corpora\tPrompting\tA\tCSQE [86]\n",
      "\tLLM + Corpora\tPrompting\tQ\tCAR [87]\n",
      "\tLLM + Corpora\tSFT & RL\tQ\tRaFe [88]\n",
      "C onvpr-onver\tLLM\tPrompting\tQ\tLLMCS [89]\n",
      "sational\tLLM\tPrompting\tQ\tCONVERSER [90]\n",
      "\tLLM\tPrompting\tQ\tYe et al. [91]\n",
      "versational search. Ad-hoc retrieval aims to bridge the semantic gap between a user ’s query and the potential documents. LLMs, with their extensive inherent knowledge, have proven effective in replacing traditional lexical knowledge databases [67–71].' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 12675.525390625\n",
      "page_content='In light of this, we next add the phrase “Your answer should contain only the failure mode and nothing else.” to the system-level prompt. Adding this sentence to the prompt results in the model predicting a single failure mode for each observation, as shown in Table 2. However, there are several notable issues with the outputs of the model after adding this phrase. Firstly, despite the addition of the phrase in the prompt, the model still occasionally adds additional text to its response. One such example is its response for the phrase “failed electrical”, to which it also adds “Failure mode: ” prior to the actual classification. It also occasionally disregards the instruction when it was not capable of recognising a particular failure mode, for example in its classification of “high earth reading”.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Stewart 等 - 2023 - Large Language Models for Failure Mode Classification An Investigation.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 12675.525390625\n",
      "page_content='In light of this, we next add the phrase “Your answer should contain only the failure mode and nothing else.” to the system-level prompt. Adding this sentence to the prompt results in the model predicting a single failure mode for each observation, as shown in Table 2. However, there are several notable issues with the outputs of the model after adding this phrase. Firstly, despite the addition of the phrase in the prompt, the model still occasionally adds additional text to its response. One such example is its response for the phrase “failed electrical”, to which it also adds “Failure mode: ” prior to the actual classification. It also occasionally disregards the instruction when it was not capable of recognising a particular failure mode, for example in its classification of “high earth reading”.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Stewart 等 - 2023 - Large Language Models for Failure Mode Classification An Investigation.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 12717.994140625\n",
      "page_content='Recently, in-context learning has achieved success and changes the paradigm in the text classification task. Schick and Schütze (2020) reformulate input examples into cloze-style phrases and annotate the unlabeled text. Han et al. (2021) design sub-prompts and applied logic rules to compose sub-prompts into final prompts. Liu et al. (2021) retrieve semantically-similar examples to a test sample to formulate its corresponding prompt. Shi et al. (2022) retrieve label-words-similar examples as demonstrations in prompts.\n",
      "3\tPrompt Construction\n",
      "3.1\tOverview\n",
      "We follow the standard prompt-based in-context learning paradigm. Given an input sequence xinput = {xi ,X2, ...,xi}, the task of assigning a text-class label to an input text is transformed to generating a pre-defined textual response y G yverb (e.g., positive, negative, etc) conditioning on the prompt xprompt using a language model.\n",
      "3.2\tPrompt Construction' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 12717.994140625\n",
      "page_content='Recently, in-context learning has achieved success and changes the paradigm in the text classification task. Schick and Schütze (2020) reformulate input examples into cloze-style phrases and annotate the unlabeled text. Han et al. (2021) design sub-prompts and applied logic rules to compose sub-prompts into final prompts. Liu et al. (2021) retrieve semantically-similar examples to a test sample to formulate its corresponding prompt. Shi et al. (2022) retrieve label-words-similar examples as demonstrations in prompts.\n",
      "3\tPrompt Construction\n",
      "3.1\tOverview\n",
      "We follow the standard prompt-based in-context learning paradigm. Given an input sequence xinput = {xi ,X2, ...,xi}, the task of assigning a text-class label to an input text is transformed to generating a pre-defined textual response y G yverb (e.g., positive, negative, etc) conditioning on the prompt xprompt using a language model.\n",
      "3.2\tPrompt Construction' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 12838.94140625\n",
      "page_content='on the question. Robinson et al. [192] proposed a new prompting strategy called multiple choice prompt which prompts the model with question and answer options so that the model generates the answer by conditioning on both question and answer options. Evaluation on 20 datasets showed that multiple-choice prompt helps GLLMs to achieve near SOTA results.\n",
      "Some of the research works explored the effectiveness of GLLMs in answering exam questions from various domains. Nunes et al. [177] investigated the performances of GLLMs like GPT-3.5, ChatGPT and GPT-4 in answering questions from the Brazilian university admission exam. Here all the questions are in Brazilian Portuguese language. The authors explored different prompting strategies like vanilla (zero-shot and fewshot) and CoT (few-shot). The authors observed that GPT-4 outperforms all other models by a large margin' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 12838.94140625\n",
      "page_content='on the question. Robinson et al. [192] proposed a new prompting strategy called multiple choice prompt which prompts the model with question and answer options so that the model generates the answer by conditioning on both question and answer options. Evaluation on 20 datasets showed that multiple-choice prompt helps GLLMs to achieve near SOTA results.\n",
      "Some of the research works explored the effectiveness of GLLMs in answering exam questions from various domains. Nunes et al. [177] investigated the performances of GLLMs like GPT-3.5, ChatGPT and GPT-4 in answering questions from the Brazilian university admission exam. Here all the questions are in Brazilian Portuguese language. The authors explored different prompting strategies like vanilla (zero-shot and fewshot) and CoT (few-shot). The authors observed that GPT-4 outperforms all other models by a large margin' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 13165.5625\n",
      "page_content='2.3\tData preparation\n",
      "[{\n",
      "\"role \" : \" system\" ,\n",
      "\" content \": \" Det ermine the failure mode of the observat ion provided by the user . \"\n",
      "},\n",
      "{\n",
      "\"role \" : \"user\" ,\n",
      "\" content \": \" too hot \"\n",
      "},\n",
      "{\n",
      "\"role \" : \" assistant \" ,\n",
      "\" content \": \" Overheat ing \"\n",
      "}]\n",
      "Listing 1: An example prompt that is fed into the GPT-3.5 and GPT-3.5 (Fine-tuned) models. The role of the assistant is only used during fine-tuning.\n",
      "The default behaviour of the GPT-based models is to act as a chatbot, and thus it will not respond with a failure mode code for a given observation unless the instruction to do so is included as part of the prompt. Structuring an input prompt to elicit a particular response from a large language model is known as prompt engineering.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Stewart 等 - 2023 - Large Language Models for Failure Mode Classification An Investigation.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 13165.5625\n",
      "page_content='2.3\tData preparation\n",
      "[{\n",
      "\"role \" : \" system\" ,\n",
      "\" content \": \" Det ermine the failure mode of the observat ion provided by the user . \"\n",
      "},\n",
      "{\n",
      "\"role \" : \"user\" ,\n",
      "\" content \": \" too hot \"\n",
      "},\n",
      "{\n",
      "\"role \" : \" assistant \" ,\n",
      "\" content \": \" Overheat ing \"\n",
      "}]\n",
      "Listing 1: An example prompt that is fed into the GPT-3.5 and GPT-3.5 (Fine-tuned) models. The role of the assistant is only used during fine-tuning.\n",
      "The default behaviour of the GPT-based models is to act as a chatbot, and thus it will not respond with a failure mode code for a given observation unless the instruction to do so is included as part of the prompt. Structuring an input prompt to elicit a particular response from a large language model is known as prompt engineering.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Stewart 等 - 2023 - Large Language Models for Failure Mode Classification An Investigation.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 13314.5498046875\n",
      "page_content='3LLMs often generate long responses, in order to ensemble more demonstrations in prompts, we use \"limit to 50 words\". After conducting an analysis of the generated responses, we find that LLMs can explain the reason within limited words.\n",
      "INPUT & GOLD LABEL\tCLUES\tREASONING' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 13314.5498046875\n",
      "page_content='3LLMs often generate long responses, in order to ensemble more demonstrations in prompts, we use \"limit to 50 words\". After conducting an analysis of the generated responses, we find that LLMs can explain the reason within limited words.\n",
      "INPUT & GOLD LABEL\tCLUES\tREASONING' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 13383.095703125\n",
      "page_content='resources. To overcome this obstacle, SPTAR [109] introduces a soft prompt tuning technique that only optimizes the prompts’ embedding layer during the training process. This approach allows LLMs to better adapt to the task of generating pseudo-queries, striking a favorable balance between training cost and generation quality.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 13383.095703125\n",
      "page_content='resources. To overcome this obstacle, SPTAR [109] introduces a soft prompt tuning technique that only optimizes the prompts’ embedding layer during the training process. This approach allows LLMs to better adapt to the task of generating pseudo-queries, striking a favorable balance between training cost and generation quality.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 13585.24609375\n",
      "page_content='in contrast to list annotated (text, label) pairs in few-shot setups, incorporating clues and reasoning process in prompts aligns closer with the instruction tuning objective. The discrepancy between LLMs training objectives and in-context learning for downstream tasks has been reduced.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 13585.24609375\n",
      "page_content='in contrast to list annotated (text, label) pairs in few-shot setups, incorporating clues and reasoning process in prompts aligns closer with the instruction tuning objective. The discrepancy between LLMs training objectives and in-context learning for downstream tasks has been reduced.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 13803.361328125\n",
      "page_content='leads to a large number of examples with the true label “politics” being incorrectly predicted as “business” (numbers underlined in Table 1(a)). Furthermore, we repeat the experiment by using another manual template. The results are shown in Figure 1(b) and Table 1(b). Surprisingly, manual template replacement greatly influences model bias on label words, which explains the dramatic performance fluctuation when changing templates in prompt tuning.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 13803.361328125\n",
      "page_content='leads to a large number of examples with the true label “politics” being incorrectly predicted as “business” (numbers underlined in Table 1(a)). Furthermore, we repeat the experiment by using another manual template. The results are shown in Figure 1(b) and Table 1(b). Surprisingly, manual template replacement greatly influences model bias on label words, which explains the dramatic performance fluctuation when changing templates in prompt tuning.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 13823.1396484375\n",
      "page_content='6.1.3\tAperiodic-Retrieval Reader' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 13823.1396484375\n",
      "page_content='6.1.3\tAperiodic-Retrieval Reader' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 13849.005859375\n",
      "page_content='solves the downstream tasks by using knowledge encoded in the model parameters [45]. In-context learning accepts prompts as input where the input prompt consists of task descriptions, optimally few examples and other instructions.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 13849.005859375\n",
      "page_content='solves the downstream tasks by using knowledge encoded in the model parameters [45]. In-context learning accepts prompts as input where the input prompt consists of task descriptions, optimally few examples and other instructions.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 13924.18359375\n",
      "page_content='highly volatile, ranging from random guesses to near state-of-the-art depending on the prompt format. LAMA (Petroni et al., 2019) uses different templates to query the same information in the language models, demonstrating that the choice of templates has an impact on query accuracy. Jiang et al. (2020) reduces the instability by automatically generating diverse templates and assembling predictions when the language model uses different templates. Liu et al. (2021) shows that changing a single word in templates can drastically impact the results of prompt tuning. In prior experiments, we provide insight into how the prompt format impacts performance by influencing model bias on certain words. In addition to the template format, the choice of training data also causes instability in low-data scenarios. Schick and Schütze (2021b) finds that using different random seeds to select training data can result in significant performance fluctuations. Gao et al. (2021) incorporates training' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 13924.18359375\n",
      "page_content='highly volatile, ranging from random guesses to near state-of-the-art depending on the prompt format. LAMA (Petroni et al., 2019) uses different templates to query the same information in the language models, demonstrating that the choice of templates has an impact on query accuracy. Jiang et al. (2020) reduces the instability by automatically generating diverse templates and assembling predictions when the language model uses different templates. Liu et al. (2021) shows that changing a single word in templates can drastically impact the results of prompt tuning. In prior experiments, we provide insight into how the prompt format impacts performance by influencing model bias on certain words. In addition to the template format, the choice of training data also causes instability in low-data scenarios. Schick and Schütze (2021b) finds that using different random seeds to select training data can result in significant performance fluctuations. Gao et al. (2021) incorporates training' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 13977.673828125\n",
      "page_content='6.1.1\tOnce-Retrieval Reader' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 13977.673828125\n",
      "page_content='6.1.1\tOnce-Retrieval Reader' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 14026.365234375\n",
      "page_content='•\tpump runs for a while and trip\n",
      "•\tengin does not work\n",
      "•\tpmp spraying out slurry\n",
      "•\tseal leaking\n",
      "•\tleak in seal' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Stewart 等 - 2023 - Large Language Models for Failure Mode Classification An Investigation.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 14026.365234375\n",
      "page_content='•\tpump runs for a while and trip\n",
      "•\tengin does not work\n",
      "•\tpmp spraying out slurry\n",
      "•\tseal leaking\n",
      "•\tleak in seal' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Stewart 等 - 2023 - Large Language Models for Failure Mode Classification An Investigation.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 14038.603515625\n",
      "page_content='SENTIMENT: Negative\n",
      "(c)\n",
      "Figure 2: Examples of few-shot (k=1) prompting methods for the text classification task: (a) represents for the vanilla prompting method; (b) denotes for the Chain-of-Thought (CoT) (Kojima et al., 2022) prompting method; (c) represents for the proposed CARP prompting method.\n",
      "LLMs can be broadly divided into three categories based on the model architecture. The first category is the encoder-only model like BERT (Devlin et al., 2018). BERT (300M) (Devlin et al., 2018) and its variants (Liu et al., 2019; Sun et al., 2020; Clark et al., 2020; Feng et al., 2020; Sun et al., 2021) adopt the pre-training then fine-tuning paradigm for NLP tasks: use masked language models as the main training objective for pretraining, and fine-tune the pretrained model in the annotated downstream datasets.\n",
      "The second category is the decoder-only models like GPT (Radford et al., 2019a). GPT (Radford et al., 2019a) uses the decoder of an autoregressive transformer (Vaswani et al., 2017)' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 14038.603515625\n",
      "page_content='SENTIMENT: Negative\n",
      "(c)\n",
      "Figure 2: Examples of few-shot (k=1) prompting methods for the text classification task: (a) represents for the vanilla prompting method; (b) denotes for the Chain-of-Thought (CoT) (Kojima et al., 2022) prompting method; (c) represents for the proposed CARP prompting method.\n",
      "LLMs can be broadly divided into three categories based on the model architecture. The first category is the encoder-only model like BERT (Devlin et al., 2018). BERT (300M) (Devlin et al., 2018) and its variants (Liu et al., 2019; Sun et al., 2020; Clark et al., 2020; Feng et al., 2020; Sun et al., 2021) adopt the pre-training then fine-tuning paradigm for NLP tasks: use masked language models as the main training objective for pretraining, and fine-tune the pretrained model in the annotated downstream datasets.\n",
      "The second category is the decoder-only models like GPT (Radford et al., 2019a). GPT (Radford et al., 2019a) uses the decoder of an autoregressive transformer (Vaswani et al., 2017)' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 14098.4482421875\n",
      "page_content='Ge (p) ^ (s, Q)\n",
      "where s represents the rewritten question and Q = {q1,q2, ••• ,q|Q|} is the set of generated queries. A basic implementation of Ge(•) can adopt a prompt-based strategy, utilizing task descriptions, the original question, and exemplars to prompt black-box large language models. This approach capitalizes on the model’s in-context learning capabilities, often yields effectiveness of question rewriting and query generation. Nevertheless, the effectiveness of this methodology is highly dependent on the meticulous construction of prompts tailored to specific domain datasets, which limits its general utility. Besides, the generated s and Q may be of low quality, failing to enhance RAG performance.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 14098.4482421875\n",
      "page_content='Ge (p) ^ (s, Q)\n",
      "where s represents the rewritten question and Q = {q1,q2, ••• ,q|Q|} is the set of generated queries. A basic implementation of Ge(•) can adopt a prompt-based strategy, utilizing task descriptions, the original question, and exemplars to prompt black-box large language models. This approach capitalizes on the model’s in-context learning capabilities, often yields effectiveness of question rewriting and query generation. Nevertheless, the effectiveness of this methodology is highly dependent on the meticulous construction of prompts tailored to specific domain datasets, which limits its general utility. Besides, the generated s and Q may be of low quality, failing to enhance RAG performance.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 14199.5654296875\n",
      "page_content='which the storytelling prompting approach achieves the best results and improves the BLUE score by 0.68. Here, the storytelling prompting approach involves generating a three-sentence story based on the source sentence and then translating each of these sentences into the target language. Abaskohi et al. [394] proposed a novel approach based on prompt-based tuning and contrastive learning to fine-tune pretrained language models for text classification. As contrastive learning requires data augmentation, the authors explored models like GPT-3 and OPT-175B [39] for paraphrasing. Experiment results showed that GPT-3 based paraphrasing outperforms existing data augmentation approaches like back translation [427] and easy data augmentation [405].' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 14199.5654296875\n",
      "page_content='which the storytelling prompting approach achieves the best results and improves the BLUE score by 0.68. Here, the storytelling prompting approach involves generating a three-sentence story based on the source sentence and then translating each of these sentences into the target language. Abaskohi et al. [394] proposed a novel approach based on prompt-based tuning and contrastive learning to fine-tune pretrained language models for text classification. As contrastive learning requires data augmentation, the authors explored models like GPT-3 and OPT-175B [39] for paraphrasing. Experiment results showed that GPT-3 based paraphrasing outperforms existing data augmentation approaches like back translation [427] and easy data augmentation [405].' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 14208.537109375\n",
      "page_content='of prompting LLMs for answer generation solely based on the probabilities of generating terms, avoiding the need for finetuning while still maintaining effectiveness. Besides, selfRAG [193] tends to solve this problem by training LLMs such as LlaMA to generate specific tokens when they need additional knowledge to support following generations. Another critical model is introduced to judge whether the retrieved references are beneficial for generating.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 14208.537109375\n",
      "page_content='of prompting LLMs for answer generation solely based on the probabilities of generating terms, avoiding the need for finetuning while still maintaining effectiveness. Besides, selfRAG [193] tends to solve this problem by training LLMs such as LlaMA to generate specific tokens when they need additional knowledge to support following generations. Another critical model is introduced to judge whether the retrieved references are beneficial for generating.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 14255.078125\n",
      "page_content='Keywords: Model Bias, Prompt Learning, Text Classification, Zero-Shot Learning\n",
      "1.\tIntroduction' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 14255.078125\n",
      "page_content='Keywords: Model Bias, Prompt Learning, Text Classification, Zero-Shot Learning\n",
      "1.\tIntroduction' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 14378.6875\n",
      "page_content='1. https://alexa.amazon.com\n",
      "2. https://assistant.google.com\n",
      "3. https://www.apple.com/in/siri/\n",
      "by day because of the ability to generate answers which are accurate, relevant and short.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 14378.6875\n",
      "page_content='1. https://alexa.amazon.com\n",
      "2. https://assistant.google.com\n",
      "3. https://www.apple.com/in/siri/\n",
      "by day because of the ability to generate answers which are accurate, relevant and short.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 14524.8349609375\n",
      "page_content='In summary we have demonstrated that it is possible to engineer the prompt to enable the LLM to predict failure mode codes without any fine-tuning. However, these outputs are not grounded in any particular ontology and are inconsistent.\n",
      "3.2\tIs it necessary to fine-tune the LLM to perform Failure Mode Classification?' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Stewart 等 - 2023 - Large Language Models for Failure Mode Classification An Investigation.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 14524.8349609375\n",
      "page_content='In summary we have demonstrated that it is possible to engineer the prompt to enable the LLM to predict failure mode codes without any fine-tuning. However, these outputs are not grounded in any particular ontology and are inconsistent.\n",
      "3.2\tIs it necessary to fine-tune the LLM to perform Failure Mode Classification?' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Stewart 等 - 2023 - Large Language Models for Failure Mode Classification An Investigation.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 14527.548828125\n",
      "page_content='In this paper, we introduce Clue And Reasoning Prompting (CARP). CARP adopts a progressive reasoning strategy tailored to addressing the complex linguistic phenomena involved in text classification: CARP first prompts LLMs to find superficial clues (e.g., keywords, tones, semantic relations, references, etc), based on which a diagnostic reasoning process is induced for final decisions. To further address the limited-token issue, CARP uses a fine-tuned model on the supervised dataset for kNN demonstration search in the in-context learning, allowing the model to take the advantage of both LLM’s generalization ability and the task-specific evidence provided by the full labeled dataset.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 14527.548828125\n",
      "page_content='In this paper, we introduce Clue And Reasoning Prompting (CARP). CARP adopts a progressive reasoning strategy tailored to addressing the complex linguistic phenomena involved in text classification: CARP first prompts LLMs to find superficial clues (e.g., keywords, tones, semantic relations, references, etc), based on which a diagnostic reasoning process is induced for final decisions. To further address the limited-token issue, CARP uses a fine-tuned model on the supervised dataset for kNN demonstration search in the in-context learning, allowing the model to take the advantage of both LLM’s generalization ability and the task-specific evidence provided by the full labeled dataset.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 14540.623046875\n",
      "page_content='4.2\tCollecting clues and reasoning in zero-shot\n",
      "In the zero-shot setup, as no demonstration is allowed, no concrete example for clues and reasons can be provided. In this way, we only add requests asking the model to output clues and reasons in the prompt. The prompt is given as follows:\n",
      "This is an overall sentiment classifier for opinion snippets.\n",
      "First, list CLUES (i.e., keywords, phrases, contextual information, semantic relations, semantic meaning, tones, references) for determining the overall sentiment of the input. Next, deduce a diagnostic reasoning process from clues and the input to determine the overall sentiment.\n",
      "Finally, determine the sentiment of input as Positive or Negative considering clues, the reasoning process and the input.\n",
      "INPUT: <text>\n",
      "CLUES:\n",
      "4.2.1\tClue Collecting and Reasoning in few-shot' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 14540.623046875\n",
      "page_content='4.2\tCollecting clues and reasoning in zero-shot\n",
      "In the zero-shot setup, as no demonstration is allowed, no concrete example for clues and reasons can be provided. In this way, we only add requests asking the model to output clues and reasons in the prompt. The prompt is given as follows:\n",
      "This is an overall sentiment classifier for opinion snippets.\n",
      "First, list CLUES (i.e., keywords, phrases, contextual information, semantic relations, semantic meaning, tones, references) for determining the overall sentiment of the input. Next, deduce a diagnostic reasoning process from clues and the input to determine the overall sentiment.\n",
      "Finally, determine the sentiment of input as Positive or Negative considering clues, the reasoning process and the input.\n",
      "INPUT: <text>\n",
      "CLUES:\n",
      "4.2.1\tClue Collecting and Reasoning in few-shot' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 14543.857421875\n",
      "page_content='•\tChain-of-thought prompting. CoT prompting [97] is a strategy that involves iterative prompting, where the model is provided with a sequence of instructions or partial outputs [76, 78]. In conversational search, the process of query rewriting is multi-turn, which means queries should be refined step-by-step with the interaction between search engines and users. This process naturally coincides with the CoT process. As shown in Figure 3, users can conduct the CoT process by adding some instructions during each turn, such as “Based on all previous turns, xxx”. While in ad-hoc search, there is only one round in query rewriting, so CoT could only be accomplished in a simple and coarse way. For example, as shown in Table 2, researchers add “Give the rationale before answering” in the instructions to prompt LLMs to think deeply [76].\n",
      "3.3.2\tSupervised Fine-tuning' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 14543.857421875\n",
      "page_content='•\tChain-of-thought prompting. CoT prompting [97] is a strategy that involves iterative prompting, where the model is provided with a sequence of instructions or partial outputs [76, 78]. In conversational search, the process of query rewriting is multi-turn, which means queries should be refined step-by-step with the interaction between search engines and users. This process naturally coincides with the CoT process. As shown in Figure 3, users can conduct the CoT process by adding some instructions during each turn, such as “Based on all previous turns, xxx”. While in ad-hoc search, there is only one round in query rewriting, so CoT could only be accomplished in a simple and coarse way. For example, as shown in Table 2, researchers add “Give the rationale before answering” in the instructions to prompt LLMs to think deeply [76].\n",
      "3.3.2\tSupervised Fine-tuning' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 14556.04296875\n",
      "page_content='proposed framework helps ChatGPT to increase its performance by more than 50% and achieve new SOTA results on the CodeContests [104] benchmark. Li et al. [254] showed that directly using ChatGPT to find failure-inducing test cases results in poor performances. So, the authors proposed a new prompting strategy called “Differential Prompting”, which enables ChatGPT to achieve new SOTA results on the Quixbugs dataset [279]. Differential Prompting involves program intention inference followed by two more steps: program generation and differential testing.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 14556.04296875\n",
      "page_content='proposed framework helps ChatGPT to increase its performance by more than 50% and achieve new SOTA results on the CodeContests [104] benchmark. Li et al. [254] showed that directly using ChatGPT to find failure-inducing test cases results in poor performances. So, the authors proposed a new prompting strategy called “Differential Prompting”, which enables ChatGPT to achieve new SOTA results on the Quixbugs dataset [279]. Differential Prompting involves program intention inference followed by two more steps: program generation and differential testing.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 14568.068359375\n",
      "page_content='R8 : topic classification\t\t\n",
      "Label Word Map\t{0: Money/Foreign Exchange, 1: Acquisitions, 2: Trade, 3: Interest Rates, 4: Shipping, 5: Earnings and Earnings Forecasts, 6: Grain, 7: Crude Oil}\t\n",
      "Zero-Shot Classify Prompt: Reason-Classify Prompts:\tPlease classify the overall SENTIMENT polarity of the INPUT sentence as INPUT: <sent> SENTIMENT: Please classify the overall SENTIMENT polarity of the INPUT sentence as INPUT: <sent>\tPositive or Negative. Positive or Negative.\n",
      "Findclue-Reason-Classify\tStep 1: Please classify the overall SENTIMENT polarity of the INPUT sentence as INPUT: <sent> Step 2: Please classify the overall SENTIMENT polarity of the INPUT sentence as INPUT: <sent> CLUES: <step-1-response>\tPositive or Negative. Positive or Negative.\n",
      "Few-Shot\t\t\n",
      "Classify Prompt:\tPlease classify the overall SENTIMENT polarity of the INPUT sentence as INPUT: <demo-sent> SENTIMENT: <demo-label-word> INPUT: <demo-sent> SENTIMENT: <demo-label-word> INPUT: <sent> SENTIMENT:\tPositive or Negative.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 14568.068359375\n",
      "page_content='R8 : topic classification\t\t\n",
      "Label Word Map\t{0: Money/Foreign Exchange, 1: Acquisitions, 2: Trade, 3: Interest Rates, 4: Shipping, 5: Earnings and Earnings Forecasts, 6: Grain, 7: Crude Oil}\t\n",
      "Zero-Shot Classify Prompt: Reason-Classify Prompts:\tPlease classify the overall SENTIMENT polarity of the INPUT sentence as INPUT: <sent> SENTIMENT: Please classify the overall SENTIMENT polarity of the INPUT sentence as INPUT: <sent>\tPositive or Negative. Positive or Negative.\n",
      "Findclue-Reason-Classify\tStep 1: Please classify the overall SENTIMENT polarity of the INPUT sentence as INPUT: <sent> Step 2: Please classify the overall SENTIMENT polarity of the INPUT sentence as INPUT: <sent> CLUES: <step-1-response>\tPositive or Negative. Positive or Negative.\n",
      "Few-Shot\t\t\n",
      "Classify Prompt:\tPlease classify the overall SENTIMENT polarity of the INPUT sentence as INPUT: <demo-sent> SENTIMENT: <demo-label-word> INPUT: <demo-sent> SENTIMENT: <demo-label-word> INPUT: <sent> SENTIMENT:\tPositive or Negative.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 14581.9228515625\n",
      "page_content='that falls within the time-scope of the data they were trained on, potentially leading to hallucinated results (Shuster et al., 2021; Ji et al., 2023; Zhang et al., 2023a;b). Additionally, RMs can conduct quick and efficient searches through a vast amount of information on the internet, making them an ideal choice for finding a wide range of data. Ultimately, both paradigms have their own unique set of irreplaceable advantages, making them useful in their respective areas of application.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Feng 等 - 2023 - Synergistic Interplay between Search and Large Language Models for Information Retrieval.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 14581.9228515625\n",
      "page_content='that falls within the time-scope of the data they were trained on, potentially leading to hallucinated results (Shuster et al., 2021; Ji et al., 2023; Zhang et al., 2023a;b). Additionally, RMs can conduct quick and efficient searches through a vast amount of information on the internet, making them an ideal choice for finding a wide range of data. Ultimately, both paradigms have their own unique set of irreplaceable advantages, making them useful in their respective areas of application.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Feng 等 - 2023 - Synergistic Interplay between Search and Large Language Models for Information Retrieval.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 14592.06640625\n",
      "page_content='Most of the research works showed that compared to' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 14592.06640625\n",
      "page_content='Most of the research works showed that compared to' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 14619.724609375\n",
      "page_content='any pre-labeled examples. Experimental results on six text classification tasks demonstrate that the proposed approach significantly outperforms standard prompt learning in zero-shot settings, achieving up to 19.7% absolute improvement and 13.8% average improvement. More surprisingly, on IMDB and SST-2, our approach even exceeds all few-shot baselines.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 14619.724609375\n",
      "page_content='any pre-labeled examples. Experimental results on six text classification tasks demonstrate that the proposed approach significantly outperforms standard prompt learning in zero-shot settings, achieving up to 19.7% absolute improvement and 13.8% average improvement. More surprisingly, on IMDB and SST-2, our approach even exceeds all few-shot baselines.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 14625.251953125\n",
      "page_content='3.2.3\tAnswer-incorporated Passages\n",
      "The semantic gap between short-form queries and long-form documents has been a persistent challenge. The advent of LLMs with their inherent question-answering capabilities has introduced a novel approach to query rewriting. This approach involves initially utilizing LLMs to generate comprehensive answers to the given queries. These detailed answers are then employed to retrieve relevant passages from\n",
      "TABLE 2. Examples of different prompting methods in query rewriter.\n",
      "Methods\tPrompts\n",
      "Zero-shot\t\n",
      "HyDE [75] LameR [85]\tPlease write a passage to answer the question. Question: {#Question} Passage: Give a question {#Question} and its possible answering passages: A. {#Passage 1} B. {#Passage 2} C. {#Passage 3} ... Please write a correct answering passage.\n",
      "Few-shot\t\n",
      "Query2Doc [65] Write a passage that answers the given query:\n",
      "Query: {#Query 1}\n",
      "Passage: {#Passage 1}\n",
      "Query: {#Query} Passage:\t\n",
      "\tChain-of-Thought' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 14625.251953125\n",
      "page_content='3.2.3\tAnswer-incorporated Passages\n",
      "The semantic gap between short-form queries and long-form documents has been a persistent challenge. The advent of LLMs with their inherent question-answering capabilities has introduced a novel approach to query rewriting. This approach involves initially utilizing LLMs to generate comprehensive answers to the given queries. These detailed answers are then employed to retrieve relevant passages from\n",
      "TABLE 2. Examples of different prompting methods in query rewriter.\n",
      "Methods\tPrompts\n",
      "Zero-shot\t\n",
      "HyDE [75] LameR [85]\tPlease write a passage to answer the question. Question: {#Question} Passage: Give a question {#Question} and its possible answering passages: A. {#Passage 1} B. {#Passage 2} C. {#Passage 3} ... Please write a correct answering passage.\n",
      "Few-shot\t\n",
      "Query2Doc [65] Write a passage that answers the given query:\n",
      "Query: {#Query 1}\n",
      "Passage: {#Passage 1}\n",
      "Query: {#Query} Passage:\t\n",
      "\tChain-of-Thought' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 14745.662109375\n",
      "page_content='4.2\tLLM Step: Refining Information in LLM via RM\n",
      "As aforementioned, we can invoke LLMs to conditionally generate knowledge collection S by preparing a prompt p that adapts the LLM to a specific function (Eq. 2). Despite the remarkable text generation capability, they are also prone to hallucination and still struggle to represent the complete long tail of knowledge contained within their training corpus (Shi et al., 2023). To mitigate the aforementioned issues, we argue that D, the documents retrieved by RMs, may provide rich information about the original query q and can potentially help the LLMs make a better prediction.\n",
      "Specifically, we include the knowledge in D into p by designing a new prompt as:\n",
      "Give a question {query} and its possible answering passages {passages} Please write a correct answering passage:\n",
      "where “{query}” and “{passages}” are the placeholders for q and D respectively from last RM step:\n",
      "s = G(q') = G(q ® p ® D)\t(4)' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Feng 等 - 2023 - Synergistic Interplay between Search and Large Language Models for Information Retrieval.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 14745.662109375\n",
      "page_content='4.2\tLLM Step: Refining Information in LLM via RM\n",
      "As aforementioned, we can invoke LLMs to conditionally generate knowledge collection S by preparing a prompt p that adapts the LLM to a specific function (Eq. 2). Despite the remarkable text generation capability, they are also prone to hallucination and still struggle to represent the complete long tail of knowledge contained within their training corpus (Shi et al., 2023). To mitigate the aforementioned issues, we argue that D, the documents retrieved by RMs, may provide rich information about the original query q and can potentially help the LLMs make a better prediction.\n",
      "Specifically, we include the knowledge in D into p by designing a new prompt as:\n",
      "Give a question {query} and its possible answering passages {passages} Please write a correct answering passage:\n",
      "where “{query}” and “{passages}” are the placeholders for q and D respectively from last RM step:\n",
      "s = G(q') = G(q ® p ® D)\t(4)' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Feng 等 - 2023 - Synergistic Interplay between Search and Large Language Models for Information Retrieval.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 14810.4306640625\n",
      "page_content='where |q | denotes the token number of query q, d denotes the document, and P represents the provided prompt. The documents are then reranked based on their relevance scores. It has been proven that some LLMs (such as T0) yield significant performance in zero-shot document reranking based on the query generation method [153]. Recently, research [154] has also shown that the LLMs that are pre-trained without any supervised instruction fine-tuning (such as LLaMA) also yield robust zero-shot ranking ability.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 14810.4306640625\n",
      "page_content='where |q | denotes the token number of query q, d denotes the document, and P represents the provided prompt. The documents are then reranked based on their relevance scores. It has been proven that some LLMs (such as T0) yield significant performance in zero-shot document reranking based on the query generation method [153]. Recently, research [154] has also shown that the LLMs that are pre-trained without any supervised instruction fine-tuning (such as LLaMA) also yield robust zero-shot ranking ability.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 14878.4560546875\n",
      "page_content='performance on some of the tasks is promising, with a lot of room for improvement in other tasks.\n",
      "Some of the existing works demonstrated that using prompts in English improves the performance of GLLMs in the case of non-English languages [131], [363]. For example, Lai et al. [363] performed a comprehensive evaluation of the multilingual abilities of ChatGPT on seven tasks covering more than 30 languages ranging from high-resource to extremely low-resource languages. The experiment results confirmed the bias of ChatGPT towards the English language, i.e., the performance is better for English compared to other languages and prompts in the English language can enhance the performance for non-English languages. The possible reason for the bias of GLLMs towards the English language is that GLLMs are trained mostly on English text corpus; hence, these models can better understand the prompt if it is in English [131].' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 14878.4560546875\n",
      "page_content='performance on some of the tasks is promising, with a lot of room for improvement in other tasks.\n",
      "Some of the existing works demonstrated that using prompts in English improves the performance of GLLMs in the case of non-English languages [131], [363]. For example, Lai et al. [363] performed a comprehensive evaluation of the multilingual abilities of ChatGPT on seven tasks covering more than 30 languages ranging from high-resource to extremely low-resource languages. The experiment results confirmed the bias of ChatGPT towards the English language, i.e., the performance is better for English compared to other languages and prompts in the English language can enhance the performance for non-English languages. The possible reason for the bias of GLLMs towards the English language is that GLLMs are trained mostly on English text corpus; hence, these models can better understand the prompt if it is in English [131].' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 14895.955078125\n",
      "page_content='on label words during training:\n",
      "d =\n",
      "m-1\n",
      "(Pb(i) - Pavg (i))2\n",
      "i=0\n",
      "(8)\n",
      "4.\tExperiments\n",
      "We conduct experiments on six text classification datasets to show the effectiveness of our approach. In this section, we first introduce statistics for the six datasets, the experimental settings we used, and the baselines for comparison with our approach. Then, we present our main results and provide possible insights into our method.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 14895.955078125\n",
      "page_content='on label words during training:\n",
      "d =\n",
      "m-1\n",
      "(Pb(i) - Pavg (i))2\n",
      "i=0\n",
      "(8)\n",
      "4.\tExperiments\n",
      "We conduct experiments on six text classification datasets to show the effectiveness of our approach. In this section, we first introduce statistics for the six datasets, the experimental settings we used, and the baselines for comparison with our approach. Then, we present our main results and provide possible insights into our method.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 14909.662109375\n",
      "page_content='Number of Demonstrations\n",
      "Figure 3: Performances v.s. the number of\n",
      "demonstrations in few-shot prompts.\n",
      "6.1\tImpact of the number of demonstrations\n",
      "We explore the effect of the number of demonstrations in prompts. We conduct experiments on the SST-2 dataset. Results for the vanilla prompting and the CARP schemas using different sampling strategies are shown in Figure 3 and Figure 4, respectively. As can be seen, performances improve as the number of demonstrations increases for both the vanilla and the CARP schemas.\n",
      "6.2\tThe effect of components in demonstrations\n",
      "CARP uses (text, clues, reasons, golden label word) pairs as demonstrations. In this subsection, we exploit the influence of each component in (text, clues, reasons, golden label word) by removing it from prompts. Experimental results are shown in Table 7. As shown in Table 7, text in demonstrations has the biggest influence\n",
      "Prompts\tSST-2\tR8\n",
      "CARP\t96.80\t98.29\n",
      "w/o Text\t92.28\t94.18\n",
      "w/o Clue\t95.48\t95.29\n",
      "w/o Reason\t95.72\t97.82' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 14909.662109375\n",
      "page_content='Number of Demonstrations\n",
      "Figure 3: Performances v.s. the number of\n",
      "demonstrations in few-shot prompts.\n",
      "6.1\tImpact of the number of demonstrations\n",
      "We explore the effect of the number of demonstrations in prompts. We conduct experiments on the SST-2 dataset. Results for the vanilla prompting and the CARP schemas using different sampling strategies are shown in Figure 3 and Figure 4, respectively. As can be seen, performances improve as the number of demonstrations increases for both the vanilla and the CARP schemas.\n",
      "6.2\tThe effect of components in demonstrations\n",
      "CARP uses (text, clues, reasons, golden label word) pairs as demonstrations. In this subsection, we exploit the influence of each component in (text, clues, reasons, golden label word) by removing it from prompts. Experimental results are shown in Table 7. As shown in Table 7, text in demonstrations has the biggest influence\n",
      "Prompts\tSST-2\tR8\n",
      "CARP\t96.80\t98.29\n",
      "w/o Text\t92.28\t94.18\n",
      "w/o Clue\t95.48\t95.29\n",
      "w/o Reason\t95.72\t97.82' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 14928.486328125\n",
      "page_content='Reason-Classify Prompts:\tStep 1: Classify the sentiment of the input sentence as positive or negative. INPUT: <demo-sent> Step 2: Classify the sentiment of the input sentence as positive or negative. INPUT: <demo-sent> REASONING: <step-1-generated> SENTIMENT: <demo-label-word> INPUT: <demo-sent> REASONING: <step-1-generated> SENTIMENT: <demo-label-word> INPUT: <test-sent>\t\n",
      "Findclue-Reason-Classify Prompts:\tStep 1: Classify the sentiment of the input sentence as positive or negative. INPUT: <demo-sent> Step 2: Classify the sentiment of the input sentence as positive or negative. INPUT: <demo-sent> REASONING: <step-1-generated> SENTIMENT: <demo-label-word> INPUT: <demo-sent> REASONING: <step-1-generated> SENTIMENT: <demo-label-word> INPUT: <test-sent>\t\n",
      "\tMR : topic classification\n",
      "Label Word Map\t{0: Negative, 1: Positive}\n",
      "Zero-Shot\n",
      "Classify Prompt:\tPlease classify the overall SENTIMENT polarity of the INPUT sentence as Positive or Negative. INPUT: <sent> SENTIMENT:' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 14928.486328125\n",
      "page_content='Reason-Classify Prompts:\tStep 1: Classify the sentiment of the input sentence as positive or negative. INPUT: <demo-sent> Step 2: Classify the sentiment of the input sentence as positive or negative. INPUT: <demo-sent> REASONING: <step-1-generated> SENTIMENT: <demo-label-word> INPUT: <demo-sent> REASONING: <step-1-generated> SENTIMENT: <demo-label-word> INPUT: <test-sent>\t\n",
      "Findclue-Reason-Classify Prompts:\tStep 1: Classify the sentiment of the input sentence as positive or negative. INPUT: <demo-sent> Step 2: Classify the sentiment of the input sentence as positive or negative. INPUT: <demo-sent> REASONING: <step-1-generated> SENTIMENT: <demo-label-word> INPUT: <demo-sent> REASONING: <step-1-generated> SENTIMENT: <demo-label-word> INPUT: <test-sent>\t\n",
      "\tMR : topic classification\n",
      "Label Word Map\t{0: Negative, 1: Positive}\n",
      "Zero-Shot\n",
      "Classify Prompt:\tPlease classify the overall SENTIMENT polarity of the INPUT sentence as Positive or Negative. INPUT: <sent> SENTIMENT:' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 14932.25\n",
      "page_content='elements of input, generating questions and answers related to the key elements, and then using them to generate the final output. Parikh et al. [143] showed that the performance of the GPT-3 model for intent classification in zeroshot settings can be enhanced by including intent class descriptions in the prompt.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 14932.25\n",
      "page_content='elements of input, generating questions and answers related to the key elements, and then using them to generate the final output. Parikh et al. [143] showed that the performance of the GPT-3 model for intent classification in zeroshot settings can be enhanced by including intent class descriptions in the prompt.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15012.66796875\n",
      "page_content='prompted with text descriptions of the image, generates the auxiliary knowledge. In the second stage, the downstream model receives the raw text and ChatGPT-generated auxiliary knowledge as input. The authors reported that the proposed approach outperforms existing SOTA approaches based on texttext and text-image paradigms.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15012.66796875\n",
      "page_content='prompted with text descriptions of the image, generates the auxiliary knowledge. In the second stage, the downstream model receives the raw text and ChatGPT-generated auxiliary knowledge as input. The authors reported that the proposed approach outperforms existing SOTA approaches based on texttext and text-image paradigms.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15016.6015625\n",
      "page_content='is a gap between pretraining and in-context learning at inference. Due to this, in many cases during inference, the GPT-3 model fails to understand the given prompt and tends to generate the next words.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15016.6015625\n",
      "page_content='is a gap between pretraining and in-context learning at inference. Due to this, in many cases during inference, the GPT-3 model fails to understand the given prompt and tends to generate the next words.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15037.7421875\n",
      "page_content='[155]\tS. Sun, S. Zhuang, S. Wang, and G. Zuccon, “An investigation of prompt variations for zero-shot llm-based rankers,” CoRR, vol. abs/2406.14117, 2024.\n",
      "[156]\tS. Cho, S. Jeong, J. Seo, and J. C. Park, “Discrete prompt optimization via constrained generation for zero-shot re-ranker,” in ACL (Findings). Association for Computational Linguistics, 2023, pp. 960–971.\n",
      "[157]\tW. Liu, Y. Zhu, and Z. Dou, “Demorank: Selecting effective demonstrations for large language models in ranking task,” CoRR, vol. abs/2406.16332, 2024.\n",
      "[158]\tA. Drozdov, H. Zhuang, Z. Dai, Z. Qin, R. Rahimi, X. Wang, D. Alon, M. Iyyer, A. McCallum, D. Metzler, and K. Hui, “PaRaDe: Passage ranking using demonstrations with LLMs,” in Findings of the Association for Computational Linguistics: EMNLP 2023, H. Bouamor, J. Pino, and K. Bali, Eds. Singapore: Association for Computational Linguistics, Dec. 2023, pp. 14 242– 14 252.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15037.7421875\n",
      "page_content='[155]\tS. Sun, S. Zhuang, S. Wang, and G. Zuccon, “An investigation of prompt variations for zero-shot llm-based rankers,” CoRR, vol. abs/2406.14117, 2024.\n",
      "[156]\tS. Cho, S. Jeong, J. Seo, and J. C. Park, “Discrete prompt optimization via constrained generation for zero-shot re-ranker,” in ACL (Findings). Association for Computational Linguistics, 2023, pp. 960–971.\n",
      "[157]\tW. Liu, Y. Zhu, and Z. Dou, “Demorank: Selecting effective demonstrations for large language models in ranking task,” CoRR, vol. abs/2406.16332, 2024.\n",
      "[158]\tA. Drozdov, H. Zhuang, Z. Dai, Z. Qin, R. Rahimi, X. Wang, D. Alon, M. Iyyer, A. McCallum, D. Metzler, and K. Hui, “PaRaDe: Passage ranking using demonstrations with LLMs,” in Findings of the Association for Computational Linguistics: EMNLP 2023, H. Bouamor, J. Pino, and K. Bali, Eds. Singapore: Association for Computational Linguistics, Dec. 2023, pp. 14 242– 14 252.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15065.537109375\n",
      "page_content='These deficiencies underscore the potential for enhancing the accuracy and efficiency of existing RAG framework, thereby guiding our investigative efforts to address these issues. We decompose the Query Rewriter module’s functionality into two subtasks, resulting in the upgraded module Query Rewriter+. The first subtask involves\n",
      "∗ Corresponding author with email: Min.Xu@uts.edu.au.\n",
      "1 https://txt.cohere.com/rerank/\n",
      "Original Question: Who sings backing vocals with piano on one of these nights, the song?\n",
      "Question Rewriter+\n",
      "Q @^0S\n",
      "Rewritten Question:\n",
      "Which artist provides backing vocals and plays the piano on the track 'One of These Nights’?\n",
      "Queries:\n",
      "q1. Backing vocals performer on 'One of These Nights' song.\n",
      "q2. Pianist accompanying 'One of These Nights' song.\n",
      "q3. One of These Nights.\n",
      "Retrieval Trigger ®k B\n",
      "Filtered Knowledge: k1, k3, k7 …\n",
      "Knowledge Filter\n",
      "Entail\n",
      "LLM Reader\n",
      "Neural\n",
      "Knowledge Retriever\n",
      "Queries Need Retrieval: q3. One of These Nights.\n",
      "Response [“Glenn Frey”]' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15065.537109375\n",
      "page_content='These deficiencies underscore the potential for enhancing the accuracy and efficiency of existing RAG framework, thereby guiding our investigative efforts to address these issues. We decompose the Query Rewriter module’s functionality into two subtasks, resulting in the upgraded module Query Rewriter+. The first subtask involves\n",
      "∗ Corresponding author with email: Min.Xu@uts.edu.au.\n",
      "1 https://txt.cohere.com/rerank/\n",
      "Original Question: Who sings backing vocals with piano on one of these nights, the song?\n",
      "Question Rewriter+\n",
      "Q @^0S\n",
      "Rewritten Question:\n",
      "Which artist provides backing vocals and plays the piano on the track 'One of These Nights’?\n",
      "Queries:\n",
      "q1. Backing vocals performer on 'One of These Nights' song.\n",
      "q2. Pianist accompanying 'One of These Nights' song.\n",
      "q3. One of These Nights.\n",
      "Retrieval Trigger ®k B\n",
      "Filtered Knowledge: k1, k3, k7 …\n",
      "Knowledge Filter\n",
      "Entail\n",
      "LLM Reader\n",
      "Neural\n",
      "Knowledge Retriever\n",
      "Queries Need Retrieval: q3. One of These Nights.\n",
      "Response [“Glenn Frey”]' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15102.755859375\n",
      "page_content='(3)\tInput xinput is the test text sequence to classify.\n",
      "The prompt xprompt for a test input is constructed by concatenating the task description xdesc, a sequence of demonstrations {(xdemo ,ydemo),..., (xdemo, ydemo)}, and the test sequence xtest, which can be given as follows:\n",
      "{xdesc; \\n; <demo>1; \\n;...; <demo>k; \\n; xtest}\n",
      "3.3\tDemonstration Sampling\n",
      "The few-shot setup requires demonstrations sampled from the training set. Strategies that we explore include:\n",
      "Random Sampling a straightforward strategy from samplings is to randomly sample k examples {(x1, y1),..., (xk, yk)} from the training set Dtrain for a text sequence xtest.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15102.755859375\n",
      "page_content='(3)\tInput xinput is the test text sequence to classify.\n",
      "The prompt xprompt for a test input is constructed by concatenating the task description xdesc, a sequence of demonstrations {(xdemo ,ydemo),..., (xdemo, ydemo)}, and the test sequence xtest, which can be given as follows:\n",
      "{xdesc; \\n; <demo>1; \\n;...; <demo>k; \\n; xtest}\n",
      "3.3\tDemonstration Sampling\n",
      "The few-shot setup requires demonstrations sampled from the training set. Strategies that we explore include:\n",
      "Random Sampling a straightforward strategy from samplings is to randomly sample k examples {(x1, y1),..., (xk, yk)} from the training set Dtrain for a text sequence xtest.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15132.5322265625\n",
      "page_content='3.3.2\tSupervised Fine-tuning\n",
      "Prompting methods directly leverage LLMs’ strong capabilities to expand or rewrite queries. Though prompting method is effective, LLMs are not naturally designed for query rewriting task. To further tailor LLMs for this task, supervised fine-tuning (SFT) has emerged as a promising approach. A crucial aspect of this methodology is the creation of an appropriate training dataset. The process of gathering this dataset varies significantly depending on the application scenario.\n",
      "In the context of e-commerce search, a wealth of supervised training data for query rewriting is naturally available. This data, sourced from the previous-generation rewriting policies of the e-commerce system, significantly simplifies the construction of the SFT dataset [81].' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15132.5322265625\n",
      "page_content='3.3.2\tSupervised Fine-tuning\n",
      "Prompting methods directly leverage LLMs’ strong capabilities to expand or rewrite queries. Though prompting method is effective, LLMs are not naturally designed for query rewriting task. To further tailor LLMs for this task, supervised fine-tuning (SFT) has emerged as a promising approach. A crucial aspect of this methodology is the creation of an appropriate training dataset. The process of gathering this dataset varies significantly depending on the application scenario.\n",
      "In the context of e-commerce search, a wealth of supervised training data for query rewriting is naturally available. This data, sourced from the previous-generation rewriting policies of the e-commerce system, significantly simplifies the construction of the SFT dataset [81].' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15165.6396484375\n",
      "page_content='the retrieved documents from the RM part as demonstrations to enrich the information in prompt formulation. This two-step refinement procedure can be seamlessly repeated to augment the inputs of RM and LLM. Implicitly, we assume that the outputs of both components supplement each other, leading to more accurate retrieval.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Feng 等 - 2023 - Synergistic Interplay between Search and Large Language Models for Information Retrieval.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15165.6396484375\n",
      "page_content='the retrieved documents from the RM part as demonstrations to enrich the information in prompt formulation. This two-step refinement procedure can be seamlessly repeated to augment the inputs of RM and LLM. Implicitly, we assume that the outputs of both components supplement each other, leading to more accurate retrieval.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Feng 等 - 2023 - Synergistic Interplay between Search and Large Language Models for Information Retrieval.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15192.93359375\n",
      "page_content='INPUT: <demo-sent> SENTIMENT: <demo-label-word> INPUT: <sent> SENTIMENT:\n",
      "Reason-Classify Prompts:\tStep 1: Classify the sentiment of the input sentence as positive or negative. INPUT: <demo-sent> Step 2: Classify the sentiment of the input sentence as positive or negative. INPUT: <demo-sent> REASONING: <step-1-generated> SENTIMENT: <demo-label-word> INPUT: <demo-sent> REASONING: <step-1-generated> SENTIMENT: <demo-label-word> INPUT: <test-sent>\n",
      "Findclue-Reason-Classify Prompts:\tStep 1: Classify the sentiment of the input sentence as positive or negative. INPUT: <demo-sent> Step 2: Classify the sentiment of the input sentence as positive or negative. INPUT: <demo-sent> REASONING: <step-1-generated> SENTIMENT: <demo-label-word> INPUT: <demo-sent> REASONING: <step-1-generated> SENTIMENT: <demo-label-word> INPUT: <test-sent>' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15192.93359375\n",
      "page_content='INPUT: <demo-sent> SENTIMENT: <demo-label-word> INPUT: <sent> SENTIMENT:\n",
      "Reason-Classify Prompts:\tStep 1: Classify the sentiment of the input sentence as positive or negative. INPUT: <demo-sent> Step 2: Classify the sentiment of the input sentence as positive or negative. INPUT: <demo-sent> REASONING: <step-1-generated> SENTIMENT: <demo-label-word> INPUT: <demo-sent> REASONING: <step-1-generated> SENTIMENT: <demo-label-word> INPUT: <test-sent>\n",
      "Findclue-Reason-Classify Prompts:\tStep 1: Classify the sentiment of the input sentence as positive or negative. INPUT: <demo-sent> Step 2: Classify the sentiment of the input sentence as positive or negative. INPUT: <demo-sent> REASONING: <step-1-generated> SENTIMENT: <demo-label-word> INPUT: <demo-sent> REASONING: <step-1-generated> SENTIMENT: <demo-label-word> INPUT: <test-sent>' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15200.259765625\n",
      "page_content='Label Word Map\t{0: Negative, 1: Positive}\n",
      "Zero-Shot\n",
      "Classify Prompt:\tPlease classify the overall SENTIMENT polarity of the INPUT sentence as Positive or Negative. INPUT: <sent> SENTIMENT:\n",
      "Reason-Classify Prompts:\tPlease classify the overall SENTIMENT polarity of the INPUT sentence as Positive or Negative. INPUT: <sent>\n",
      "Findclue-Reason-Classify\tStep 1: Please classify the overall SENTIMENT polarity of the INPUT sentence as Positive or Negative. INPUT: <sent>\n",
      "\tStep 2: Please classify the overall SENTIMENT polarity of the INPUT sentence as Positive or Negative. INPUT: <sent> CLUES: <step-1-response>\n",
      "Few-Shot\n",
      "Classify Prompt:\tPlease classify the overall SENTIMENT polarity of the INPUT sentence as Positive or Negative. INPUT: <demo-sent> SENTIMENT: <demo-label-word>\n",
      "\tINPUT: <demo-sent> SENTIMENT: <demo-label-word> INPUT: <sent> SENTIMENT:' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15200.259765625\n",
      "page_content='Label Word Map\t{0: Negative, 1: Positive}\n",
      "Zero-Shot\n",
      "Classify Prompt:\tPlease classify the overall SENTIMENT polarity of the INPUT sentence as Positive or Negative. INPUT: <sent> SENTIMENT:\n",
      "Reason-Classify Prompts:\tPlease classify the overall SENTIMENT polarity of the INPUT sentence as Positive or Negative. INPUT: <sent>\n",
      "Findclue-Reason-Classify\tStep 1: Please classify the overall SENTIMENT polarity of the INPUT sentence as Positive or Negative. INPUT: <sent>\n",
      "\tStep 2: Please classify the overall SENTIMENT polarity of the INPUT sentence as Positive or Negative. INPUT: <sent> CLUES: <step-1-response>\n",
      "Few-Shot\n",
      "Classify Prompt:\tPlease classify the overall SENTIMENT polarity of the INPUT sentence as Positive or Negative. INPUT: <demo-sent> SENTIMENT: <demo-label-word>\n",
      "\tINPUT: <demo-sent> SENTIMENT: <demo-label-word> INPUT: <sent> SENTIMENT:' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15216.48046875\n",
      "page_content='scientific literature [155], [420], healthcare [410], [415], [422], dialogue [419], programming [411] etc. Table 19 presents a summary of research works exploring GLLMs for data generationbased data augmentation.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15216.48046875\n",
      "page_content='scientific literature [155], [420], healthcare [410], [415], [422], dialogue [419], programming [411] etc. Table 19 presents a summary of research works exploring GLLMs for data generationbased data augmentation.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15225.0205078125\n",
      "page_content='7339–7353.\n",
      "[216]\tS. Kadavath, T. Conerly, A. Askell, T. Henighan, D. Drain, E. Perez, N. Schiefer, Z. Hatfield-Dodds, N. DasSarma, E. Tran-Johnson, S. Johnston, S. E. Showk, A. Jones, N. Elhage, T. Hume, A. Chen, Y. Bai, S. Bowman, S. Fort, D. Ganguli, D. Hernandez, J. Jacobson, J. Kernion, S. Kravec, L. Lovitt, K. Ndousse, C. Olsson, S. Ringer, D. Amodei, T. Brown, J. Clark, N. Joseph, B. Mann, S. McCandlish, C. Olah, and J. Kaplan, “Language models (mostly) know what they know,” CoRR, vol. abs/2207.05221, 2022.\n",
      "[217]\tZ. Jiang, J. Araki, H. Ding, and G. Neubig, “How can we know When language models know? on the calibration of language models for question answering,” Trans. Assoc. Comput. Linguistics, vol. 9, pp. 962–977, 2021.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15225.0205078125\n",
      "page_content='7339–7353.\n",
      "[216]\tS. Kadavath, T. Conerly, A. Askell, T. Henighan, D. Drain, E. Perez, N. Schiefer, Z. Hatfield-Dodds, N. DasSarma, E. Tran-Johnson, S. Johnston, S. E. Showk, A. Jones, N. Elhage, T. Hume, A. Chen, Y. Bai, S. Bowman, S. Fort, D. Ganguli, D. Hernandez, J. Jacobson, J. Kernion, S. Kravec, L. Lovitt, K. Ndousse, C. Olsson, S. Ringer, D. Amodei, T. Brown, J. Clark, N. Joseph, B. Mann, S. McCandlish, C. Olah, and J. Kaplan, “Language models (mostly) know what they know,” CoRR, vol. abs/2207.05221, 2022.\n",
      "[217]\tZ. Jiang, J. Araki, H. Ding, and G. Neubig, “How can we know When language models know? on the calibration of language models for question answering,” Trans. Assoc. Comput. Linguistics, vol. 9, pp. 962–977, 2021.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15272.59765625\n",
      "page_content='3.4. Unlabeled Validation\n",
      "Previous work has shown that prompt engineering is a crucial step in prompt learning. However, the effectiveness of prompt learning varies considerably even when modifying a word in a template without changing the semantics. Some research has used a large validation set to determine the best template and when to stop training, which is not applicable in true zero-shot scenarios. In this work, instead of evaluating the model’s accuracy on a validation set, we measure whether the model bias distribution on the unlabeled validation set U is balanced over label words since the training objective is to eliminate model bias. Ideally, the model bias on label words should be nearly uniformly distributed:\n",
      "Pavg (i)\t= m + O , 0 < i <m\n",
      "P m— Oi =0\n",
      "where σi is a randomly generated small number that represents noise. Therefore, we use the distance between pb and pavg to represent model bias\n",
      "4.1.\tDataset Statistics' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15272.59765625\n",
      "page_content='3.4. Unlabeled Validation\n",
      "Previous work has shown that prompt engineering is a crucial step in prompt learning. However, the effectiveness of prompt learning varies considerably even when modifying a word in a template without changing the semantics. Some research has used a large validation set to determine the best template and when to stop training, which is not applicable in true zero-shot scenarios. In this work, instead of evaluating the model’s accuracy on a validation set, we measure whether the model bias distribution on the unlabeled validation set U is balanced over label words since the training objective is to eliminate model bias. Ideally, the model bias on label words should be nearly uniformly distributed:\n",
      "Pavg (i)\t= m + O , 0 < i <m\n",
      "P m— Oi =0\n",
      "where σi is a randomly generated small number that represents noise. Therefore, we use the distance between pb and pavg to represent model bias\n",
      "4.1.\tDataset Statistics' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15314.673828125\n",
      "page_content='the Memory Knowledge module can achieve a significant reduction in response time—by approximately 46%—without substantially compromising the quality of the answers. Furthermore, adjusting the threshold to 0.8 enhances the response quality beyond that at τ = 1.0, underscoring that leveraging highly relevant historical experience can generate responses with superior quality.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15314.673828125\n",
      "page_content='the Memory Knowledge module can achieve a significant reduction in response time—by approximately 46%—without substantially compromising the quality of the answers. Furthermore, adjusting the threshold to 0.8 enhances the response quality beyond that at τ = 1.0, underscoring that leveraging highly relevant historical experience can generate responses with superior quality.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15317.158203125\n",
      "page_content='[121]\tT. Mesnard, C. Hardin, R. Dadashi, S. Bhupatiraju, S. Pathak, L. Sifre, M. Rivie` re, M. S. Kale, J. Love, P. Tafti, L. Hussenot, A. Chowdhery, A. Roberts, A. Barua, A. Botev, A. Castro-Ros, A. Slone, A. He´ liou, A. Tacchetti, A. Bulanova, A. Paterson, B. Tsai, B. Shahriari, C. L. Lan, C. A. Choquette-Choo, C. Crepy, D. Cer, D. Ippolito, D. Reid, E. Buchatskaya,\n",
      "E. Ni, E. Noland, G. Yan, G. Tucker, G. Mu-raru, G. Rozhdestvenskiy, H. Michalewski, I. Tenney, I. Grishchenko, J. Austin, J. Keeling, J. Labanowski, J. Lespiau, J. Stanway, J. Brennan, J. Chen, J. Ferret, J. Chiu, and et al., “Gemma: Open models based on gemini research and technology,” CoRR, vol. abs/2403.08295, 2024.\n",
      "[122]\tX. Ma, L. Wang, N. Yang, F. Wei, and J. Lin, “Finetuning llama for multi-stage text retrieval,” CoRR, vol. abs/2310.08319, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15317.158203125\n",
      "page_content='[121]\tT. Mesnard, C. Hardin, R. Dadashi, S. Bhupatiraju, S. Pathak, L. Sifre, M. Rivie` re, M. S. Kale, J. Love, P. Tafti, L. Hussenot, A. Chowdhery, A. Roberts, A. Barua, A. Botev, A. Castro-Ros, A. Slone, A. He´ liou, A. Tacchetti, A. Bulanova, A. Paterson, B. Tsai, B. Shahriari, C. L. Lan, C. A. Choquette-Choo, C. Crepy, D. Cer, D. Ippolito, D. Reid, E. Buchatskaya,\n",
      "E. Ni, E. Noland, G. Yan, G. Tucker, G. Mu-raru, G. Rozhdestvenskiy, H. Michalewski, I. Tenney, I. Grishchenko, J. Austin, J. Keeling, J. Labanowski, J. Lespiau, J. Stanway, J. Brennan, J. Chen, J. Ferret, J. Chiu, and et al., “Gemma: Open models based on gemini research and technology,” CoRR, vol. abs/2403.08295, 2024.\n",
      "[122]\tX. Ma, L. Wang, N. Yang, F. Wei, and J. Lin, “Finetuning llama for multi-stage text retrieval,” CoRR, vol. abs/2310.08319, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15335.7509765625\n",
      "page_content='INPUT: <demo-sent> SENTIMENT: <demo-label-word> INPUT: <sent> SENTIMENT:\n",
      "Reason-Classify Prompts:\tStep 1: Classify the sentiment of the input sentence as positive or negative. INPUT: <demo-sent> Step 2: Classify the sentiment of the input sentence as positive or negative. INPUT: <demo-sent> REASONING: <step-1-generated> SENTIMENT: <demo-label-word> INPUT: <demo-sent> REASONING: <step-1-generated> SENTIMENT: <demo-label-word> INPUT: <test-sent>\n",
      "Findclue-Reason-Classify Prompts:\tStep 1: Classify the sentiment of the input sentence as positive or negative. INPUT: <demo-sent> Step 2: Classify the sentiment of the input sentence as positive or negative. INPUT: <demo-sent> REASONING: <step-1-generated> SENTIMENT: <demo-label-word> INPUT: <demo-sent> REASONING: <step-1-generated> SENTIMENT: <demo-label-word> INPUT: <test-sent>\n",
      "R8 : topic classification' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15335.7509765625\n",
      "page_content='INPUT: <demo-sent> SENTIMENT: <demo-label-word> INPUT: <sent> SENTIMENT:\n",
      "Reason-Classify Prompts:\tStep 1: Classify the sentiment of the input sentence as positive or negative. INPUT: <demo-sent> Step 2: Classify the sentiment of the input sentence as positive or negative. INPUT: <demo-sent> REASONING: <step-1-generated> SENTIMENT: <demo-label-word> INPUT: <demo-sent> REASONING: <step-1-generated> SENTIMENT: <demo-label-word> INPUT: <test-sent>\n",
      "Findclue-Reason-Classify Prompts:\tStep 1: Classify the sentiment of the input sentence as positive or negative. INPUT: <demo-sent> Step 2: Classify the sentiment of the input sentence as positive or negative. INPUT: <demo-sent> REASONING: <step-1-generated> SENTIMENT: <demo-label-word> INPUT: <demo-sent> REASONING: <step-1-generated> SENTIMENT: <demo-label-word> INPUT: <test-sent>\n",
      "R8 : topic classification' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15340.166015625\n",
      "page_content='[257]\tJ. Jin, Y. Zhu, X. Yang, C. Zhang, and Z. Dou, “Flashrag: A modular toolkit for efficient retrieval-augmented generation research,”\tCoRR, vol.\n",
      "abs/2405.13576, 2024.\n",
      "[258]\tR. Thoppilan, D. D. Freitas, J. Hall, N. Shazeer, A. Kulshreshtha, H. Cheng, A. Jin, T. Bos, L. Baker, Y. Du, Y. Li, H. Lee, H. S. Zheng, A. Ghafouri, M. Menegali, Y. Huang, M. Krikun, D. Lepikhin, J. Qin, D. Chen, Y. Xu, Z. Chen, A. Roberts, M. Bosma, Y. Zhou, C. Chang, I. Krivokon, W. Rusch, M. Pickett, K. S. Meier-Hellstern, M. R. Morris, T. Doshi, R. D. Santos, T. Duke, J. Soraker, B. Zevenbergen, V. Prabhakaran, M. Diaz, B. Hutchinson, K. Olson, A. Molina, E. Hoffman-John, J. Lee, L. Aroyo, R. Ra-jakumar, A. Butryna, M. Lamm, V. Kuzmina, J. Fenton, A. Cohen, R. Bernstein, R. Kurzweil, B. A. y Arcas, C. Cui, M. Croak, E. H. Chi, and Q. Le, “Lamda: Language models for dialog applications,” CoRR, vol. abs/2201.08239, 2022.\n",
      "[259]\tK. Shuster, M. Komeili, L. Adolphs, S. Roller,' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15340.166015625\n",
      "page_content='[257]\tJ. Jin, Y. Zhu, X. Yang, C. Zhang, and Z. Dou, “Flashrag: A modular toolkit for efficient retrieval-augmented generation research,”\tCoRR, vol.\n",
      "abs/2405.13576, 2024.\n",
      "[258]\tR. Thoppilan, D. D. Freitas, J. Hall, N. Shazeer, A. Kulshreshtha, H. Cheng, A. Jin, T. Bos, L. Baker, Y. Du, Y. Li, H. Lee, H. S. Zheng, A. Ghafouri, M. Menegali, Y. Huang, M. Krikun, D. Lepikhin, J. Qin, D. Chen, Y. Xu, Z. Chen, A. Roberts, M. Bosma, Y. Zhou, C. Chang, I. Krivokon, W. Rusch, M. Pickett, K. S. Meier-Hellstern, M. R. Morris, T. Doshi, R. D. Santos, T. Duke, J. Soraker, B. Zevenbergen, V. Prabhakaran, M. Diaz, B. Hutchinson, K. Olson, A. Molina, E. Hoffman-John, J. Lee, L. Aroyo, R. Ra-jakumar, A. Butryna, M. Lamm, V. Kuzmina, J. Fenton, A. Cohen, R. Bernstein, R. Kurzweil, B. A. y Arcas, C. Cui, M. Croak, E. H. Chi, and Q. Le, “Lamda: Language models for dialog applications,” CoRR, vol. abs/2201.08239, 2022.\n",
      "[259]\tK. Shuster, M. Komeili, L. Adolphs, S. Roller,' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15343.4443359375\n",
      "page_content='CARP\t95.99\t95.53\t95.31\t93.84\t90.64\t94.26\n",
      "FT kNN-Sampler\t\t\t\t\t\t\n",
      "Vanilla\t94.01\t94.14\t95.57\t95.79\t90.90\t94.08\n",
      "Zero-shot-CoT\t95.48\t94.89\t95.59\t95.89\t90.17\t94.40\n",
      "CARP\t96.62\t95.97\t98.13\t96.12\t91.86\t95.74\n",
      "Table 6: Accuracy performances of different settings on test subsets (results are over 5 runs). GPT-3 denotes text-davinci-003. In few-shot experiments, we sample 16 annotated examples (k=16) per prompt. \"MJ Vote\" is short for majority vote. \"WP Vote\" denotes weighted probability vote.\n",
      "elements of CARP.\n",
      "0\t2\t4\t8\t12\t16\t20\t24\n",
      "Number of Demonstrations\n",
      "Figure 4: Performances v.s. the number of demonstrations in few-shot prompts for the CARP strategy, where LLMs are first asked to generate evidence, then to reason and at last to generate final results.\n",
      "Number of Demonstrations\n",
      "Figure 3: Performances v.s. the number of\n",
      "demonstrations in few-shot prompts.\n",
      "6.1\tImpact of the number of demonstrations' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15343.4443359375\n",
      "page_content='CARP\t95.99\t95.53\t95.31\t93.84\t90.64\t94.26\n",
      "FT kNN-Sampler\t\t\t\t\t\t\n",
      "Vanilla\t94.01\t94.14\t95.57\t95.79\t90.90\t94.08\n",
      "Zero-shot-CoT\t95.48\t94.89\t95.59\t95.89\t90.17\t94.40\n",
      "CARP\t96.62\t95.97\t98.13\t96.12\t91.86\t95.74\n",
      "Table 6: Accuracy performances of different settings on test subsets (results are over 5 runs). GPT-3 denotes text-davinci-003. In few-shot experiments, we sample 16 annotated examples (k=16) per prompt. \"MJ Vote\" is short for majority vote. \"WP Vote\" denotes weighted probability vote.\n",
      "elements of CARP.\n",
      "0\t2\t4\t8\t12\t16\t20\t24\n",
      "Number of Demonstrations\n",
      "Figure 4: Performances v.s. the number of demonstrations in few-shot prompts for the CARP strategy, where LLMs are first asked to generate evidence, then to reason and at last to generate final results.\n",
      "Number of Demonstrations\n",
      "Figure 3: Performances v.s. the number of\n",
      "demonstrations in few-shot prompts.\n",
      "6.1\tImpact of the number of demonstrations' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15399.97265625\n",
      "page_content='1\tIntroduction' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Feng 等 - 2023 - Synergistic Interplay between Search and Large Language Models for Information Retrieval.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15399.97265625\n",
      "page_content='1\tIntroduction' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Feng 等 - 2023 - Synergistic Interplay between Search and Large Language Models for Information Retrieval.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15419.767578125\n",
      "page_content='Case: query_id: 1112341, query: “what is the daily life of thai people”' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Feng 等 - 2023 - Synergistic Interplay between Search and Large Language Models for Information Retrieval.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15419.767578125\n",
      "page_content='Case: query_id: 1112341, query: “what is the daily life of thai people”' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Feng 等 - 2023 - Synergistic Interplay between Search and Large Language Models for Information Retrieval.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15478.99609375\n",
      "page_content='the approaches of generating document identifiers through fine-tuning and prompting of LLMs [136, 137]' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15478.99609375\n",
      "page_content='the approaches of generating document identifiers through fine-tuning and prompting of LLMs [136, 137]' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15492.9521484375\n",
      "page_content='2.4\tPretrained Language Models\n",
      "2.4.1\tOverview' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15492.9521484375\n",
      "page_content='2.4\tPretrained Language Models\n",
      "2.4.1\tOverview' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15495.59375\n",
      "page_content='[343]\tQ. Lyu, J. Tan, M. E. Zapadka, J. Ponnatapura, C. Niu, K. J. Myers, G. Wang, and C. T. Whitlow, “Translating radiology reports into plain language using chatgpt and gpt-4 with prompt learning: results, limitations, and potential,” Visual Computing for Industry, Biomedicine, and Art, vol. 6, no. 1, p. 9, 2023.\n",
      "[344]\tF. Yu, L. Quartey, and F. Schilder, “Legal prompting: Teaching a language model to think like a lawyer,” arXiv preprint arXiv:2212.01326, 2022.\n",
      "[345]\tH.-T. Nguyen, “A brief report on lawgpt 1.0: A virtual legal assistant based on gpt-3,” arXiv preprint arXiv:2302.05729, 2023.\n",
      "[346]\tI. Chalkidis, “Chatgpt may pass the bar exam soon, but has a long way to go for the lexglue benchmark,” arXiv preprint arXiv:2304.12202, 2023.\n",
      "[347]\tJ. H. Choi, K. E. Hickman, A. Monahan, and D. Schwarcz, “Chatgpt goes to law school,” Available at SSRN, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15495.59375\n",
      "page_content='[343]\tQ. Lyu, J. Tan, M. E. Zapadka, J. Ponnatapura, C. Niu, K. J. Myers, G. Wang, and C. T. Whitlow, “Translating radiology reports into plain language using chatgpt and gpt-4 with prompt learning: results, limitations, and potential,” Visual Computing for Industry, Biomedicine, and Art, vol. 6, no. 1, p. 9, 2023.\n",
      "[344]\tF. Yu, L. Quartey, and F. Schilder, “Legal prompting: Teaching a language model to think like a lawyer,” arXiv preprint arXiv:2212.01326, 2022.\n",
      "[345]\tH.-T. Nguyen, “A brief report on lawgpt 1.0: A virtual legal assistant based on gpt-3,” arXiv preprint arXiv:2302.05729, 2023.\n",
      "[346]\tI. Chalkidis, “Chatgpt may pass the bar exam soon, but has a long way to go for the lexglue benchmark,” arXiv preprint arXiv:2304.12202, 2023.\n",
      "[347]\tJ. H. Choi, K. E. Hickman, A. Monahan, and D. Schwarcz, “Chatgpt goes to law school,” Available at SSRN, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15544.2177734375\n",
      "page_content='Human Language Technologies, pages 2339– 2352, Online. Association for Computational Linguistics.\n",
      "Taylor Shin, Yasaman Razeghi, Robert L. Logan IV, Eric Wallace, and Sameer Singh. 2020. AutoPrompt: Eliciting knowledge from language models with automatically generated prompts. In Empirical Methods in Natural Language Processing (EMNLP).\n",
      "Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher D. Manning, Andrew Y. Ng, and Christopher Potts. 2013. Recursive deep models for semantic compositionality over a sentiment treebank. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, EMNLP 2013, 1821 October 2013, Grand Hyatt Seattle, Seattle, Washington, USA, A meeting of SIGDAT, a Special Interest Group of the ACL, pages 1631– 1642. ACL.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15544.2177734375\n",
      "page_content='Human Language Technologies, pages 2339– 2352, Online. Association for Computational Linguistics.\n",
      "Taylor Shin, Yasaman Razeghi, Robert L. Logan IV, Eric Wallace, and Sameer Singh. 2020. AutoPrompt: Eliciting knowledge from language models with automatically generated prompts. In Empirical Methods in Natural Language Processing (EMNLP).\n",
      "Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher D. Manning, Andrew Y. Ng, and Christopher Potts. 2013. Recursive deep models for semantic compositionality over a sentiment treebank. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, EMNLP 2013, 1821 October 2013, Grand Hyatt Seattle, Seattle, Washington, USA, A meeting of SIGDAT, a Special Interest Group of the ACL, pages 1631– 1642. ACL.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15586.771484375\n",
      "page_content='Predicting Questions: Predicting questions is the process of anticipating what questions an audience or user might have and preparing answers or responses in advance.\n",
      "Entertainment: Entertainment by GPT-3 refers to the use of the GPT-3 language model for creating various forms of entertainment, such as games, Chatbots, and interactive stories.\n",
      "Scheduling and appointment booking: GPT-3 can be trained to understand and respond to natural language queries related to scheduling and booking, allowing it to communicate with users and coordinate appointments with minimal human intervention.\n",
      "Education or training: GPT-3 can be used to generate educational materials such as textbooks, instructional videos, and quizzes, or to interact with students in the form of chatbots or virtual assistants.[7]\n",
      "3.2\tLaMDA' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kania和Mehta - 2023 - A Literature Review on Augmented Analytics and Natural Language Generation A Review of State of Art.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15586.771484375\n",
      "page_content='Predicting Questions: Predicting questions is the process of anticipating what questions an audience or user might have and preparing answers or responses in advance.\n",
      "Entertainment: Entertainment by GPT-3 refers to the use of the GPT-3 language model for creating various forms of entertainment, such as games, Chatbots, and interactive stories.\n",
      "Scheduling and appointment booking: GPT-3 can be trained to understand and respond to natural language queries related to scheduling and booking, allowing it to communicate with users and coordinate appointments with minimal human intervention.\n",
      "Education or training: GPT-3 can be used to generate educational materials such as textbooks, instructional videos, and quizzes, or to interact with students in the form of chatbots or virtual assistants.[7]\n",
      "3.2\tLaMDA' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kania和Mehta - 2023 - A Literature Review on Augmented Analytics and Natural Language Generation A Review of State of Art.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15611.861328125\n",
      "page_content='Few-shot PT‡\t96.4 ± 0.7\t82.1 ± 13.3\t90.7 ± 5.2\t76.8 ± 13.3\t82.2 ± 3.2\t61.1 ± 1.7\n",
      "Few-shot PT+UV‡\t96.4 ± 0.9\t83.9 ± 14.4\t94.0 ± 1.1\t75.9 ± 12.9\t84.7 ± 2.2\t61.5 ± 1.7\n",
      "Zero-shot PT\t68.0 ± 3.4\t84.3 ± 12.4\t75.5 ± 11.5\t68.3 ± 13.4\t75.9 ± 5.1\t47.5 ± 7.0\n",
      "Zero-shot PT+CC\t77.5 ± 6.2\t89.3 ± 5.0\t85.9 ± 3.9\t82.4 ± 5.2\t79.6 ± 2.5\t56.4 ± 2.5\n",
      "Ours\t87.7 ± 5.9\t92.2 ± 1.5\t93.8 ± 1.3\t87.9 ± 3.1\t82.0 ± 2.6\t58.4 ± 1.9\n",
      "- UV\t86.7 ± 5.4\t89.2 ± 4.3\t91.0 ± 2.5\t84.8 ± 4.9\t80.2 ± 2.9\t57.6 ± 2.8\n",
      "- UV - APR\t86.3 ± 5.7\t88.0 ± 4.8\t90.9 ± 3.5\t85.0 ± 4.3\t79.4 ± 3.2\t57.2 ± 2.8\n",
      "- UV - APR - BA\t69.7 ± 5.9\t86.8 ± 3.9\t87.9 ± 5.8\t80.7 ± 6.7\t72.6 ± 4.2\t42.8 ± 2.6\n",
      "Table 4: Results of classification on AG’s News using the same template as in Table 1(a).\n",
      "Label Word\tPrediction Label Word\t\t\t\n",
      "\tpolitics\tsports\tbusiness\ttechnology\n",
      "politics\t1420\t116\t252\t112\n",
      "sports\t10\t1873\t11\t6\n",
      "business\t46\t18\t1491\t345\n",
      "technology\t69\t80\t102\t1649' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15611.861328125\n",
      "page_content='Few-shot PT‡\t96.4 ± 0.7\t82.1 ± 13.3\t90.7 ± 5.2\t76.8 ± 13.3\t82.2 ± 3.2\t61.1 ± 1.7\n",
      "Few-shot PT+UV‡\t96.4 ± 0.9\t83.9 ± 14.4\t94.0 ± 1.1\t75.9 ± 12.9\t84.7 ± 2.2\t61.5 ± 1.7\n",
      "Zero-shot PT\t68.0 ± 3.4\t84.3 ± 12.4\t75.5 ± 11.5\t68.3 ± 13.4\t75.9 ± 5.1\t47.5 ± 7.0\n",
      "Zero-shot PT+CC\t77.5 ± 6.2\t89.3 ± 5.0\t85.9 ± 3.9\t82.4 ± 5.2\t79.6 ± 2.5\t56.4 ± 2.5\n",
      "Ours\t87.7 ± 5.9\t92.2 ± 1.5\t93.8 ± 1.3\t87.9 ± 3.1\t82.0 ± 2.6\t58.4 ± 1.9\n",
      "- UV\t86.7 ± 5.4\t89.2 ± 4.3\t91.0 ± 2.5\t84.8 ± 4.9\t80.2 ± 2.9\t57.6 ± 2.8\n",
      "- UV - APR\t86.3 ± 5.7\t88.0 ± 4.8\t90.9 ± 3.5\t85.0 ± 4.3\t79.4 ± 3.2\t57.2 ± 2.8\n",
      "- UV - APR - BA\t69.7 ± 5.9\t86.8 ± 3.9\t87.9 ± 5.8\t80.7 ± 6.7\t72.6 ± 4.2\t42.8 ± 2.6\n",
      "Table 4: Results of classification on AG’s News using the same template as in Table 1(a).\n",
      "Label Word\tPrediction Label Word\t\t\t\n",
      "\tpolitics\tsports\tbusiness\ttechnology\n",
      "politics\t1420\t116\t252\t112\n",
      "sports\t10\t1873\t11\t6\n",
      "business\t46\t18\t1491\t345\n",
      "technology\t69\t80\t102\t1649' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15644.34375\n",
      "page_content='noise into the context. At last, we have identified a phenomenon of (4) redundant retrieval, where users pose questions similar to previous inquiries, causing the RAG system to fetch the same external information repeatedly. This redundancy severely compromises the efficiency of the RAG system.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15644.34375\n",
      "page_content='noise into the context. At last, we have identified a phenomenon of (4) redundant retrieval, where users pose questions similar to previous inquiries, causing the RAG system to fetch the same external information repeatedly. This redundancy severely compromises the efficiency of the RAG system.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15654.751953125\n",
      "page_content='[170]\tY. Ma, Z. Wang, Y. Cao, M. Li, M. Chen, K. Wang, and J. Shao, “Prompt for extraction? paie: Prompting argument interaction for event argument extraction,” in Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), 2022, pp. 6759–6774.\n",
      "[171]\tX. Du and C. Cardie, “Event extraction by answering (almost) natural questions,” in Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), 2020, pp. 671–683.\n",
      "[172]\tZ. Zhao, E. Wallace, S. Feng, D. Klein, and S. Singh, “Calibrate before use: Improving few-shot performance of language models,” in International Conference on Machine Learning. PMLR, 2021, pp. 12 697–12 706.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15654.751953125\n",
      "page_content='[170]\tY. Ma, Z. Wang, Y. Cao, M. Li, M. Chen, K. Wang, and J. Shao, “Prompt for extraction? paie: Prompting argument interaction for event argument extraction,” in Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), 2022, pp. 6759–6774.\n",
      "[171]\tX. Du and C. Cardie, “Event extraction by answering (almost) natural questions,” in Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), 2020, pp. 671–683.\n",
      "[172]\tZ. Zhao, E. Wallace, S. Feng, D. Klein, and S. Singh, “Calibrate before use: Improving few-shot performance of language models,” in International Conference on Machine Learning. PMLR, 2021, pp. 12 697–12 706.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15665.095703125\n",
      "page_content='LLM Reader We primarily used GPT-3.5-turbo-0613 as the blackbox LLM model for generating answers. The prompt structure includes task instruction, question, external knowledge, examples, and response format. The external knowledge section comprises up to 30 knowledge instances arranged in mixed order, as discussed in Section 2.\n",
      "4.2\tTask Setting' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15665.095703125\n",
      "page_content='LLM Reader We primarily used GPT-3.5-turbo-0613 as the blackbox LLM model for generating answers. The prompt structure includes task instruction, question, external knowledge, examples, and response format. The external knowledge section comprises up to 30 knowledge instances arranged in mixed order, as discussed in Section 2.\n",
      "4.2\tTask Setting' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15671.689453125\n",
      "page_content='Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark,\n",
      "Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language models are few-shot learners. In Advances in Neural Information Processing Systems, volume 33, pages 1877–1901. Curran Associates, Inc.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15671.689453125\n",
      "page_content='Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark,\n",
      "Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language models are few-shot learners. In Advances in Neural Information Processing Systems, volume 33, pages 1877–1901. Curran Associates, Inc.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15678.958984375\n",
      "page_content='[5]\tD. Chen, A. Fisch, J. Weston, and A. Bordes. Reading wikipedia to answer open-domain questions. arXiv preprint arXiv:1704.00051, 2017.\n",
      "[6]\tA. Chowdhery, S. Narang, J. Devlin, M. Bosma, G. Mishra, A. Roberts, P. Barham, H. W. Chung, C. Sutton, S. Gehrmann, P. Schuh, K. Shi, S. Tsvyashchenko, J. Maynez, A. Rao, P. Barnes, Y. Tay, N. Shazeer, V. Prabhakaran, E. Reif, N. Du, B. Hutchinson, R. Pope, J. Bradbury, J. Austin, M. Isard, G. Gur-Ari, P. Yin, T. Duke, A. Levskaya, S. Ghe-mawat, S. Dev, H. Michalewski, X. Garcia, V. Misra, K. Robinson, L. Fedus, D. Zhou, D. Ippolito, D. Luan, H. Lim, B. Zoph, A. Spiridonov, R. Sepassi, D. Dohan, S. Agrawal, M. Omernick, A. M. Dai, T. S. Pillai, M. Pellat, A. Lewkowycz, E. Moreira, R. Child, O. Polozov, K. Lee, Z. Zhou, X. Wang, B. Saeta, M. Diaz, O. Firat, M. Catasta, J. Wei, K. Meier-Hellstern, D. Eck, J. Dean, S. Petrov, and N. Fiedel. Palm: Scaling language modeling with pathways, 2022.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15678.958984375\n",
      "page_content='[5]\tD. Chen, A. Fisch, J. Weston, and A. Bordes. Reading wikipedia to answer open-domain questions. arXiv preprint arXiv:1704.00051, 2017.\n",
      "[6]\tA. Chowdhery, S. Narang, J. Devlin, M. Bosma, G. Mishra, A. Roberts, P. Barham, H. W. Chung, C. Sutton, S. Gehrmann, P. Schuh, K. Shi, S. Tsvyashchenko, J. Maynez, A. Rao, P. Barnes, Y. Tay, N. Shazeer, V. Prabhakaran, E. Reif, N. Du, B. Hutchinson, R. Pope, J. Bradbury, J. Austin, M. Isard, G. Gur-Ari, P. Yin, T. Duke, A. Levskaya, S. Ghe-mawat, S. Dev, H. Michalewski, X. Garcia, V. Misra, K. Robinson, L. Fedus, D. Zhou, D. Ippolito, D. Luan, H. Lim, B. Zoph, A. Spiridonov, R. Sepassi, D. Dohan, S. Agrawal, M. Omernick, A. M. Dai, T. S. Pillai, M. Pellat, A. Lewkowycz, E. Moreira, R. Child, O. Polozov, K. Lee, Z. Zhou, X. Wang, B. Saeta, M. Diaz, O. Firat, M. Catasta, J. Wei, K. Meier-Hellstern, D. Eck, J. Dean, S. Petrov, and N. Fiedel. Palm: Scaling language modeling with pathways, 2022.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15746.5009765625\n",
      "page_content='GPT-4 (OpenAI, 2023), Bard (Google, 2023), LLaMA (Touvron et al., 2023a;b)) has further revolutionized the NLP community and given intriguing insights into IR applications as users can now interact with search systems in natural languages.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Feng 等 - 2023 - Synergistic Interplay between Search and Large Language Models for Information Retrieval.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15746.5009765625\n",
      "page_content='GPT-4 (OpenAI, 2023), Bard (Google, 2023), LLaMA (Touvron et al., 2023a;b)) has further revolutionized the NLP community and given intriguing insights into IR applications as users can now interact with search systems in natural languages.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Feng 等 - 2023 - Synergistic Interplay between Search and Large Language Models for Information Retrieval.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15748.947265625\n",
      "page_content='The merits for the incorporation of clue finding and reasonings are as follows: (1) it prompts the model to progressively think and make decisions: clue finding focuses more on superficial features such as keywords, while reasoning makes deeper justifications based on superficial features. This process better mimics how we humans decide; (2) clue finding and reasoning serve as a tunnel to let human intervene: in the few-shot setup, where clues and reasons need to be prepared in advance for demonstrations, we can modify them as we see fit. This is extremely helpful for trouble shooting in the prompt-construction stage for error corrections; (3) from an interpretation and uncertainty estimation perspective, clues and reasoning in few-shot setups are human-readable influence functions; (4) in contrast to list annotated (text, label) pairs in few-shot setups, incorporating clues and reasoning process in prompts aligns closer with the instruction tuning objective. The discrepancy between' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15748.947265625\n",
      "page_content='The merits for the incorporation of clue finding and reasonings are as follows: (1) it prompts the model to progressively think and make decisions: clue finding focuses more on superficial features such as keywords, while reasoning makes deeper justifications based on superficial features. This process better mimics how we humans decide; (2) clue finding and reasoning serve as a tunnel to let human intervene: in the few-shot setup, where clues and reasons need to be prepared in advance for demonstrations, we can modify them as we see fit. This is extremely helpful for trouble shooting in the prompt-construction stage for error corrections; (3) from an interpretation and uncertainty estimation perspective, clues and reasoning in few-shot setups are human-readable influence functions; (4) in contrast to list annotated (text, label) pairs in few-shot setups, incorporating clues and reasoning process in prompts aligns closer with the instruction tuning objective. The discrepancy between' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15805.1923828125\n",
      "page_content='5.2.2\tListwise Methods\n",
      "Listwise methods [159, 160] aim to directly rank a list of documents (see Figure 5 (b)). These methods insert the query and a document list into the prompt and instruct the LLMs to output the reranked document identifiers. Due to the limited input length of LLMs, it is not feasible to insert all candidate documents into the prompt. To alleviate this issue, these methods employ a sliding window strategy to rerank a subset of candidate documents each time. This strategy involves ranking from back to front using a sliding window, re-ranking only the documents within the window at a time.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15805.1923828125\n",
      "page_content='5.2.2\tListwise Methods\n",
      "Listwise methods [159, 160] aim to directly rank a list of documents (see Figure 5 (b)). These methods insert the query and a document list into the prompt and instruct the LLMs to output the reranked document identifiers. Due to the limited input length of LLMs, it is not feasible to insert all candidate documents into the prompt. To alleviate this issue, these methods employ a sliding window strategy to rerank a subset of candidate documents each time. This strategy involves ranking from back to front using a sliding window, re-ranking only the documents within the window at a time.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15807.240234375\n",
      "page_content='[461]\tChatGPT, GPT-4\tQuestion Answering\tZS, FS\tOut-of-Distribution\tGeneral\tEnglish\n",
      "[462]\tChatGPT\tText-to-SQL Generation\tZS\tAdversarial Input\tGeneral\tEnglish\n",
      "TABLE 21. Summary of research works exploring GLLMs robustness to out-of-distribution instances, adversarial prompts and adversarial inputs. Here ZS represents zero-shot, and FS represents few-shot.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15807.240234375\n",
      "page_content='[461]\tChatGPT, GPT-4\tQuestion Answering\tZS, FS\tOut-of-Distribution\tGeneral\tEnglish\n",
      "[462]\tChatGPT\tText-to-SQL Generation\tZS\tAdversarial Input\tGeneral\tEnglish\n",
      "TABLE 21. Summary of research works exploring GLLMs robustness to out-of-distribution instances, adversarial prompts and adversarial inputs. Here ZS represents zero-shot, and FS represents few-shot.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15841.54296875\n",
      "page_content='Some of the research works [254], [255], [262] explored advanced prompting like CoT, brainstorming, differential prompting, etc., for coding tasks. Liu et al. [255] evaluated the code generation capabilities of ChatGPT by evaluating its performances on text-to-code and code-to-code generation tasks on CodeXGLUE [273] datasets. The authors observed that advanced prompting strategies like CoT enhance the code generation capabilities of models like ChatGPT. Li et al. [262] proposed Brainstorm, a new framework for code generation. Brainstorm involves three steps: brainstorming to generate diverse thoughts, thoughts selection to select the best thought using a ranking model and writing code to generate the code based on the problem statement and the best thought. The authors reported that the proposed framework helps ChatGPT to increase its performance by more than 50% and achieve new SOTA results on the CodeContests [104] benchmark. Li et al. [254] showed that directly using ChatGPT to' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15841.54296875\n",
      "page_content='Some of the research works [254], [255], [262] explored advanced prompting like CoT, brainstorming, differential prompting, etc., for coding tasks. Liu et al. [255] evaluated the code generation capabilities of ChatGPT by evaluating its performances on text-to-code and code-to-code generation tasks on CodeXGLUE [273] datasets. The authors observed that advanced prompting strategies like CoT enhance the code generation capabilities of models like ChatGPT. Li et al. [262] proposed Brainstorm, a new framework for code generation. Brainstorm involves three steps: brainstorming to generate diverse thoughts, thoughts selection to select the best thought using a ranking model and writing code to generate the code based on the problem statement and the best thought. The authors reported that the proposed framework helps ChatGPT to increase its performance by more than 50% and achieve new SOTA results on the CodeContests [104] benchmark. Li et al. [254] showed that directly using ChatGPT to' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15901.322265625\n",
      "page_content='strings into the prompt to measure model bias, and then uses model bias to adjust the model predictions on real inputs. Holtzman et al. (2021) find that language models divide the probability of the correct answer into multiple answer’s synonyms when making predictions. To address this issue, Holtzman et al. (2021) modify the predicted probabilities according to answer’s prior likelihood within the context. However, the above methods mainly focus on modifying the model output, and model bias still exists' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15901.322265625\n",
      "page_content='strings into the prompt to measure model bias, and then uses model bias to adjust the model predictions on real inputs. Holtzman et al. (2021) find that language models divide the probability of the correct answer into multiple answer’s synonyms when making predictions. To address this issue, Holtzman et al. (2021) modify the predicted probabilities according to answer’s prior likelihood within the context. However, the above methods mainly focus on modifying the model output, and model bias still exists' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15907.365234375\n",
      "page_content='that GPT-4 with IRSA prompting strategy outperforms ChatGPT in both zero and few-shot settings. IRSA stands for Instruction Response Semantic Alignment. IRSA prompting strategy is almost the same as direct prompting except that in the case of IRSA prompting, the model is instructed to give the labels “contain” and “not contain” instead of “entailment” and “not entailment”, just to reduce the complexity. Wang et al. [138] evaluated the performances of the latest LLMs like GPT-3.5, GPT-4, and Bard models on text classification tasks like natural language inference and document classification in the healthcare domain. The GPT-4 model with the newly designed self-question prompting (SQP) outperforms other models in both zero and few-shot settings. The SQP strategy involves identifying the key elements of input, generating questions and answers related to the key elements, and then using them to generate the final output. Parikh et al. [143] showed that the performance of the GPT-3 model' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15907.365234375\n",
      "page_content='that GPT-4 with IRSA prompting strategy outperforms ChatGPT in both zero and few-shot settings. IRSA stands for Instruction Response Semantic Alignment. IRSA prompting strategy is almost the same as direct prompting except that in the case of IRSA prompting, the model is instructed to give the labels “contain” and “not contain” instead of “entailment” and “not entailment”, just to reduce the complexity. Wang et al. [138] evaluated the performances of the latest LLMs like GPT-3.5, GPT-4, and Bard models on text classification tasks like natural language inference and document classification in the healthcare domain. The GPT-4 model with the newly designed self-question prompting (SQP) outperforms other models in both zero and few-shot settings. The SQP strategy involves identifying the key elements of input, generating questions and answers related to the key elements, and then using them to generate the final output. Parikh et al. [143] showed that the performance of the GPT-3 model' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15919.2900390625\n",
      "page_content='•\tPseudo query generation. Given the abundance of documents, a straightforward idea is to use LLMs for generating their corresponding pseudo queries. One such illustration is presented by inPairs [103], which leverages the in-context learning capability of GPT-3. This method employs a collection of query-document pairs as demonstrations. These pairs are combined with a document and presented as input to GPT-3, which subsequently generates possible relevant queries for the given document. By combining the same demonstration with various documents, it is easy to create a' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15919.2900390625\n",
      "page_content='•\tPseudo query generation. Given the abundance of documents, a straightforward idea is to use LLMs for generating their corresponding pseudo queries. One such illustration is presented by inPairs [103], which leverages the in-context learning capability of GPT-3. This method employs a collection of query-document pairs as demonstrations. These pairs are combined with a document and presented as input to GPT-3, which subsequently generates possible relevant queries for the given document. By combining the same demonstration with various documents, it is easy to create a' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15929.916015625\n",
      "page_content='Given the premise and hypothesis, please justify whether the HYPOTHESIS can be entailed from the PREMISE. Please return yes or no.\n",
      "PREMISE: <text>\n",
      "HYPOTHESIS: <reasoning-process>\n",
      "Evaluation results are shown in Table 11. As can be seen, the reliability percentages for SST-2 and R5 are higher than 95%. This indicates that it is feasible to use the model-generated reasoning process as part of the prompts to augment ICL performances. The perplexity of generated reasoning text is smaller than 4, which denotes that\n",
      "the generated reasoning text is fluent. And scores of logic faithful are larger than 93%, which is in line with our expectation that LLMs can generate reasonable explanations.\n",
      "7\tConclusion' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15929.916015625\n",
      "page_content='Given the premise and hypothesis, please justify whether the HYPOTHESIS can be entailed from the PREMISE. Please return yes or no.\n",
      "PREMISE: <text>\n",
      "HYPOTHESIS: <reasoning-process>\n",
      "Evaluation results are shown in Table 11. As can be seen, the reliability percentages for SST-2 and R5 are higher than 95%. This indicates that it is feasible to use the model-generated reasoning process as part of the prompts to augment ICL performances. The perplexity of generated reasoning text is smaller than 4, which denotes that\n",
      "the generated reasoning text is fluent. And scores of logic faithful are larger than 93%, which is in line with our expectation that LLMs can generate reasonable explanations.\n",
      "7\tConclusion' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15940.349609375\n",
      "page_content='The prompt for SST-2 is shown as follows:\n",
      "Is the following REASONING process supporting determinate sentiment label to INPUT? Please answer Yes or No.\n",
      "INPUT: <text>\n",
      "REASONING: <reasoning-process>\n",
      "where <text> is the text sequence for the data and <reasoning-process> is generated reasoning process.\n",
      "(2)\tFluency: use LLMs to generate reasoning explanations is a reference-free text generation task. We use perplexity to evaluate the generated text.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15940.349609375\n",
      "page_content='The prompt for SST-2 is shown as follows:\n",
      "Is the following REASONING process supporting determinate sentiment label to INPUT? Please answer Yes or No.\n",
      "INPUT: <text>\n",
      "REASONING: <reasoning-process>\n",
      "where <text> is the text sequence for the data and <reasoning-process> is generated reasoning process.\n",
      "(2)\tFluency: use LLMs to generate reasoning explanations is a reference-free text generation task. We use perplexity to evaluate the generated text.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15946.6064453125\n",
      "page_content='﻿A Preprint\n",
      "arXiv:2309.08181v1 [cs.CL] 15 Sep 2023\n",
      "® Michael Stewart\n",
      "Department of Computer Science and Software Engineering The University of Western Australia Perth, Western Australia michael.stewart@uwa.edu.au\n",
      "© Melinda Hodkiewicz School of Engineering The University of Western Australia Perth, Western Australia melinda.hodkiewicz@uwa.edu.au\n",
      "© Sirui Li\n",
      "Department of Computer Science and Software Engineering The University of Western Australia Perth, Western Australia sirui.li@uwa.edu.au\n",
      "September 18, 2023\n",
      "Abstract' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Stewart 等 - 2023 - Large Language Models for Failure Mode Classification An Investigation.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15946.6064453125\n",
      "page_content='﻿A Preprint\n",
      "arXiv:2309.08181v1 [cs.CL] 15 Sep 2023\n",
      "® Michael Stewart\n",
      "Department of Computer Science and Software Engineering The University of Western Australia Perth, Western Australia michael.stewart@uwa.edu.au\n",
      "© Melinda Hodkiewicz School of Engineering The University of Western Australia Perth, Western Australia melinda.hodkiewicz@uwa.edu.au\n",
      "© Sirui Li\n",
      "Department of Computer Science and Software Engineering The University of Western Australia Perth, Western Australia sirui.li@uwa.edu.au\n",
      "September 18, 2023\n",
      "Abstract' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Stewart 等 - 2023 - Large Language Models for Failure Mode Classification An Investigation.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15948.6201171875\n",
      "page_content='4.2.2\tGenerative Retriever' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15948.6201171875\n",
      "page_content='4.2.2\tGenerative Retriever' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15970.1025390625\n",
      "page_content='need for better approaches which can reliably detect GLLM generated text and also robust to various attacks, including paraphrasing. With reliable and robust detection approaches, the misuse of GLLMs for various illegal activities can be reduced to a great extent.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 15970.1025390625\n",
      "page_content='need for better approaches which can reliably detect GLLM generated text and also robust to various attacks, including paraphrasing. With reliable and robust detection approaches, the misuse of GLLMs for various illegal activities can be reduced to a great extent.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16057.826171875\n",
      "page_content='[224]\tH. Wang, R. Wang, F. Mi, Z. Wang, R. Xu, and K.-F. Wong, “Chain-of-thought prompting for responding to in-depth dialogue questions with llm,” arXiv preprint arXiv:2305.11792, 2023.\n",
      "[225]\tR. Meng, X. Yuan, T. Wang, S. Zhao, A. Trischler, and D. He, “An empirical study on neural keyphrase generation,” in Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, 2021, pp. 4985–5007.\n",
      "[226]\tX. Yuan, T. Wang, R. Meng, K. Thaker, P. Brusilovsky, D. He, and A. Trischler, “One size does not fit all: Generating and evaluating variable number of keyphrases,” in Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, 2020, pp. 7961–7975.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16057.826171875\n",
      "page_content='[224]\tH. Wang, R. Wang, F. Mi, Z. Wang, R. Xu, and K.-F. Wong, “Chain-of-thought prompting for responding to in-depth dialogue questions with llm,” arXiv preprint arXiv:2305.11792, 2023.\n",
      "[225]\tR. Meng, X. Yuan, T. Wang, S. Zhao, A. Trischler, and D. He, “An empirical study on neural keyphrase generation,” in Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, 2021, pp. 4985–5007.\n",
      "[226]\tX. Yuan, T. Wang, R. Meng, K. Thaker, P. Brusilovsky, D. He, and A. Trischler, “One size does not fit all: Generating and evaluating variable number of keyphrases,” in Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, 2020, pp. 7961–7975.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16074.125\n",
      "page_content='Prompts\tSST-2\tR8\n",
      "CARP\t96.80\t98.29\n",
      "w/o Text\t92.28\t94.18\n",
      "w/o Clue\t95.48\t95.29\n",
      "w/o Reason\t95.72\t97.82\n",
      "w/o Label\t96.53\t98.18\n",
      "Table 7: The effect of components on the SST-2 dataset with different strategies.\n",
      "Prompts\tSST-2\tR8\n",
      "Clues\t96.80\t98.29\n",
      "w/o keyword&phrase\t96.21\t96.91\n",
      "w/o contextual info.\t96.23\t97.10\n",
      "w/o semantic relations\t96.30\t97.38\n",
      "w/o tones\t96.40\t97.35\n",
      "w/o reference\t96.50\t97.19\n",
      "Table 9: Label words and results on the SST-2 dataset with different strategies.\n",
      "Strategy\tLabel Words(+,-)\tCARP\n",
      "Position Index\tOne, Two\t95.66\n",
      "Annotation Words\tPositive, Negative\t96.86\n",
      "Synonyms Words\tGreat, Terrible\t96.27\n",
      "Flipped Words\tNegative, Positive\t64.63\n",
      "Random Words\tCf, Ng\t95.06\n",
      "Special Tokens\t<POS>, <NEG>\t96.65\n",
      "Table 8: Label words and results on the SST-2 dataset with different strategies. \"+\" represents positive polarity; \"-\" denotes negative polarity.\n",
      "impact of the final results. When (text, clue, reason) as demonstrations, the label has effect to the performances.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16074.125\n",
      "page_content='Prompts\tSST-2\tR8\n",
      "CARP\t96.80\t98.29\n",
      "w/o Text\t92.28\t94.18\n",
      "w/o Clue\t95.48\t95.29\n",
      "w/o Reason\t95.72\t97.82\n",
      "w/o Label\t96.53\t98.18\n",
      "Table 7: The effect of components on the SST-2 dataset with different strategies.\n",
      "Prompts\tSST-2\tR8\n",
      "Clues\t96.80\t98.29\n",
      "w/o keyword&phrase\t96.21\t96.91\n",
      "w/o contextual info.\t96.23\t97.10\n",
      "w/o semantic relations\t96.30\t97.38\n",
      "w/o tones\t96.40\t97.35\n",
      "w/o reference\t96.50\t97.19\n",
      "Table 9: Label words and results on the SST-2 dataset with different strategies.\n",
      "Strategy\tLabel Words(+,-)\tCARP\n",
      "Position Index\tOne, Two\t95.66\n",
      "Annotation Words\tPositive, Negative\t96.86\n",
      "Synonyms Words\tGreat, Terrible\t96.27\n",
      "Flipped Words\tNegative, Positive\t64.63\n",
      "Random Words\tCf, Ng\t95.06\n",
      "Special Tokens\t<POS>, <NEG>\t96.65\n",
      "Table 8: Label words and results on the SST-2 dataset with different strategies. \"+\" represents positive polarity; \"-\" denotes negative polarity.\n",
      "impact of the final results. When (text, clue, reason) as demonstrations, the label has effect to the performances.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16090.013671875\n",
      "page_content='using a novel pivot prompting strategy, which involves translating into high resource language before translating into the target low resource language. The naive prompts are unable to elicit the translation ability of ChatGPT fully. So, Gao et al. [200] focused on developing advanced prompting strategies by including additional information like task information, domain information and syntactic information like PoS (parts of speech) tags. The authors showed that ChatGPT, with the proposed advanced prompting strategy, achieves promising results and even outperforms commercial systems like Google Translate and DeepL Translate. Wang et al. [201] examined the performances of ChatGPT and GPT-4 for document-level machine translation and also compared the results with commercial systems from Google, DeepL and Tencent. The authors reported that GLLMs do well when the' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16090.013671875\n",
      "page_content='using a novel pivot prompting strategy, which involves translating into high resource language before translating into the target low resource language. The naive prompts are unable to elicit the translation ability of ChatGPT fully. So, Gao et al. [200] focused on developing advanced prompting strategies by including additional information like task information, domain information and syntactic information like PoS (parts of speech) tags. The authors showed that ChatGPT, with the proposed advanced prompting strategy, achieves promising results and even outperforms commercial systems like Google Translate and DeepL Translate. Wang et al. [201] examined the performances of ChatGPT and GPT-4 for document-level machine translation and also compared the results with commercial systems from Google, DeepL and Tencent. The authors reported that GLLMs do well when the' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16096.5126953125\n",
      "page_content='courses. Experiment results showed that MCQs with code snippets have lower success rates compared to those without code, indicating a challenge in answering multiple-choice questions with code snippets. Pereira et al.[189] presented Visconde, a novel framework based on the GPT-3.5 model to tackle multi-document question answering. Visconde follows a three-step process involving decomposition, retrieval, and aggregation. The decomposition phase uses the GPT-3.5 model in fewshot settings for question simplification, the retrieval stage uses the SOTA model to select the relevant text chunks, and the final aggregation phase uses the GPT-3.5 with few-shot CoT prompting to get the answer. The authors observed that CoT prompting, i.e., generating reasoning steps before generating the final answer, enhances the performance. Weng et al. [193] enhanced the performance of GLLMs in answering medical conversational questions in English and Chinese using a novel prompt strategy called Holistically' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16096.5126953125\n",
      "page_content='courses. Experiment results showed that MCQs with code snippets have lower success rates compared to those without code, indicating a challenge in answering multiple-choice questions with code snippets. Pereira et al.[189] presented Visconde, a novel framework based on the GPT-3.5 model to tackle multi-document question answering. Visconde follows a three-step process involving decomposition, retrieval, and aggregation. The decomposition phase uses the GPT-3.5 model in fewshot settings for question simplification, the retrieval stage uses the SOTA model to select the relevant text chunks, and the final aggregation phase uses the GPT-3.5 with few-shot CoT prompting to get the answer. The authors observed that CoT prompting, i.e., generating reasoning steps before generating the final answer, enhances the performance. Weng et al. [193] enhanced the performance of GLLMs in answering medical conversational questions in English and Chinese using a novel prompt strategy called Holistically' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16113.455078125\n",
      "page_content='Label Word\tPrediction Label Word\t\t\t\n",
      "\tpolitics\tsports\tbusiness\ttechnology\n",
      "politics\t356\t310\t1217\t17\n",
      "sports\t2\t1876\t22\t0\n",
      "business\t14\t15\t1767\t104\n",
      "technology\t20\t90\t699\t1091\n",
      "(a)\n",
      "Label Word\tPrediction Label Word\t\t\t\n",
      "\tpolitics\tsports\tbusiness\ttechnology\n",
      "politics\t1214\t80\t240\t366\n",
      "sports\t41\t1774\t22\t63\n",
      "business\t212\t17\t885\t786\n",
      "technology\t63\t26\t85\t1726\n",
      "(b)\n",
      "Figure 1: Illustration of RoBERTa-large model bias on AG’s News label words under different templates. (a) Template: A [mask] news: x. (b) Template: x This topic is about [mask] .\n",
      "politics sports\n",
      "business technology' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16113.455078125\n",
      "page_content='Label Word\tPrediction Label Word\t\t\t\n",
      "\tpolitics\tsports\tbusiness\ttechnology\n",
      "politics\t356\t310\t1217\t17\n",
      "sports\t2\t1876\t22\t0\n",
      "business\t14\t15\t1767\t104\n",
      "technology\t20\t90\t699\t1091\n",
      "(a)\n",
      "Label Word\tPrediction Label Word\t\t\t\n",
      "\tpolitics\tsports\tbusiness\ttechnology\n",
      "politics\t1214\t80\t240\t366\n",
      "sports\t41\t1774\t22\t63\n",
      "business\t212\t17\t885\t786\n",
      "technology\t63\t26\t85\t1726\n",
      "(b)\n",
      "Figure 1: Illustration of RoBERTa-large model bias on AG’s News label words under different templates. (a) Template: A [mask] news: x. (b) Template: x This topic is about [mask] .\n",
      "politics sports\n",
      "business technology' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16119.0400390625\n",
      "page_content='[184]\tI. Joshi, R. Budhiraja, H. Dev, J. Kadia, M. O. Ataullah, S. Mitra, D. Kumar, and H. D. Akolekar, “Chatgpt–a blessing or a curse for undergraduate computer science students and instructors?” arXiv preprint arXiv:2304.14993, 2023.\n",
      "[185]\tH. Nori, N. King, S. M. McKinney, D. Carignan, and E. Horvitz, “Capabilities of gpt-4 on medical challenge problems,” arXiv preprint arXiv:2303.13375, 2023.\n",
      "[186]\tA. Hamidi and K. Roberts, “Evaluation of ai chatbots for patientspecific ehr questions,” arXiv preprint arXiv:2306.02549, 2023.\n",
      "[187]\tJ. Savelka, A. Agarwal, C. Bogart, and M. Sakr, “Large language models (gpt) struggle to answer multiple-choice questions about code,” arXiv preprint arXiv:2303.08033, 2023.\n",
      "[188]\tM. Bommarito II and D. M. Katz, “Gpt takes the bar exam,” arXiv preprint arXiv:2212.14402, 2022.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16119.0400390625\n",
      "page_content='[184]\tI. Joshi, R. Budhiraja, H. Dev, J. Kadia, M. O. Ataullah, S. Mitra, D. Kumar, and H. D. Akolekar, “Chatgpt–a blessing or a curse for undergraduate computer science students and instructors?” arXiv preprint arXiv:2304.14993, 2023.\n",
      "[185]\tH. Nori, N. King, S. M. McKinney, D. Carignan, and E. Horvitz, “Capabilities of gpt-4 on medical challenge problems,” arXiv preprint arXiv:2303.13375, 2023.\n",
      "[186]\tA. Hamidi and K. Roberts, “Evaluation of ai chatbots for patientspecific ehr questions,” arXiv preprint arXiv:2306.02549, 2023.\n",
      "[187]\tJ. Savelka, A. Agarwal, C. Bogart, and M. Sakr, “Large language models (gpt) struggle to answer multiple-choice questions about code,” arXiv preprint arXiv:2303.08033, 2023.\n",
      "[188]\tM. Bommarito II and D. M. Katz, “Gpt takes the bar exam,” arXiv preprint arXiv:2212.14402, 2022.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16165.404296875\n",
      "page_content='Fine-tuning (FT). The fine-tuning method adds a random-initialized classification head on top of the PLM. The classification head takes the last hidden states of the [cls] token as input and makes predictions. Fine-tuning updates the model parameters and the classification head parameters during training.\n",
      "Prompt-tuning (PT). Proposed by GPT-3 (Brown et al., 2020) and PET (Schick and Schütze, 2021a), the prompt-tuning method converts input examples into cloze questions and maps PLM’s prediction words on the [mask] token to classes via the verbalizer. For a fair comparison, all prompt-based methods use the same templates and verbalizers.\n",
      "Contextual Calibration (CC). Contextual calibration is proposed by Zhao et al. (2021). They first evaluate model bias on label words by concatenating a content-free text at the end of the prompt as input to GPT-3. Then they calibrate the model predictions by element-wisely dividing model bias.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16165.404296875\n",
      "page_content='Fine-tuning (FT). The fine-tuning method adds a random-initialized classification head on top of the PLM. The classification head takes the last hidden states of the [cls] token as input and makes predictions. Fine-tuning updates the model parameters and the classification head parameters during training.\n",
      "Prompt-tuning (PT). Proposed by GPT-3 (Brown et al., 2020) and PET (Schick and Schütze, 2021a), the prompt-tuning method converts input examples into cloze questions and maps PLM’s prediction words on the [mask] token to classes via the verbalizer. For a fair comparison, all prompt-based methods use the same templates and verbalizers.\n",
      "Contextual Calibration (CC). Contextual calibration is proposed by Zhao et al. (2021). They first evaluate model bias on label words by concatenating a content-free text at the end of the prompt as input to GPT-3. Then they calibrate the model predictions by element-wisely dividing model bias.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16178.2353515625\n",
      "page_content='First, list CLUES (i.e., keywords, phrases, contextual information, semantic relations, semantic meaning, tones, references) that support the sentiment determination of input..\n",
      "Second, deduce the diagnostic REASONING process from premises (i.e., clues, input) that supports the INPUT sentiment determination (Limit the number of words to 130).\n",
      "Third, based on clues, reasoning and input, determine the overall SENTIMENT of INPUT as Positive or Negative.\n",
      "(c)\tINPUT: press the delete key\n",
      "CLUES: delete key\n",
      "REASONING: The phrase \"delete key\" implies an action of removing something, which could be interpreted as a negative sentiment.\n",
      "SENTIMENT: Negative\n",
      "Figure 1: Examples of zero-shot prompting methods for the text classification task: (a) represents for the vanilla prompting method; (b) denotes for the Chain-of-Thought (CoT) (Kojima et al., 2022) prompting method; c represents for the proposed CARP prompting method.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16178.2353515625\n",
      "page_content='First, list CLUES (i.e., keywords, phrases, contextual information, semantic relations, semantic meaning, tones, references) that support the sentiment determination of input..\n",
      "Second, deduce the diagnostic REASONING process from premises (i.e., clues, input) that supports the INPUT sentiment determination (Limit the number of words to 130).\n",
      "Third, based on clues, reasoning and input, determine the overall SENTIMENT of INPUT as Positive or Negative.\n",
      "(c)\tINPUT: press the delete key\n",
      "CLUES: delete key\n",
      "REASONING: The phrase \"delete key\" implies an action of removing something, which could be interpreted as a negative sentiment.\n",
      "SENTIMENT: Negative\n",
      "Figure 1: Examples of zero-shot prompting methods for the text classification task: (a) represents for the vanilla prompting method; (b) denotes for the Chain-of-Thought (CoT) (Kojima et al., 2022) prompting method; c represents for the proposed CARP prompting method.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16187.5224609375\n",
      "page_content='•\tWe pinpoint the problem of redundant retrieval within the current RAG system. To address this efficiency concern, we introduce the Memory Knowledge Reservoir and the Retrieval Trigger module.\n",
      "•\tEmpirical evaluations and ablation studies across six QA datasets demonstrate the superior response accuracy and enhanced efficiency of our methods. Overall, our approach yields a 5%-10% increase in correctly hitting the target answers compared to direct inquiry. For historically similar questions, our method reduces the response time by 46% without compromising the response quality.\n",
      "2\tMotivation\n",
      "In this section, we empirically investigate several preliminary studies to highlight the limitations of current RAG systems in Open-Domain QA tasks.\n",
      "•\tPS 1: We investigate the maximum amount of relevant information that can be retrieved by converting input text into a single\n",
      "search-friendly query.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16187.5224609375\n",
      "page_content='•\tWe pinpoint the problem of redundant retrieval within the current RAG system. To address this efficiency concern, we introduce the Memory Knowledge Reservoir and the Retrieval Trigger module.\n",
      "•\tEmpirical evaluations and ablation studies across six QA datasets demonstrate the superior response accuracy and enhanced efficiency of our methods. Overall, our approach yields a 5%-10% increase in correctly hitting the target answers compared to direct inquiry. For historically similar questions, our method reduces the response time by 46% without compromising the response quality.\n",
      "2\tMotivation\n",
      "In this section, we empirically investigate several preliminary studies to highlight the limitations of current RAG systems in Open-Domain QA tasks.\n",
      "•\tPS 1: We investigate the maximum amount of relevant information that can be retrieved by converting input text into a single\n",
      "search-friendly query.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16189.70703125\n",
      "page_content='politics sports business □\n",
      "Bias-removed Pre-trained Language Model\n",
      "unlabeled validation train\n",
      "J Labeled Examples\n",
      "Elon Musk announced the acquisition of Twitter and became its CEO.\n",
      "The next World Cup will be hosted by the US, Mexico and Canada.\n",
      "PLM mask prediction\n",
      "technology □\n",
      "□\n",
      "______Business(\n",
      "Elon Musk announced the acquisition of Twitter and became its CEO.\n",
      "___Sports__________\n",
      "The next World Cup will be hosted by the US, Mexico and Canada.\n",
      "annotation & refinement\n",
      "politics sports business' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16189.70703125\n",
      "page_content='politics sports business □\n",
      "Bias-removed Pre-trained Language Model\n",
      "unlabeled validation train\n",
      "J Labeled Examples\n",
      "Elon Musk announced the acquisition of Twitter and became its CEO.\n",
      "The next World Cup will be hosted by the US, Mexico and Canada.\n",
      "PLM mask prediction\n",
      "technology □\n",
      "□\n",
      "______Business(\n",
      "Elon Musk announced the acquisition of Twitter and became its CEO.\n",
      "___Sports__________\n",
      "The next World Cup will be hosted by the US, Mexico and Canada.\n",
      "annotation & refinement\n",
      "politics sports business' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16194.5751953125\n",
      "page_content='[221]\tG. P. Prodan and E. Pelican, “Prompt scoring system for dialogue summarization using gpt-3,” ACM Transaction on Audio, Speech, and Language Processing, pp. 1–9, 2022.\n",
      "[222]\tJ. Huynh, C. Jiao, P. Gupta, S. Mehri, P. Bajaj, V. Chaudhary, and M. Eskenazi, “Understanding the effectiveness of very large language models on dialog evaluation,” arXiv preprint arXiv:2301.12004, 2023.\n",
      "[223]\tY. Fan and F. Jiang, “Uncovering the potential of chatgpt for discourse analysis in dialogue: An empirical study,” arXiv preprint arXiv:2305.08391, 2023.\n",
      "[224]\tH. Wang, R. Wang, F. Mi, Z. Wang, R. Xu, and K.-F. Wong, “Chain-of-thought prompting for responding to in-depth dialogue questions with llm,” arXiv preprint arXiv:2305.11792, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16194.5751953125\n",
      "page_content='[221]\tG. P. Prodan and E. Pelican, “Prompt scoring system for dialogue summarization using gpt-3,” ACM Transaction on Audio, Speech, and Language Processing, pp. 1–9, 2022.\n",
      "[222]\tJ. Huynh, C. Jiao, P. Gupta, S. Mehri, P. Bajaj, V. Chaudhary, and M. Eskenazi, “Understanding the effectiveness of very large language models on dialog evaluation,” arXiv preprint arXiv:2301.12004, 2023.\n",
      "[223]\tY. Fan and F. Jiang, “Uncovering the potential of chatgpt for discourse analysis in dialogue: An empirical study,” arXiv preprint arXiv:2305.08391, 2023.\n",
      "[224]\tH. Wang, R. Wang, F. Mi, Z. Wang, R. Xu, and K.-F. Wong, “Chain-of-thought prompting for responding to in-depth dialogue questions with llm,” arXiv preprint arXiv:2305.11792, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16194.869140625\n",
      "page_content='5.2.3\tPairwise Methods\n",
      "In pairwise methods, LLMs are given a prompt that consists of a query and a document pair (see Figure 5 (c)). Then, they are instructed to generate the identifier of the document with higher relevance. To rerank all candidate documents, aggregation methods like AllPairs are used [164]. AllPairs first generates all possible document pairs, yields discrete judgments for each pair (e.g., Document 1 or Document 2), and aggregates a final relevance score for each document. Efficient sorting algorithms, such as heap sort and' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16194.869140625\n",
      "page_content='5.2.3\tPairwise Methods\n",
      "In pairwise methods, LLMs are given a prompt that consists of a query and a document pair (see Figure 5 (c)). Then, they are instructed to generate the identifier of the document with higher relevance. To rerank all candidate documents, aggregation methods like AllPairs are used [164]. AllPairs first generates all possible document pairs, yields discrete judgments for each pair (e.g., Document 1 or Document 2), and aggregates a final relevance score for each document. Efficient sorting algorithms, such as heap sort and' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16223.0771484375\n",
      "page_content='[451]\tL. Yang, F. Jiang, and H. Li, “Is chatgpt involved in texts? measure the polish ratio to detect chatgpt-generated text,” ArXiv, vol. abs/2307.11380, 2023.\n",
      "[452]\tK. Krishna, Y. Song, M. Karpinska, J. Wieting, and M. Iyyer, “Paraphrasing evades detectors of ai-generated text, but retrieval is an effective defense,” arXiv preprint arXiv:2303.13408, 2023.\n",
      "[453]\tD. Ippolito, D. Duckworth, C. Callison-Burch, and D. Eck, “Automatic detection of generated text is easiest when humans are\n",
      "fooled,” in Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, 2020, pp. 1808–1822.\n",
      "[454]\tS. M. Lundberg and S.-I. Lee, “A unified approach to interpreting model predictions,” Advances in neural information processing systems, vol. 30, 2017.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16223.0771484375\n",
      "page_content='[451]\tL. Yang, F. Jiang, and H. Li, “Is chatgpt involved in texts? measure the polish ratio to detect chatgpt-generated text,” ArXiv, vol. abs/2307.11380, 2023.\n",
      "[452]\tK. Krishna, Y. Song, M. Karpinska, J. Wieting, and M. Iyyer, “Paraphrasing evades detectors of ai-generated text, but retrieval is an effective defense,” arXiv preprint arXiv:2303.13408, 2023.\n",
      "[453]\tD. Ippolito, D. Duckworth, C. Callison-Burch, and D. Eck, “Automatic detection of generated text is easiest when humans are\n",
      "fooled,” in Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, 2020, pp. 1808–1822.\n",
      "[454]\tS. M. Lundberg and S.-I. Lee, “A unified approach to interpreting model predictions,” Advances in neural information processing systems, vol. 30, 2017.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16246.8349609375\n",
      "page_content='does not work spilling spraying out slurry\tThe failure mode of the observation \"does not work\" is a breakdown. The failure mode of the observation \"spillage\" is a leakage. The failure mode of the observation \"spraying out slurry\" is leaking.\n",
      "Table 1: Some examples of predictions made by the off-the-shelf GPT-3.5-Turbo on a sample of the test data. The system-level prompt is “Determine the failure mode of the observation provided by the user.”\n",
      "assistant-level prompt is the desired input from the LLM (this is used when fine-tuning to inform the model of the expected output).' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Stewart 等 - 2023 - Large Language Models for Failure Mode Classification An Investigation.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16246.8349609375\n",
      "page_content='does not work spilling spraying out slurry\tThe failure mode of the observation \"does not work\" is a breakdown. The failure mode of the observation \"spillage\" is a leakage. The failure mode of the observation \"spraying out slurry\" is leaking.\n",
      "Table 1: Some examples of predictions made by the off-the-shelf GPT-3.5-Turbo on a sample of the test data. The system-level prompt is “Determine the failure mode of the observation provided by the user.”\n",
      "assistant-level prompt is the desired input from the LLM (this is used when fine-tuning to inform the model of the expected output).' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Stewart 等 - 2023 - Large Language Models for Failure Mode Classification An Investigation.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16248.283203125\n",
      "page_content='due to the limited computing resources, many methods [186, 187, 195, 198] choose to prompt LLMs for generation as they could use larger LMs in this way. Furthermore, to improve the quality of the generated answers, several approaches [188, 199] also try to train or prompt the LLMs to generate contexts such as citations or notes in addition to the answers to force LLMs to understand and assess the relevance of retrieved passages to the user queries. ActiveRAG [200] and PG-RAG [201] improve them by using knowledge construction during the answer generation process. Some approaches [196, 202] evaluate the importance of each retrieved reference using policy gradients to indicate which reference is more useful for generating. Specifically, [202] utilize LLMs themselves to provide importance for different references which also supply additional training signals. Besides, researchers explore instruction tuning LLMs such LLaMAs to improve' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16248.283203125\n",
      "page_content='due to the limited computing resources, many methods [186, 187, 195, 198] choose to prompt LLMs for generation as they could use larger LMs in this way. Furthermore, to improve the quality of the generated answers, several approaches [188, 199] also try to train or prompt the LLMs to generate contexts such as citations or notes in addition to the answers to force LLMs to understand and assess the relevance of retrieved passages to the user queries. ActiveRAG [200] and PG-RAG [201] improve them by using knowledge construction during the answer generation process. Some approaches [196, 202] evaluate the importance of each retrieved reference using policy gradients to indicate which reference is more useful for generating. Specifically, [202] utilize LLMs themselves to provide importance for different references which also supply additional training signals. Besides, researchers explore instruction tuning LLMs such LLaMAs to improve' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16286.50390625\n",
      "page_content='PS2: The Effect of Using Multiple Queries. The analysis of An-\n",
      "Figure 2: PS1 & PS2. Analysis of Information Plateaus in Retrieving Knowledge and Overcoming the Bottlenecks with New Queries.\n",
      "swer Recall in Sequence Order indicates that introducing fresh snippets from new queries effectively mitigates plateauing in Answer Recall (light purple solid line). Additionally, the Answer Recall in Mixed Order consistently outperforms that in Sequence Order at the same snippet number (purple solid line), particularly when the number has not yet reached the maximum retrievable information limit (30 snippets). This underscores the significance of multiple queries in enhancing retrieval quality.\n",
      "PS3: The Low Relevance of Retrieved Information. As shown in Figure 2, Snippet Precision notably decreases as the number of snippets increases, eventually stabilizing. This suggests a significant presence of retrieved external knowledge snippets that do not contain relevant answer information.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16286.50390625\n",
      "page_content='PS2: The Effect of Using Multiple Queries. The analysis of An-\n",
      "Figure 2: PS1 & PS2. Analysis of Information Plateaus in Retrieving Knowledge and Overcoming the Bottlenecks with New Queries.\n",
      "swer Recall in Sequence Order indicates that introducing fresh snippets from new queries effectively mitigates plateauing in Answer Recall (light purple solid line). Additionally, the Answer Recall in Mixed Order consistently outperforms that in Sequence Order at the same snippet number (purple solid line), particularly when the number has not yet reached the maximum retrievable information limit (30 snippets). This underscores the significance of multiple queries in enhancing retrieval quality.\n",
      "PS3: The Low Relevance of Retrieved Information. As shown in Figure 2, Snippet Precision notably decreases as the number of snippets increases, eventually stabilizing. This suggests a significant presence of retrieved external knowledge snippets that do not contain relevant answer information.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16294.970703125\n",
      "page_content='task to sift through retrieved information and assess its relevance. This NLI model is also based on Gemma-2B and fine-tuned on a carefully designed dataset. The synergistic use of these two modules demonstrably enhances the accuracy of RAG responses across various datasets.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16294.970703125\n",
      "page_content='task to sift through retrieved information and assess its relevance. This NLI model is also based on Gemma-2B and fine-tuned on a carefully designed dataset. The synergistic use of these two modules demonstrably enhances the accuracy of RAG responses across various datasets.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16297.1005859375\n",
      "page_content='Finally, determine the sentiment of input as Positive or Negative considering clues, the reasoning process and the input.\n",
      "INPUT: <text>\n",
      "CLUES:\n",
      "4.2.1\tClue Collecting and Reasoning in few-shot\n",
      "In the few-shot setup , we need to prepare clues and reasonings for all examples in the training set in advance as all training examples have chances to be selected as demonstrations given different test inputs. Previous efforts in math problems (Wei et al., 2022b; Kojima et al., 2022; Ye and Durrett, 2022; Zhang et al., 2022b) prepare hand-drafted reasoning for a few examples, and always use these example as demonstrations. This strategy does not fit for our situation as it is extremely timeintensive to manually generate clues and reasonings for all training examples, To resolve this issue, we harness LLMs for automatic clue and reasoning generation, where we ask LLMs to generate clues and reasoning based on both the input and its corresponding label.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16297.1005859375\n",
      "page_content='Finally, determine the sentiment of input as Positive or Negative considering clues, the reasoning process and the input.\n",
      "INPUT: <text>\n",
      "CLUES:\n",
      "4.2.1\tClue Collecting and Reasoning in few-shot\n",
      "In the few-shot setup , we need to prepare clues and reasonings for all examples in the training set in advance as all training examples have chances to be selected as demonstrations given different test inputs. Previous efforts in math problems (Wei et al., 2022b; Kojima et al., 2022; Ye and Durrett, 2022; Zhang et al., 2022b) prepare hand-drafted reasoning for a few examples, and always use these example as demonstrations. This strategy does not fit for our situation as it is extremely timeintensive to manually generate clues and reasonings for all training examples, To resolve this issue, we harness LLMs for automatic clue and reasoning generation, where we ask LLMs to generate clues and reasoning based on both the input and its corresponding label.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16300.97265625\n",
      "page_content='enhances the performance. Weng et al. [193] enhanced the performance of GLLMs in answering medical conversational questions in English and Chinese using a novel prompt strategy called Holistically Thought (HoT). The HoT prompting strategy involves diffused thinking and focused thinking strategies to generate high-quality responses. Diffused thinking helps to generate various responses through diversified decoding, focused thinking generates a concise medical summary based on the dialogues and the final response is generated based on the dialogues, outputs of diffused thinking and focused thinking.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16300.97265625\n",
      "page_content='enhances the performance. Weng et al. [193] enhanced the performance of GLLMs in answering medical conversational questions in English and Chinese using a novel prompt strategy called Holistically Thought (HoT). The HoT prompting strategy involves diffused thinking and focused thinking strategies to generate high-quality responses. Diffused thinking helps to generate various responses through diversified decoding, focused thinking generates a concise medical summary based on the dialogues and the final response is generated based on the dialogues, outputs of diffused thinking and focused thinking.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16301.00390625\n",
      "page_content='where “{query}” and “{passages}” are the placeholders for q and D respectively from last RM step:\n",
      "s = G(q') = G(q ® p ® D)\t(4)\n",
      "Now the query q′ is refined and contains more plentiful information about q through retrieved documents D as demonstrations. Here we simply concatenate D for placeholder “{passages}”, which contains k retrieved documents from RM part for input of LLM G.\n",
      "4.3\tIterative Interplay B etween RM and LLM' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Feng 等 - 2023 - Synergistic Interplay between Search and Large Language Models for Information Retrieval.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16301.00390625\n",
      "page_content='where “{query}” and “{passages}” are the placeholders for q and D respectively from last RM step:\n",
      "s = G(q') = G(q ® p ® D)\t(4)\n",
      "Now the query q′ is refined and contains more plentiful information about q through retrieved documents D as demonstrations. Here we simply concatenate D for placeholder “{passages}”, which contains k retrieved documents from RM part for input of LLM G.\n",
      "4.3\tIterative Interplay B etween RM and LLM' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Feng 等 - 2023 - Synergistic Interplay between Search and Large Language Models for Information Retrieval.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16304.3056640625\n",
      "page_content='compared to random selection, showing that the demonstration selection in ranking task is a very challenging problem. The main challenge lies in the complex nature of query-document relationship, which requires effectively' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16304.3056640625\n",
      "page_content='compared to random selection, showing that the demonstration selection in ranking task is a very challenging problem. The main challenge lies in the complex nature of query-document relationship, which requires effectively' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16305.4609375\n",
      "page_content='[126]\tB. Lamichhane, “Evaluation of chatgpt for nlp-based mental health applications,” arXiv preprint arXiv:2303.15727, 2023.\n",
      "[127]\tK. Yang, S. Ji, T. Zhang, Q. Xie, and S. Ananiadou, “On the evaluations of chatgpt and emotion-enhanced prompting for mental health analysis,” arXiv preprint arXiv:2304.03347, 2023.\n",
      "[128]\tZ. Wang, Q. Xie, Z. Ding, Y. Feng, and R. Xia, “Is chatgpt a good sentiment analyzer? a preliminary study,” arXiv preprint arXiv:2304.04339, 2023.\n",
      "[129]\tA. Lopez-Lira and Y. Tang, “Can chatgpt forecast stock price movements? return predictability and large language models,” arXiv preprint arXiv:2304.07619, 2023.\n",
      "[130]\tC. Ziems, W. Held, O. Shaikh, J. Chen, Z. Zhang, and D. Yang, “Can large language models transform computational social science?” arXiv preprint arXiv:2305.03514, 2023.\n",
      "[131]\tT. Kuzman, N. Ljubesˇic´, and I. Mozeticˇ, “Chatgpt: Beginning of an end of manual annotation? use case of automatic genre identification,” arXiv preprint arXiv:2303.03953, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16305.4609375\n",
      "page_content='[126]\tB. Lamichhane, “Evaluation of chatgpt for nlp-based mental health applications,” arXiv preprint arXiv:2303.15727, 2023.\n",
      "[127]\tK. Yang, S. Ji, T. Zhang, Q. Xie, and S. Ananiadou, “On the evaluations of chatgpt and emotion-enhanced prompting for mental health analysis,” arXiv preprint arXiv:2304.03347, 2023.\n",
      "[128]\tZ. Wang, Q. Xie, Z. Ding, Y. Feng, and R. Xia, “Is chatgpt a good sentiment analyzer? a preliminary study,” arXiv preprint arXiv:2304.04339, 2023.\n",
      "[129]\tA. Lopez-Lira and Y. Tang, “Can chatgpt forecast stock price movements? return predictability and large language models,” arXiv preprint arXiv:2304.07619, 2023.\n",
      "[130]\tC. Ziems, W. Held, O. Shaikh, J. Chen, Z. Zhang, and D. Yang, “Can large language models transform computational social science?” arXiv preprint arXiv:2305.03514, 2023.\n",
      "[131]\tT. Kuzman, N. Ljubesˇic´, and I. Mozeticˇ, “Chatgpt: Beginning of an end of manual annotation? use case of automatic genre identification,” arXiv preprint arXiv:2303.03953, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16364.556640625\n",
      "page_content='-\t\"user_query\": a string, a random user sea rch query specified by the retrieval task.\n",
      "-\t\"positive_document\": a string, a relevant document for the user query.\n",
      "-\t\"hard_negative_document\": a string, a ha rd negative document that only a ppears relevant to the query.\n",
      "Please adhere to the following guidelines:\n",
      "-\tThe \"user_q uery\" should be {#Query_type}, {#Query_length}, {#Clarity}, and diverse in topic.\n",
      "-\tAll documents should be at least {#Num_words} words long.\n",
      "-\tBoth the query and documents should be in {#Language}.\n",
      "Your output must always be a JSON object only, do not explain yourself or output anything else. Be creative!\n",
      "(3) Framework of complete example generation' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16364.556640625\n",
      "page_content='-\t\"user_query\": a string, a random user sea rch query specified by the retrieval task.\n",
      "-\t\"positive_document\": a string, a relevant document for the user query.\n",
      "-\t\"hard_negative_document\": a string, a ha rd negative document that only a ppears relevant to the query.\n",
      "Please adhere to the following guidelines:\n",
      "-\tThe \"user_q uery\" should be {#Query_type}, {#Query_length}, {#Clarity}, and diverse in topic.\n",
      "-\tAll documents should be at least {#Num_words} words long.\n",
      "-\tBoth the query and documents should be in {#Language}.\n",
      "Your output must always be a JSON object only, do not explain yourself or output anything else. Be creative!\n",
      "(3) Framework of complete example generation' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16381.98046875\n",
      "page_content='HyDE (Gao et al., 2023)\t69.1\t46.6\t59.3\t27.3\t36.8\t44.0\n",
      "InteR (Vicuna-13B-v1.5 from LLaMa-2)\t69.3\t42.7\t70.1\t23.6\t39.6\t51.9\n",
      "InteR (Vicuna-33B-v1.3 from LLaMa-1)\t70.3\t39.9\t67.4\t26.0\t40.1\t51.4\n",
      "InteR (gpt-3.5-turbo)\t71.7\t40.9\t69.7\t26.0\t42.1\t52.8\n",
      "w/ relevance judgment\t\t\t\t\t\t\n",
      "DPR (Karpukhin et al., 2020)\t31.8\t17.5\t33.2\t29.5\t26.3\t16.1\n",
      "ANCE (Xiong et al., 2021)\t50.7\t41.5\t65.4¶\t30.0\t28.1\t38.2\n",
      "ContrieverFT (Izacard et al., 2022)\t67.7¶\t44.6¶\t59.6\t32.9¶\t41.3¶\t42.8¶\n",
      "LLM. After hyper-parameter search on validation sets, we set k as 15 for gpt-3.5-turbo, and 5 for Vicuna-13B-v1.5 and Vicuna-33B-v1.3. We also set M as 2 by default. We use a temperature of 1 for LLM part in generation and a frequency penalty of zero. We also truncate each RM-retrieved passage/document to 256 tokens and set the maximum number of tokens for each LLM-generated knowledge example to 256 for efficiency.\n",
      "5.4\tMain Results' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Feng 等 - 2023 - Synergistic Interplay between Search and Large Language Models for Information Retrieval.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16381.98046875\n",
      "page_content='HyDE (Gao et al., 2023)\t69.1\t46.6\t59.3\t27.3\t36.8\t44.0\n",
      "InteR (Vicuna-13B-v1.5 from LLaMa-2)\t69.3\t42.7\t70.1\t23.6\t39.6\t51.9\n",
      "InteR (Vicuna-33B-v1.3 from LLaMa-1)\t70.3\t39.9\t67.4\t26.0\t40.1\t51.4\n",
      "InteR (gpt-3.5-turbo)\t71.7\t40.9\t69.7\t26.0\t42.1\t52.8\n",
      "w/ relevance judgment\t\t\t\t\t\t\n",
      "DPR (Karpukhin et al., 2020)\t31.8\t17.5\t33.2\t29.5\t26.3\t16.1\n",
      "ANCE (Xiong et al., 2021)\t50.7\t41.5\t65.4¶\t30.0\t28.1\t38.2\n",
      "ContrieverFT (Izacard et al., 2022)\t67.7¶\t44.6¶\t59.6\t32.9¶\t41.3¶\t42.8¶\n",
      "LLM. After hyper-parameter search on validation sets, we set k as 15 for gpt-3.5-turbo, and 5 for Vicuna-13B-v1.5 and Vicuna-33B-v1.3. We also set M as 2 by default. We use a temperature of 1 for LLM part in generation and a frequency penalty of zero. We also truncate each RM-retrieved passage/document to 256 tokens and set the maximum number of tokens for each LLM-generated knowledge example to 256 for efficiency.\n",
      "5.4\tMain Results' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Feng 等 - 2023 - Synergistic Interplay between Search and Large Language Models for Information Retrieval.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16385.81640625\n",
      "page_content='text and a polish ratio (regression) model to explain the ChatGPT involvement. A Polish ratio of 0.2 indicates ChatGPT involvement and a value of more than 0.6 represents the text is entirely ChatGPT generated.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16385.81640625\n",
      "page_content='text and a polish ratio (regression) model to explain the ChatGPT involvement. A Polish ratio of 0.2 indicates ChatGPT involvement and a value of more than 0.6 represents the text is entirely ChatGPT generated.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16386.111328125\n",
      "page_content='This survey focuses on reviewing recent studies of applying LLMs to different IR components and using LLMs as search agents. Beyond this, a more significant problem brought by the appearance of LLMs is: is the conventional IR framework necessary in the era of LLMs? For example, traditional IR aims to return a ranking list of documents that are relevant to issued queries. However, the development of generative language models has introduced a novel paradigm: the direct generation of answers to input questions. Furthermore, according to a recent perspective paper [50], IR might evolve into a fundamental service for diverse systems. For example, in a multi-agent simulation system [290], an IR component can be used for memory recall. This implies that there will be many new challenges in future IR.\n",
      "References' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16386.111328125\n",
      "page_content='This survey focuses on reviewing recent studies of applying LLMs to different IR components and using LLMs as search agents. Beyond this, a more significant problem brought by the appearance of LLMs is: is the conventional IR framework necessary in the era of LLMs? For example, traditional IR aims to return a ranking list of documents that are relevant to issued queries. However, the development of generative language models has introduced a novel paradigm: the direct generation of answers to input questions. Furthermore, according to a recent perspective paper [50], IR might evolve into a fundamental service for diverse systems. For example, in a multi-agent simulation system [290], an IR component can be used for memory recall. This implies that there will be many new challenges in future IR.\n",
      "References' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16392.21484375\n",
      "page_content='(i.e., relevance label between a pair of query and document), which is considered “unsupervised” as the only supervision resides in the LLM where learning to follow instructions is conducted in earlier times (Sachan et al., 2022). In this work, we follow this zero-shot unsupervised setting and conduct information refinement through synergy between RMs and LLMs without any relevance supervision to handle the aforementioned issues.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Feng 等 - 2023 - Synergistic Interplay between Search and Large Language Models for Information Retrieval.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16392.21484375\n",
      "page_content='(i.e., relevance label between a pair of query and document), which is considered “unsupervised” as the only supervision resides in the LLM where learning to follow instructions is conducted in earlier times (Sachan et al., 2022). In this work, we follow this zero-shot unsupervised setting and conduct information refinement through synergy between RMs and LLMs without any relevance supervision to handle the aforementioned issues.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Feng 等 - 2023 - Synergistic Interplay between Search and Large Language Models for Information Retrieval.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16394.47265625\n",
      "page_content='7https://platform.openai.com/docs/guides/fine-tuning/fine-tuning-examples\n",
      "Observation\tLLM output\n",
      "runs for a while and trip very stiff to operate requires rebuild has no equipment earth high earth reading failed electrical\tOverheating Stiff operation Noisy operation N/A No failure mode can be determined from the given observation. Failure mode: Electrical failure\n",
      "Table 2: Some examples of predictions made by the off-the-shelf GPT-3.5-Turbo on a sample of the test data. The system-level prompt is “Determine the failure mode of the observation provided by the user. Your answer should contain only the failure mode and nothing else.”\n",
      "the user-level prompt (the observation, e.g. “runs for a while and trip”), the LLM produces outputs as shown in Table 1. These outputs, which are conversational in nature, are not machine-readable and are therefore not applicable to downstream analysis. A more specific prompt is needed to perform FMC.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Stewart 等 - 2023 - Large Language Models for Failure Mode Classification An Investigation.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16394.47265625\n",
      "page_content='7https://platform.openai.com/docs/guides/fine-tuning/fine-tuning-examples\n",
      "Observation\tLLM output\n",
      "runs for a while and trip very stiff to operate requires rebuild has no equipment earth high earth reading failed electrical\tOverheating Stiff operation Noisy operation N/A No failure mode can be determined from the given observation. Failure mode: Electrical failure\n",
      "Table 2: Some examples of predictions made by the off-the-shelf GPT-3.5-Turbo on a sample of the test data. The system-level prompt is “Determine the failure mode of the observation provided by the user. Your answer should contain only the failure mode and nothing else.”\n",
      "the user-level prompt (the observation, e.g. “runs for a while and trip”), the LLM produces outputs as shown in Table 1. These outputs, which are conversational in nature, are not machine-readable and are therefore not applicable to downstream analysis. A more specific prompt is needed to perform FMC.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Stewart 等 - 2023 - Large Language Models for Failure Mode Classification An Investigation.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16394.669921875\n",
      "page_content='•\tPS 1: We investigate the maximum amount of relevant information that can be retrieved by converting input text into a single\n",
      "search-friendly query.\n",
      "•\tPS 2: We examine whether using multiple queries that focus on different detailed semantic aspects can retrieve more relevant information than a single query.\n",
      "•\tPS 3: We analyze how the proportion of irrelevant information changes as the volume of retrieved data increases.\n",
      "•\tPS 4: We assess whether clarifying the input question is unnecessary for LLMs with strong semantic understanding capabilities.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16394.669921875\n",
      "page_content='•\tPS 1: We investigate the maximum amount of relevant information that can be retrieved by converting input text into a single\n",
      "search-friendly query.\n",
      "•\tPS 2: We examine whether using multiple queries that focus on different detailed semantic aspects can retrieve more relevant information than a single query.\n",
      "•\tPS 3: We analyze how the proportion of irrelevant information changes as the volume of retrieved data increases.\n",
      "•\tPS 4: We assess whether clarifying the input question is unnecessary for LLMs with strong semantic understanding capabilities.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16411.646484375\n",
      "page_content='Zhu et al. [458] developed PromptBench, a benchmark with more than 4k adversarial prompts to evaluate the robustness of large language models to adversarial prompts. The benchmark covers 13 datasets spanning eight tasks, including four NLU tasks. The\n",
      "authors observed that GLLMs are not robust to adversarial prompts. Moreover, word-level attacks are the most effective, which results in a performance drop of more than 30%. Based on the evaluation of ChatGPT on fourteen information extraction sub-tasks, Han et al. [460] showed that ChatGPT is vulnerable to adversarial prompts, i.e., the performance is greatly affected by including irrelevant context in the prompt.\n",
      "10\tGLLMs as Evaluators' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16411.646484375\n",
      "page_content='Zhu et al. [458] developed PromptBench, a benchmark with more than 4k adversarial prompts to evaluate the robustness of large language models to adversarial prompts. The benchmark covers 13 datasets spanning eight tasks, including four NLU tasks. The\n",
      "authors observed that GLLMs are not robust to adversarial prompts. Moreover, word-level attacks are the most effective, which results in a performance drop of more than 30%. Based on the evaluation of ChatGPT on fourteen information extraction sub-tasks, Han et al. [460] showed that ChatGPT is vulnerable to adversarial prompts, i.e., the performance is greatly affected by including irrelevant context in the prompt.\n",
      "10\tGLLMs as Evaluators' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16415.1171875\n",
      "page_content='[470], [472] and error analysis prompting [474]. Some of the proposed evaluation frameworks work with and without references [470], [473], [483], while some of them require references [426], [471], [474], [480], [485], and some don’t require any references [468], [472], [475]– [479], [481], [482], [484], [486].' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16415.1171875\n",
      "page_content='[470], [472] and error analysis prompting [474]. Some of the proposed evaluation frameworks work with and without references [470], [473], [483], while some of them require references [426], [471], [474], [480], [485], and some don’t require any references [468], [472], [475]– [479], [481], [482], [484], [486].' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16426.326171875\n",
      "page_content='Over the decades, search engines like Google or Bing have become a staple for people looking to retrieve information on a variety of topics, allowing users to quickly sift through millions of documents to find the information they need by providing keywords or a query. Spurred by advancements in scale, LLMs have now exhibited the ability to undertake a variety of NLP tasks in a zero-shot scenario (Qin et al., 2023) by following instructions (Ouyang et al., 2022; Sanh et al., 2022; Min et al., 2022; Wei et al., 2022). Therefore, they could serve as an alternative option for people to obtain information directly by posing a question or query in natural languages (OpenAI, 2022), instead of relying on specific keywords. For example, suppose a student is looking to write a research paper on the history\n",
      "∗ Equal contribution. Work done during the internship at Microsoft.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Feng 等 - 2023 - Synergistic Interplay between Search and Large Language Models for Information Retrieval.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16426.326171875\n",
      "page_content='Over the decades, search engines like Google or Bing have become a staple for people looking to retrieve information on a variety of topics, allowing users to quickly sift through millions of documents to find the information they need by providing keywords or a query. Spurred by advancements in scale, LLMs have now exhibited the ability to undertake a variety of NLP tasks in a zero-shot scenario (Qin et al., 2023) by following instructions (Ouyang et al., 2022; Sanh et al., 2022; Min et al., 2022; Wei et al., 2022). Therefore, they could serve as an alternative option for people to obtain information directly by posing a question or query in natural languages (OpenAI, 2022), instead of relying on specific keywords. For example, suppose a student is looking to write a research paper on the history\n",
      "∗ Equal contribution. Work done during the internship at Microsoft.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Feng 等 - 2023 - Synergistic Interplay between Search and Large Language Models for Information Retrieval.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16426.984375\n",
      "page_content='4.6\tDialogue Tasks\n",
      "Overview. Dialogue tasks in natural language processing (NLP) deal with understanding and generating humanlike conversations between machines and users [228]. The main objective of these tasks is to enable machines to have conversations with humans in a natural way. These dialogue tasks are essential components of building effective conversational agents, which have a wide range of applications, including customer support\n",
      "Paper\tGLLMs Explored\tPrompt Settings\tDomain(s)\tLanguage(s)\tSOTA Results\n",
      "[216]\tChatGPT\tZS\tNews, Scientific Literature\tEnglish\tYes\n",
      "[217]\tChatGPT\tZS\tScientific Literature\tEnglish\tNo\n",
      "TABLE 5. Summary of research works exploring GLLMs for keyphrase generation task. Here ZS represents zero-shot, and FS represents few-shot.\n",
      "Paper\tTask(s)\tGLLMs Explored\tPrompt Settings\tDomain(s)\tLanguage(s)\n",
      "[218]\tSpoken Language Understanding and Dialogue State Tracking\tGPT-3.5, ChatGPT\tZS\tGeneral\tEnglish' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16426.984375\n",
      "page_content='4.6\tDialogue Tasks\n",
      "Overview. Dialogue tasks in natural language processing (NLP) deal with understanding and generating humanlike conversations between machines and users [228]. The main objective of these tasks is to enable machines to have conversations with humans in a natural way. These dialogue tasks are essential components of building effective conversational agents, which have a wide range of applications, including customer support\n",
      "Paper\tGLLMs Explored\tPrompt Settings\tDomain(s)\tLanguage(s)\tSOTA Results\n",
      "[216]\tChatGPT\tZS\tNews, Scientific Literature\tEnglish\tYes\n",
      "[217]\tChatGPT\tZS\tScientific Literature\tEnglish\tNo\n",
      "TABLE 5. Summary of research works exploring GLLMs for keyphrase generation task. Here ZS represents zero-shot, and FS represents few-shot.\n",
      "Paper\tTask(s)\tGLLMs Explored\tPrompt Settings\tDomain(s)\tLanguage(s)\n",
      "[218]\tSpoken Language Understanding and Dialogue State Tracking\tGPT-3.5, ChatGPT\tZS\tGeneral\tEnglish' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16437.38671875\n",
      "page_content='and eventually played a crucial role in the evolution of advanced deep learning models like pretrained language models [1], [3] and the recent large language models. Overall, the advantages of transfer learning are' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16437.38671875\n",
      "page_content='and eventually played a crucial role in the evolution of advanced deep learning models like pretrained language models [1], [3] and the recent large language models. Overall, the advantages of transfer learning are' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16447.9296875\n",
      "page_content='4.1\tOverview\n",
      "Collecting Clues For a test sequence, clues are local fact evidence such as keywords, phrases, contextual information, semantic meaning, semantic relationships, tones, references, etc. The following is an example for clues of an input: Input: Steers turns in a snappy screenplay that curls at the edges; it’s so clever you want to hate it.\n",
      "Clues: \"snappy\", \"clever\", \"want to hate it\" are clues for determining the sentiment of the input sentence.\n",
      "Reasoning For reasoning, the LLM is prompted to go beyond superficial keywords to mine deeper perspectives, considering language phenomenon such as negation, intensification, irony, etc), and piece together local evidence to form the final decision. The following example shows the reasoning process to decide the sentiment of the above example based on the evidence collected:\n",
      "1.\tThe phrase \"snappy screenplay\" implies that the screenplay is of a high quality and is well-crafted.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16447.9296875\n",
      "page_content='4.1\tOverview\n",
      "Collecting Clues For a test sequence, clues are local fact evidence such as keywords, phrases, contextual information, semantic meaning, semantic relationships, tones, references, etc. The following is an example for clues of an input: Input: Steers turns in a snappy screenplay that curls at the edges; it’s so clever you want to hate it.\n",
      "Clues: \"snappy\", \"clever\", \"want to hate it\" are clues for determining the sentiment of the input sentence.\n",
      "Reasoning For reasoning, the LLM is prompted to go beyond superficial keywords to mine deeper perspectives, considering language phenomenon such as negation, intensification, irony, etc), and piece together local evidence to form the final decision. The following example shows the reasoning process to decide the sentiment of the above example based on the evidence collected:\n",
      "1.\tThe phrase \"snappy screenplay\" implies that the screenplay is of a high quality and is well-crafted.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16470.5234375\n",
      "page_content='Few-shot\t\n",
      "Query2Doc [65] Write a passage that answers the given query:\n",
      "Query: {#Query 1}\n",
      "Passage: {#Passage 1}\n",
      "Query: {#Query} Passage:\t\n",
      "\tChain-of-Thought\n",
      "CoT [76]\tAnswer the following query based on the context: Context: {#PRF doc 1} {#PRF doc 2} {#PRF doc 3} Query: {#Query} Give the rationale before answering\n",
      "the corpus, thereby effectively bridging the semantic divide between short queries and long candidate documents. The prompt employed for this mechanism is typically structured as follows: “Given a question query and its potential answer passages passages, compose a passage that provides an answer to the question” [84, 85]. This approach enables a more nuanced and contextually relevant retrieval of information, enhancing the overall effectiveness of the query rewriting process [65, 75–77, 83–85].\n",
      "3.3\tApproaches' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16470.5234375\n",
      "page_content='Few-shot\t\n",
      "Query2Doc [65] Write a passage that answers the given query:\n",
      "Query: {#Query 1}\n",
      "Passage: {#Passage 1}\n",
      "Query: {#Query} Passage:\t\n",
      "\tChain-of-Thought\n",
      "CoT [76]\tAnswer the following query based on the context: Context: {#PRF doc 1} {#PRF doc 2} {#PRF doc 3} Query: {#Query} Give the rationale before answering\n",
      "the corpus, thereby effectively bridging the semantic divide between short queries and long candidate documents. The prompt employed for this mechanism is typically structured as follows: “Given a question query and its potential answer passages passages, compose a passage that provides an answer to the question” [84, 85]. This approach enables a more nuanced and contextually relevant retrieval of information, enhancing the overall effectiveness of the query rewriting process [65, 75–77, 83–85].\n",
      "3.3\tApproaches' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16474.58984375\n",
      "page_content='Methods\t\tDL’19\t\t\tDL’20\t\t\n",
      "\t\tMAP\tnDCG@10\tR@1k\tMAP\tnDCG@10\tR@1k\n",
      "InteR (M =\t0)\t30.1\t50.6\t75.0\t28.6\t48.0\t78.6\n",
      "InteR (M =\t1)\t45.8\t65.3\t89.3\t42.6\t61.0\t88.7\n",
      "InteR (M =\t2)*\t50.0\t68.3\t89.3\t46.8\t63.5\t88.8\n",
      "InteR (M =\t3)\t49.1\t68.2\t88.0\t42.8\t59.3\t85.6\n",
      "models. This could potentially be attributed to the LLM’s limited financial knowledge of FiQA and the RM’s marginal qualification to effectively handle relatively longer queries for ArguAna (Thakur et al., 2021).\n",
      "5.5\tDiscussions' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Feng 等 - 2023 - Synergistic Interplay between Search and Large Language Models for Information Retrieval.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16474.58984375\n",
      "page_content='Methods\t\tDL’19\t\t\tDL’20\t\t\n",
      "\t\tMAP\tnDCG@10\tR@1k\tMAP\tnDCG@10\tR@1k\n",
      "InteR (M =\t0)\t30.1\t50.6\t75.0\t28.6\t48.0\t78.6\n",
      "InteR (M =\t1)\t45.8\t65.3\t89.3\t42.6\t61.0\t88.7\n",
      "InteR (M =\t2)*\t50.0\t68.3\t89.3\t46.8\t63.5\t88.8\n",
      "InteR (M =\t3)\t49.1\t68.2\t88.0\t42.8\t59.3\t85.6\n",
      "models. This could potentially be attributed to the LLM’s limited financial knowledge of FiQA and the RM’s marginal qualification to effectively handle relatively longer queries for ArguAna (Thakur et al., 2021).\n",
      "5.5\tDiscussions' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Feng 等 - 2023 - Synergistic Interplay between Search and Large Language Models for Information Retrieval.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16485.892578125\n",
      "page_content='CorpusLM [141] further explores combining the retrieval and answering tasks together based on LLMs, making the two mutually reinforcing. Researchers devise various training tasks, e.g., DocID list generation, closed-book answers generation, and RAG generation, to sufficiently leverage and enhance the world knowledge of LLMs, improving the performance of these generation tasks.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16485.892578125\n",
      "page_content='CorpusLM [141] further explores combining the retrieval and answering tasks together based on LLMs, making the two mutually reinforcing. Researchers devise various training tasks, e.g., DocID list generation, closed-book answers generation, and RAG generation, to sufficiently leverage and enhance the world knowledge of LLMs, improving the performance of these generation tasks.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16497.876953125\n",
      "page_content='7.2.2\tFramework and System' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16497.876953125\n",
      "page_content='7.2.2\tFramework and System' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16518.8125\n",
      "page_content='Index Terms—Large Language Models; Information Retrieval; Query Rewriter; Reranking; Reader; Fine-tuning; Prompting\n",
      "♦\n",
      "1\tIntroduction' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16518.8125\n",
      "page_content='Index Terms—Large Language Models; Information Retrieval; Query Rewriter; Reranking; Reader; Fine-tuning; Prompting\n",
      "♦\n",
      "1\tIntroduction' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16526.123046875\n",
      "page_content='sequential interaction history and ranking instruction is included. Zhiyuli [244] proposed BookGPT, a novel framework which leverages GLLMs like ChatGPT for book recommendation. Specifically, the performance of BookGPT is evaluated on three sub-tasks, namely the book rating task, book summary recommendation task and user rating recommendation task. The performance of BookGPT is promising in all three sub-tasks, and the performance increases with an increase in prompt examples.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16526.123046875\n",
      "page_content='sequential interaction history and ranking instruction is included. Zhiyuli [244] proposed BookGPT, a novel framework which leverages GLLMs like ChatGPT for book recommendation. Specifically, the performance of BookGPT is evaluated on three sub-tasks, namely the book rating task, book summary recommendation task and user rating recommendation task. The performance of BookGPT is promising in all three sub-tasks, and the performance increases with an increase in prompt examples.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16528.087890625\n",
      "page_content='scale synthetic dataset for the detection of implicit hate speech. Here, the authors explored a variant of constrained beam search to ensure subtle toxicity in the generated examples. Michail et al. [421] investigated the effectiveness of ChatGPT-generated synthetic data to fine-tune multilingual models for tweet intimacy prediction in the case of languages with no labelled instances. Here, ChatGPT is prompted with instructions and examples from a high-resource language and asked to generate new examples in the target language. Most of the existing research works use simple prompts for data generation, limiting the diversity of the generated synthetic data. To address this, Yu et al. [423] proposed a novel approach that leverages attributed prompts for data generation to increase the diversity in the generated data. Based on the evaluation on four topic classification datasets, the authors observed that (i) the proposed approach enhances the model performance and (ii) reduces the' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16528.087890625\n",
      "page_content='scale synthetic dataset for the detection of implicit hate speech. Here, the authors explored a variant of constrained beam search to ensure subtle toxicity in the generated examples. Michail et al. [421] investigated the effectiveness of ChatGPT-generated synthetic data to fine-tune multilingual models for tweet intimacy prediction in the case of languages with no labelled instances. Here, ChatGPT is prompted with instructions and examples from a high-resource language and asked to generate new examples in the target language. Most of the existing research works use simple prompts for data generation, limiting the diversity of the generated synthetic data. To address this, Yu et al. [423] proposed a novel approach that leverages attributed prompts for data generation to increase the diversity in the generated data. Based on the evaluation on four topic classification datasets, the authors observed that (i) the proposed approach enhances the model performance and (ii) reduces the' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16553.791015625\n",
      "page_content='The NLI training dataset is constructed semi-automatically using the similar method we described in Section 3.1. We provide task instruction, rewritten question s, along with knowledge context k as prompt to GPT-4, which then generated a brief explanation e and a classification result j, resulting in the data instance ((s, k, (e,j)). The prompt template is as follows:\n",
      "[Instruction]: Your task is to solve the NLI problem: given the premise in [Knowledge] and the hypothesis that \"The [Knowledge] contains reliable answers aiding the response to [Question]\". You should classify the response as entailment, contradiction, or neutral.\n",
      "[Question]: {Question is here.}\n",
      "[Knowledge]: {The judging knowledge is here.}\n",
      "[Format]: {The explanation.}**{The NLI result.}' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16553.791015625\n",
      "page_content='The NLI training dataset is constructed semi-automatically using the similar method we described in Section 3.1. We provide task instruction, rewritten question s, along with knowledge context k as prompt to GPT-4, which then generated a brief explanation e and a classification result j, resulting in the data instance ((s, k, (e,j)). The prompt template is as follows:\n",
      "[Instruction]: Your task is to solve the NLI problem: given the premise in [Knowledge] and the hypothesis that \"The [Knowledge] contains reliable answers aiding the response to [Question]\". You should classify the response as entailment, contradiction, or neutral.\n",
      "[Question]: {Question is here.}\n",
      "[Knowledge]: {The judging knowledge is here.}\n",
      "[Format]: {The explanation.}**{The NLI result.}' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16568.36328125\n",
      "page_content='11.3\tState-Of-The-Art Results Across NLP Tasks\n",
      "In the beginning, GLLMs like GPT-3 achieved impressive performances in zero and few-shot settings across NLP tasks. Advanced GLLMs like ChatGPT and GPT-4 further pushed the results but still lag behind SOTA results achieved by pretrained language models finetuned based on supervised learning. Later, with the evolution of advanced prompting strategies and novel approaches, GLLMs are able to achieve SOTA results in some of the NLP tasks. For example, InstructGPT with CARP prompting strategy using just 16 examples' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16568.36328125\n",
      "page_content='11.3\tState-Of-The-Art Results Across NLP Tasks\n",
      "In the beginning, GLLMs like GPT-3 achieved impressive performances in zero and few-shot settings across NLP tasks. Advanced GLLMs like ChatGPT and GPT-4 further pushed the results but still lag behind SOTA results achieved by pretrained language models finetuned based on supervised learning. Later, with the evolution of advanced prompting strategies and novel approaches, GLLMs are able to achieve SOTA results in some of the NLP tasks. For example, InstructGPT with CARP prompting strategy using just 16 examples' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16576.52734375\n",
      "page_content='Code-LLaMA-Instruct. Liu et al. [149] propose PE-Rank, which compresses each document in the list into a single embedding and then inputs these document embeddings into reranker, which significantly reduces the input length and improves the efficiency of reranker.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16576.52734375\n",
      "page_content='Code-LLaMA-Instruct. Liu et al. [149] propose PE-Rank, which compresses each document in the list into a single embedding and then inputs these document embeddings into reranker, which significantly reduces the input length and improves the efficiency of reranker.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16590.646484375\n",
      "page_content='report from the Chinese IR community [50], which discusses the opportunity and future directions of IR in the era of LLMs, and we think it is an excellent supplement to this survey.\n",
      "The remaining part of this survey is organized as follows: Section 2 introduces the background for IR and LLMs. Section 3, 4, 5, 6 respectively review recent progress from the four perspectives of query rewriter, retriever, reranker, and reader, which are four key components of an IR system. Section 7 introduces recent studies of search agents. Then, Section 8 discusses some potential directions in future research. Finally, we conclude the survey in Section 9 by summarizing the major findings.\n",
      "2\tBackground\n",
      "2.1\tInformation Retrieval' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16590.646484375\n",
      "page_content='report from the Chinese IR community [50], which discusses the opportunity and future directions of IR in the era of LLMs, and we think it is an excellent supplement to this survey.\n",
      "The remaining part of this survey is organized as follows: Section 2 introduces the background for IR and LLMs. Section 3, 4, 5, 6 respectively review recent progress from the four perspectives of query rewriter, retriever, reranker, and reader, which are four key components of an IR system. Section 7 introduces recent studies of search agents. Then, Section 8 discusses some potential directions in future research. Finally, we conclude the survey in Section 9 by summarizing the major findings.\n",
      "2\tBackground\n",
      "2.1\tInformation Retrieval' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16592.6171875\n",
      "page_content='[332]\tChatGPT\tMulti-Turn Medical Dialogue\tZS\tChinese\tNo\n",
      "[117]\tGPT-4\tQuestion Answering\tFS\tEnglish\tNo\n",
      "[333]\tChatGPT\tQuestion Answering\tZS\tChinese\t-\n",
      "[334]\tGPT-3\tSynonym Generation\tZS\tEnglish\t-\n",
      "[335]\tGPT-3\tNatural Language Inference, Question Answering, Text Classification\tZS\tEnglish\tNo\n",
      "[336]\tChatGPT\tClinical Decision Support\tZS\tEnglish\t-\n",
      "[337]\tChatGPT\tQuestion Answering\tZS\tEnglish\t-\n",
      "[338]\tChatGPT\tQuestion Answering\tZS\tEnglish\t-\n",
      "[339]\tChatGPT\tDiagnosis Lists Generation\tZS\tEnglish\t-\n",
      "[340]\tChatGPT\tClinical Decision Support\tZS\tEnglish\t-\n",
      "[341]\tGPT-3, GPT-3.5, ChatGPT\tQuestion Answering\tZS\tEnglish\t-\n",
      "[342]\tChatGPT\tQuestion Answering\tZS\tEnglish\t-\n",
      "[343]\tChatGPT, GPT-4\tText Simplification\tZS\tEnglish\t-\n",
      "TABLE 13. Summary of research works exploring GLLMs for various NLP tasks in the healthcare domain. Here ZS represents zero-shot, and FS represents few-shot. Here ’-’ represents there is no comparison between GLLMs and domain-specific pretrained language models in the paper.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16592.6171875\n",
      "page_content='[332]\tChatGPT\tMulti-Turn Medical Dialogue\tZS\tChinese\tNo\n",
      "[117]\tGPT-4\tQuestion Answering\tFS\tEnglish\tNo\n",
      "[333]\tChatGPT\tQuestion Answering\tZS\tChinese\t-\n",
      "[334]\tGPT-3\tSynonym Generation\tZS\tEnglish\t-\n",
      "[335]\tGPT-3\tNatural Language Inference, Question Answering, Text Classification\tZS\tEnglish\tNo\n",
      "[336]\tChatGPT\tClinical Decision Support\tZS\tEnglish\t-\n",
      "[337]\tChatGPT\tQuestion Answering\tZS\tEnglish\t-\n",
      "[338]\tChatGPT\tQuestion Answering\tZS\tEnglish\t-\n",
      "[339]\tChatGPT\tDiagnosis Lists Generation\tZS\tEnglish\t-\n",
      "[340]\tChatGPT\tClinical Decision Support\tZS\tEnglish\t-\n",
      "[341]\tGPT-3, GPT-3.5, ChatGPT\tQuestion Answering\tZS\tEnglish\t-\n",
      "[342]\tChatGPT\tQuestion Answering\tZS\tEnglish\t-\n",
      "[343]\tChatGPT, GPT-4\tText Simplification\tZS\tEnglish\t-\n",
      "TABLE 13. Summary of research works exploring GLLMs for various NLP tasks in the healthcare domain. Here ZS represents zero-shot, and FS represents few-shot. Here ’-’ represents there is no comparison between GLLMs and domain-specific pretrained language models in the paper.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16603.529296875\n",
      "page_content='impact of the final results. When (text, clue, reason) as demonstrations, the label has effect to the performances.\n",
      "6.3\tThe effect of different types of label words Label words denote words generated by LLMs that indicate the label of the input. In this subsection, we explore the impact of using different kinds of label words:\n",
      "•\tPosition index: number of index. i.e., one, two, three and etc to denote the label.\n",
      "•\tAnnotation words: words used to refer to the category in the annotation file. e.g., positive, negative. 9\n",
      "•\tSynonyms words: synonyms words e.g., great, terrible.\n",
      "•\tFlipped words: words that are contrary to original target meanings. e.g., \"positive\" to denote the negative polarity, \"negative\" to denote the positive polarity.\n",
      "•\tRandom words: randomly choose words in the vocabulary. e.g., order, number.\n",
      "•\tSpecial tokens: tokens that do not have semantic meaning. They are independent of the input and added for a certain purpose. e.g., <cls>, <mask>.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16603.529296875\n",
      "page_content='impact of the final results. When (text, clue, reason) as demonstrations, the label has effect to the performances.\n",
      "6.3\tThe effect of different types of label words Label words denote words generated by LLMs that indicate the label of the input. In this subsection, we explore the impact of using different kinds of label words:\n",
      "•\tPosition index: number of index. i.e., one, two, three and etc to denote the label.\n",
      "•\tAnnotation words: words used to refer to the category in the annotation file. e.g., positive, negative. 9\n",
      "•\tSynonyms words: synonyms words e.g., great, terrible.\n",
      "•\tFlipped words: words that are contrary to original target meanings. e.g., \"positive\" to denote the negative polarity, \"negative\" to denote the positive polarity.\n",
      "•\tRandom words: randomly choose words in the vocabulary. e.g., order, number.\n",
      "•\tSpecial tokens: tokens that do not have semantic meaning. They are independent of the input and added for a certain purpose. e.g., <cls>, <mask>.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16606.48046875\n",
      "page_content='5.\tAs yet, there has not been a formal definition for LLMs. In this paper, we mainly focus on models with more than 1B parameters. We also notice that some methods do not rely on such strictly defined LLMs, but due to their representativeness, we still include an introduction to them in this survey.\n",
      "6.\thttps://github.com/RUC-NLPIR/LLM4IR-Survey\n",
      "report from the Chinese IR community [50], which discusses the opportunity and future directions of IR in the era of LLMs, and we think it is an excellent supplement to this survey.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16606.48046875\n",
      "page_content='5.\tAs yet, there has not been a formal definition for LLMs. In this paper, we mainly focus on models with more than 1B parameters. We also notice that some methods do not rely on such strictly defined LLMs, but due to their representativeness, we still include an introduction to them in this survey.\n",
      "6.\thttps://github.com/RUC-NLPIR/LLM4IR-Survey\n",
      "report from the Chinese IR community [50], which discusses the opportunity and future directions of IR in the era of LLMs, and we think it is an excellent supplement to this survey.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16613.61328125\n",
      "page_content='[410]\tJ. Wang, Z. Yao, A. Mitra, S. Osebe, Z. Yang, and H. Yu, “Umass bionlp at mediqa-chat 2023: Can llms generate high-\n",
      "quality synthetic note-oriented doctor-patient conversations?” arXiv preprint arXiv:2306.16931, 2023.\n",
      "[411]\tS. Gunasekar, Y. Zhang, J. Aneja, C. C. T. Mendes, A. D. Giorno, S. Gopi, M. Javaheripi, P. C. Kauffmann, G. de Rosa, O. Saarikivi, A. Salim, S. Shah, H. S. Behl, X. Wang, S. Bubeck, R. Eldan, A. T. Kalai, Y. T. Lee, and Y.-F. Li, “Textbooks are all you need,” ArXiv, vol. abs/2306.11644, 2023.\n",
      "[412]\tC. Whitehouse, M. Choudhury, and A. F. Aji, “Llm-powered data augmentation for enhanced crosslingual performance,” ArXiv, vol. abs/2305.14288, 2023.\n",
      "[413]\tT. Hartvigsen, S. Gabriel, H. Palangi, M. Sap, D. Ray, and E. Kamar, “Toxigen: A large-scale machine-generated dataset for adversarial and implicit hate speech detection,” in Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), 2022, pp. 3309–3326.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16613.61328125\n",
      "page_content='[410]\tJ. Wang, Z. Yao, A. Mitra, S. Osebe, Z. Yang, and H. Yu, “Umass bionlp at mediqa-chat 2023: Can llms generate high-\n",
      "quality synthetic note-oriented doctor-patient conversations?” arXiv preprint arXiv:2306.16931, 2023.\n",
      "[411]\tS. Gunasekar, Y. Zhang, J. Aneja, C. C. T. Mendes, A. D. Giorno, S. Gopi, M. Javaheripi, P. C. Kauffmann, G. de Rosa, O. Saarikivi, A. Salim, S. Shah, H. S. Behl, X. Wang, S. Bubeck, R. Eldan, A. T. Kalai, Y. T. Lee, and Y.-F. Li, “Textbooks are all you need,” ArXiv, vol. abs/2306.11644, 2023.\n",
      "[412]\tC. Whitehouse, M. Choudhury, and A. F. Aji, “Llm-powered data augmentation for enhanced crosslingual performance,” ArXiv, vol. abs/2305.14288, 2023.\n",
      "[413]\tT. Hartvigsen, S. Gabriel, H. Palangi, M. Sap, D. Ray, and E. Kamar, “Toxigen: A large-scale machine-generated dataset for adversarial and implicit hate speech detection,” in Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), 2022, pp. 3309–3326.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16625.60546875\n",
      "page_content='and readily comprehensible answers. WebGPT [24] serves as a pioneering work in this category, which models the search process as a sequence of actions of an LLM-based agent within a search engine environment, autonomously accomplishing the whole search pipeline. By integrating the existing search stack, search agents have the potential to become a new paradigm in future IR.\n",
      "2.2\tLarge Language Models' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16625.60546875\n",
      "page_content='and readily comprehensible answers. WebGPT [24] serves as a pioneering work in this category, which models the search process as a sequence of actions of an LLM-based agent within a search engine environment, autonomously accomplishing the whole search pipeline. By integrating the existing search stack, search agents have the potential to become a new paradigm in future IR.\n",
      "2.2\tLarge Language Models' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16627.93359375\n",
      "page_content='[131]\tT. Kuzman, N. Ljubesˇic´, and I. Mozeticˇ, “Chatgpt: Beginning of an end of manual annotation? use case of automatic genre identification,” arXiv preprint arXiv:2303.03953, 2023.\n",
      "[132]\tY. Bang, S. Cahyawijaya, N. Lee, W. Dai, D. Su, B. Wilie, H. Love-nia, Z. Ji, T. Yu, W. Chung et al., “A multitask, multilingual, multimodal evaluation of chatgpt on reasoning, hallucination, and interactivity,” arXiv preprint arXiv:2302.04023, 2023.\n",
      "[133]\tJ. Kocon´ , I. Cichecki, O. Kaszyca, M. Kochanek, D. Szydło, J. Baran, J. Bielaniewicz, M. Gruza, A. Janz, K. Kanclerz et al., “Chatgpt: Jack of all trades, master of none,” arXiv preprint arXiv:2302.10724, 2023.\n",
      "[134]\tQ. Zhong, L. Ding, J. Liu, B. Du, and D. Tao, “Can chatgpt understand too? a comparative study on chatgpt and fine-tuned bert,” arXiv preprint arXiv:2302.10198, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16627.93359375\n",
      "page_content='[131]\tT. Kuzman, N. Ljubesˇic´, and I. Mozeticˇ, “Chatgpt: Beginning of an end of manual annotation? use case of automatic genre identification,” arXiv preprint arXiv:2303.03953, 2023.\n",
      "[132]\tY. Bang, S. Cahyawijaya, N. Lee, W. Dai, D. Su, B. Wilie, H. Love-nia, Z. Ji, T. Yu, W. Chung et al., “A multitask, multilingual, multimodal evaluation of chatgpt on reasoning, hallucination, and interactivity,” arXiv preprint arXiv:2302.04023, 2023.\n",
      "[133]\tJ. Kocon´ , I. Cichecki, O. Kaszyca, M. Kochanek, D. Szydło, J. Baran, J. Bielaniewicz, M. Gruza, A. Janz, K. Kanclerz et al., “Chatgpt: Jack of all trades, master of none,” arXiv preprint arXiv:2302.10724, 2023.\n",
      "[134]\tQ. Zhong, L. Ding, J. Liu, B. Du, and D. Tao, “Can chatgpt understand too? a comparative study on chatgpt and fine-tuned bert,” arXiv preprint arXiv:2302.10198, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16641.572265625\n",
      "page_content='diversity in the generated data. Based on the evaluation on four topic classification datasets, the authors observed that (i) the proposed approach enhances the model performance and (ii) reduces the querying cost of ChatGPT by a large margin.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16641.572265625\n",
      "page_content='diversity in the generated data. Based on the evaluation on four topic classification datasets, the authors observed that (i) the proposed approach enhances the model performance and (ii) reduces the querying cost of ChatGPT by a large margin.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16660.453125\n",
      "page_content='Zaragoza Robertson. Robertson s., zaragoza h. The probabilistic relevance framework: Bm25 and beyond, Found. Trends Inf. Retr, 3(4):333–389, 2009.\n",
      "Devendra Sachan, Mike Lewis, Mandar Joshi, Armen Aghajanyan, Wen-tau Yih, Joelle Pineau, and Luke Zettlemoyer. Improving passage retrieval with zero-shot question generation. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pp. 3781–3797, Abu Dhabi, United Arab Emirates, December 2022. Association for Computational Linguistics. URL https://aclanthology.org/2022.emnlp-main.249.\n",
      "Victor Sanh, Albert Webson, Colin Raffel, Stephen Bach, Lintang Sutawika, Zaid Alyafeai, Antoine Chaffin, Arnaud Stiegler, Arun Raja, Manan Dey, et al. Multitask prompted training enables zero-shot task generalization. In International Conference on Learning Representations, 2022.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Feng 等 - 2023 - Synergistic Interplay between Search and Large Language Models for Information Retrieval.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16660.453125\n",
      "page_content='Zaragoza Robertson. Robertson s., zaragoza h. The probabilistic relevance framework: Bm25 and beyond, Found. Trends Inf. Retr, 3(4):333–389, 2009.\n",
      "Devendra Sachan, Mike Lewis, Mandar Joshi, Armen Aghajanyan, Wen-tau Yih, Joelle Pineau, and Luke Zettlemoyer. Improving passage retrieval with zero-shot question generation. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pp. 3781–3797, Abu Dhabi, United Arab Emirates, December 2022. Association for Computational Linguistics. URL https://aclanthology.org/2022.emnlp-main.249.\n",
      "Victor Sanh, Albert Webson, Colin Raffel, Stephen Bach, Lintang Sutawika, Zaid Alyafeai, Antoine Chaffin, Arnaud Stiegler, Arun Raja, Manan Dey, et al. Multitask prompted training enables zero-shot task generalization. In International Conference on Learning Representations, 2022.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Feng 等 - 2023 - Synergistic Interplay between Search and Large Language Models for Information Retrieval.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16677.65234375\n",
      "page_content='Papers collection. For this survey paper, we gathered over 350 research papers that appeared online in the period of June 2020 to September 2023. Initially, we selected GLLMs like GPT-3, InstructGPT, Codex and GPT-4 papers as seed papers and collected all the citing papers. We also collected papers from popular venues like ACL,\n",
      "EMNLP, COLING, AAAI, ICML, ICLR, NeurIPS etc and popular databases like Google Scholar and ScienceDirect using the keywords GPT-3, ChatGPT, GPT-3.5, Instruct-GPT, Codex and GPT-4. After removing the duplicate papers, we did a manual review to arrive at a final set of over 350 relevant research papers.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16677.65234375\n",
      "page_content='Papers collection. For this survey paper, we gathered over 350 research papers that appeared online in the period of June 2020 to September 2023. Initially, we selected GLLMs like GPT-3, InstructGPT, Codex and GPT-4 papers as seed papers and collected all the citing papers. We also collected papers from popular venues like ACL,\n",
      "EMNLP, COLING, AAAI, ICML, ICLR, NeurIPS etc and popular databases like Google Scholar and ScienceDirect using the keywords GPT-3, ChatGPT, GPT-3.5, Instruct-GPT, Codex and GPT-4. After removing the duplicate papers, we did a manual review to arrive at a final set of over 350 relevant research papers.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16681.7421875\n",
      "page_content='InteR (Vicuna-33B-v1.3 from LLaMa-1)\t45.8\t68.9\t85.6\t45.1\t64.0\t87.9\n",
      "InteR (gpt-3.5-turbo)\t50.0\t68.3\t89.3\t46.8\t63.5\t88.8\n",
      "w/ relevance judgment\t\t\t\t\t\t\n",
      "DeepCT (Dai & Callan, 2019)\t-\t55.1\t-\t-\t55.6\t-\n",
      "DPR (Karpukhin et al., 2020)\t36.5\t62.2\t76.9\t41.8\t65.3¶\t81.4\n",
      "ANCE (Xiong et al., 2021)\t37.1\t64.5¶\t75.5\t40.8\t64.6\t77.6\n",
      "ContrieverFT (Izacard et al., 2022)\t41.7¶\t62.1\t83.6¶\t43.6¶\t63.2\t85.8¶\n",
      "Table 2: Experimental results (nDCG@10) on low-resource tasks from BEIR (%). The best results are marked in bold and the best performing w/ relevance judgment are marked with ¶ .\n",
      "Methods\tSciFact\tArguAna\tTREC-COVID\tFiQA\tDBPedia\tTREC-NEWS\n",
      "w/o relevance judgment\t\t\t\t\t\t\n",
      "BM25 (Robertson & Zaragoza, 2009)\t67.9\t39.7\t59.5\t23.6\t31.8\t39.5\n",
      "Contriever (Izacard et al., 2022)\t64.9\t37.9\t27.3\t24.5\t29.2\t34.8\n",
      "HyDE (Gao et al., 2023)\t69.1\t46.6\t59.3\t27.3\t36.8\t44.0\n",
      "InteR (Vicuna-13B-v1.5 from LLaMa-2)\t69.3\t42.7\t70.1\t23.6\t39.6\t51.9\n",
      "InteR (Vicuna-33B-v1.3 from LLaMa-1)\t70.3\t39.9\t67.4\t26.0\t40.1\t51.4' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Feng 等 - 2023 - Synergistic Interplay between Search and Large Language Models for Information Retrieval.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16681.7421875\n",
      "page_content='InteR (Vicuna-33B-v1.3 from LLaMa-1)\t45.8\t68.9\t85.6\t45.1\t64.0\t87.9\n",
      "InteR (gpt-3.5-turbo)\t50.0\t68.3\t89.3\t46.8\t63.5\t88.8\n",
      "w/ relevance judgment\t\t\t\t\t\t\n",
      "DeepCT (Dai & Callan, 2019)\t-\t55.1\t-\t-\t55.6\t-\n",
      "DPR (Karpukhin et al., 2020)\t36.5\t62.2\t76.9\t41.8\t65.3¶\t81.4\n",
      "ANCE (Xiong et al., 2021)\t37.1\t64.5¶\t75.5\t40.8\t64.6\t77.6\n",
      "ContrieverFT (Izacard et al., 2022)\t41.7¶\t62.1\t83.6¶\t43.6¶\t63.2\t85.8¶\n",
      "Table 2: Experimental results (nDCG@10) on low-resource tasks from BEIR (%). The best results are marked in bold and the best performing w/ relevance judgment are marked with ¶ .\n",
      "Methods\tSciFact\tArguAna\tTREC-COVID\tFiQA\tDBPedia\tTREC-NEWS\n",
      "w/o relevance judgment\t\t\t\t\t\t\n",
      "BM25 (Robertson & Zaragoza, 2009)\t67.9\t39.7\t59.5\t23.6\t31.8\t39.5\n",
      "Contriever (Izacard et al., 2022)\t64.9\t37.9\t27.3\t24.5\t29.2\t34.8\n",
      "HyDE (Gao et al., 2023)\t69.1\t46.6\t59.3\t27.3\t36.8\t44.0\n",
      "InteR (Vicuna-13B-v1.5 from LLaMa-2)\t69.3\t42.7\t70.1\t23.6\t39.6\t51.9\n",
      "InteR (Vicuna-33B-v1.3 from LLaMa-1)\t70.3\t39.9\t67.4\t26.0\t40.1\t51.4' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Feng 等 - 2023 - Synergistic Interplay between Search and Large Language Models for Information Retrieval.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16683.603515625\n",
      "page_content='need for zero-shot and few-shot learning models to address this problem [113]. A common practice to improve the models’ effectiveness in a target domain without adequate label signals is through data augmentation.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16683.603515625\n",
      "page_content='need for zero-shot and few-shot learning models to address this problem [113]. A common practice to improve the models’ effectiveness in a target domain without adequate label signals is through data augmentation.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16685.9140625\n",
      "page_content='The performance of fine-tuned pretrained language models is largely determined by the quality as well as the quantity of labelled data. Human-annotated data' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16685.9140625\n",
      "page_content='The performance of fine-tuned pretrained language models is largely determined by the quality as well as the quantity of labelled data. Human-annotated data' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16743.03515625\n",
      "page_content='[180]\tP. Srivastava, T. Ganu, and S. Guha, “Towards zero-shot and few-shot table question answering using gpt-3,” arXiv preprint arXiv:2210.17284, 2022.\n",
      "[181]\tS. Zheng, J. Huang, and K. C.-C. Chang, “Why does chatgpt fall short in answering questions faithfully?” arXiv preprint arXiv:2304.10513, 2023.\n",
      "[182]\tJ. S. Samaan, Y. H. Yeo, N. Rajeev, L. Hawley, S. Abel, W. H. Ng, N. Srinivasan, J. Park, M. Burch, R. Watson et al., “Assessing the accuracy of responses by the language model chatgpt to questions regarding bariatric surgery,” Obesity surgery, pp. 1–7, 2023.\n",
      "[183]\tJ. Holmes, Z. Liu, L. Zhang, Y. Ding, T. T. Sio, L. A. McGee, J. B. Ashman, X. Li, T. Liu, J. Shen et al., “Evaluating large language models on a highly-specialized topic, radiation oncology physics,” Frontiers in Oncology, vol. 13, p. 1219326.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16743.03515625\n",
      "page_content='[180]\tP. Srivastava, T. Ganu, and S. Guha, “Towards zero-shot and few-shot table question answering using gpt-3,” arXiv preprint arXiv:2210.17284, 2022.\n",
      "[181]\tS. Zheng, J. Huang, and K. C.-C. Chang, “Why does chatgpt fall short in answering questions faithfully?” arXiv preprint arXiv:2304.10513, 2023.\n",
      "[182]\tJ. S. Samaan, Y. H. Yeo, N. Rajeev, L. Hawley, S. Abel, W. H. Ng, N. Srinivasan, J. Park, M. Burch, R. Watson et al., “Assessing the accuracy of responses by the language model chatgpt to questions regarding bariatric surgery,” Obesity surgery, pp. 1–7, 2023.\n",
      "[183]\tJ. Holmes, Z. Liu, L. Zhang, Y. Ding, T. T. Sio, L. A. McGee, J. B. Ashman, X. Li, T. Liu, J. Shen et al., “Evaluating large language models on a highly-specialized topic, radiation oncology physics,” Frontiers in Oncology, vol. 13, p. 1219326.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16745.37109375\n",
      "page_content='Research works exploring GLLMs for question answering tasks. The NLP research community explored GLLMs for question answering in various domains like education [177], [184], news [180], healthcare [138], [182], [183], [185], [186], [190], [191], [193], [195], social media [135], coding [187], legal [188], [194], finance [136] and scientific literature [189]. Most of the research works focused on the English language, except a few research works focusing on languages like Portuguese [177], Japanese [191], [195] and Chinese [193]. As advanced prompting methods allow GLLMs to perform well, some of the research works investigated the effectiveness of advanced prompting strategies like chain-of-thought [138], [177], [178], [183], [189], [195], selfquestion prompting [138], [193] and holistically thought [193] for question answering. Table 3 presents a summary of research works exploring GLLMs for question answering across various domains and languages.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16745.37109375\n",
      "page_content='Research works exploring GLLMs for question answering tasks. The NLP research community explored GLLMs for question answering in various domains like education [177], [184], news [180], healthcare [138], [182], [183], [185], [186], [190], [191], [193], [195], social media [135], coding [187], legal [188], [194], finance [136] and scientific literature [189]. Most of the research works focused on the English language, except a few research works focusing on languages like Portuguese [177], Japanese [191], [195] and Chinese [193]. As advanced prompting methods allow GLLMs to perform well, some of the research works investigated the effectiveness of advanced prompting strategies like chain-of-thought [138], [177], [178], [183], [189], [195], selfquestion prompting [138], [193] and holistically thought [193] for question answering. Table 3 presents a summary of research works exploring GLLMs for question answering across various domains and languages.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16749.775390625\n",
      "page_content='Initial Retriever\tBM25\t-\t-\t-\t-\t-\t50.58\t47.96\n",
      "\tmonoBERT [12]\tBERT\t340M\t-\t✓\t✓\t70.50\t67.28\n",
      "Supervised\tmonoT5 [13]\tT5\t220M\t-\t✓\t✓\t71.48\t66.99\n",
      "\tRankT5 [144]\tT5\t3B\t-\t✓\t✓\t71.22\t69.49\n",
      "Unsupervised-Pointwise\tQuery Generation [153]\tFLAN-UL2\t20B\tO(N)\t✓\t✓\t58.95\t60.02\n",
      "\tRelevance Generation [150]\tFLAN-UL2\t20B\tO(N)\t✓\t✓\t64.61\t65.39\n",
      "Unsupervised-Listwise\tRankGPT3.5 [159] RankGPT4 [159]\tgpt-3.5-turbo gpt-4\t154B* 1T*\tO(k * N) O(k * N)\t\t\t65.80 75.59\t62.91 70.56\n",
      "Unsupervised-Pairwise\tPRP-Allpair [164] PRP-Heapsort [164]\tFLAN-UL2 FLAN-UL2\t20B 20B\tO(N 2) O(N * logN)\t✓ ✓\t✓\t72.42 71.88\t70.68 69.43\n",
      "Furthermore, Askari et al. [172] propose to utilize reinforcement learning to improve the quality of synthetic documents generated by LLMs.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16749.775390625\n",
      "page_content='Initial Retriever\tBM25\t-\t-\t-\t-\t-\t50.58\t47.96\n",
      "\tmonoBERT [12]\tBERT\t340M\t-\t✓\t✓\t70.50\t67.28\n",
      "Supervised\tmonoT5 [13]\tT5\t220M\t-\t✓\t✓\t71.48\t66.99\n",
      "\tRankT5 [144]\tT5\t3B\t-\t✓\t✓\t71.22\t69.49\n",
      "Unsupervised-Pointwise\tQuery Generation [153]\tFLAN-UL2\t20B\tO(N)\t✓\t✓\t58.95\t60.02\n",
      "\tRelevance Generation [150]\tFLAN-UL2\t20B\tO(N)\t✓\t✓\t64.61\t65.39\n",
      "Unsupervised-Listwise\tRankGPT3.5 [159] RankGPT4 [159]\tgpt-3.5-turbo gpt-4\t154B* 1T*\tO(k * N) O(k * N)\t\t\t65.80 75.59\t62.91 70.56\n",
      "Unsupervised-Pairwise\tPRP-Allpair [164] PRP-Heapsort [164]\tFLAN-UL2 FLAN-UL2\t20B 20B\tO(N 2) O(N * logN)\t✓ ✓\t✓\t72.42 71.88\t70.68 69.43\n",
      "Furthermore, Askari et al. [172] propose to utilize reinforcement learning to improve the quality of synthetic documents generated by LLMs.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16762.369140625\n",
      "page_content='•\tReducing the latency of LLM-based retrievers. LLMs, with their massive parameters and world knowledge, often entail high latency during the inferring process. This delay poses a significant challenge for practical applications of LLM-based retrievers, as search engines require in-time responses. To address this issue, promising research directions include transferring the capabilities of LLMs to smaller models, exploring quantization techniques for LLMs in IR tasks, and so on.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16762.369140625\n",
      "page_content='•\tReducing the latency of LLM-based retrievers. LLMs, with their massive parameters and world knowledge, often entail high latency during the inferring process. This delay poses a significant challenge for practical applications of LLM-based retrievers, as search engines require in-time responses. To address this issue, promising research directions include transferring the capabilities of LLMs to smaller models, exploring quantization techniques for LLMs in IR tasks, and so on.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16768.494140625\n",
      "page_content='Danqi Chen, Adam Fisch, Jason Weston, and Antoine Bordes. Reading Wikipedia to answer open-domain questions. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 1870–1879, Vancouver, Canada, July 2017. Association for Computational Linguistics. doi: 10.18653/v1/P17-1171. URL https://aclanthology.org/P17-1171.\n",
      "Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin Zheng, Siyuan Zhuang, Yonghao Zhuang, Joseph E. Gonzalez, Ion Stoica, and Eric P. Xing. Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality, March 2023. URL https: //lmsys.org/blog/2023-03-30-vicuna/.\n",
      "Nick Craswell, Bhaskar Mitra, Emine Yilmaz, Daniel Campos, and Ellen M Voorhees. Overview of the trec 2019 deep learning track. arXiv preprint arXiv:2003.07820, 2020.\n",
      "Nick Craswell, Bhaskar Mitra, Emine Yilmaz, and Daniel Campos. Overview of the trec 2020 deep learning track. arXiv preprint arXiv:2102.07662, 2021.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Feng 等 - 2023 - Synergistic Interplay between Search and Large Language Models for Information Retrieval.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16768.494140625\n",
      "page_content='Danqi Chen, Adam Fisch, Jason Weston, and Antoine Bordes. Reading Wikipedia to answer open-domain questions. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 1870–1879, Vancouver, Canada, July 2017. Association for Computational Linguistics. doi: 10.18653/v1/P17-1171. URL https://aclanthology.org/P17-1171.\n",
      "Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin Zheng, Siyuan Zhuang, Yonghao Zhuang, Joseph E. Gonzalez, Ion Stoica, and Eric P. Xing. Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality, March 2023. URL https: //lmsys.org/blog/2023-03-30-vicuna/.\n",
      "Nick Craswell, Bhaskar Mitra, Emine Yilmaz, Daniel Campos, and Ellen M Voorhees. Overview of the trec 2019 deep learning track. arXiv preprint arXiv:2003.07820, 2020.\n",
      "Nick Craswell, Bhaskar Mitra, Emine Yilmaz, and Daniel Campos. Overview of the trec 2020 deep learning track. arXiv preprint arXiv:2102.07662, 2021.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Feng 等 - 2023 - Synergistic Interplay between Search and Large Language Models for Information Retrieval.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16775.28515625\n",
      "page_content='documents to the input for the frozen LM and treats the LM as a black box. Demonstrate–Search–Predict (DSP) (Khattab et al., 2022) obtains performance gains by relying on passing natural language texts in sophisticated pipelines between a language model and a retrieval model, which is most closely related to our approach. However, they rely on composing two parts with in-context learning and target on multi-hop question answering. While we aim at conducting information refinement via multiple interactions between RMs and LLMs for large-scale retrieval.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Feng 等 - 2023 - Synergistic Interplay between Search and Large Language Models for Information Retrieval.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16775.28515625\n",
      "page_content='documents to the input for the frozen LM and treats the LM as a black box. Demonstrate–Search–Predict (DSP) (Khattab et al., 2022) obtains performance gains by relying on passing natural language texts in sophisticated pipelines between a language model and a retrieval model, which is most closely related to our approach. However, they rely on composing two parts with in-context learning and target on multi-hop question answering. While we aim at conducting information refinement via multiple interactions between RMs and LLMs for large-scale retrieval.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Feng 等 - 2023 - Synergistic Interplay between Search and Large Language Models for Information Retrieval.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16826.1171875\n",
      "page_content='1.\tThe phrase \"snappy screenplay\" implies that the screenplay is of a high quality and is well-crafted.\n",
      "2.\tThe phrase \"curls at the edges\" implies that the screenplay is cleverly written.\n",
      "3.\tThe phrase \"so clever you want to hate it\" is a paradoxical statement, which suggests that the sentiment is positive despite the use of the word \"hate\".\n",
      "Decision Making Based on the reasoning process, the model makes the decision for the sentiment of the given input:\n",
      "Overall, the clues and reasoning process point to a positive sentiment for the input sentence.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16826.1171875\n",
      "page_content='1.\tThe phrase \"snappy screenplay\" implies that the screenplay is of a high quality and is well-crafted.\n",
      "2.\tThe phrase \"curls at the edges\" implies that the screenplay is cleverly written.\n",
      "3.\tThe phrase \"so clever you want to hate it\" is a paradoxical statement, which suggests that the sentiment is positive despite the use of the word \"hate\".\n",
      "Decision Making Based on the reasoning process, the model makes the decision for the sentiment of the given input:\n",
      "Overall, the clues and reasoning process point to a positive sentiment for the input sentence.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16841.142578125\n",
      "page_content='Chalkidis et al. [346] investigated how effective Chat-GPT is for legal text classification by evaluating the model performance on the LexGLUE [360] benchmark, which consists of seven legal text classification datasets.\n",
      "The evaluation is performed in both zero and few-shot settings. Experiment results showed that ChatGPT performs poorly on legal text classification datasets. Choi et al. [347] demonstrated that the performance of ChatGPT is just above the passing threshold, i.e., equivalent to a C+ grade student. The authors found that advanced prompts like CoT [361] and Ranking prompts performed worse or the same as simple prompts for multiple-choice questions. For essay writing, the authors used carefully crafted simple prompts by including specific instructions at the end of the prompt.\n",
      "5.3\tFinance Domain' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16841.142578125\n",
      "page_content='Chalkidis et al. [346] investigated how effective Chat-GPT is for legal text classification by evaluating the model performance on the LexGLUE [360] benchmark, which consists of seven legal text classification datasets.\n",
      "The evaluation is performed in both zero and few-shot settings. Experiment results showed that ChatGPT performs poorly on legal text classification datasets. Choi et al. [347] demonstrated that the performance of ChatGPT is just above the passing threshold, i.e., equivalent to a C+ grade student. The authors found that advanced prompts like CoT [361] and Ranking prompts performed worse or the same as simple prompts for multiple-choice questions. For essay writing, the authors used carefully crafted simple prompts by including specific instructions at the end of the prompt.\n",
      "5.3\tFinance Domain' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16844.9140625\n",
      "page_content='Pop(qi) > ^\n",
      "Conversely, a query qi is outside the knowledge boundary if:\n",
      "Pop(qi) < e\n",
      "4\tExperiments\n",
      "4.1\tModular Setting\n",
      "Fine-tuning Gemma-2B We follow the Alpaca’s training method2, employing the LoRa[12] method to instruction-tune the pre-trained Gemma-2B model3 for the Question Rewriter+ and Knowledge Filter modules. We set the learning rate to 1e-4, batch size to 8, and epochs to 6. We set the rank of the LoRa low-rank matrix to 8, and the scaling factor, alpha to 16. Additionally, we utilize the 4-bit quantization method with NF4 quantization type [7]. The training and inference process are all conducted on a single Nvidia Quadro RTX 6000.\n",
      "Knowledge Retriever We utilize the Bing Search Engine v7 as the information retrieval method. For each query q, we select the top-n items from the search results, and each item is regarded as a knowledge instance. We utilize the snippet of a search item as the content of a knowledge instance. The hyperparameter n is predetermined at 10.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16844.9140625\n",
      "page_content='Pop(qi) > ^\n",
      "Conversely, a query qi is outside the knowledge boundary if:\n",
      "Pop(qi) < e\n",
      "4\tExperiments\n",
      "4.1\tModular Setting\n",
      "Fine-tuning Gemma-2B We follow the Alpaca’s training method2, employing the LoRa[12] method to instruction-tune the pre-trained Gemma-2B model3 for the Question Rewriter+ and Knowledge Filter modules. We set the learning rate to 1e-4, batch size to 8, and epochs to 6. We set the rank of the LoRa low-rank matrix to 8, and the scaling factor, alpha to 16. Additionally, we utilize the 4-bit quantization method with NF4 quantization type [7]. The training and inference process are all conducted on a single Nvidia Quadro RTX 6000.\n",
      "Knowledge Retriever We utilize the Bing Search Engine v7 as the information retrieval method. For each query q, we select the top-n items from the search results, and each item is regarded as a knowledge instance. We utilize the snippet of a search item as the content of a knowledge instance. The hyperparameter n is predetermined at 10.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16857.361328125\n",
      "page_content='Paper\tGLLMs Explored\tTask(s)\tPrompt Settings\tRobustness\tDomain(s)\tLanguage(s)\n",
      "[455]\tGPT-3, GPT-3.5\tNine NLU Tasks\tZS, FS\tAdversarial Input\tGeneral\tEnglish\n",
      "[456]\tGPT-3.5, ChatGPT\tFour NLU Tasks, Machine Translation\tZS\tOut of Distribution\tGeneral, Medical\tEnglish\n",
      "[457]\tCodex\tSemantic Parsing\tZS, FS\tAdversarial Input\tProgramming\tEnglish\n",
      "[458]\tChatGPT\tEight Tasks including Four NLU tasks\tZS, FS\tAdversarial Prompt\tGeneral\tEnglish\n",
      "[459]\tCodex, InstructGPT, ChatGPT\tCode Generation\tZS\tAdversarial Prompt\tProgramming\tEnglish\n",
      "[425]\tGPT-3, Codex\tTable Question Answering\tFS\tAdversarial Input\tGeneral\tEnglish\n",
      "[460]\tChatGPT\tFourteen IE Tasks\tZS, FS\tAdversarial Prompt\tGeneral\tEnglish\n",
      "[461]\tChatGPT, GPT-4\tQuestion Answering\tZS, FS\tOut-of-Distribution\tGeneral\tEnglish\n",
      "[462]\tChatGPT\tText-to-SQL Generation\tZS\tAdversarial Input\tGeneral\tEnglish' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16857.361328125\n",
      "page_content='Paper\tGLLMs Explored\tTask(s)\tPrompt Settings\tRobustness\tDomain(s)\tLanguage(s)\n",
      "[455]\tGPT-3, GPT-3.5\tNine NLU Tasks\tZS, FS\tAdversarial Input\tGeneral\tEnglish\n",
      "[456]\tGPT-3.5, ChatGPT\tFour NLU Tasks, Machine Translation\tZS\tOut of Distribution\tGeneral, Medical\tEnglish\n",
      "[457]\tCodex\tSemantic Parsing\tZS, FS\tAdversarial Input\tProgramming\tEnglish\n",
      "[458]\tChatGPT\tEight Tasks including Four NLU tasks\tZS, FS\tAdversarial Prompt\tGeneral\tEnglish\n",
      "[459]\tCodex, InstructGPT, ChatGPT\tCode Generation\tZS\tAdversarial Prompt\tProgramming\tEnglish\n",
      "[425]\tGPT-3, Codex\tTable Question Answering\tFS\tAdversarial Input\tGeneral\tEnglish\n",
      "[460]\tChatGPT\tFourteen IE Tasks\tZS, FS\tAdversarial Prompt\tGeneral\tEnglish\n",
      "[461]\tChatGPT, GPT-4\tQuestion Answering\tZS, FS\tOut-of-Distribution\tGeneral\tEnglish\n",
      "[462]\tChatGPT\tText-to-SQL Generation\tZS\tAdversarial Input\tGeneral\tEnglish' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16863.244140625\n",
      "page_content='11.9\tReduce Hallucinations' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16863.244140625\n",
      "page_content='11.9\tReduce Hallucinations' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16867.513671875\n",
      "page_content='Paper\tTask(s)\tGLLMs Explored\tPrompt Settings\tDomain(s)\tLanguage(s)\tSOTA Results\n",
      "[230]\tPassage Re-ranking\tGPT-3, GPT-3.5, ChatGPT, GPT-4\tZS, FS\tGeneral, News, Healthcare, Scientific Literature\tEnglish, Ten Low Resource Languages\tYes\n",
      "[231]\tDocument Retrieval\tGPT-3.5\tZS, FS\tGeneral\tEnglish\tYes\n",
      "TABLE 7. Summary of research works exploring GLLMs for information retrieval tasks. Here ZS represents zero-shot, and FS represents few-shot.\n",
      "4.7\tInformation Retrieval' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16867.513671875\n",
      "page_content='Paper\tTask(s)\tGLLMs Explored\tPrompt Settings\tDomain(s)\tLanguage(s)\tSOTA Results\n",
      "[230]\tPassage Re-ranking\tGPT-3, GPT-3.5, ChatGPT, GPT-4\tZS, FS\tGeneral, News, Healthcare, Scientific Literature\tEnglish, Ten Low Resource Languages\tYes\n",
      "[231]\tDocument Retrieval\tGPT-3.5\tZS, FS\tGeneral\tEnglish\tYes\n",
      "TABLE 7. Summary of research works exploring GLLMs for information retrieval tasks. Here ZS represents zero-shot, and FS represents few-shot.\n",
      "4.7\tInformation Retrieval' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16877.962890625\n",
      "page_content='and further analysis showed that the incorrect answers are due to insufficient medical knowledge and insufficient information about the Japanese-specific medical system. Kasai et al. [195] reported that GPT-4 outperforms other models and passes the Japanese national medical licensing exam in the last six years. Moreover, ChatGPT with English-translated prompts achieves better results than ChatGPT with Japanese prompts. This is because ChatGPT is predominantly trained over the English text corpus.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16877.962890625\n",
      "page_content='and further analysis showed that the incorrect answers are due to insufficient medical knowledge and insufficient information about the Japanese-specific medical system. Kasai et al. [195] reported that GPT-4 outperforms other models and passes the Japanese national medical licensing exam in the last six years. Moreover, ChatGPT with English-translated prompts achieves better results than ChatGPT with Japanese prompts. This is because ChatGPT is predominantly trained over the English text corpus.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16900.97265625\n",
      "page_content='[326]\tM. Moradi, K. Blagec, F. Haberl, and M. Samwald, “Gpt-3 models are poor few-shot learners in the biomedical domain,” arXiv preprint arXiv:2109.02555, 2021.\n",
      "[327]\tK. Jeblick, B. Schachtner, J. Dexl, A. Mittermeier, A. T. Stu¨ ber, J. Topalis, T. Weber, P. Wesp, B. Sabel, J. Ricke et al., “Chatgpt makes medicine easy to swallow: An exploratory case study on simplified radiology reports,” arXiv preprint arXiv:2212.14882, 2022.\n",
      "[328]\tX. Tang, A. Tran, J. Tan, and M. Gerstein, “Gersteinlab at mediqa-chat 2023: Clinical note summarization from doctor-patient conversations through fine-tuning and in-context learning,” arXiv preprint arXiv:2305.05001, 2023.\n",
      "[329]\tM. Agrawal, S. Hegselmann, H. Lang, Y. Kim, and D. Sontag, “Large language models are few-shot clinical information extractors,” in Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, 2022, pp. 1998–2022.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16900.97265625\n",
      "page_content='[326]\tM. Moradi, K. Blagec, F. Haberl, and M. Samwald, “Gpt-3 models are poor few-shot learners in the biomedical domain,” arXiv preprint arXiv:2109.02555, 2021.\n",
      "[327]\tK. Jeblick, B. Schachtner, J. Dexl, A. Mittermeier, A. T. Stu¨ ber, J. Topalis, T. Weber, P. Wesp, B. Sabel, J. Ricke et al., “Chatgpt makes medicine easy to swallow: An exploratory case study on simplified radiology reports,” arXiv preprint arXiv:2212.14882, 2022.\n",
      "[328]\tX. Tang, A. Tran, J. Tan, and M. Gerstein, “Gersteinlab at mediqa-chat 2023: Clinical note summarization from doctor-patient conversations through fine-tuning and in-context learning,” arXiv preprint arXiv:2305.05001, 2023.\n",
      "[329]\tM. Agrawal, S. Hegselmann, H. Lang, Y. Kim, and D. Sontag, “Large language models are few-shot clinical information extractors,” in Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, 2022, pp. 1998–2022.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16905.55859375\n",
      "page_content='The pointwise methods (query generation and relevance generation) judge the relevance of each query-document pair independently, thus offering lower time complexity and enabling batch inference. However, compared to other methods, it does not have an advantage in terms of performance. The listwise method yields significant performance especially when calling GPT-4, but suffers from expensive API cost and non-reproducibility [173]. Compared with the listwise method, the pairwise method shows competitive results based on a much smaller model FLAN-UL2 (20B). Stemming from the necessity to compare an extensive number of document pairs, its primary drawback is low efficiency.\n",
      "5.3\tUtilizing LLMs for Training Data Augmentation' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16905.55859375\n",
      "page_content='The pointwise methods (query generation and relevance generation) judge the relevance of each query-document pair independently, thus offering lower time complexity and enabling batch inference. However, compared to other methods, it does not have an advantage in terms of performance. The listwise method yields significant performance especially when calling GPT-4, but suffers from expensive API cost and non-reproducibility [173]. Compared with the listwise method, the pairwise method shows competitive results based on a much smaller model FLAN-UL2 (20B). Stemming from the necessity to compare an extensive number of document pairs, its primary drawback is low efficiency.\n",
      "5.3\tUtilizing LLMs for Training Data Augmentation' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16908.55078125\n",
      "page_content='to assess NLG outputs using GLLMs like ChatGPT. Luo et al. [475] evaluated ChatGPT’s ability as a factual inconsistency evaluator for text summarization task. Experiment results showed that ChatGPT outperforms existing metrics on most of the datasets.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16908.55078125\n",
      "page_content='to assess NLG outputs using GLLMs like ChatGPT. Luo et al. [475] evaluated ChatGPT’s ability as a factual inconsistency evaluator for text summarization task. Experiment results showed that ChatGPT outperforms existing metrics on most of the datasets.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16919.69921875\n",
      "page_content='Shengding Hu, Ning Ding, Huadong Wang, Zhiyuan Liu, Jingang Wang, Juanzi Li, Wei Wu, and Maosong Sun. 2022. Knowledgeable prompt-tuning: Incorporating knowledge into prompt verbalizer for text classification. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 2225–2240, Dublin, Ireland. Association for Computational Linguistics.\n",
      "Zhengbao Jiang, Jun Araki, Haibo Ding, and Graham Neubig. 2021. How can we know when language models know? on the calibration of language models for question answering. Transac-\n",
      "tions of the Association for Computational Linguistics, 9:962–977.\n",
      "Zhengbao Jiang, Frank F. Xu, Jun Araki, and Graham Neubig. 2020. How Can We Know What Language Models Know? Transactions of the Association for Computational Linguistics, 8:423–438.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16919.69921875\n",
      "page_content='Shengding Hu, Ning Ding, Huadong Wang, Zhiyuan Liu, Jingang Wang, Juanzi Li, Wei Wu, and Maosong Sun. 2022. Knowledgeable prompt-tuning: Incorporating knowledge into prompt verbalizer for text classification. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 2225–2240, Dublin, Ireland. Association for Computational Linguistics.\n",
      "Zhengbao Jiang, Jun Araki, Haibo Ding, and Graham Neubig. 2021. How can we know when language models know? on the calibration of language models for question answering. Transac-\n",
      "tions of the Association for Computational Linguistics, 9:962–977.\n",
      "Zhengbao Jiang, Frank F. Xu, Jun Araki, and Graham Neubig. 2020. How Can We Know What Language Models Know? Transactions of the Association for Computational Linguistics, 8:423–438.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16932.251953125\n",
      "page_content='reasoning: <demo-reason-2> sentiment: <demo-label-word-2>\n",
      ".....\n",
      "input: <demo-text-n>\n",
      "clues: <demo-clues-n> reasoning: <demo-reason-n> sentiment: <demo-label-word-n> input: <text>\n",
      "Examples for prompts with clues and reasons are shown in Figure 2. In this way, for a test example, by following the format of demonstrations, the\n",
      "LLM will first output clues, then reasons, and at last decisions.\n",
      "4.3\tVoting\n",
      "Unlike conventional discriminative models for text classification, which generate deterministic results during inferences, LLMs for in-context learning are generative models and generate distinct textual responses with diverse sampling strategies in multiple runs. We consider the following voting strategies in the paper:\n",
      "•\tMajority Vote: the final result is the most frequent prediction among multiple runs.\n",
      "•\tWeighted Probability Vote: the final result is the one with weighted summed probability from multiple runs.\n",
      "5\tExperiments' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16932.251953125\n",
      "page_content='reasoning: <demo-reason-2> sentiment: <demo-label-word-2>\n",
      ".....\n",
      "input: <demo-text-n>\n",
      "clues: <demo-clues-n> reasoning: <demo-reason-n> sentiment: <demo-label-word-n> input: <text>\n",
      "Examples for prompts with clues and reasons are shown in Figure 2. In this way, for a test example, by following the format of demonstrations, the\n",
      "LLM will first output clues, then reasons, and at last decisions.\n",
      "4.3\tVoting\n",
      "Unlike conventional discriminative models for text classification, which generate deterministic results during inferences, LLMs for in-context learning are generative models and generate distinct textual responses with diverse sampling strategies in multiple runs. We consider the following voting strategies in the paper:\n",
      "•\tMajority Vote: the final result is the most frequent prediction among multiple runs.\n",
      "•\tWeighted Probability Vote: the final result is the one with weighted summed probability from multiple runs.\n",
      "5\tExperiments' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16944.6953125\n",
      "page_content='In an attempt to solve this issue we add a final phrase to the prompt: “Valid failure modes include: ” followed by a newline-separated list of the failure mode labels appearing across the entire dataset. We found that this addition generally causes the model to behave as expected. However, it occasionally hallucinates labels: for example, it predicts the label “Fail to open” for “sticking shu”, and “Fail to adjust” for “cant be adjusted”. It also has issues with label consistency - for example, it predicts both “Fail to function” and “Failure to function”. Similarly to the previous attempt without constraining the label space, this attempt at using the LLM directly without fine-tuning is not directly applicable to failure mode analysis as a result of these issues.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Stewart 等 - 2023 - Large Language Models for Failure Mode Classification An Investigation.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16944.6953125\n",
      "page_content='In an attempt to solve this issue we add a final phrase to the prompt: “Valid failure modes include: ” followed by a newline-separated list of the failure mode labels appearing across the entire dataset. We found that this addition generally causes the model to behave as expected. However, it occasionally hallucinates labels: for example, it predicts the label “Fail to open” for “sticking shu”, and “Fail to adjust” for “cant be adjusted”. It also has issues with label consistency - for example, it predicts both “Fail to function” and “Failure to function”. Similarly to the previous attempt without constraining the label space, this attempt at using the LLM directly without fine-tuning is not directly applicable to failure mode analysis as a result of these issues.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Stewart 等 - 2023 - Large Language Models for Failure Mode Classification An Investigation.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16946.064453125\n",
      "page_content='survey which summarizes the recent research progress in multiple dimensions and can guide the research community with insightful future research directions. We start the survey paper with foundation concepts like transformers, transfer learning, self-supervised learning, pretrained language models and large language models. We then present a brief overview of GLLMs and discuss the performances of GLLMs in various downstream tasks, specific domains and multiple languages. We also discuss the data labelling and data augmentation abilities of GLLMs, the robustness of GLLMs, the effectiveness of GLLMs as evaluators, and finally, conclude with multiple insightful future research directions. To summarize, this comprehensive survey paper will serve as a good resource for both academic and industry people to stay updated with the latest research related to GPT-3 family large language models.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16946.064453125\n",
      "page_content='survey which summarizes the recent research progress in multiple dimensions and can guide the research community with insightful future research directions. We start the survey paper with foundation concepts like transformers, transfer learning, self-supervised learning, pretrained language models and large language models. We then present a brief overview of GLLMs and discuss the performances of GLLMs in various downstream tasks, specific domains and multiple languages. We also discuss the data labelling and data augmentation abilities of GLLMs, the robustness of GLLMs, the effectiveness of GLLMs as evaluators, and finally, conclude with multiple insightful future research directions. To summarize, this comprehensive survey paper will serve as a good resource for both academic and industry people to stay updated with the latest research related to GPT-3 family large language models.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16946.681640625\n",
      "page_content='performance on a wide range of natural language processing tasks, LLMs have already been applied to a variety of domains. Examples include medicine [Singhal et al., 2022, Thirunavukarasu et al., 2023], education [Kasneci et al., 2023], and vehicle accident records [Mumtarin et al., 2023].' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Stewart 等 - 2023 - Large Language Models for Failure Mode Classification An Investigation.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16946.681640625\n",
      "page_content='performance on a wide range of natural language processing tasks, LLMs have already been applied to a variety of domains. Examples include medicine [Singhal et al., 2022, Thirunavukarasu et al., 2023], education [Kasneci et al., 2023], and vehicle accident records [Mumtarin et al., 2023].' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Stewart 等 - 2023 - Large Language Models for Failure Mode Classification An Investigation.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16960.51171875\n",
      "page_content='TABLE 3. Summary of research works exploring GLLMs for question answering tasks. Here ZS represents zero-shot, and FS represents few-shot.\n",
      "in answering patient-specific medical questions from MIMIC-III clinical notes. Experiment results demonstrated that the performances of both models are promising as these models display significant levels of coherence, accuracy, coverage and relevance in their answers. Li et al. [136] demonstrated that GPT4 achieves the best results for question answering in the finance domain and outperforms ChatGPT, domain-specific models like BloombergGPT, FinQANet and general LLMs like OPT (66B), and BLOOM (176B). Although the performance of GLLMs is impressive in zero and few-shot settings in multiple choice question answering, these models still lag behind SOTA results. The main reason for this is the use of cloze prompts. In cloze prompts, the model is prompted with only question without answer options, so the model generates the answers just by conditioning' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16960.51171875\n",
      "page_content='TABLE 3. Summary of research works exploring GLLMs for question answering tasks. Here ZS represents zero-shot, and FS represents few-shot.\n",
      "in answering patient-specific medical questions from MIMIC-III clinical notes. Experiment results demonstrated that the performances of both models are promising as these models display significant levels of coherence, accuracy, coverage and relevance in their answers. Li et al. [136] demonstrated that GPT4 achieves the best results for question answering in the finance domain and outperforms ChatGPT, domain-specific models like BloombergGPT, FinQANet and general LLMs like OPT (66B), and BLOOM (176B). Although the performance of GLLMs is impressive in zero and few-shot settings in multiple choice question answering, these models still lag behind SOTA results. The main reason for this is the use of cloze prompts. In cloze prompts, the model is prompted with only question without answer options, so the model generates the answers just by conditioning' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16963.650390625\n",
      "page_content='sentences in the document are combined and given at once to the model. Moreover, with this prompting strategy, both the GLLMs exhibit better performances than commercial machine translation systems according to human evaluation and also outperform most documentlevel neural machine translation methods in terms of d-BLEU scores. Karpinska et al. [204] explored the GPT-3.5 model for paragraph-level machine translation. The authors experimented with three different prompting strategies, namely translating sentence by sentence in isolation, translating sentence by sentence in the presence of the rest of the paragraph and translating the entire paragraph at once. After extensive evaluation of 18 language pairs, including English and Japanese, the authors report that translating the entire paragraph at once outperforms other strategies and commercial systems like Google Translate. Raunak et al. [208] examined the differences between the translations generated by GLLMs like GPT-3.5 and NMT' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16963.650390625\n",
      "page_content='sentences in the document are combined and given at once to the model. Moreover, with this prompting strategy, both the GLLMs exhibit better performances than commercial machine translation systems according to human evaluation and also outperform most documentlevel neural machine translation methods in terms of d-BLEU scores. Karpinska et al. [204] explored the GPT-3.5 model for paragraph-level machine translation. The authors experimented with three different prompting strategies, namely translating sentence by sentence in isolation, translating sentence by sentence in the presence of the rest of the paragraph and translating the entire paragraph at once. After extensive evaluation of 18 language pairs, including English and Japanese, the authors report that translating the entire paragraph at once outperforms other strategies and commercial systems like Google Translate. Raunak et al. [208] examined the differences between the translations generated by GLLMs like GPT-3.5 and NMT' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16991.92578125\n",
      "page_content='Summary. Based on above results from a series of experiments on\n",
      "various datasets, our findings reveal that: (1) single query have an inherent upper limit of retrievable relevant information; (2) employing multiple queries that focus on different semantic aspects can surpass the information plateau, enhancing both the precision and recall of information retrieval; (3) The phenomenon of irrelevant knowledge is pervasive in RAG and becomes more pronounced with larger volumes of retrieved external information; and (4) rewriting ambiguous questions into intent-specific questions improves the precision of responses.\n",
      "3\tMethodology\n",
      "3.1\tQuestion Rewriter+\n",
      "The design of the Question Rewriter+ module encompasses two primary functions: (1) enhancing the original question semantically into a rewritten question, and (2) generating multiple search-friendly queries. Formally, the Question Rewriter+ is denoted as Ge (•), which takes an original question p as input:\n",
      "Ge (p) ^ (s, Q)' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16991.92578125\n",
      "page_content='Summary. Based on above results from a series of experiments on\n",
      "various datasets, our findings reveal that: (1) single query have an inherent upper limit of retrievable relevant information; (2) employing multiple queries that focus on different semantic aspects can surpass the information plateau, enhancing both the precision and recall of information retrieval; (3) The phenomenon of irrelevant knowledge is pervasive in RAG and becomes more pronounced with larger volumes of retrieved external information; and (4) rewriting ambiguous questions into intent-specific questions improves the precision of responses.\n",
      "3\tMethodology\n",
      "3.1\tQuestion Rewriter+\n",
      "The design of the Question Rewriter+ module encompasses two primary functions: (1) enhancing the original question semantically into a rewritten question, and (2) generating multiple search-friendly queries. Formally, the Question Rewriter+ is denoted as Ge (•), which takes an original question p as input:\n",
      "Ge (p) ^ (s, Q)' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16996.796875\n",
      "page_content='While the LLM is capable of predicting failure modes using this prompt, they are not aligned with any particular failure mode ontology. Downstream analysis using these failure modes is thus not possible, due to the sheer number of possible failure modes and inconsistency between them. For example, the model predicts both “Leakage” and “Leaking”, which are the same failure mode written two different ways. One can liken the LLM’s predicted failure modes to that which might be produced by a layperson, i.e. not a domain expert.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Stewart 等 - 2023 - Large Language Models for Failure Mode Classification An Investigation.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16996.796875\n",
      "page_content='While the LLM is capable of predicting failure modes using this prompt, they are not aligned with any particular failure mode ontology. Downstream analysis using these failure modes is thus not possible, due to the sheer number of possible failure modes and inconsistency between them. For example, the model predicts both “Leakage” and “Leaking”, which are the same failure mode written two different ways. One can liken the LLM’s predicted failure modes to that which might be produced by a layperson, i.e. not a domain expert.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Stewart 等 - 2023 - Large Language Models for Failure Mode Classification An Investigation.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16998.533203125\n",
      "page_content='also focus on this problem using triplets extracted from the knowledge graph and the confidence of LLMs. [239, 240] solve this problem by training LLMs or small language models to judge whether the questions are known by LLMs.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 16998.533203125\n",
      "page_content='also focus on this problem using triplets extracted from the knowledge graph and the confidence of LLMs. [239, 240] solve this problem by training LLMs or small language models to judge whether the questions are known by LLMs.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17005.654296875\n",
      "page_content='[505]\tY. Li, “Unlocking context constraints of llms: Enhancing context efficiency of llms with self-information-based content filtering,” arXiv preprint arXiv:2304.12102, 2023.\n",
      "[506]\tM. A. Arefeen, B. Debnath, and S. Chakradhar, “Leancontext: Cost-efficient domain-specific question answering using llms,” arXiv preprint arXiv:2309.00841, 2023.\n",
      "[507]\tS. Golchin and M. Surdeanu, “Time travel in llms: Tracing data contamination in large language models,” arXiv preprint arXiv:2308.08493, 2023.\n",
      "[508]\tR. Aiyappa, J. An, H. Kwak, and Y.-Y. Ahn, “Can we trust the evaluation on chatgpt?” arXiv preprint arXiv:2303.12767, 2023.\n",
      "[509]\tA. Wang, A. Singh, J. Michael, F. Hill, O. Levy, and S. R. Bowman, “Glue: A multi-task benchmark and analysis platform for natural language understanding,” in International Conference on Learning Representations, 2018.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17005.654296875\n",
      "page_content='[505]\tY. Li, “Unlocking context constraints of llms: Enhancing context efficiency of llms with self-information-based content filtering,” arXiv preprint arXiv:2304.12102, 2023.\n",
      "[506]\tM. A. Arefeen, B. Debnath, and S. Chakradhar, “Leancontext: Cost-efficient domain-specific question answering using llms,” arXiv preprint arXiv:2309.00841, 2023.\n",
      "[507]\tS. Golchin and M. Surdeanu, “Time travel in llms: Tracing data contamination in large language models,” arXiv preprint arXiv:2308.08493, 2023.\n",
      "[508]\tR. Aiyappa, J. An, H. Kwak, and Y.-Y. Ahn, “Can we trust the evaluation on chatgpt?” arXiv preprint arXiv:2303.12767, 2023.\n",
      "[509]\tA. Wang, A. Singh, J. Michael, F. Hill, O. Levy, and S. R. Bowman, “Glue: A multi-task benchmark and analysis platform for natural language understanding,” in International Conference on Learning Representations, 2018.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17015.38671875\n",
      "page_content='bubble sort, are employed to speed up the ranking process. These sorting algorithms utilize efficient data structures to compare document pairs selectively and elevate the most relevant documents to the top of the ranking list, which is particularly useful in top-k ranking. Experimental results show the state-of-the-art performance on the standard benchmarks using moderate-size LLMs (e.g., Flan-UL2 with 20B parameters), which are much smaller than those typically employed in listwise methods (e.g., GPT3.5). Building on the pairwise prompting approach, Luo et al. [166] introduce an innovative scoring unit that leverages the generation probability of judgments instead of discrete judgments, and further design a graph-based aggregation approach to obtain a final relevance score for each document. Besides, the pairwise comparison can also be utilized as a postprocessing step to adjust the relevance scores generated by the pointwise LLM reranker [167].' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17015.38671875\n",
      "page_content='bubble sort, are employed to speed up the ranking process. These sorting algorithms utilize efficient data structures to compare document pairs selectively and elevate the most relevant documents to the top of the ranking list, which is particularly useful in top-k ranking. Experimental results show the state-of-the-art performance on the standard benchmarks using moderate-size LLMs (e.g., Flan-UL2 with 20B parameters), which are much smaller than those typically employed in listwise methods (e.g., GPT3.5). Building on the pairwise prompting approach, Luo et al. [166] introduce an innovative scoring unit that leverages the generation probability of judgments instead of discrete judgments, and further design a graph-based aggregation approach to obtain a final relevance score for each document. Besides, the pairwise comparison can also be utilized as a postprocessing step to adjust the relevance scores generated by the pointwise LLM reranker [167].' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17018.75390625\n",
      "page_content='[186]\tPatient-specific Question Answering\tChatGPT\tZS\tHealthcare\tEnglish\tNo\n",
      "[132]\tQuestion Answering\tChatGPT\tZS\tGeneral\tEnglish\tYes\n",
      "[157]\tBoolean Question Answering\tChatGPT\tZS\tGeneral\tEnglish\tNo\n",
      "[133]\tMultiple Choice Question Answering\tChatGPT\tZS\tGeneral, Social Media\tEnglish\tNo\n",
      "[135]\tQuestion Answering\tGPT-3, GPT-3.5, ChatGPT\tZS, FS\tGeneral\tEnglish\tNo\n",
      "[187]\tMultiple Choice Code Question Answering\tGPT-3.5\tZS\tCoding\tEnglish\tNo\n",
      "[188]\tBar Exam Question Answering\tGPT-3.5\tZS\tLegal\tEnglish\tNo\n",
      "[189]\tMulti-Document Question Answering\tGPT-3.5\tFS\tGeneral, Scientific Literature\tEnglish\tNo\n",
      "[190]\tPlastic Survey Exam Question Answering\tChatGPT\tZS\tHealthcare\tEnglish\tNo\n",
      "[191]\tJapanese Medical Exam Question Answering\tGPT-3.5, GPT-4\tFS\tHealthcare\tJapanese\tNo\n",
      "[136]\tFinancial Question Answering\tChatGPT, GPT-4\tZS\tFinance\tEnglish\tNo\n",
      "[138]\tMedical Question Answering\tGPT-3.5, GPT4\tZS, FS\tHealthcare\tEnglish\tNo\n",
      "[192]\tMultiple Choice Question Answering\tGPT-3, Codex, InstructGPT\tZS\tGeneral\tEnglish\tNo' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17018.75390625\n",
      "page_content='[186]\tPatient-specific Question Answering\tChatGPT\tZS\tHealthcare\tEnglish\tNo\n",
      "[132]\tQuestion Answering\tChatGPT\tZS\tGeneral\tEnglish\tYes\n",
      "[157]\tBoolean Question Answering\tChatGPT\tZS\tGeneral\tEnglish\tNo\n",
      "[133]\tMultiple Choice Question Answering\tChatGPT\tZS\tGeneral, Social Media\tEnglish\tNo\n",
      "[135]\tQuestion Answering\tGPT-3, GPT-3.5, ChatGPT\tZS, FS\tGeneral\tEnglish\tNo\n",
      "[187]\tMultiple Choice Code Question Answering\tGPT-3.5\tZS\tCoding\tEnglish\tNo\n",
      "[188]\tBar Exam Question Answering\tGPT-3.5\tZS\tLegal\tEnglish\tNo\n",
      "[189]\tMulti-Document Question Answering\tGPT-3.5\tFS\tGeneral, Scientific Literature\tEnglish\tNo\n",
      "[190]\tPlastic Survey Exam Question Answering\tChatGPT\tZS\tHealthcare\tEnglish\tNo\n",
      "[191]\tJapanese Medical Exam Question Answering\tGPT-3.5, GPT-4\tFS\tHealthcare\tJapanese\tNo\n",
      "[136]\tFinancial Question Answering\tChatGPT, GPT-4\tZS\tFinance\tEnglish\tNo\n",
      "[138]\tMedical Question Answering\tGPT-3.5, GPT4\tZS, FS\tHealthcare\tEnglish\tNo\n",
      "[192]\tMultiple Choice Question Answering\tGPT-3, Codex, InstructGPT\tZS\tGeneral\tEnglish\tNo' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17026.150390625\n",
      "page_content='technology and people. The purpose of this study is to examine cutting-edge approaches in augmented analytics and natural language processing in order to create a sophisticated natural language generation model for augmented analytics data interpretation.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kania和Mehta - 2023 - A Literature Review on Augmented Analytics and Natural Language Generation A Review of State of Art.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17026.150390625\n",
      "page_content='technology and people. The purpose of this study is to examine cutting-edge approaches in augmented analytics and natural language processing in order to create a sophisticated natural language generation model for augmented analytics data interpretation.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kania和Mehta - 2023 - A Literature Review on Augmented Analytics and Natural Language Generation A Review of State of Art.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17037.486328125\n",
      "page_content='4.1\tRM Step: Refining Information in RM via LLM\n",
      "When people use search systems, the natural way is to first type in a search query q whose genre can be a question, a keyword, or a combination of both. The RMs in search systems then process the search query q and retrieve several documents D based on their relevance ^(q, d) to the search query q. Ideally, D contains the necessary information related to the user-issued query q. However, it may include irrelevant information to query as the candidate documents for retrieval are chunked and fixed (Yu et al., 2023). Moreover, it may also miss some required knowledge since the query is often fairly condensed and short (e.g., “best sushi in San Francisco”).' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Feng 等 - 2023 - Synergistic Interplay between Search and Large Language Models for Information Retrieval.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17037.486328125\n",
      "page_content='4.1\tRM Step: Refining Information in RM via LLM\n",
      "When people use search systems, the natural way is to first type in a search query q whose genre can be a question, a keyword, or a combination of both. The RMs in search systems then process the search query q and retrieve several documents D based on their relevance ^(q, d) to the search query q. Ideally, D contains the necessary information related to the user-issued query q. However, it may include irrelevant information to query as the candidate documents for retrieval are chunked and fixed (Yu et al., 2023). Moreover, it may also miss some required knowledge since the query is often fairly condensed and short (e.g., “best sushi in San Francisco”).' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Feng 等 - 2023 - Synergistic Interplay between Search and Large Language Models for Information Retrieval.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17038.328125\n",
      "page_content='τ = 0.4\t96.40\n",
      "τ = 0.6\t96.59\n",
      "τ =0.8\t96.68\n",
      "τ=1.0\t96.70\n",
      "11https://platform.openai.com/tokenizer\n",
      "\tSST-2 : positive/negative sentiment analysis\n",
      "Label Word Map\t{0: Negative, 1: Positive}\n",
      "Zero-Shot\n",
      "Classify Prompt:\tPlease classify the overall SENTIMENT polarity of the INPUT sentence as Positive or Negative. INPUT: <sent> SENTIMENT:\n",
      "Reason-Classify Prompts:\tPlease classify the overall SENTIMENT polarity of the INPUT sentence as Positive or Negative. INPUT: <sent>\n",
      "Findclue-Reason-Classify\tStep 1: Please classify the overall SENTIMENT polarity of the INPUT sentence as Positive or Negative. INPUT: <sent>\n",
      "\tStep 2: Please classify the overall SENTIMENT polarity of the INPUT sentence as Positive or Negative. INPUT: <sent> CLUES: <step-1-response>\n",
      "Few-Shot\n",
      "Classify Prompt:\tPlease classify the overall SENTIMENT polarity of the INPUT sentence as Positive or Negative. INPUT: <demo-sent> SENTIMENT: <demo-label-word>\n",
      "\tINPUT: <demo-sent> SENTIMENT: <demo-label-word> INPUT: <sent> SENTIMENT:' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17038.328125\n",
      "page_content='τ = 0.4\t96.40\n",
      "τ = 0.6\t96.59\n",
      "τ =0.8\t96.68\n",
      "τ=1.0\t96.70\n",
      "11https://platform.openai.com/tokenizer\n",
      "\tSST-2 : positive/negative sentiment analysis\n",
      "Label Word Map\t{0: Negative, 1: Positive}\n",
      "Zero-Shot\n",
      "Classify Prompt:\tPlease classify the overall SENTIMENT polarity of the INPUT sentence as Positive or Negative. INPUT: <sent> SENTIMENT:\n",
      "Reason-Classify Prompts:\tPlease classify the overall SENTIMENT polarity of the INPUT sentence as Positive or Negative. INPUT: <sent>\n",
      "Findclue-Reason-Classify\tStep 1: Please classify the overall SENTIMENT polarity of the INPUT sentence as Positive or Negative. INPUT: <sent>\n",
      "\tStep 2: Please classify the overall SENTIMENT polarity of the INPUT sentence as Positive or Negative. INPUT: <sent> CLUES: <step-1-response>\n",
      "Few-Shot\n",
      "Classify Prompt:\tPlease classify the overall SENTIMENT polarity of the INPUT sentence as Positive or Negative. INPUT: <demo-sent> SENTIMENT: <demo-label-word>\n",
      "\tINPUT: <demo-sent> SENTIMENT: <demo-label-word> INPUT: <sent> SENTIMENT:' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17039.716796875\n",
      "page_content='RETRO [23]\tTransformer\tAttention layer\tDuring generation (every n tokens)\tTraining from scratch\n",
      "ITERGEN [190]\tGPT\tInput layer\tDuring generation (every answer)\tPrompting\n",
      "IRCoT [191]\tFlan-T5 & GPT\tInput layer\tDuring generation (every sentence)\tPrompting\n",
      "FLARE [192]\tGPT\tInput layer\tDuring generation (aperiodic)\tPrompting\n",
      "Self-RAG [193]\tLLaMA\tInput layer\tDuring generation (aperiodic)\tFine-tuning\n",
      "6.1\tPassive Reader\n",
      "To generate answers for users, a straightforward strategy is to supply the retrieved documents according to the queries or previously generated texts from IR systems as inputs to LLMs for creating passages [23, 182–187, 189, 191, 192, 194– 197]. By this means, these approaches use the LLMs and IR systems separately, with LLMs functioning as passive recipients of documents from the IR systems. The strategies for utilizing LLMs within IR systems’ reader modules can be categorized into the following three groups according to the frequency of retrieving documents for LLMs.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17039.716796875\n",
      "page_content='RETRO [23]\tTransformer\tAttention layer\tDuring generation (every n tokens)\tTraining from scratch\n",
      "ITERGEN [190]\tGPT\tInput layer\tDuring generation (every answer)\tPrompting\n",
      "IRCoT [191]\tFlan-T5 & GPT\tInput layer\tDuring generation (every sentence)\tPrompting\n",
      "FLARE [192]\tGPT\tInput layer\tDuring generation (aperiodic)\tPrompting\n",
      "Self-RAG [193]\tLLaMA\tInput layer\tDuring generation (aperiodic)\tFine-tuning\n",
      "6.1\tPassive Reader\n",
      "To generate answers for users, a straightforward strategy is to supply the retrieved documents according to the queries or previously generated texts from IR systems as inputs to LLMs for creating passages [23, 182–187, 189, 191, 192, 194– 197]. By this means, these approaches use the LLMs and IR systems separately, with LLMs functioning as passive recipients of documents from the IR systems. The strategies for utilizing LLMs within IR systems’ reader modules can be categorized into the following three groups according to the frequency of retrieving documents for LLMs.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17057.353515625\n",
      "page_content='using LLM-generated knowledge collections and enables LLMs to enhance prompt formulation using retrieved documents. This iterative refinement process augments the inputs of RMs and LLMs, leading to more accurate retrieval. Experiments on large-scale retrieval benchmarks involving web search and low-resource retrieval tasks demonstrate that InteR achieves overall superior zero-shot retrieval performance compared to state-of-the-art methods, even those using relevance judgment. Source code is available at https://github.com/Cyril-JZ/InteR.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Feng 等 - 2023 - Synergistic Interplay between Search and Large Language Models for Information Retrieval.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17057.353515625\n",
      "page_content='using LLM-generated knowledge collections and enables LLMs to enhance prompt formulation using retrieved documents. This iterative refinement process augments the inputs of RMs and LLMs, leading to more accurate retrieval. Experiments on large-scale retrieval benchmarks involving web search and low-resource retrieval tasks demonstrate that InteR achieves overall superior zero-shot retrieval performance compared to state-of-the-art methods, even those using relevance judgment. Source code is available at https://github.com/Cyril-JZ/InteR.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Feng 等 - 2023 - Synergistic Interplay between Search and Large Language Models for Information Retrieval.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17060.625\n",
      "page_content='to leverage the extraordinary generative abilities of GLLMs to make the data annotation process less expensive, faster and consistent. Similar to the human annotation process, GLLMs are provided with detailed instructions along with some labelled examples to label the data.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17060.625\n",
      "page_content='to leverage the extraordinary generative abilities of GLLMs to make the data annotation process less expensive, faster and consistent. Similar to the human annotation process, GLLMs are provided with detailed instructions along with some labelled examples to label the data.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17066.677734375\n",
      "page_content='Paper\tTask(s)\tGLLMs Explored\tPrompt Settings\tDomain(s)\tLanguage(s)\n",
      "[218]\tSpoken Language Understanding and Dialogue State Tracking\tGPT-3.5, ChatGPT\tZS\tGeneral\tEnglish\n",
      "[219]\tEmotion Dialogue Understanding and Generation Tasks\tChatGPT\tZS, FS\tGeneral\tEnglish\n",
      "[220]\tDialogue Summarization\tGPT-3\tZS\tHealthcare\tEnglish\n",
      "[132]\tDialogue Generation\tChatGPT\tZS\tGeneral\tEnglish\n",
      "[157]\tDialogue Summarization\tChatGPT\tZS\tGeneral\tEnglish\n",
      "[221]\tDialogue Summarization\tGPT-3\tFS\tGeneral\tEnglish\n",
      "[222]\tDialog Evaluation\tGPT-3\tFS\tGeneral\tEnglish\n",
      "[223]\tDialogue Discourse Analysis\tChatGPT\tZS, FS\tGeneral\tEnglish, Chinese\n",
      "[224]\tDialogue Question Answering\tChatGPT\tZS, FS\tGeneral\tEnglish, Chinese\n",
      "TABLE 6. Summary of research works exploring GLLMs for various dialogue tasks. Here ZS represents zero-shot, and FS represents few-shot.\n",
      "[228], [229].' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17066.677734375\n",
      "page_content='Paper\tTask(s)\tGLLMs Explored\tPrompt Settings\tDomain(s)\tLanguage(s)\n",
      "[218]\tSpoken Language Understanding and Dialogue State Tracking\tGPT-3.5, ChatGPT\tZS\tGeneral\tEnglish\n",
      "[219]\tEmotion Dialogue Understanding and Generation Tasks\tChatGPT\tZS, FS\tGeneral\tEnglish\n",
      "[220]\tDialogue Summarization\tGPT-3\tZS\tHealthcare\tEnglish\n",
      "[132]\tDialogue Generation\tChatGPT\tZS\tGeneral\tEnglish\n",
      "[157]\tDialogue Summarization\tChatGPT\tZS\tGeneral\tEnglish\n",
      "[221]\tDialogue Summarization\tGPT-3\tFS\tGeneral\tEnglish\n",
      "[222]\tDialog Evaluation\tGPT-3\tFS\tGeneral\tEnglish\n",
      "[223]\tDialogue Discourse Analysis\tChatGPT\tZS, FS\tGeneral\tEnglish, Chinese\n",
      "[224]\tDialogue Question Answering\tChatGPT\tZS, FS\tGeneral\tEnglish, Chinese\n",
      "TABLE 6. Summary of research works exploring GLLMs for various dialogue tasks. Here ZS represents zero-shot, and FS represents few-shot.\n",
      "[228], [229].' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17081.25\n",
      "page_content='paradigm, which involves task-specific fine-tuning and hundreds or thousands of labelled instances [1], [3]. LLMs leverage in-context learning (ICL), a new learning paradigm which doesn’t require task-specific fine-tuning and a large number of labelled instances [4]. LLMs treat any NLP task as a conditional text generation problem and generate the desired text output just by conditioning on the input prompt, which includes task description, test input and optionally, a few examples. Figure 1 shows the evolution of artificial intelligence from machine learning to large language models.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17081.25\n",
      "page_content='paradigm, which involves task-specific fine-tuning and hundreds or thousands of labelled instances [1], [3]. LLMs leverage in-context learning (ICL), a new learning paradigm which doesn’t require task-specific fine-tuning and a large number of labelled instances [4]. LLMs treat any NLP task as a conditional text generation problem and generate the desired text output just by conditioning on the input prompt, which includes task description, test input and optionally, a few examples. Figure 1 shows the evolution of artificial intelligence from machine learning to large language models.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17085.39453125\n",
      "page_content='Despite significant advancements, several unresolved deficiencies persist in practical applications. In the Query Rewriter module, the reliance on generating a single query for retrieval leads to (1) Information Plateau, as this unidirectional search method limits the scope of retrievable information. Besides, the frequent misalignment between the input question and the underlying inquiry intent often exacerbated by (2) ambiguous phrasing, significantly impedes the LLM’s accurately interpreting users’ demand. Furthermore, while the Query Rewriter can facilitate the retrieval of relevant information, it cannot guarantee the accuracy of the retrieved information. The extensive retrieval process may also acquire (3) irrelevant knowledge, which detracts from the response quality by introducing noise into the context. At last, we have identified a phenomenon of (4) redundant retrieval, where users pose questions similar to previous inquiries, causing the RAG system to fetch the same' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17085.39453125\n",
      "page_content='Despite significant advancements, several unresolved deficiencies persist in practical applications. In the Query Rewriter module, the reliance on generating a single query for retrieval leads to (1) Information Plateau, as this unidirectional search method limits the scope of retrievable information. Besides, the frequent misalignment between the input question and the underlying inquiry intent often exacerbated by (2) ambiguous phrasing, significantly impedes the LLM’s accurately interpreting users’ demand. Furthermore, while the Query Rewriter can facilitate the retrieval of relevant information, it cannot guarantee the accuracy of the retrieved information. The extensive retrieval process may also acquire (3) irrelevant knowledge, which detracts from the response quality by introducing noise into the context. At last, we have identified a phenomenon of (4) redundant retrieval, where users pose questions similar to previous inquiries, causing the RAG system to fetch the same' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17113.919921875\n",
      "page_content='Supervised Methods\t\t\t\t\t\t\n",
      "RoBERTa-Large (Liu et al., 2019)\t95.99\t95.55\t97.76\t96.42\t91.16\t95.38\n",
      "DeBERTa (He et al., 2020)\t94.75\t95.32\t98.33\t96.32\t90.19\t94.99\n",
      "RoBERTa-GCN (Lin et al., 2021)\t95.80\t95.68*\t98.2\t96.1\t89.7\t95.10\n",
      "XLNet (Yang et al., 2019)\t96.10*\t95.55\t-\t-\t-\t-\n",
      "VLAWE (Ionescu and Butnaru, 2019)\t-\t-\t-\t-\t93.3*\t-\n",
      "GCN-SB (Zeng et al., 2022)\t-\t-\t98.53*\t96.35*\t87.59\t-\n",
      "Zero-shot Setting\t\t\t\t\t\t\n",
      "Vanilla (Brown et al., 2020)\t91.55\t90.72\t90.19\t89.06\t88.69\t90.04\n",
      "CoT (Kojima et al., 2022)\t92.11\t91.25\t90.48\t91.24\t89.37\t90.89\n",
      "CARP\t93.01\t92.60\t91.75\t91.80\t89.94\t91.82\n",
      "Few-shot Setting (k=16)\t\t\t\t\t\t\n",
      "Random Sampler\t\t\t\t\t\t\n",
      "Vanilla (Brown et al., 2020)\t92.36\t91.74\t91.58\t91.56\t89.15\t91.28\n",
      "CoT (Kojima et al., 2022)\t94.56\t95.02\t92.49\t92.03\t89.91\t92.80\n",
      "CARP\t96.20\t95.18\t97.60\t96.19\t90.03\t95.04\n",
      "SimCSE kNN-Sampler\t\t\t\t\t\t\n",
      "Vanilla (Brown et al., 2020)\t93.90\t93.50\t94.36\t92.40\t89.59\t94.05\n",
      "CoT (Kojima et al., 2022)\t94.21\t94.28\t95.07\t92.98\t90.27\t93.69\n",
      "CARP\t95.69\t95.25\t97.83\t96.27\t90.74\t95.16\n",
      "FT kNN-Sampler' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17113.919921875\n",
      "page_content='Supervised Methods\t\t\t\t\t\t\n",
      "RoBERTa-Large (Liu et al., 2019)\t95.99\t95.55\t97.76\t96.42\t91.16\t95.38\n",
      "DeBERTa (He et al., 2020)\t94.75\t95.32\t98.33\t96.32\t90.19\t94.99\n",
      "RoBERTa-GCN (Lin et al., 2021)\t95.80\t95.68*\t98.2\t96.1\t89.7\t95.10\n",
      "XLNet (Yang et al., 2019)\t96.10*\t95.55\t-\t-\t-\t-\n",
      "VLAWE (Ionescu and Butnaru, 2019)\t-\t-\t-\t-\t93.3*\t-\n",
      "GCN-SB (Zeng et al., 2022)\t-\t-\t98.53*\t96.35*\t87.59\t-\n",
      "Zero-shot Setting\t\t\t\t\t\t\n",
      "Vanilla (Brown et al., 2020)\t91.55\t90.72\t90.19\t89.06\t88.69\t90.04\n",
      "CoT (Kojima et al., 2022)\t92.11\t91.25\t90.48\t91.24\t89.37\t90.89\n",
      "CARP\t93.01\t92.60\t91.75\t91.80\t89.94\t91.82\n",
      "Few-shot Setting (k=16)\t\t\t\t\t\t\n",
      "Random Sampler\t\t\t\t\t\t\n",
      "Vanilla (Brown et al., 2020)\t92.36\t91.74\t91.58\t91.56\t89.15\t91.28\n",
      "CoT (Kojima et al., 2022)\t94.56\t95.02\t92.49\t92.03\t89.91\t92.80\n",
      "CARP\t96.20\t95.18\t97.60\t96.19\t90.03\t95.04\n",
      "SimCSE kNN-Sampler\t\t\t\t\t\t\n",
      "Vanilla (Brown et al., 2020)\t93.90\t93.50\t94.36\t92.40\t89.59\t94.05\n",
      "CoT (Kojima et al., 2022)\t94.21\t94.28\t95.07\t92.98\t90.27\t93.69\n",
      "CARP\t95.69\t95.25\t97.83\t96.27\t90.74\t95.16\n",
      "FT kNN-Sampler' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17117.3046875\n",
      "page_content='In this paper, we introduce Clue And Reasoning Prompting (CARP), an extensible, annotation-\n",
      "xiaoya_li@shannonai.com, swguo@cqu.edu.cn tianwei.zhang@ntu.edu.sg, guoyiwan@amazon.com\n",
      "This is an overall sentiment classifier for movie reviews. Classify the overall SENTIMENT of the INPUT as Positive or Negative.\n",
      "(a)\tINPUT: press the delete key\n",
      "SENTIMENT: Neutral\n",
      "This is an overall sentiment classifier for movie reviews. Classify the overall SENTIMENT of the INPUT as Positive or Negative.\n",
      "(b)\tINPUT: press the delete key\n",
      "SENTIMENT: Let's think step-by-step. The input does not contain any words that would indicate a sentiment, so it is not possible to classify the sentiment as either positive or negative.\n",
      "This is an overall sentiment classifier for movie reviews.\n",
      "First, list CLUES (i.e., keywords, phrases, contextual information, semantic relations, semantic meaning, tones, references) that support the sentiment determination of input..' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17117.3046875\n",
      "page_content='In this paper, we introduce Clue And Reasoning Prompting (CARP), an extensible, annotation-\n",
      "xiaoya_li@shannonai.com, swguo@cqu.edu.cn tianwei.zhang@ntu.edu.sg, guoyiwan@amazon.com\n",
      "This is an overall sentiment classifier for movie reviews. Classify the overall SENTIMENT of the INPUT as Positive or Negative.\n",
      "(a)\tINPUT: press the delete key\n",
      "SENTIMENT: Neutral\n",
      "This is an overall sentiment classifier for movie reviews. Classify the overall SENTIMENT of the INPUT as Positive or Negative.\n",
      "(b)\tINPUT: press the delete key\n",
      "SENTIMENT: Let's think step-by-step. The input does not contain any words that would indicate a sentiment, so it is not possible to classify the sentiment as either positive or negative.\n",
      "This is an overall sentiment classifier for movie reviews.\n",
      "First, list CLUES (i.e., keywords, phrases, contextual information, semantic relations, semantic meaning, tones, references) that support the sentiment determination of input..' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17118.986328125\n",
      "page_content='Bard and GPT-3.5 by evaluating their performances in generating Java language code given the natural language descriptions. The authors observed that GPT-3.5 outperforms the Bard model by a large margin of more than 37%.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17118.986328125\n",
      "page_content='Bard and GPT-3.5 by evaluating their performances in generating Java language code given the natural language descriptions. The authors observed that GPT-3.5 outperforms the Bard model by a large margin of more than 37%.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17128.115234375\n",
      "page_content='Prompting LLMs. In addition to fine-tuning LLMs for retrieval, it has been found that LLMs (e.g., GPT-series models) can directly generate relevant web URLs for user queries with a few in-context demonstrations [137]. This unique capability of LLMs is believed to arise from their training exposure to various HTML resources. As a result, LLMs can naturally serve as generative retrievers that directly generate document identifiers to retrieve relevant documents for input queries. To achieve this, an LLM-URL [137] model is proposed. It utilizes the GPT-3 text-davinci-003 model to yield candidate URLs. Furthermore, it designs regular expressions to extract valid URLs from these candidates to locate the retrieved documents.\n",
      "To provide a comprehensive understanding of this topic, Table 4 summarizes the common and unique characteristics of the LLM-based retrievers discussed above.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17128.115234375\n",
      "page_content='Prompting LLMs. In addition to fine-tuning LLMs for retrieval, it has been found that LLMs (e.g., GPT-series models) can directly generate relevant web URLs for user queries with a few in-context demonstrations [137]. This unique capability of LLMs is believed to arise from their training exposure to various HTML resources. As a result, LLMs can naturally serve as generative retrievers that directly generate document identifiers to retrieve relevant documents for input queries. To achieve this, an LLM-URL [137] model is proposed. It utilizes the GPT-3 text-davinci-003 model to yield candidate URLs. Furthermore, it designs regular expressions to extract valid URLs from these candidates to locate the retrieved documents.\n",
      "To provide a comprehensive understanding of this topic, Table 4 summarizes the common and unique characteristics of the LLM-based retrievers discussed above.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17140.5\n",
      "page_content='[265]\tH. Tian, W. Lu, T. O. Li, X. Tang, S.-C. Cheung, J. Klein, and T. F. Bissyande´, “Is chatgpt the ultimate programming assistant–how far is it?” arXiv preprint arXiv:2304.11938, 2023.\n",
      "[266]\tM. Geng, S. Wang, D. Dong, H. Wang, G. Li, Z. Jin, X. Mao, and X. Liao, “An empirical study on using large language models for multi-intent comment generation,” ArXiv, vol. abs/2304.11384, 2023.\n",
      "[267]\tS. Kang, B. Chen, S. Yoo, and J.-G. Lou, “Explainable automated debugging via large language model-driven scientific debugging,” arXiv preprint arXiv:2304.02195, 2023.\n",
      "[268]\tA. Kashefi and T. Mukerji, “Chatgpt for programming numerical methods,” ArXiv, vol. abs/2303.12093, 2023.\n",
      "[269]\tG. Destefanis, S. Bartolucci, and M. Ortu, “A preliminary analysis on the code generation capabilities of gpt-3.5 and bard ai models for java functions,” arXiv preprint arXiv:2305.09402, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17140.5\n",
      "page_content='[265]\tH. Tian, W. Lu, T. O. Li, X. Tang, S.-C. Cheung, J. Klein, and T. F. Bissyande´, “Is chatgpt the ultimate programming assistant–how far is it?” arXiv preprint arXiv:2304.11938, 2023.\n",
      "[266]\tM. Geng, S. Wang, D. Dong, H. Wang, G. Li, Z. Jin, X. Mao, and X. Liao, “An empirical study on using large language models for multi-intent comment generation,” ArXiv, vol. abs/2304.11384, 2023.\n",
      "[267]\tS. Kang, B. Chen, S. Yoo, and J.-G. Lou, “Explainable automated debugging via large language model-driven scientific debugging,” arXiv preprint arXiv:2304.02195, 2023.\n",
      "[268]\tA. Kashefi and T. Mukerji, “Chatgpt for programming numerical methods,” ArXiv, vol. abs/2303.12093, 2023.\n",
      "[269]\tG. Destefanis, S. Bartolucci, and M. Ortu, “A preliminary analysis on the code generation capabilities of gpt-3.5 and bard ai models for java functions,” arXiv preprint arXiv:2305.09402, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17159.66015625\n",
      "page_content='2.2\tIn-context Learning\n",
      "Unlike the pre-training then fine-tuning paradigm (Devlin et al., 2018), which saves model weights and uses task-specific datasets (i.e., train/valid/test set), in-context learning (ICL) generates textual responses (i.e., label words) conditioning on the given prompt (usually) with a few annotated examples for downstream tasks.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17159.66015625\n",
      "page_content='2.2\tIn-context Learning\n",
      "Unlike the pre-training then fine-tuning paradigm (Devlin et al., 2018), which saves model weights and uses task-specific datasets (i.e., train/valid/test set), in-context learning (ICL) generates textual responses (i.e., label words) conditioning on the given prompt (usually) with a few annotated examples for downstream tasks.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17164.75\n",
      "page_content='Research works exploring GLLMs for keyphrase generation. Martinez et al. [216] performed a comprehensive evaluation of ChatGPT as a keyphrase generator by evaluating its performance on six datasets using six candidate prompts. The authors reported that the results are promising, but ChatGPT struggles in the case of generating absent keyphrases. Song et al. [217] evaluated ChatGPT on multiple datasets from news and scientific literature domains having both short and long documents. Experiment results showed that ChatGPT outperforms KeyBART [227], the SOTA model, on all the datasets.\n",
      "4.6\tDialogue Tasks' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17164.75\n",
      "page_content='Research works exploring GLLMs for keyphrase generation. Martinez et al. [216] performed a comprehensive evaluation of ChatGPT as a keyphrase generator by evaluating its performance on six datasets using six candidate prompts. The authors reported that the results are promising, but ChatGPT struggles in the case of generating absent keyphrases. Song et al. [217] evaluated ChatGPT on multiple datasets from news and scientific literature domains having both short and long documents. Experiment results showed that ChatGPT outperforms KeyBART [227], the SOTA model, on all the datasets.\n",
      "4.6\tDialogue Tasks' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17211.162109375\n",
      "page_content='We conduct another experiment using 50 questions from the CAm-bigNQ dataset. We obtain responses by directly inputting the original questions into the LLM, labeled as org. Another set of responses, labeled as rewrt, is generated by inputting rewritten questions into the LLM. The accuracy of these two sets of responses is quantified using the metrics: EM (Exact Match), Precision, Recall, and F1 Score. Additionally, we also use retrieval-enhanced method to generate answers again. These responses are labeled as org_rag for original questions and rewrt_rag for rewritten questions. A comparative analysis of the answer accuracy is conducted in the same manner. These results are illustrated in Figure 3.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17211.162109375\n",
      "page_content='We conduct another experiment using 50 questions from the CAm-bigNQ dataset. We obtain responses by directly inputting the original questions into the LLM, labeled as org. Another set of responses, labeled as rewrt, is generated by inputting rewritten questions into the LLM. The accuracy of these two sets of responses is quantified using the metrics: EM (Exact Match), Precision, Recall, and F1 Score. Additionally, we also use retrieval-enhanced method to generate answers again. These responses are labeled as org_rag for original questions and rewrt_rag for rewritten questions. A comparative analysis of the answer accuracy is conducted in the same manner. These results are illustrated in Figure 3.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17229.15234375\n",
      "page_content='[340]\tS. Liu, A. P. Wright, B. L. Patterson, J. P. Wanderer, R. W. Turer, S. D. Nelson, A. B. McCoy, D. F. Sittig, and A. Wright, “Assessing the value of chatgpt for clinical decision support optimization,” MedRxiv, pp. 2023–02, 2023.\n",
      "[341]\tA. Gilson, C. W. Safranek, T. Huang, V. Socrates, L. Chi, R. A. Taylor, D. Chartash et al., “How does chatgpt perform on the united states medical licensing examination? the implications of large language models for medical education and knowledge assessment,” JMIR Medical Education, vol. 9, no. 1, p. e45312, 2023.\n",
      "[342]\tF. Antaki, S. Touma, D. Milad, J. El-Khoury, and R. Duval, “Evaluating the performance of chatgpt in ophthalmology: An analysis of its successes and shortcomings,” Ophthalmology Science, p. 100324, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17229.15234375\n",
      "page_content='[340]\tS. Liu, A. P. Wright, B. L. Patterson, J. P. Wanderer, R. W. Turer, S. D. Nelson, A. B. McCoy, D. F. Sittig, and A. Wright, “Assessing the value of chatgpt for clinical decision support optimization,” MedRxiv, pp. 2023–02, 2023.\n",
      "[341]\tA. Gilson, C. W. Safranek, T. Huang, V. Socrates, L. Chi, R. A. Taylor, D. Chartash et al., “How does chatgpt perform on the united states medical licensing examination? the implications of large language models for medical education and knowledge assessment,” JMIR Medical Education, vol. 9, no. 1, p. e45312, 2023.\n",
      "[342]\tF. Antaki, S. Touma, D. Milad, J. El-Khoury, and R. Duval, “Evaluating the performance of chatgpt in ophthalmology: An analysis of its successes and shortcomings,” Ophthalmology Science, p. 100324, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17237.013671875\n",
      "page_content='There is a strong need for the development of approaches to detect GLLM generated text, as there are growing concerns regarding the misuse of GLLMs. Such approaches help to distinguish the GLLM generated text from human-generated text and verify the source as well as the authenticity of the information. However, detecting GLLM generated text is more challenging as models like ChatGPT and GPT-4 can generate content with human-like fluency.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17237.013671875\n",
      "page_content='There is a strong need for the development of approaches to detect GLLM generated text, as there are growing concerns regarding the misuse of GLLMs. Such approaches help to distinguish the GLLM generated text from human-generated text and verify the source as well as the authenticity of the information. However, detecting GLLM generated text is more challenging as models like ChatGPT and GPT-4 can generate content with human-like fluency.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17287.107421875\n",
      "page_content='7.\thttps://platform.openai.com/docs/models/overview\n",
      "the application of GLLMs in tasks that require processing long inputs.\n",
      "11.8\tEnsure Fair Evaluation of GLLMs' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17287.107421875\n",
      "page_content='7.\thttps://platform.openai.com/docs/models/overview\n",
      "the application of GLLMs in tasks that require processing long inputs.\n",
      "11.8\tEnsure Fair Evaluation of GLLMs' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17297.912109375\n",
      "page_content='[337]\tT. H. Kung, M. Cheatham, A. Medenilla, C. Sillos, L. De Leon, C. Elepan˜ o, M. Madriaga, R. Aggabao, G. Diaz-Candido, J. Maningo et al., “Performance of chatgpt on usmle: Potential for ai-assisted medical education using large language models,” PLoS digital health, vol. 2, no. 2, p. e0000198, 2023.\n",
      "[338]\tA. Hulman, O. L. Dollerup, J. F. Mortensen, M. Fenech, K. Norman, H. Stoevring, and T. K. Hansen, “Chatgpt-versus humangenerated answers to frequently asked questions about diabetes: a turing test-inspired survey among employees of a danish diabetes center,” medRxiv, pp. 2023–02, 2023.\n",
      "[339]\tT. Hirosawa, Y. Harada, M. Yokose, T. Sakamoto, R. Kawamura, and T. Shimizu, “Diagnostic accuracy of differential-diagnosis lists generated by generative pretrained transformer 3 chatbot for clinical vignettes with common chief complaints: A pilot study,” International journal of environmental research and public health, vol. 20, no. 4, p. 3378, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17297.912109375\n",
      "page_content='[337]\tT. H. Kung, M. Cheatham, A. Medenilla, C. Sillos, L. De Leon, C. Elepan˜ o, M. Madriaga, R. Aggabao, G. Diaz-Candido, J. Maningo et al., “Performance of chatgpt on usmle: Potential for ai-assisted medical education using large language models,” PLoS digital health, vol. 2, no. 2, p. e0000198, 2023.\n",
      "[338]\tA. Hulman, O. L. Dollerup, J. F. Mortensen, M. Fenech, K. Norman, H. Stoevring, and T. K. Hansen, “Chatgpt-versus humangenerated answers to frequently asked questions about diabetes: a turing test-inspired survey among employees of a danish diabetes center,” medRxiv, pp. 2023–02, 2023.\n",
      "[339]\tT. Hirosawa, Y. Harada, M. Yokose, T. Sakamoto, R. Kawamura, and T. Shimizu, “Diagnostic accuracy of differential-diagnosis lists generated by generative pretrained transformer 3 chatbot for clinical vignettes with common chief complaints: A pilot study,” International journal of environmental research and public health, vol. 20, no. 4, p. 3378, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17298.140625\n",
      "page_content='8.1\tQuery Rewriter\n",
      "LLMs have enhanced query rewriter for both ad-hoc and conversational search scenarios. Most of the existing methods rely on prompting LLMs to generate new queries. While yielding remarkable results, the refinement of rewriting quality and the exploration of potential application scenarios require further investigation.\n",
      "•\tRewriting queries according to ranking performance. A typical paradigm of prompting-based methods is providing LLMs with several ground-truth rewriting cases (optional) and the task description of query rewriter. Despite LLMs being capable of identifying potential user intents of the query [278], they lack awareness of the resulting retrieval quality of the rewritten query. The absence of this connection can result in rewritten queries that seem correct yet' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17298.140625\n",
      "page_content='8.1\tQuery Rewriter\n",
      "LLMs have enhanced query rewriter for both ad-hoc and conversational search scenarios. Most of the existing methods rely on prompting LLMs to generate new queries. While yielding remarkable results, the refinement of rewriting quality and the exploration of potential application scenarios require further investigation.\n",
      "•\tRewriting queries according to ranking performance. A typical paradigm of prompting-based methods is providing LLMs with several ground-truth rewriting cases (optional) and the task description of query rewriter. Despite LLMs being capable of identifying potential user intents of the query [278], they lack awareness of the resulting retrieval quality of the rewritten query. The absence of this connection can result in rewritten queries that seem correct yet' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17298.78125\n",
      "page_content='•\tAksitov et al. [233] demonstrate that there exists an attribution and fluency tradeoff for retrieval-augmented LLMs: with more received references, the attribution of generated answers increases while the fluency decreases.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17298.78125\n",
      "page_content='•\tAksitov et al. [233] demonstrate that there exists an attribution and fluency tradeoff for retrieval-augmented LLMs: with more received references, the attribution of generated answers increases while the fluency decreases.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17309.552734375\n",
      "page_content='golchin et al. [507] proposed a novel approach to detect data contamination for LLMs. Future research must focus on developing simple and effective approaches to identify data contamination and ensure fair evaluation, enhancing the reliability of impressive performances of GLLMs.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17309.552734375\n",
      "page_content='golchin et al. [507] proposed a novel approach to detect data contamination for LLMs. Future research must focus on developing simple and effective approaches to identify data contamination and ensure fair evaluation, enhancing the reliability of impressive performances of GLLMs.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17318.375\n",
      "page_content='deviation of our method is smaller than other baselines in most cases, which indicates that our method can maintain good performance with different templates and can therefore reduce human labor in template engineering. Our insight on this is that different templates cause performance fluctuations by impacting model bias on label words, while our approach can greatly eliminate model bias during training.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17318.375\n",
      "page_content='deviation of our method is smaller than other baselines in most cases, which indicates that our method can maintain good performance with different templates and can therefore reduce human labor in template engineering. Our insight on this is that different templates cause performance fluctuations by impacting model bias on label words, while our approach can greatly eliminate model bias during training.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17319.779296875\n",
      "page_content='Assessing the synergistic effect of two modules, we find that while each module individually improves response accuracy, the effect is sometimes modest. However, their combined yields a significant enhancement. For instance, on the CAmbigNQ dataset, the individual application of each module resulted in a maximum of 2% more correctly answered questions, whereas their combined application led to a 7% increase in correctly answered questions. A similar phenomenon can also been observed on the PopQA dataset.\n",
      "6\tEfficiency Improvement Investigation\n",
      "In this section, we explore how efficiently our proposed method reduces redundant retrieval when answering recurring questions with historically similar semantics. We also examine the hyperparameter τ to balance efficiency and response accuracy. The experimental procedure is as follows:' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17319.779296875\n",
      "page_content='Assessing the synergistic effect of two modules, we find that while each module individually improves response accuracy, the effect is sometimes modest. However, their combined yields a significant enhancement. For instance, on the CAmbigNQ dataset, the individual application of each module resulted in a maximum of 2% more correctly answered questions, whereas their combined application led to a 7% increase in correctly answered questions. A similar phenomenon can also been observed on the PopQA dataset.\n",
      "6\tEfficiency Improvement Investigation\n",
      "In this section, we explore how efficiently our proposed method reduces redundant retrieval when answering recurring questions with historically similar semantics. We also examine the hyperparameter τ to balance efficiency and response accuracy. The experimental procedure is as follows:' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17322.173828125\n",
      "page_content='Paper\tGLLMs Explored\tTask(s)\tPrompt Settings\tLanguage(s)\tOutperforms Domain-Specific Models\n",
      "[317]\tChatGPT, GPT-4\tQuestion Answering\tZS\tEnglish\t-\n",
      "[318]\tChatGPT, GPT-4\tText De-identification\tZS\tEnglish\tYes\n",
      "[319]\tGPT-4\tDialogue Summarization\tFS\tEnglish\tYes\n",
      "[320]\tGPT-3.5, ChatGPT, GPT-4\tQuestion Answering\tZS, FS\tEnglish\tYes\n",
      "[321]\tGPT-3.5, GPT-4\tNamed Entity Recognition, Relation Extraction, Document Classification and Semantic Similarity\tZS, FS\tEnglish\tYes\n",
      "[322]\tGPT-3.5, ChatGPT\tQuestion Answering\tZS\tJapanese\t-\n",
      "[323]\tGPT-3.5, GPT-4\tQuestion Answering, Reasoning\tZS\tChinese\tYes\n",
      "[324]\tGPT-3\tText Simplification\tFS\tEnglish\t-\n",
      "[149]\tGPT-3\tEntity Extraction, Relation Classification\tFS\tEnglish\tNo\n",
      "[[137]\tChatGPT, GPT-4\tNatural Language Inference\tZS, FS\tEnglish\t-\n",
      "[325]\tChatGPT\tText Summarization\tFS\tEnglish\tYes\n",
      "[138]\tGPT3.5, GPT4\tNatural Language Inference, Document Classification\tZS, FS\tEnglish\t-\n",
      "[195]\tGPT-3, ChatGPT, GPT-4\tQuestion Answering\tFS\tJapanese\t-' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17322.173828125\n",
      "page_content='Paper\tGLLMs Explored\tTask(s)\tPrompt Settings\tLanguage(s)\tOutperforms Domain-Specific Models\n",
      "[317]\tChatGPT, GPT-4\tQuestion Answering\tZS\tEnglish\t-\n",
      "[318]\tChatGPT, GPT-4\tText De-identification\tZS\tEnglish\tYes\n",
      "[319]\tGPT-4\tDialogue Summarization\tFS\tEnglish\tYes\n",
      "[320]\tGPT-3.5, ChatGPT, GPT-4\tQuestion Answering\tZS, FS\tEnglish\tYes\n",
      "[321]\tGPT-3.5, GPT-4\tNamed Entity Recognition, Relation Extraction, Document Classification and Semantic Similarity\tZS, FS\tEnglish\tYes\n",
      "[322]\tGPT-3.5, ChatGPT\tQuestion Answering\tZS\tJapanese\t-\n",
      "[323]\tGPT-3.5, GPT-4\tQuestion Answering, Reasoning\tZS\tChinese\tYes\n",
      "[324]\tGPT-3\tText Simplification\tFS\tEnglish\t-\n",
      "[149]\tGPT-3\tEntity Extraction, Relation Classification\tFS\tEnglish\tNo\n",
      "[[137]\tChatGPT, GPT-4\tNatural Language Inference\tZS, FS\tEnglish\t-\n",
      "[325]\tChatGPT\tText Summarization\tFS\tEnglish\tYes\n",
      "[138]\tGPT3.5, GPT4\tNatural Language Inference, Document Classification\tZS, FS\tEnglish\t-\n",
      "[195]\tGPT-3, ChatGPT, GPT-4\tQuestion Answering\tFS\tJapanese\t-' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17336.86328125\n",
      "page_content='[134]\tQ. Zhong, L. Ding, J. Liu, B. Du, and D. Tao, “Can chatgpt understand too? a comparative study on chatgpt and fine-tuned bert,” arXiv preprint arXiv:2302.10198, 2023.\n",
      "[135]\tJ. Ye, X. Chen, N. Xu, C. Zu, Z. Shao, S. Liu, Y. Cui, Z. Zhou, C. Gong, Y. Shen et al., “A comprehensive capability analysis of gpt-3 and gpt-3.5 series models,” arXiv preprint arXiv:2303.10420, 2023.\n",
      "[136]\tX. Li, X. Zhu, Z. Ma, X. Liu, and S. Shah, “Are chatgpt and gpt-4 general-purpose solvers for financial text analytics? an examination on several typical tasks,” arXiv preprint arXiv:2305.05862, 2023.\n",
      "[137]\tZ. Wu, L. Zhang, C. Cao, X. Yu, H. Dai, C. Ma, Z. Liu, L. Zhao, G. Li, W. Liu et al., “Exploring the trade-offs: Unified large language models vs local fine-tuned models for highly-specific radiology nli task,” arXiv preprint arXiv:2304.09138, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17336.86328125\n",
      "page_content='[134]\tQ. Zhong, L. Ding, J. Liu, B. Du, and D. Tao, “Can chatgpt understand too? a comparative study on chatgpt and fine-tuned bert,” arXiv preprint arXiv:2302.10198, 2023.\n",
      "[135]\tJ. Ye, X. Chen, N. Xu, C. Zu, Z. Shao, S. Liu, Y. Cui, Z. Zhou, C. Gong, Y. Shen et al., “A comprehensive capability analysis of gpt-3 and gpt-3.5 series models,” arXiv preprint arXiv:2303.10420, 2023.\n",
      "[136]\tX. Li, X. Zhu, Z. Ma, X. Liu, and S. Shah, “Are chatgpt and gpt-4 general-purpose solvers for financial text analytics? an examination on several typical tasks,” arXiv preprint arXiv:2305.05862, 2023.\n",
      "[137]\tZ. Wu, L. Zhang, C. Cao, X. Yu, H. Dai, C. Ma, Z. Liu, L. Zhao, G. Li, W. Liu et al., “Exploring the trade-offs: Unified large language models vs local fine-tuned models for highly-specific radiology nli task,” arXiv preprint arXiv:2304.09138, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17338.068359375\n",
      "page_content='Limitations While InteR demonstrates improved zero-shot retrieval performance, it should be noted that its effectiveness heavily relies on the quality of the used large language models (LLMs). If these underlying components contain biases, inaccuracies, or limitations in their training data, it could impact the reliability and generalizability of the retrieval results. In that case, one may need to design a more sophisticated method of information refinement, especially the prompt formulation part. We leave this exploration for future work.\n",
      "References' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Feng 等 - 2023 - Synergistic Interplay between Search and Large Language Models for Information Retrieval.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17338.068359375\n",
      "page_content='Limitations While InteR demonstrates improved zero-shot retrieval performance, it should be noted that its effectiveness heavily relies on the quality of the used large language models (LLMs). If these underlying components contain biases, inaccuracies, or limitations in their training data, it could impact the reliability and generalizability of the retrieval results. In that case, one may need to design a more sophisticated method of information refinement, especially the prompt formulation part. We leave this exploration for future work.\n",
      "References' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Feng 等 - 2023 - Synergistic Interplay between Search and Large Language Models for Information Retrieval.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17341.2890625\n",
      "page_content='[247]\tGPT-3.5, ChatGPT\tZS, FS\tMovies, Books\tEnglish\tNo\n",
      "[248]\tChatGPT\tZS\tMusic, Movies\tEnglish\tNo\n",
      "[245]\tChatGPT\tZS, FS\tBeauty\tEnglish\tYes\n",
      "[249]\tChatGPT\tZS\tMovies, Games\tEnglish\tNo\n",
      "[244]\tChatGPT\tZS, FS\tBooks\tEnglish\tNo\n",
      "TABLE 8. Summary of research works exploring GLLMs for recommendation systems. Here ZS represents zero-shot, and FS represents few-shot.\n",
      "than GLLMs. Zhang et al. [248] introduced FaiRLLM, a new benchmark having eight sensitive attributes from domains like movies and music, to investigate the fairness of GLLM recommendations. The authors reported that GLLM-based recommendation systems are not fair to certain sensitive attributes.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17341.2890625\n",
      "page_content='[247]\tGPT-3.5, ChatGPT\tZS, FS\tMovies, Books\tEnglish\tNo\n",
      "[248]\tChatGPT\tZS\tMusic, Movies\tEnglish\tNo\n",
      "[245]\tChatGPT\tZS, FS\tBeauty\tEnglish\tYes\n",
      "[249]\tChatGPT\tZS\tMovies, Games\tEnglish\tNo\n",
      "[244]\tChatGPT\tZS, FS\tBooks\tEnglish\tNo\n",
      "TABLE 8. Summary of research works exploring GLLMs for recommendation systems. Here ZS represents zero-shot, and FS represents few-shot.\n",
      "than GLLMs. Zhang et al. [248] introduced FaiRLLM, a new benchmark having eight sensitive attributes from domains like movies and music, to investigate the fairness of GLLM recommendations. The authors reported that GLLM-based recommendation systems are not fair to certain sensitive attributes.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17350.9765625\n",
      "page_content='Similarly, in question-answering systems [3, 9], IR systems are employed to select relevant clues essential for addressing user questions effectively. In image search engines [4], IR systems excel at returning images that align with user input queries. Given the exponential growth of information, research and industry have become increasingly interested in the development of effective IR systems.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17350.9765625\n",
      "page_content='Similarly, in question-answering systems [3, 9], IR systems are employed to select relevant clues essential for addressing user questions effectively. In image search engines [4], IR systems excel at returning images that align with user input queries. Given the exponential growth of information, research and industry have become increasingly interested in the development of effective IR systems.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17357.50390625\n",
      "page_content='the performance of LLMs in four Southeast Asian languages. The benchmark consists of 20 datasets covering eight NLP tasks. The authors reported that (i) GPT-4 achieves better results compared to ChatGPT, and (ii) overall, the' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17357.50390625\n",
      "page_content='the performance of LLMs in four Southeast Asian languages. The benchmark consists of 20 datasets covering eight NLP tasks. The authors reported that (i) GPT-4 achieves better results compared to ChatGPT, and (ii) overall, the' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17387.52734375\n",
      "page_content='(a) before calibration\n",
      "LLMs\tModel Bias\t\t\t\n",
      "\tpolitics\tsports\tbusiness\ttechnology\n",
      "XLNet-large\t0.24\t0.23\t0.26\t0.27\n",
      "BERT-large\t0.25\t0.28\t0.23\t0.24\n",
      "ALBERT-xxlarge\t0.26\t0.25\t0.25\t0.24\n",
      "(b) after calibration\n",
      "Figure 5: A lower ratio of N (# unlabeled examples per class) toK (# training examples per class) results in an increase in mislabeled training examples.\n",
      "5.3.\tSensitivity to Templates and Label Words\n",
      "As shown in Figure 1 and Table 1, the effect of prompt tuning is sensitive to different templates, which makes it hard to design templates manually. One advantage of our approach is that it can calibrate model bias on label words and thus reduce the sensitivity to prompts. We conduct a case study on AG’s News using two templates6 with four label word sets7. As shown in Figure 6, the accuracy of our approach maintains stability while consistently outperforming Zero-shot PT.\n",
      "5.4.\tModel Bias in Other LLMs' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17387.52734375\n",
      "page_content='(a) before calibration\n",
      "LLMs\tModel Bias\t\t\t\n",
      "\tpolitics\tsports\tbusiness\ttechnology\n",
      "XLNet-large\t0.24\t0.23\t0.26\t0.27\n",
      "BERT-large\t0.25\t0.28\t0.23\t0.24\n",
      "ALBERT-xxlarge\t0.26\t0.25\t0.25\t0.24\n",
      "(b) after calibration\n",
      "Figure 5: A lower ratio of N (# unlabeled examples per class) toK (# training examples per class) results in an increase in mislabeled training examples.\n",
      "5.3.\tSensitivity to Templates and Label Words\n",
      "As shown in Figure 1 and Table 1, the effect of prompt tuning is sensitive to different templates, which makes it hard to design templates manually. One advantage of our approach is that it can calibrate model bias on label words and thus reduce the sensitivity to prompts. We conduct a case study on AG’s News using two templates6 with four label word sets7. As shown in Figure 6, the accuracy of our approach maintains stability while consistently outperforming Zero-shot PT.\n",
      "5.4.\tModel Bias in Other LLMs' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17389.763671875\n",
      "page_content='at the [mask] position. However, due to the different distributions between the pre-training corpus and the task-specific data, PLMs show different propensities in predicting label words. An intuitive thought is that PLMs tend to predict label words that occur more frequently in the pretraining corpus (Zhao et al., 2021). Model bias on label words can lead to severe performance degradation on text classification in zero-shot settings since model parameters are not updated. In practice, we evaluate1 RoBERTa-large (Liu et al., 2019) model bias on label words of AG’s News2 (Zhang et al., 2015), a four-class topic classification dataset, with a manual template. As illustrated in Figure 1(a) and Table 1(a), the model shows a much higher tendency to predict “business” than “politics”, which leads to a large number of examples with the true label “politics” being incorrectly predicted as “business” (numbers underlined in Table 1(a)). Furthermore, we repeat the experiment by using another' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17389.763671875\n",
      "page_content='at the [mask] position. However, due to the different distributions between the pre-training corpus and the task-specific data, PLMs show different propensities in predicting label words. An intuitive thought is that PLMs tend to predict label words that occur more frequently in the pretraining corpus (Zhao et al., 2021). Model bias on label words can lead to severe performance degradation on text classification in zero-shot settings since model parameters are not updated. In practice, we evaluate1 RoBERTa-large (Liu et al., 2019) model bias on label words of AG’s News2 (Zhang et al., 2015), a four-class topic classification dataset, with a manual template. As illustrated in Figure 1(a) and Table 1(a), the model shows a much higher tendency to predict “business” than “politics”, which leads to a large number of examples with the true label “politics” being incorrectly predicted as “business” (numbers underlined in Table 1(a)). Furthermore, we repeat the experiment by using another' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17392.13671875\n",
      "page_content='4.12\tPlanning\n",
      "Overview. Many important industries, like finance and banking, often involve repetitive sequential tasks. These workflows, despite their significance, are typically not fully automated or formally defined. Recently, due to strong reasoning capabilities, the research community explored GLLMs for planning. Some of the research works [309], [311] directly used LLMs for planning, while some of them [308], [310] explored LLMs for planning extraction, which can then be used by automated systems.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17392.13671875\n",
      "page_content='4.12\tPlanning\n",
      "Overview. Many important industries, like finance and banking, often involve repetitive sequential tasks. These workflows, despite their significance, are typically not fully automated or formally defined. Recently, due to strong reasoning capabilities, the research community explored GLLMs for planning. Some of the research works [309], [311] directly used LLMs for planning, while some of them [308], [310] explored LLMs for planning extraction, which can then be used by automated systems.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17393.77734375\n",
      "page_content='4.5\tKeyphrase Generation\n",
      "Overview. Keyphrase generation (KPG) involves generating a set of phrases that capture the main ideas of a document [225]. The primary advantage of KPG over keyphrase extraction is the ability to generate both extractive and abstractive keyphrases. Keyphrase generation is approached as a sequence-to-sequence generation task [12], [226], [227] in the existing works. The current state-of-the-art model for keyphrase generation is, Key-BART [227], which is based on BART and trained using the text-to-text generation paradigm. Table 5 presents a summary of research works exploring GLLMs for keyphrase generation.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17393.77734375\n",
      "page_content='4.5\tKeyphrase Generation\n",
      "Overview. Keyphrase generation (KPG) involves generating a set of phrases that capture the main ideas of a document [225]. The primary advantage of KPG over keyphrase extraction is the ability to generate both extractive and abstractive keyphrases. Keyphrase generation is approached as a sequence-to-sequence generation task [12], [226], [227] in the existing works. The current state-of-the-art model for keyphrase generation is, Key-BART [227], which is based on BART and trained using the text-to-text generation paradigm. Table 5 presents a summary of research works exploring GLLMs for keyphrase generation.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17401.443359375\n",
      "page_content='[501]\tN. Mehrabi, P. Goyal, C. Dupuy, Q. Hu, S. Ghosh, R. Zemel, K.-W. Chang, A. Galstyan, and R. Gupta, “Flirt: Feedback loop in-context red teaming,” arXiv preprint arXiv:2308.04265, 2023.\n",
      "[502]\tE. Perez, S. Huang, F. Song, T. Cai, R. Ring, J. Aslanides, A. Glaese, N. McAleese, and G. Irving, “Red teaming language models with language models,” in Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, 2022, pp. 3419–3448.\n",
      "[503]\tL. Chen, M. Zaharia, and J. Zou, “Frugalgpt: How to use large language models while reducing cost and improving performance,” arXiv preprint arXiv:2305.05176, 2023.\n",
      "[504]\tZ. Cheng, J. Kasai, and T. Yu, “Batch prompting: Efficient inference with large language model apis,” arXiv preprint arXiv:2301.08721, 2023.\n",
      "[505]\tY. Li, “Unlocking context constraints of llms: Enhancing context efficiency of llms with self-information-based content filtering,” arXiv preprint arXiv:2304.12102, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17401.443359375\n",
      "page_content='[501]\tN. Mehrabi, P. Goyal, C. Dupuy, Q. Hu, S. Ghosh, R. Zemel, K.-W. Chang, A. Galstyan, and R. Gupta, “Flirt: Feedback loop in-context red teaming,” arXiv preprint arXiv:2308.04265, 2023.\n",
      "[502]\tE. Perez, S. Huang, F. Song, T. Cai, R. Ring, J. Aslanides, A. Glaese, N. McAleese, and G. Irving, “Red teaming language models with language models,” in Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, 2022, pp. 3419–3448.\n",
      "[503]\tL. Chen, M. Zaharia, and J. Zou, “Frugalgpt: How to use large language models while reducing cost and improving performance,” arXiv preprint arXiv:2305.05176, 2023.\n",
      "[504]\tZ. Cheng, J. Kasai, and T. Yu, “Batch prompting: Efficient inference with large language model apis,” arXiv preprint arXiv:2301.08721, 2023.\n",
      "[505]\tY. Li, “Unlocking context constraints of llms: Enhancing context efficiency of llms with self-information-based content filtering,” arXiv preprint arXiv:2304.12102, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17402.796875\n",
      "page_content='methods, which directly align the prior distribution (the predicted importance probability distribution of sentences without knowing the gold answer) to the posterior distribution (the same distribution of sentences within knowing the gold answer) to tune language models to select sentences.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17402.796875\n",
      "page_content='methods, which directly align the prior distribution (the predicted importance probability distribution of sentences without knowing the gold answer) to the posterior distribution (the same distribution of sentences within knowing the gold answer) to tune language models to select sentences.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17405.56640625\n",
      "page_content='[196]\tW. Gu, “Linguistically informed chatgpt prompts to enhance japanese-chinese machine translation: A case study on attributive clauses,” arXiv preprint arXiv:2303.15587, 2023.\n",
      "[197]\tK. Peng, L. Ding, Q. Zhong, L. Shen, X. Liu, M. Zhang, Y. Ouyang, and D. Tao, “Towards making the most of chatgpt for machine translation,” arXiv preprint arXiv:2303.13780, 2023.\n",
      "[198]\tW. Jiao, W. Wang, J. Huang, X. Wang, and Z. Tu, “Is chatgpt a good translator? yes with gpt-4 as the engine,” arXiv preprint arXiv:2301.08745, 2023.\n",
      "[199]\tA. Hendy, M. Abdelrehim, A. Sharaf, V. Raunak, M. Gabr, H. Matsushita, Y. J. Kim, M. Afify, and H. H. Awadalla, “How good are gpt models at machine translation? a comprehensive evaluation,” arXiv preprint arXiv:2302.09210, 2023.\n",
      "[200]\tY. Gao, R. Wang, and F. Hou, “How to design translation prompts for chatgpt: An empirical study,” arXiv e-prints, pp. arXiv–2304, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17405.56640625\n",
      "page_content='[196]\tW. Gu, “Linguistically informed chatgpt prompts to enhance japanese-chinese machine translation: A case study on attributive clauses,” arXiv preprint arXiv:2303.15587, 2023.\n",
      "[197]\tK. Peng, L. Ding, Q. Zhong, L. Shen, X. Liu, M. Zhang, Y. Ouyang, and D. Tao, “Towards making the most of chatgpt for machine translation,” arXiv preprint arXiv:2303.13780, 2023.\n",
      "[198]\tW. Jiao, W. Wang, J. Huang, X. Wang, and Z. Tu, “Is chatgpt a good translator? yes with gpt-4 as the engine,” arXiv preprint arXiv:2301.08745, 2023.\n",
      "[199]\tA. Hendy, M. Abdelrehim, A. Sharaf, V. Raunak, M. Gabr, H. Matsushita, Y. J. Kim, M. Afify, and H. H. Awadalla, “How good are gpt models at machine translation? a comprehensive evaluation,” arXiv preprint arXiv:2302.09210, 2023.\n",
      "[200]\tY. Gao, R. Wang, and F. Hou, “How to design translation prompts for chatgpt: An empirical study,” arXiv e-prints, pp. arXiv–2304, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17413.90234375\n",
      "page_content='[243]\tL. Wang and E.-P. Lim, “Zero-shot next-item recommendation using large pretrained language models,” arXiv preprint arXiv:2304.03153, 2023.\n",
      "[244]\tA. Zhiyuli, Y. Chen, X. Zhang, and X. Liang, “Bookgpt: A general framework for book recommendation empowered by large language model,” arXiv preprint arXiv:2305.15673, 2023.\n",
      "[245]\tJ. Liu, C. Liu, R. Lv, K. Zhou, and Y. Zhang, “Is chatgpt a good recommender? a preliminary study,” arXiv preprint arXiv:2304.10149, 2023.\n",
      "[246]\tS. Dai, N. Shao, H. Zhao, W. Yu, Z. Si, C. Xu, Z. Sun, X. Zhang, and J. Xu, “Uncovering chatgpt’s capabilities in recommender systems,” arXiv preprint arXiv:2305.02182, 2023.\n",
      "[247]\tW.-C. Kang, J. Ni, N. Mehta, M. Sathiamoorthy, L. Hong, E. Chi, and D. Z. Cheng, “Do llms understand user preferences? evaluating llms on user rating prediction,” arXiv preprint arXiv:2305.06474, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17413.90234375\n",
      "page_content='[243]\tL. Wang and E.-P. Lim, “Zero-shot next-item recommendation using large pretrained language models,” arXiv preprint arXiv:2304.03153, 2023.\n",
      "[244]\tA. Zhiyuli, Y. Chen, X. Zhang, and X. Liang, “Bookgpt: A general framework for book recommendation empowered by large language model,” arXiv preprint arXiv:2305.15673, 2023.\n",
      "[245]\tJ. Liu, C. Liu, R. Lv, K. Zhou, and Y. Zhang, “Is chatgpt a good recommender? a preliminary study,” arXiv preprint arXiv:2304.10149, 2023.\n",
      "[246]\tS. Dai, N. Shao, H. Zhao, W. Yu, Z. Si, C. Xu, Z. Sun, X. Zhang, and J. Xu, “Uncovering chatgpt’s capabilities in recommender systems,” arXiv preprint arXiv:2305.02182, 2023.\n",
      "[247]\tW.-C. Kang, J. Ni, N. Mehta, M. Sathiamoorthy, L. Hong, E. Chi, and D. Z. Cheng, “Do llms understand user preferences? evaluating llms on user rating prediction,” arXiv preprint arXiv:2305.06474, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17419.02734375\n",
      "page_content='Research works exploring GLLMs for planning. Table 12 presents a summary of research works exploring GLLMs for planning. Human models are crucial in facilitating human-robot interaction (HRI), as they empower robots to plan their behaviour based on the impact of their actions on individuals. As it is difficult to craft good human labels, Zhang et al. [309] used the GPT-3.5 model (i) as zero-shot human models and also (ii) for planning in trust-related scenarios. Hu et al. [311] proposed a novel prompting strategy called “Chain of Symbol” prompting to elicit better the planning abilities of large language models like InstructGPT and ChatGPT. Unlike CoT prompting, which uses natural language descriptions to represent complex environments, CoS prompting uses condensed symbols to represent them in intermediate reasoning steps. The authors reported that CoS prompting outperforms CoT prompting in both performance and efficiency.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17419.02734375\n",
      "page_content='Research works exploring GLLMs for planning. Table 12 presents a summary of research works exploring GLLMs for planning. Human models are crucial in facilitating human-robot interaction (HRI), as they empower robots to plan their behaviour based on the impact of their actions on individuals. As it is difficult to craft good human labels, Zhang et al. [309] used the GPT-3.5 model (i) as zero-shot human models and also (ii) for planning in trust-related scenarios. Hu et al. [311] proposed a novel prompting strategy called “Chain of Symbol” prompting to elicit better the planning abilities of large language models like InstructGPT and ChatGPT. Unlike CoT prompting, which uses natural language descriptions to represent complex environments, CoS prompting uses condensed symbols to represent them in intermediate reasoning steps. The authors reported that CoS prompting outperforms CoT prompting in both performance and efficiency.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17439.306640625\n",
      "page_content='[256]\tR. A. Poldrack, T. Lu, and G. Begusˇ, “Ai-assisted coding: Experiments with gpt-4,” arXiv preprint arXiv:2304.13187, 2023.\n",
      "[257]\tJ. Liu, C. S. Xia, Y. Wang, and L. Zhang, “Is your code generated by chatgpt really correct? rigorous evaluation of large language models for code generation,” arXiv preprint arXiv:2305.01210, 2023.\n",
      "[258]\tE. Chen, R. Huang, H.-S. Chen, Y.-H. Tseng, and L.-Y. Li, “Gptu-tor: a chatgpt-powered programming tool for code explanation,” arXiv preprint arXiv:2305.01863, 2023.\n",
      "[259]\tN. Nascimento, P. Alencar, and D. Cowan, “Comparing software developers with chatgpt: An empirical investigation,” arXiv preprint arXiv:2305.11837, 2023.\n",
      "[260]\tJ. Y. Khan and G. Uddin, “Automatic code documentation generation using gpt-3,” in Proceedings of the 37th IEEE/ACM International Conference on Automated Software Engineering, 2022, pp. 1–6.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17439.306640625\n",
      "page_content='[256]\tR. A. Poldrack, T. Lu, and G. Begusˇ, “Ai-assisted coding: Experiments with gpt-4,” arXiv preprint arXiv:2304.13187, 2023.\n",
      "[257]\tJ. Liu, C. S. Xia, Y. Wang, and L. Zhang, “Is your code generated by chatgpt really correct? rigorous evaluation of large language models for code generation,” arXiv preprint arXiv:2305.01210, 2023.\n",
      "[258]\tE. Chen, R. Huang, H.-S. Chen, Y.-H. Tseng, and L.-Y. Li, “Gptu-tor: a chatgpt-powered programming tool for code explanation,” arXiv preprint arXiv:2305.01863, 2023.\n",
      "[259]\tN. Nascimento, P. Alencar, and D. Cowan, “Comparing software developers with chatgpt: An empirical investigation,” arXiv preprint arXiv:2305.11837, 2023.\n",
      "[260]\tJ. Y. Khan and G. Uddin, “Automatic code documentation generation using gpt-3,” in Proceedings of the 37th IEEE/ACM International Conference on Automated Software Engineering, 2022, pp. 1–6.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17446.8359375\n",
      "page_content='[200]\tY. Gao, R. Wang, and F. Hou, “How to design translation prompts for chatgpt: An empirical study,” arXiv e-prints, pp. arXiv–2304, 2023.\n",
      "[201]\tL. Wang, C. Lyu, T. Ji, Z. Zhang, D. Yu, S. Shi, and Z. Tu, “Document-level machine translation with large language models,” arXiv preprint arXiv:2304.02210, 2023.\n",
      "[202]\tW. Zhu, H. Liu, Q. Dong, J. Xu, L. Kong, J. Chen, L. Li, and S. Huang, “Multilingual machine translation with large language models: Empirical results and analysis,” arXiv preprint arXiv:2304.04675, 2023.\n",
      "[203]\tC. Lyu, J. Xu, and L. Wang, “New trends in machine translation using large language models: Case examples with chatgpt,” arXiv preprint arXiv:2305.01181, 2023.\n",
      "[204]\tM. Karpinska and M. Iyyer, “Large language models effectively leverage document-level context for literary translation, but critical errors persist,” arXiv preprint arXiv:2304.03245, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17446.8359375\n",
      "page_content='[200]\tY. Gao, R. Wang, and F. Hou, “How to design translation prompts for chatgpt: An empirical study,” arXiv e-prints, pp. arXiv–2304, 2023.\n",
      "[201]\tL. Wang, C. Lyu, T. Ji, Z. Zhang, D. Yu, S. Shi, and Z. Tu, “Document-level machine translation with large language models,” arXiv preprint arXiv:2304.02210, 2023.\n",
      "[202]\tW. Zhu, H. Liu, Q. Dong, J. Xu, L. Kong, J. Chen, L. Li, and S. Huang, “Multilingual machine translation with large language models: Empirical results and analysis,” arXiv preprint arXiv:2304.04675, 2023.\n",
      "[203]\tC. Lyu, J. Xu, and L. Wang, “New trends in machine translation using large language models: Case examples with chatgpt,” arXiv preprint arXiv:2305.01181, 2023.\n",
      "[204]\tM. Karpinska and M. Iyyer, “Large language models effectively leverage document-level context for literary translation, but critical errors persist,” arXiv preprint arXiv:2304.03245, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17449.6640625\n",
      "page_content='Fig. 2. An example of LLM-based query rewriter for ad-hoc search. The example is cited from the Query2Doc paper [65]. LLMs are used to generate a passage to supplement the original query, where N = 0 and N > 0 correspond to zero-shot and few-shot scenarios.\n",
      "aging a frozen 4-bit quantized LLM for gradient computation. Despite the exploration of parameter-efficient finetuning for various NLP tasks, its implementation in IR tasks remains relatively limited, representing a potential avenue for future research.\n",
      "3\tQuery Rewriter' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17449.6640625\n",
      "page_content='Fig. 2. An example of LLM-based query rewriter for ad-hoc search. The example is cited from the Query2Doc paper [65]. LLMs are used to generate a passage to supplement the original query, where N = 0 and N > 0 correspond to zero-shot and few-shot scenarios.\n",
      "aging a frozen 4-bit quantized LLM for gradient computation. Despite the exploration of parameter-efficient finetuning for various NLP tasks, its implementation in IR tasks remains relatively limited, representing a potential avenue for future research.\n",
      "3\tQuery Rewriter' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17452.89453125\n",
      "page_content='•\tEnhancing the Trustworthiness of LLMs. When LLMs are enabled to browse the web, it is important to ensure the validity of retrieved documents. Otherwise, the unfaithful information may increase the LLMs’ hallucination problem. Besides, even if the gathered information has high quality, it remains unclear whether they are really used for synthesizing responses. A potential strategy to address this issue is enabling LLMs to autonomously validate the documents they scrape. This self-validation process could incorporate mechanisms for assessing the credibility and accuracy of the information within these documents.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17452.89453125\n",
      "page_content='•\tEnhancing the Trustworthiness of LLMs. When LLMs are enabled to browse the web, it is important to ensure the validity of retrieved documents. Otherwise, the unfaithful information may increase the LLMs’ hallucination problem. Besides, even if the gathered information has high quality, it remains unclear whether they are really used for synthesizing responses. A potential strategy to address this issue is enabling LLMs to autonomously validate the documents they scrape. This self-validation process could incorporate mechanisms for assessing the credibility and accuracy of the information within these documents.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17476.7578125\n",
      "page_content='7.1\tStatic Agent\n",
      "To mimic human search patterns, a straightforward approach is to design a static system to browse the web and synthesize information step by step [258–263]. By breaking the information-seeking process into multiple subtasks, they design a pipeline that contains various LLM-based modules in advance and assigns different subtasks to them.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17476.7578125\n",
      "page_content='7.1\tStatic Agent\n",
      "To mimic human search patterns, a straightforward approach is to design a static system to browse the web and synthesize information step by step [258–263]. By breaking the information-seeking process into multiple subtasks, they design a pipeline that contains various LLM-based modules in advance and assigns different subtasks to them.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17477.1640625\n",
      "page_content='We also tested the effectiveness of “few-shot learning”, i.e. providing a list of example (observation: failure mode) pairs to the model as part of the system-level prompt as opposed to a list of only the valid failure modes. We found that the results were near identical to the non fine-tuned model, and thus did not include these results in the table for brevity. Overall, the results show that fine-tuning is necessary to achieve strong performance. This demonstrates the importance of high quality annotated data when applying LLMs to maintenance work orders.\n",
      "3.3\tAre LLMs more effective at failure mode classification than text classification models?' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Stewart 等 - 2023 - Large Language Models for Failure Mode Classification An Investigation.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17477.1640625\n",
      "page_content='We also tested the effectiveness of “few-shot learning”, i.e. providing a list of example (observation: failure mode) pairs to the model as part of the system-level prompt as opposed to a list of only the valid failure modes. We found that the results were near identical to the non fine-tuned model, and thus did not include these results in the table for brevity. Overall, the results show that fine-tuning is necessary to achieve strong performance. This demonstrates the importance of high quality annotated data when applying LLMs to maintenance work orders.\n",
      "3.3\tAre LLMs more effective at failure mode classification than text classification models?' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Stewart 等 - 2023 - Large Language Models for Failure Mode Classification An Investigation.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17478.240234375\n",
      "page_content='[93]\tZ. Dai, A. T. Chaganty, V. Y. Zhao, A. Amini, Q. M. Rashid, M. Green, and K. Guu, “Dialog inpainting: Turning documents into dialogs,” in International Conference on Machine Learning, ICML 2022, 17-23 July 2022, Baltimore, Maryland, USA, ser. Proceedings of Machine Learning Research, K. Chaudhuri, S. Jegelka, L. Song, C. Szepesva´ ri, G. Niu, and S. Sabato, Eds., vol. 162. PMLR, 2022, pp. 4558–4586.\n",
      "[94]\tK. D. Dhole, R. Chandradevan, and E. Agichtein, “An interactive query generation assistant using llm-based prompt modification and user feedback,” CoRR, vol. abs/2311.11226, 2023.\n",
      "[95]\tC. Deng, K. Mao, and Z. Dou, “Learning interpretable legal case retrieval via knowledge-guided case reformulation,” CoRR, vol. abs/2406.19760, 2024.\n",
      "[96]\tM. Li, H. Zhuang, K. Hui, Z. Qin, J. Lin, R. Jager-man, X. Wang, and M. Bendersky, “Generate, filter, and fuse: Query expansion via multi-step keyword generation for zero-shot neural rankers,” CoRR, vol. abs/2311.09175, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17478.240234375\n",
      "page_content='[93]\tZ. Dai, A. T. Chaganty, V. Y. Zhao, A. Amini, Q. M. Rashid, M. Green, and K. Guu, “Dialog inpainting: Turning documents into dialogs,” in International Conference on Machine Learning, ICML 2022, 17-23 July 2022, Baltimore, Maryland, USA, ser. Proceedings of Machine Learning Research, K. Chaudhuri, S. Jegelka, L. Song, C. Szepesva´ ri, G. Niu, and S. Sabato, Eds., vol. 162. PMLR, 2022, pp. 4558–4586.\n",
      "[94]\tK. D. Dhole, R. Chandradevan, and E. Agichtein, “An interactive query generation assistant using llm-based prompt modification and user feedback,” CoRR, vol. abs/2311.11226, 2023.\n",
      "[95]\tC. Deng, K. Mao, and Z. Dou, “Learning interpretable legal case retrieval via knowledge-guided case reformulation,” CoRR, vol. abs/2406.19760, 2024.\n",
      "[96]\tM. Li, H. Zhuang, K. Hui, Z. Qin, J. Lin, R. Jager-man, X. Wang, and M. Bendersky, “Generate, filter, and fuse: Query expansion via multi-step keyword generation for zero-shot neural rankers,” CoRR, vol. abs/2311.09175, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17502.8515625\n",
      "page_content='Some of the research works focused on addressing the limitations of using GLLMs as evaluators. For example, Wang et al. [481] demonstrated positional bias in GLLM-based evaluation, i.e., the order of candidate responses can significantly influence the results. The authors demonstrated that the two proposed strategies, namely multiple evidence calibration and balanced position calibration, can reduce the bias and enhance the correlation with human judgements.\n",
      "11\tFuture Research Directions\n",
      "11.1\tEnhance Robustness of GLLMs' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17502.8515625\n",
      "page_content='Some of the research works focused on addressing the limitations of using GLLMs as evaluators. For example, Wang et al. [481] demonstrated positional bias in GLLM-based evaluation, i.e., the order of candidate responses can significantly influence the results. The authors demonstrated that the two proposed strategies, namely multiple evidence calibration and balanced position calibration, can reduce the bias and enhance the correlation with human judgements.\n",
      "11\tFuture Research Directions\n",
      "11.1\tEnhance Robustness of GLLMs' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17505.5546875\n",
      "page_content='8.5\tSearch Agent\n",
      "With the outstanding performance of LLMs, the patterns of searching may completely change from traditional IR systems to autonomous search agents. In Section 7, we have discussed many existing works that utilize a static or dynamic pipeline to autonomously browse the web. These works are believed to be the pioneering works of the new searching paradigm. However, there is still plenty of room for further improvements.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17505.5546875\n",
      "page_content='8.5\tSearch Agent\n",
      "With the outstanding performance of LLMs, the patterns of searching may completely change from traditional IR systems to autonomous search agents. In Section 7, we have discussed many existing works that utilize a static or dynamic pipeline to autonomously browse the web. These works are believed to be the pioneering works of the new searching paradigm. However, there is still plenty of room for further improvements.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17507.150390625\n",
      "page_content='4.3\tQuestion Answering\n",
      "Overview. Question Answering (QA) is an important natural language processing task which deals with the development of algorithms to understand and interpret user queries in natural language and then deliver accurate responses [174], [175]. The main aim of question answering systems is to enhance human-computer interaction, i.e., QA systems avoid the use of complex commands and allow the user to interact with machines in a more natural way through natural language queries. For example, popular AI assistants like Amazon Alexa1, Google Assistant2 and Apple Siri3 rely on QA to provide accurate answers to user queries. The option of interaction through natural language queries enhances the reach of technology to a broader audience. QA can be treated as a fine-grained version of information retrieval [176], and the demand for QA systems is increasing day\n",
      "1. https://alexa.amazon.com\n",
      "2. https://assistant.google.com\n",
      "3. https://www.apple.com/in/siri/' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17507.150390625\n",
      "page_content='4.3\tQuestion Answering\n",
      "Overview. Question Answering (QA) is an important natural language processing task which deals with the development of algorithms to understand and interpret user queries in natural language and then deliver accurate responses [174], [175]. The main aim of question answering systems is to enhance human-computer interaction, i.e., QA systems avoid the use of complex commands and allow the user to interact with machines in a more natural way through natural language queries. For example, popular AI assistants like Amazon Alexa1, Google Assistant2 and Apple Siri3 rely on QA to provide accurate answers to user queries. The option of interaction through natural language queries enhances the reach of technology to a broader audience. QA can be treated as a fine-grained version of information retrieval [176], and the demand for QA systems is increasing day\n",
      "1. https://alexa.amazon.com\n",
      "2. https://assistant.google.com\n",
      "3. https://www.apple.com/in/siri/' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17514.56640625\n",
      "page_content='4.11\tMachine Learning Tasks\n",
      "Overview. Machine learning (ML) is an area of artificial intelligence (AI) that deals with the development of algorithms that can learn from data and make decisions [305]. Even though machine learning algorithms are successfully used in various real-world applications, creating an effective ML solution for a new task can be difficult due to the numerous design choices involved. In recent times, AutoML has evolved as a solution to reduce the human effort involved in designing ML solutions [307]. However, AutoML algorithms suffer from various drawbacks [305], like (i) the requirement of multiple rounds of trial-and-error, resulting in significant time consumption, (ii) starting the search for a new task from scratch, ignoring past experience gained from the previous tasks and (iii) many AutoML methods lack interpretability because of their black-box nature.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17514.56640625\n",
      "page_content='4.11\tMachine Learning Tasks\n",
      "Overview. Machine learning (ML) is an area of artificial intelligence (AI) that deals with the development of algorithms that can learn from data and make decisions [305]. Even though machine learning algorithms are successfully used in various real-world applications, creating an effective ML solution for a new task can be difficult due to the numerous design choices involved. In recent times, AutoML has evolved as a solution to reduce the human effort involved in designing ML solutions [307]. However, AutoML algorithms suffer from various drawbacks [305], like (i) the requirement of multiple rounds of trial-and-error, resulting in significant time consumption, (ii) starting the search for a new task from scratch, ignoring past experience gained from the previous tasks and (iii) many AutoML methods lack interpretability because of their black-box nature.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17527.931640625\n",
      "page_content='[Instruction]: Your task is to transform a potentially colloquial or jargon-heavy [Original Question] into a semantically enhanced Rewritten Question with a clear intention. Additionally, generating several search-friendly Queries that can help find relevant information for answering the question. You can consider the provided [Examples] and response following the [Format].\n",
      "[Original Question]: {User’s original question is here.} [Examples]: {The examples should be specially tailored for different datasets.}\n",
      "[Format]:\t{The generated Rewritten Question is\n",
      "here}**{query1}**{query2}**{query3}...\n",
      "3.2\tKnowledge Filter\n",
      "The accuracy of responses generated by LLMs can be significantly compromised by noisy retrieved contexts [34]. To mitigate this, we introduce the Knowledge Filter module, designed to enhance response accuracy and robustness. This module utilizes LLMs to filter' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17527.931640625\n",
      "page_content='[Instruction]: Your task is to transform a potentially colloquial or jargon-heavy [Original Question] into a semantically enhanced Rewritten Question with a clear intention. Additionally, generating several search-friendly Queries that can help find relevant information for answering the question. You can consider the provided [Examples] and response following the [Format].\n",
      "[Original Question]: {User’s original question is here.} [Examples]: {The examples should be specially tailored for different datasets.}\n",
      "[Format]:\t{The generated Rewritten Question is\n",
      "here}**{query1}**{query2}**{query3}...\n",
      "3.2\tKnowledge Filter\n",
      "The accuracy of responses generated by LLMs can be significantly compromised by noisy retrieved contexts [34]. To mitigate this, we introduce the Knowledge Filter module, designed to enhance response accuracy and robustness. This module utilizes LLMs to filter' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17534.4453125\n",
      "page_content='9 GPT-3 generates the same label words for binary sentiment classification task.\n",
      "decrease when flipped words are used as label words in demonstrations.\n",
      "6.4\tThe influence of clues\n",
      "As mentioned in Section 3, clues are keywords, phrases, contextual information, semantic meaning, semantic relationships, tones, references that support making decisions. We remove different types of words in clues and evaluate its influence on SST-2 and R8 datasets. Editing prompts achieve this goal. The original prompt for clue collecting is List CLUES (i.e., keywords, phrases, contextual information, semantic meaning, semantic relationships, tones, references) that support the sentiment determination of the input. If we want to remove keywords & phrases, we just remove them from the prompt.\n",
      "•\tw/o keywords & phrases: keywords and phrases are surface evidence for making decisions such as \"like\", \"hate\".\n",
      "•\tw/o contextual information & semantic meaning:\tcontextual information and' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17534.4453125\n",
      "page_content='9 GPT-3 generates the same label words for binary sentiment classification task.\n",
      "decrease when flipped words are used as label words in demonstrations.\n",
      "6.4\tThe influence of clues\n",
      "As mentioned in Section 3, clues are keywords, phrases, contextual information, semantic meaning, semantic relationships, tones, references that support making decisions. We remove different types of words in clues and evaluate its influence on SST-2 and R8 datasets. Editing prompts achieve this goal. The original prompt for clue collecting is List CLUES (i.e., keywords, phrases, contextual information, semantic meaning, semantic relationships, tones, references) that support the sentiment determination of the input. If we want to remove keywords & phrases, we just remove them from the prompt.\n",
      "•\tw/o keywords & phrases: keywords and phrases are surface evidence for making decisions such as \"like\", \"hate\".\n",
      "•\tw/o contextual information & semantic meaning:\tcontextual information and' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17538.4921875\n",
      "page_content='For our method, we conduct ablation experiments to evaluate the effectiveness of each module. -UV, -APR and -BA denote the absence of unlabeled validation, absolute probability refinement and bias-based annotation, respectively. In addition, we incorporate our proposed unlabeled validation into few-shot prompt-tuning to further illustrate its effect.\n",
      "4.4.\tMain Results\n",
      "As shown in Table 3, our approach outperforms zero-shot PT by a large margin (on average +13.8%), especially on DBPedia, Amazon and SST-2, with improvements up to 19.7%, 18.3% and 19.6%, respectively. Compared to zero-shot' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17538.4921875\n",
      "page_content='For our method, we conduct ablation experiments to evaluate the effectiveness of each module. -UV, -APR and -BA denote the absence of unlabeled validation, absolute probability refinement and bias-based annotation, respectively. In addition, we incorporate our proposed unlabeled validation into few-shot prompt-tuning to further illustrate its effect.\n",
      "4.4.\tMain Results\n",
      "As shown in Table 3, our approach outperforms zero-shot PT by a large margin (on average +13.8%), especially on DBPedia, Amazon and SST-2, with improvements up to 19.7%, 18.3% and 19.6%, respectively. Compared to zero-shot' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17550.951171875\n",
      "page_content='Karen Hambardzumyan, Hrant Khachatrian, and Jonathan May. 2021. WARP: Word-level Adversarial ReProgramming. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 4921–4933, Online. Association for Computational Linguistics.\n",
      "Ari Holtzman, Peter West, Vered Shwartz, Yejin Choi, and Luke Zettlemoyer. 2021. Surface form competition: Why the highest probability answer isn’t always right. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 7038–7051, Online and Punta Cana, Dominican Republic. Association for Computational Linguistics.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17550.951171875\n",
      "page_content='Karen Hambardzumyan, Hrant Khachatrian, and Jonathan May. 2021. WARP: Word-level Adversarial ReProgramming. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 4921–4933, Online. Association for Computational Linguistics.\n",
      "Ari Holtzman, Peter West, Vered Shwartz, Yejin Choi, and Luke Zettlemoyer. 2021. Surface form competition: Why the highest probability answer isn’t always right. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 7038–7051, Online and Punta Cana, Dominican Republic. Association for Computational Linguistics.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17558.7890625\n",
      "page_content='Limitation: ChatGPT has multiple limitations. OpenAI acknowledges that ChatGPT “occasionally writes plausible-sounding but incorrect or nonsensical\n",
      "answers\".[8] This behavior is common to large language models and is called \"hallucination\". [4][10]\n",
      "Figure 4. Use Case of ChatGPT [7]\n",
      "GPT-3 has a wide range of use cases due to its ability to generate natural language text. The Figure .4 depicts the Use Case of ChatGPT. Some of its most common use cases include:\n",
      "Prompts for AI generator: Prompts for AI generator are specific topics or ideas given to an AI language model to generate text or content.\n",
      "Debugging Code: Debugging code refers to the process of finding and fixing errors or bugs in software code.\n",
      "Predicting Questions: Predicting questions is the process of anticipating what questions an audience or user might have and preparing answers or responses in advance.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kania和Mehta - 2023 - A Literature Review on Augmented Analytics and Natural Language Generation A Review of State of Art.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17558.7890625\n",
      "page_content='Limitation: ChatGPT has multiple limitations. OpenAI acknowledges that ChatGPT “occasionally writes plausible-sounding but incorrect or nonsensical\n",
      "answers\".[8] This behavior is common to large language models and is called \"hallucination\". [4][10]\n",
      "Figure 4. Use Case of ChatGPT [7]\n",
      "GPT-3 has a wide range of use cases due to its ability to generate natural language text. The Figure .4 depicts the Use Case of ChatGPT. Some of its most common use cases include:\n",
      "Prompts for AI generator: Prompts for AI generator are specific topics or ideas given to an AI language model to generate text or content.\n",
      "Debugging Code: Debugging code refers to the process of finding and fixing errors or bugs in software code.\n",
      "Predicting Questions: Predicting questions is the process of anticipating what questions an audience or user might have and preparing answers or responses in advance.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kania和Mehta - 2023 - A Literature Review on Augmented Analytics and Natural Language Generation A Review of State of Art.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17566.021484375\n",
      "page_content='f (q, d) =\n",
      "exp(SY)\n",
      "exp(SY) + exp(SN) ’\n",
      "(1)\n",
      "where SY and SN represent the LLM’s log-likelihood scores of “Yes” and “No” respectively. In addition to binary labels, Zhuang et al. [151] propose to incorporate fine-grained relevance labels (e.g., “highly relevant”, “somewhat relevant” and “not relevant”) into the prompt, which helps LLMs more effectively differentiate among documents with varying levels of relevance to a query. Guo et al. [152] discuss the issues of inconsistent and biased relevance assessments of existing pointwise rerankers and introduce MCRanker that generates relevance scores based on a series of criteria from multiple perspectives.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17566.021484375\n",
      "page_content='f (q, d) =\n",
      "exp(SY)\n",
      "exp(SY) + exp(SN) ’\n",
      "(1)\n",
      "where SY and SN represent the LLM’s log-likelihood scores of “Yes” and “No” respectively. In addition to binary labels, Zhuang et al. [151] propose to incorporate fine-grained relevance labels (e.g., “highly relevant”, “somewhat relevant” and “not relevant”) into the prompt, which helps LLMs more effectively differentiate among documents with varying levels of relevance to a query. Guo et al. [152] discuss the issues of inconsistent and biased relevance assessments of existing pointwise rerankers and introduce MCRanker that generates relevance scores based on a series of criteria from multiple perspectives.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17568.3125\n",
      "page_content='al. [516] proposed HaluEval, a novel benchmark to assess the ability of GLLMs to identify hallucinations. Peng et al. [517] introduced LLM-AUGMENTER, a novel approach that reduces hallucinations in ChatGPT without impacting the quality of generated responses. Considering the seriousness of the hallucination problem, we can expect more future research to identify and reduce hallucinations in GLLMs, which enhance their reliability and adoption across domains, including sensitive domains like healthcare.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17568.3125\n",
      "page_content='al. [516] proposed HaluEval, a novel benchmark to assess the ability of GLLMs to identify hallucinations. Peng et al. [517] introduced LLM-AUGMENTER, a novel approach that reduces hallucinations in ChatGPT without impacting the quality of generated responses. Considering the seriousness of the hallucination problem, we can expect more future research to identify and reduce hallucinations in GLLMs, which enhance their reliability and adoption across domains, including sensitive domains like healthcare.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17569.76953125\n",
      "page_content='[170]\tL. Boytsov, P. Patel, V. Sourabh, R. Nisar, S. Kundu, R. Ramanathan, and E. Nyberg, “Inpars-light: Costeffective unsupervised training of efficient rankers,” CoRR, vol. abs/2301.02998, 2023.\n",
      "[171]\tA. Askari, M. Aliannejadi, E. Kanoulas, and S. Ver-berne, “Generating synthetic documents for crossencoder re-rankers: A comparative study of chatgpt and human experts,” CoRR, vol. abs/2305.02320, 2023.\n",
      "[172]\tA. Askari, M. Aliannejadi, C. Meng, E. Kanoulas, and S. Verberne, “Expand, highlight, generate: Rl-driven document generation for passage reranking,” in EMNLP. Association for Computational Linguistics, 2023, pp. 10 087–10 099.\n",
      "[173]\tR. Pradeep, S. Sharifymoghaddam, and J. Lin, “Rankvicuna: Zero-shot listwise document reranking with open-source large language models,” CoRR, vol. abs/2309.15088, 2023.\n",
      "[174]\t——, “Rankzephyr: Effective and robust zeroshot listwise reranking is a breeze!” CoRR, vol. abs/2312.02724, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17569.76953125\n",
      "page_content='[170]\tL. Boytsov, P. Patel, V. Sourabh, R. Nisar, S. Kundu, R. Ramanathan, and E. Nyberg, “Inpars-light: Costeffective unsupervised training of efficient rankers,” CoRR, vol. abs/2301.02998, 2023.\n",
      "[171]\tA. Askari, M. Aliannejadi, E. Kanoulas, and S. Ver-berne, “Generating synthetic documents for crossencoder re-rankers: A comparative study of chatgpt and human experts,” CoRR, vol. abs/2305.02320, 2023.\n",
      "[172]\tA. Askari, M. Aliannejadi, C. Meng, E. Kanoulas, and S. Verberne, “Expand, highlight, generate: Rl-driven document generation for passage reranking,” in EMNLP. Association for Computational Linguistics, 2023, pp. 10 087–10 099.\n",
      "[173]\tR. Pradeep, S. Sharifymoghaddam, and J. Lin, “Rankvicuna: Zero-shot listwise document reranking with open-source large language models,” CoRR, vol. abs/2309.15088, 2023.\n",
      "[174]\t——, “Rankzephyr: Effective and robust zeroshot listwise reranking is a breeze!” CoRR, vol. abs/2312.02724, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17581.8359375\n",
      "page_content='0.2\t5.68\t0.00\t30.30\t11.62\t48.5\n",
      "0.4\t5.89\t0.00\t19.58\t3.52\t50.5\n",
      "0.6\t3.97\t4.39\t11.57\t1.53\t53.0\n",
      "0.8\t7.17\t14.33\t1.72\t0.86\t55.0\n",
      "1.0\t7.45\t15.00\t0.00\t0.79\t53.5\n",
      "Table 3: Investigation of the Individual and Combined Effects of Question Rewriting and Knowledge Filtering on CAMbigNQ and PopQA\n",
      "Dataset\tSetting\t\tF1\tHit Rate\n",
      "\tQuestion\tKnowledge\t\t\n",
      "\tOriginal\t\\\t37.38\t55.67\n",
      "\tRewritten\t\\\t38.45\t57.67\n",
      "CAmbigNQ\tOriginal Rewritten\tAll All\t38.24 41.58\t54.00 58.00\n",
      "\tOriginal\tFiltered\t39.62\t59.67\n",
      "\tRewritten\tFiltered\t43.39\t64.33\n",
      "\tOriginal\t\\\t35.24\t42.33\n",
      "\tRewritten\t\\\t36.73\t42.67\n",
      "PopQA\tOriginal\tAll\t38.14\t44.33\n",
      "\tRewritten\tAll\t38.51\t46.67\n",
      "\tOriginal\tFiltered\t39.79\t47.33\n",
      "\tRewritten\tFiltered\t41.77\t51.33\n",
      "Module\tDetails\t\tResults\t\n",
      "\tOriginal Question\tQuery\tRetrieve Knowledge\tResponse\n",
      "Query Rewriter\tWhich film was released earlier, The Girl From Monterrey or Jhuthi Sharm?\tRelease dates of The Girl From Monterrey and Jhuthi Sharm\t1, 2\tThe Girl from Monterrey\n",
      "\tRewritten Question\tQueries\tRetrieve Knowledge\tResponse' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17581.8359375\n",
      "page_content='0.2\t5.68\t0.00\t30.30\t11.62\t48.5\n",
      "0.4\t5.89\t0.00\t19.58\t3.52\t50.5\n",
      "0.6\t3.97\t4.39\t11.57\t1.53\t53.0\n",
      "0.8\t7.17\t14.33\t1.72\t0.86\t55.0\n",
      "1.0\t7.45\t15.00\t0.00\t0.79\t53.5\n",
      "Table 3: Investigation of the Individual and Combined Effects of Question Rewriting and Knowledge Filtering on CAMbigNQ and PopQA\n",
      "Dataset\tSetting\t\tF1\tHit Rate\n",
      "\tQuestion\tKnowledge\t\t\n",
      "\tOriginal\t\\\t37.38\t55.67\n",
      "\tRewritten\t\\\t38.45\t57.67\n",
      "CAmbigNQ\tOriginal Rewritten\tAll All\t38.24 41.58\t54.00 58.00\n",
      "\tOriginal\tFiltered\t39.62\t59.67\n",
      "\tRewritten\tFiltered\t43.39\t64.33\n",
      "\tOriginal\t\\\t35.24\t42.33\n",
      "\tRewritten\t\\\t36.73\t42.67\n",
      "PopQA\tOriginal\tAll\t38.14\t44.33\n",
      "\tRewritten\tAll\t38.51\t46.67\n",
      "\tOriginal\tFiltered\t39.79\t47.33\n",
      "\tRewritten\tFiltered\t41.77\t51.33\n",
      "Module\tDetails\t\tResults\t\n",
      "\tOriginal Question\tQuery\tRetrieve Knowledge\tResponse\n",
      "Query Rewriter\tWhich film was released earlier, The Girl From Monterrey or Jhuthi Sharm?\tRelease dates of The Girl From Monterrey and Jhuthi Sharm\t1, 2\tThe Girl from Monterrey\n",
      "\tRewritten Question\tQueries\tRetrieve Knowledge\tResponse' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17587.310546875\n",
      "page_content='search engines for text generation, enhancing the reliability and real-time capability of the generated texts. A following study [265] has extended this paradigm to the domain of Chinese question answering. ASH (Actor-Summarizer-Hierarchical) prompting [266] significantly enhances the ability of LLMs on WebShop benchmark. TRAD [267] enhances LLM agents for sequential decision-making tasks. It first utilizes step-level demonstration selection through thought matching. Then it enhances the agent’s decisionmaking process by considering the temporal context of actions. AutoWebGLM [268] aims address the limitations of current web browsing agents, which often struggle with the versatility of webpage actions, the length of HTML text, and the open-domain nature of web decision-making. It uses an HTML simplification algorithm, a hybrid human-AI method and reinforcement learning and rejection sampling to bootstrap the model, allowing it to improve webpage comprehension, browser operations, and' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17587.310546875\n",
      "page_content='search engines for text generation, enhancing the reliability and real-time capability of the generated texts. A following study [265] has extended this paradigm to the domain of Chinese question answering. ASH (Actor-Summarizer-Hierarchical) prompting [266] significantly enhances the ability of LLMs on WebShop benchmark. TRAD [267] enhances LLM agents for sequential decision-making tasks. It first utilizes step-level demonstration selection through thought matching. Then it enhances the agent’s decisionmaking process by considering the temporal context of actions. AutoWebGLM [268] aims address the limitations of current web browsing agents, which often struggle with the versatility of webpage actions, the length of HTML text, and the open-domain nature of web decision-making. It uses an HTML simplification algorithm, a hybrid human-AI method and reinforcement learning and rejection sampling to bootstrap the model, allowing it to improve webpage comprehension, browser operations, and' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17587.84375\n",
      "page_content='Research works exploring GLLMs for recommendation systems. Wang et al. [243] proposed a novel prompting strategy called “Next-Item Recommendation (NIR)” to recommend movies using GLLMs. The proposed prompting strategy involves a three-step process to capture the user ’s preferences, choose representative movies they have watched in the past, and provide a ranked list of ten recommended movies. Dai et al. [246] reported that ChatGPT outperforms other GLLMs and is more effective with pair-wise and list-wise ranking compared to point-wise ranking. When it comes to balancing cost and performance, ChatGPT with listwise ranking outperforms both point-wise and pair-wise ranking approaches. ChatGPT demonstrates the potential for providing explanations for recommendations and addressing the challenges of the cold start problem. Gao et al. [241] proposed Chat-REC, which leverages GLLMs to build conversational recommendation systems. The authors reported that Chat-REC performs well in tasks like' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17587.84375\n",
      "page_content='Research works exploring GLLMs for recommendation systems. Wang et al. [243] proposed a novel prompting strategy called “Next-Item Recommendation (NIR)” to recommend movies using GLLMs. The proposed prompting strategy involves a three-step process to capture the user ’s preferences, choose representative movies they have watched in the past, and provide a ranked list of ten recommended movies. Dai et al. [246] reported that ChatGPT outperforms other GLLMs and is more effective with pair-wise and list-wise ranking compared to point-wise ranking. When it comes to balancing cost and performance, ChatGPT with listwise ranking outperforms both point-wise and pair-wise ranking approaches. ChatGPT demonstrates the potential for providing explanations for recommendations and addressing the challenges of the cold start problem. Gao et al. [241] proposed Chat-REC, which leverages GLLMs to build conversational recommendation systems. The authors reported that Chat-REC performs well in tasks like' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17599.578125\n",
      "page_content='4.1.1\tSearch Data Refinement\n",
      "Typically, input queries consist of short sentences or keyword-based phrases that may be ambiguous and contain multiple possible user intents. Accurately determining the specific user intent is essential in such cases. Moreover, documents usually contain redundant or noisy information, which poses a challenge for retrievers to extract relevance signals between queries and documents. Leveraging the strong text understanding and generation capabilities of LLMs offers a promising solution to these challenges. As yet, research efforts in this domain primarily concentrate on employing LLMs as query rewriters, aiming to refine input queries for more precise expressions of the user’s search' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17599.578125\n",
      "page_content='4.1.1\tSearch Data Refinement\n",
      "Typically, input queries consist of short sentences or keyword-based phrases that may be ambiguous and contain multiple possible user intents. Accurately determining the specific user intent is essential in such cases. Moreover, documents usually contain redundant or noisy information, which poses a challenge for retrievers to extract relevance signals between queries and documents. Leveraging the strong text understanding and generation capabilities of LLMs offers a promising solution to these challenges. As yet, research efforts in this domain primarily concentrate on employing LLMs as query rewriters, aiming to refine input queries for more precise expressions of the user’s search' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17613.373046875\n",
      "page_content='Hamidi et al. [186] evaluated ChatGPT and Claude\n",
      "Paper\tTask(s)\tGLLMs Explored\tPrompt Settings\tDomain(s)\tLanguage(s)\tSOTA Results\n",
      "[177]\tAdmission Exam Question Answering\tGPT-3.5, ChatGPT, GPT-4\tZS, FS\tEducation\tBrazilian Portuguese\tNo\n",
      "[178]\tKnowledge-based Complex Question Answering\tGPT-3, GPT-3.5, ChatGPT\tZS\tGeneral\tMultiple languages\tNo\n",
      "[179]\tKnowledge-based Visual Question Answering\tGPT-3\tZS\tGeneral\tEnglish\tYes\n",
      "[180]\tTabular Question Answering\tGPT-3\tZS, FS\tNews\tEnglish\tNo\n",
      "[181]\tOpen Domain Question Answering\tChatGPT\tZS\tGeneral\tEnglish\tNo\n",
      "[182]\tBariatric Surgery Question Answering\tChatGPT\tZS\tHealthcare\tEnglish\tNo\n",
      "[183]\tRadiation Oncology Physics Question Answering\tChatGPT, GPT-4\tZS\tHealthcare\tEnglish\tNo\n",
      "[184]\tComputer Science Question Answering\tChatGPT\tZS\tEducation\tEnglish\tNo\n",
      "[185]\tMedical Question Answering\tGPT-3.5, GPT-4\tZS, FS\tHealthcare\tEnglish\tNo\n",
      "[186]\tPatient-specific Question Answering\tChatGPT\tZS\tHealthcare\tEnglish\tNo\n",
      "[132]\tQuestion Answering\tChatGPT\tZS\tGeneral\tEnglish\tYes' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17613.373046875\n",
      "page_content='Hamidi et al. [186] evaluated ChatGPT and Claude\n",
      "Paper\tTask(s)\tGLLMs Explored\tPrompt Settings\tDomain(s)\tLanguage(s)\tSOTA Results\n",
      "[177]\tAdmission Exam Question Answering\tGPT-3.5, ChatGPT, GPT-4\tZS, FS\tEducation\tBrazilian Portuguese\tNo\n",
      "[178]\tKnowledge-based Complex Question Answering\tGPT-3, GPT-3.5, ChatGPT\tZS\tGeneral\tMultiple languages\tNo\n",
      "[179]\tKnowledge-based Visual Question Answering\tGPT-3\tZS\tGeneral\tEnglish\tYes\n",
      "[180]\tTabular Question Answering\tGPT-3\tZS, FS\tNews\tEnglish\tNo\n",
      "[181]\tOpen Domain Question Answering\tChatGPT\tZS\tGeneral\tEnglish\tNo\n",
      "[182]\tBariatric Surgery Question Answering\tChatGPT\tZS\tHealthcare\tEnglish\tNo\n",
      "[183]\tRadiation Oncology Physics Question Answering\tChatGPT, GPT-4\tZS\tHealthcare\tEnglish\tNo\n",
      "[184]\tComputer Science Question Answering\tChatGPT\tZS\tEducation\tEnglish\tNo\n",
      "[185]\tMedical Question Answering\tGPT-3.5, GPT-4\tZS, FS\tHealthcare\tEnglish\tNo\n",
      "[186]\tPatient-specific Question Answering\tChatGPT\tZS\tHealthcare\tEnglish\tNo\n",
      "[132]\tQuestion Answering\tChatGPT\tZS\tGeneral\tEnglish\tYes' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17645.09375\n",
      "page_content='etc. In domains like healthcare, finance and legal, domain experts use many words and abbreviations that are specific to the domain and not commonly found in general domain texts. There is a lot of scope to improve the performance of GLLMs in domain-specific NLP tasks, which reduces the bottleneck for the widespread adoption of these models in specific domains.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17645.09375\n",
      "page_content='etc. In domains like healthcare, finance and legal, domain experts use many words and abbreviations that are specific to the domain and not commonly found in general domain texts. There is a lot of scope to improve the performance of GLLMs in domain-specific NLP tasks, which reduces the bottleneck for the widespread adoption of these models in specific domains.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17649.36328125\n",
      "page_content='[146]\tC.-E. Gonza´lez-Gallardo, E. Boros, N. Girdhar, A. Hamdi, J. G. Moreno, and A. Doucet, “Yes but.. can chatgpt identify entities in historical documents?” arXiv preprint arXiv:2303.17322, 2023.\n",
      "[147]\tY. Hu, I. Ameer, X. Zuo, X. Peng, Y. Zhou, Z. Li, Y. Li, J. Li, X. Jiang, and H. Xu, “Zero-shot clinical entity recognition using chatgpt,” arXiv preprint arXiv:2303.16416, 2023.\n",
      "[148]\tX. Wei, X. Cui, N. Cheng, X. Wang, X. Zhang, S. Huang, P. Xie, J. Xu, Y. Chen, M. Zhang et al., “Zero-shot information extraction via chatting with chatgpt,” arXiv preprint arXiv:2302.10205, 2023.\n",
      "[149]\tB. J. Gutie´ rrez, N. McNeal, C. Washington, Y. Chen, L. Li, H. Sun, and Y. Su, “Thinking about gpt-3 in-context learning for biomedical ie? think again,” in Findings of the Association for Computational Linguistics: EMNLP 2022, 2022, pp. 4497–4512.\n",
      "[150]\tJ. Gao, H. Zhao, C. Yu, and R. Xu, “Exploring the feasibility of chatgpt for event extraction,” arXiv preprint arXiv:2303.03836, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17649.36328125\n",
      "page_content='[146]\tC.-E. Gonza´lez-Gallardo, E. Boros, N. Girdhar, A. Hamdi, J. G. Moreno, and A. Doucet, “Yes but.. can chatgpt identify entities in historical documents?” arXiv preprint arXiv:2303.17322, 2023.\n",
      "[147]\tY. Hu, I. Ameer, X. Zuo, X. Peng, Y. Zhou, Z. Li, Y. Li, J. Li, X. Jiang, and H. Xu, “Zero-shot clinical entity recognition using chatgpt,” arXiv preprint arXiv:2303.16416, 2023.\n",
      "[148]\tX. Wei, X. Cui, N. Cheng, X. Wang, X. Zhang, S. Huang, P. Xie, J. Xu, Y. Chen, M. Zhang et al., “Zero-shot information extraction via chatting with chatgpt,” arXiv preprint arXiv:2302.10205, 2023.\n",
      "[149]\tB. J. Gutie´ rrez, N. McNeal, C. Washington, Y. Chen, L. Li, H. Sun, and Y. Su, “Thinking about gpt-3 in-context learning for biomedical ie? think again,” in Findings of the Association for Computational Linguistics: EMNLP 2022, 2022, pp. 4497–4512.\n",
      "[150]\tJ. Gao, H. Zhao, C. Yu, and R. Xu, “Exploring the feasibility of chatgpt for event extraction,” arXiv preprint arXiv:2303.03836, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17655.46484375\n",
      "page_content='[217]\tM. Song, H. Jiang, S. Shi, S. Yao, S. Lu, Y. Feng, H. Liu, and L. Jing, “Is chatgpt a good keyphrase generator? a preliminary study,” arXiv preprint arXiv:2303.13001, 2023.\n",
      "[218]\tW. Pan, Q. Chen, X. Xu, W. Che, and L. Qin, “A preliminary evaluation of chatgpt for zero-shot dialogue understanding,” arXiv preprint arXiv:2304.04256, 2023.\n",
      "[219]\tW. Zhao, Y. Zhao, X. Lu, S. Wang, Y. Tong, and B. Qin, “Is chatgpt equipped with emotional dialogue capabilities?” arXiv preprint arXiv:2304.09582, 2023.\n",
      "[220]\tB. Chintagunta, N. Katariya, X. Amatriain, and A. Kannan, “Medically aware gpt-3 as a data generator for medical dialogue summarization,” in Machine Learning for Healthcare Conference. PMLR, 2021, pp. 354–372.\n",
      "[221]\tG. P. Prodan and E. Pelican, “Prompt scoring system for dialogue summarization using gpt-3,” ACM Transaction on Audio, Speech, and Language Processing, pp. 1–9, 2022.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17655.46484375\n",
      "page_content='[217]\tM. Song, H. Jiang, S. Shi, S. Yao, S. Lu, Y. Feng, H. Liu, and L. Jing, “Is chatgpt a good keyphrase generator? a preliminary study,” arXiv preprint arXiv:2303.13001, 2023.\n",
      "[218]\tW. Pan, Q. Chen, X. Xu, W. Che, and L. Qin, “A preliminary evaluation of chatgpt for zero-shot dialogue understanding,” arXiv preprint arXiv:2304.04256, 2023.\n",
      "[219]\tW. Zhao, Y. Zhao, X. Lu, S. Wang, Y. Tong, and B. Qin, “Is chatgpt equipped with emotional dialogue capabilities?” arXiv preprint arXiv:2304.09582, 2023.\n",
      "[220]\tB. Chintagunta, N. Katariya, X. Amatriain, and A. Kannan, “Medically aware gpt-3 as a data generator for medical dialogue summarization,” in Machine Learning for Healthcare Conference. PMLR, 2021, pp. 354–372.\n",
      "[221]\tG. P. Prodan and E. Pelican, “Prompt scoring system for dialogue summarization using gpt-3,” ACM Transaction on Audio, Speech, and Language Processing, pp. 1–9, 2022.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17655.6015625\n",
      "page_content='Figure 4: Examples for answering question \"Which film was released earlier, The Girl From Monterrey or Jhuthi Sharm?\" in the 2WIKIMQA dataset.\n",
      "heuristic retrievers like TF-IDF for sourcing evidence. Subsequently, RAG evolved with the introduction of Dense Passage Retrieval [15] and REALM [26]. These methods utilize pre-trained transformers and are characterized by the joint optimization of retrieval and generation process. Recent advancements have extended RAG’s capabilities by integrating Large Language Models (LLMs), with developments such as REPLUG [29] and IC-RALM [26] demonstrating the potent generalization abilities of LLMs in zero-shot or few-shot scenarios. These models can follow complex instructions, understand retrieved information, and utilize limited demonstrations for generating high-quality responses.\n",
      "8.2\tModular RAG' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17655.6015625\n",
      "page_content='Figure 4: Examples for answering question \"Which film was released earlier, The Girl From Monterrey or Jhuthi Sharm?\" in the 2WIKIMQA dataset.\n",
      "heuristic retrievers like TF-IDF for sourcing evidence. Subsequently, RAG evolved with the introduction of Dense Passage Retrieval [15] and REALM [26]. These methods utilize pre-trained transformers and are characterized by the joint optimization of retrieval and generation process. Recent advancements have extended RAG’s capabilities by integrating Large Language Models (LLMs), with developments such as REPLUG [29] and IC-RALM [26] demonstrating the potent generalization abilities of LLMs in zero-shot or few-shot scenarios. These models can follow complex instructions, understand retrieved information, and utilize limited demonstrations for generating high-quality responses.\n",
      "8.2\tModular RAG' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17671.94140625\n",
      "page_content='[375]\tP. To¨ rnberg, “Chatgpt-4 outperforms experts and crowd workers in annotating political twitter messages with zero-shot learning,” arXiv preprint arXiv:2304.06588, 2023.\n",
      "[376]\tY. Zhu, P. Zhang, E.-U. Haq, P. Hui, and G. Tyson, “Can chatgpt reproduce human-generated labels? a study of social computing tasks,” arXiv preprint arXiv:2304.10145, 2023.\n",
      "[377]\tL. Li, L. Fan, S. Atreja, and L. Hemphill, “” hot” chatgpt: The promise of chatgpt in detecting and discriminating hateful, offensive, and toxic comments on social media,” arXiv preprint arXiv:2304.10619, 2023.\n",
      "[378]\tY. Gu, S. Zhang, N. Usuyama, Y. Woldesenbet, C. Wong, P. Sana-pathi, M. Wei, N. Valluri, E. Strandberg, T. Naumann et al., “Distilling large language models for biomedical knowledge extraction: A case study on adverse drug events,” arXiv preprint arXiv:2307.06439, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17671.94140625\n",
      "page_content='[375]\tP. To¨ rnberg, “Chatgpt-4 outperforms experts and crowd workers in annotating political twitter messages with zero-shot learning,” arXiv preprint arXiv:2304.06588, 2023.\n",
      "[376]\tY. Zhu, P. Zhang, E.-U. Haq, P. Hui, and G. Tyson, “Can chatgpt reproduce human-generated labels? a study of social computing tasks,” arXiv preprint arXiv:2304.10145, 2023.\n",
      "[377]\tL. Li, L. Fan, S. Atreja, and L. Hemphill, “” hot” chatgpt: The promise of chatgpt in detecting and discriminating hateful, offensive, and toxic comments on social media,” arXiv preprint arXiv:2304.10619, 2023.\n",
      "[378]\tY. Gu, S. Zhang, N. Usuyama, Y. Woldesenbet, C. Wong, P. Sana-pathi, M. Wei, N. Valluri, E. Strandberg, T. Naumann et al., “Distilling large language models for biomedical knowledge extraction: A case study on adverse drug events,” arXiv preprint arXiv:2307.06439, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17676.3984375\n",
      "page_content='Initial efforts have been made to utilize the potential of LLMs in the development of novel IR systems. Notably, in terms of practical applications, New Bing is designed to improve the users’ experience of using search engines by extracting information from disparate web pages and condensing it into concise summaries that serve as responses to user-generated queries. In the research community, LLMs have proven useful within specific modules of IR systems (such as retrievers), thereby enhancing the overall performance of these systems. Due to the rapid evolution of LLM-enhanced IR systems, it is essential to comprehensively review their most recent advancements and challenges.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17676.3984375\n",
      "page_content='Initial efforts have been made to utilize the potential of LLMs in the development of novel IR systems. Notably, in terms of practical applications, New Bing is designed to improve the users’ experience of using search engines by extracting information from disparate web pages and condensing it into concise summaries that serve as responses to user-generated queries. In the research community, LLMs have proven useful within specific modules of IR systems (such as retrievers), thereby enhancing the overall performance of these systems. Due to the rapid evolution of LLM-enhanced IR systems, it is essential to comprehensively review their most recent advancements and challenges.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17680.50390625\n",
      "page_content='To allow LLMs to actively use search engines, SelfAsk [218], DSP [219], and PlanRAG [220] try to employ fewshot prompts for LLMs, triggering them to search queries when they believe it is required. For example, in a scenario where the query is “When was the existing tallest wooden lattice tower built?”, these prompted LLMs can decide to search a query “What is the existing tallest wooden lattice tower” to gather necessary references as they find the query cannot be directly answered. Once acquired information about the tower, they can iteratively query IR systems for more details until they determine to generate the final answers instead of asking questions. To alleviate the problem of insufficient manually annotated data for fine-tuning, LPKG [221] constructs high-quality active retrieval-augmented reasoning paths from existing knowledge graphs. Notably, these methods involve IR systems to construct a single reasoning chain for LLMs. MRC [222] further improves these methods by' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17680.50390625\n",
      "page_content='To allow LLMs to actively use search engines, SelfAsk [218], DSP [219], and PlanRAG [220] try to employ fewshot prompts for LLMs, triggering them to search queries when they believe it is required. For example, in a scenario where the query is “When was the existing tallest wooden lattice tower built?”, these prompted LLMs can decide to search a query “What is the existing tallest wooden lattice tower” to gather necessary references as they find the query cannot be directly answered. Once acquired information about the tower, they can iteratively query IR systems for more details until they determine to generate the final answers instead of asking questions. To alleviate the problem of insufficient manually annotated data for fine-tuning, LPKG [221] constructs high-quality active retrieval-augmented reasoning paths from existing knowledge graphs. Notably, these methods involve IR systems to construct a single reasoning chain for LLMs. MRC [222] further improves these methods by' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17689.89453125\n",
      "page_content='8.4\tReader\n",
      "With the increasing capabilities of LLMs, the future interaction between users and IR systems will be significantly changed. Due to the powerful natural language processing and understanding capabilities of LLMs, the traditional search paradigm of providing ranking results is expected to be progressively replaced by synthesizing conclusive answering passages for user queries using the reader module. Although such strategies have already been investigated by academia and facilitated by industry as we stated in Section 6, there still exists much room for exploration.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17689.89453125\n",
      "page_content='8.4\tReader\n",
      "With the increasing capabilities of LLMs, the future interaction between users and IR systems will be significantly changed. Due to the powerful natural language processing and understanding capabilities of LLMs, the traditional search paradigm of providing ranking results is expected to be progressively replaced by synthesizing conclusive answering passages for user queries using the reader module. Although such strategies have already been investigated by academia and facilitated by industry as we stated in Section 6, there still exists much room for exploration.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17689.904296875\n",
      "page_content='[356]\tA. Shah and S. Chava, “Zero is not hero yet: Benchmarking zero-shot performance of llms for financial tasks,” arXiv preprint arXiv:2305.16633, 2023.\n",
      "[357]\tL. Zhang, W. Cai, Z. Liu, Z. Yang, W. Dai, Y. Liao, Q. Qin, Y. Li, X. Liu, Z. Liu et al., “Fineval: A chinese financial domain knowledge evaluation benchmark for large language models,” arXiv preprint arXiv:2308.09975, 2023.\n",
      "[358]\tP. K. Rajpoot and A. Parikh, “Gpt-finre: In-context learning for financial relation extraction using large language models,” arXiv preprint arXiv:2306.17519, 2023.\n",
      "[359]\tL. Loukas, I. Stogiannidis, P. Malakasiotis, and S. Vassos, “Breaking the bank with chatgpt: Few-shot text classification for finance,” arXiv preprint arXiv:2308.14634, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17689.904296875\n",
      "page_content='[356]\tA. Shah and S. Chava, “Zero is not hero yet: Benchmarking zero-shot performance of llms for financial tasks,” arXiv preprint arXiv:2305.16633, 2023.\n",
      "[357]\tL. Zhang, W. Cai, Z. Liu, Z. Yang, W. Dai, Y. Liao, Q. Qin, Y. Li, X. Liu, Z. Liu et al., “Fineval: A chinese financial domain knowledge evaluation benchmark for large language models,” arXiv preprint arXiv:2308.09975, 2023.\n",
      "[358]\tP. K. Rajpoot and A. Parikh, “Gpt-finre: In-context learning for financial relation extraction using large language models,” arXiv preprint arXiv:2306.17519, 2023.\n",
      "[359]\tL. Loukas, I. Stogiannidis, P. Malakasiotis, and S. Vassos, “Breaking the bank with chatgpt: Few-shot text classification for finance,” arXiv preprint arXiv:2308.14634, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17693.150390625\n",
      "page_content='5\tAblation Studies\n",
      "In this section, we analyze the individual and combined effects of question rewriting and knowledge filtering. The results presented in Table 3 indicate that the question rewriting process consistently improves answer accuracy across the setups of direct generation, retrieval-augmented generation using all knowledge, and retrieval-augmented generation using filtered knowledge.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17693.150390625\n",
      "page_content='5\tAblation Studies\n",
      "In this section, we analyze the individual and combined effects of question rewriting and knowledge filtering. The results presented in Table 3 indicate that the question rewriting process consistently improves answer accuracy across the setups of direct generation, retrieval-augmented generation using all knowledge, and retrieval-augmented generation using filtered knowledge.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17693.154296875\n",
      "page_content='Additionally, to highlight the similarities and differences among the corresponding methods, we present a comparative result in Table 3. It compares the aforementioned methods from various perspectives, including the number of examples, the generator employed, the type of synthetic data produced, the method applied to filter synthetic data, and whether LLMs are fine-tuned. This table serves to facilitate a clearer understanding of the landscape of these\n",
      "methods.\n",
      "4.2 Leveraging LLMs as Retrievers’ Backbone\n",
      "Thanks to the superior text representation capability, LLMs excel at comprehending the underlying semantics of queries and documents. Therefore, it becomes increasingly popular to apply such large-scale models as the backbone of text retrievers, leading to substantial improvements over the conventional methods based on smaller-sized models [55].\n",
      "4.2.1\tDense Retriever' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17693.154296875\n",
      "page_content='Additionally, to highlight the similarities and differences among the corresponding methods, we present a comparative result in Table 3. It compares the aforementioned methods from various perspectives, including the number of examples, the generator employed, the type of synthetic data produced, the method applied to filter synthetic data, and whether LLMs are fine-tuned. This table serves to facilitate a clearer understanding of the landscape of these\n",
      "methods.\n",
      "4.2 Leveraging LLMs as Retrievers’ Backbone\n",
      "Thanks to the superior text representation capability, LLMs excel at comprehending the underlying semantics of queries and documents. Therefore, it becomes increasingly popular to apply such large-scale models as the backbone of text retrievers, leading to substantial improvements over the conventional methods based on smaller-sized models [55].\n",
      "4.2.1\tDense Retriever' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17699.45703125\n",
      "page_content='Leaking\t3\t0.67\t0.86\t1.00\n",
      "Low output\t2\t0.00\t0.00\t0.00\n",
      "Minor in-service problems\t17\t0.73\t0.11\t1.00\n",
      "Other\t2\t0.67\t0.40\t0.00\n",
      "Overheating\t4\t1.00\t1.00\t1.00\n",
      "Plugged / choked\t6\t0.67\t0.25\t1.00\n",
      "Spurious stop\t1\t0.00\t0.00\t0.00\n",
      "Structural deficiency\t3\t0.60\t0.57\t1.00\n",
      "Vibration\t2\t0.67\t1.00\t1.00\n",
      "Micro-F1\t\t0.60\t0.46\t0.81\n",
      "Macro-F1\t\t0.46\t0.53\t0.62\n",
      "Table 3: A comparison of the Flair model [Stewart et al., 2022] and the GPT-3.5 LLMs (non-fine-tuned and fine-tuned) on the test dataset. Support is the number of times the label appears in the test dataset. The results of the top-performing model (when there are no ties) are in bold.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Stewart 等 - 2023 - Large Language Models for Failure Mode Classification An Investigation.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17699.45703125\n",
      "page_content='Leaking\t3\t0.67\t0.86\t1.00\n",
      "Low output\t2\t0.00\t0.00\t0.00\n",
      "Minor in-service problems\t17\t0.73\t0.11\t1.00\n",
      "Other\t2\t0.67\t0.40\t0.00\n",
      "Overheating\t4\t1.00\t1.00\t1.00\n",
      "Plugged / choked\t6\t0.67\t0.25\t1.00\n",
      "Spurious stop\t1\t0.00\t0.00\t0.00\n",
      "Structural deficiency\t3\t0.60\t0.57\t1.00\n",
      "Vibration\t2\t0.67\t1.00\t1.00\n",
      "Micro-F1\t\t0.60\t0.46\t0.81\n",
      "Macro-F1\t\t0.46\t0.53\t0.62\n",
      "Table 3: A comparison of the Flair model [Stewart et al., 2022] and the GPT-3.5 LLMs (non-fine-tuned and fine-tuned) on the test dataset. Support is the number of times the label appears in the test dataset. The results of the top-performing model (when there are no ties) are in bold.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Stewart 等 - 2023 - Large Language Models for Failure Mode Classification An Investigation.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17699.7265625\n",
      "page_content='(PLMs), with the “pre-training then fine-tuning” paradigm emerging as the prevailing learning approach. Along this line, numerous generative PLMs (e.g., GPT-2 [33], BART [57], and T5 [58]) have been developed for text generation problems including summarization, machine translation, and dialogue generation. Recently, researchers have observed that increasing the scale of PLMs (e.g., model size or data amount) can consistently improve their performance on downstream tasks (a phenomenon commonly referred to as the scaling law [59, 60]). Moreover, large-sized PLMs exhibit promising abilities (termed emergent abilities [42]) in addressing complex tasks, which are not evident in their smaller counterparts. Therefore, the research community refers to these large-sized PLMs as large language models (LLMs).' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17699.7265625\n",
      "page_content='(PLMs), with the “pre-training then fine-tuning” paradigm emerging as the prevailing learning approach. Along this line, numerous generative PLMs (e.g., GPT-2 [33], BART [57], and T5 [58]) have been developed for text generation problems including summarization, machine translation, and dialogue generation. Recently, researchers have observed that increasing the scale of PLMs (e.g., model size or data amount) can consistently improve their performance on downstream tasks (a phenomenon commonly referred to as the scaling law [59, 60]). Moreover, large-sized PLMs exhibit promising abilities (termed emergent abilities [42]) in addressing complex tasks, which are not evident in their smaller counterparts. Therefore, the research community refers to these large-sized PLMs as large language models (LLMs).' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17705.58984375\n",
      "page_content='R52\ttopic\t52\tnews\t5,905\t627\t2,568\tR52\ttopic\t52\tnews\t5,905\t627\t1,027\n",
      "MR\tsentiment\t2\treviews\t6,398\t710\t3,554\tMR\tsentiment\t2\treviews\t6,398\t710\t888\n",
      "Table 12: Benchmark Dataset\n",
      "Table 13: Dataset Subsets\n",
      "Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen, Christopher Dewan, Mona Diab, Xian Li, Xi Victoria Lin, et al. 2022a. Opt: Open pre-trained transformer language models. arXiv preprint arXiv:2205.01068.\n",
      "Xiang Zhang, Junbo Zhao, and Yann LeCun. 2015. Character-level convolutional networks for text classification. Advances in neural information processing systems, 28.\n",
      "Zhuosheng Zhang, Aston Zhang, Mu Li, and Alex Smola. 2022b. Automatic chain of thought prompting in large language models. arXiv preprint arXiv:2210.03493.\n",
      "Zexuan Zhong, Dan Friedman, and Danqi Chen. 2021. Factual probing is [mask]: Learning vs. learning to recall. arXiv preprint arXiv:2104.05240.\n",
      "A Dataset' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17705.58984375\n",
      "page_content='R52\ttopic\t52\tnews\t5,905\t627\t2,568\tR52\ttopic\t52\tnews\t5,905\t627\t1,027\n",
      "MR\tsentiment\t2\treviews\t6,398\t710\t3,554\tMR\tsentiment\t2\treviews\t6,398\t710\t888\n",
      "Table 12: Benchmark Dataset\n",
      "Table 13: Dataset Subsets\n",
      "Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen, Christopher Dewan, Mona Diab, Xian Li, Xi Victoria Lin, et al. 2022a. Opt: Open pre-trained transformer language models. arXiv preprint arXiv:2205.01068.\n",
      "Xiang Zhang, Junbo Zhao, and Yann LeCun. 2015. Character-level convolutional networks for text classification. Advances in neural information processing systems, 28.\n",
      "Zhuosheng Zhang, Aston Zhang, Mu Li, and Alex Smola. 2022b. Automatic chain of thought prompting in large language models. arXiv preprint arXiv:2210.03493.\n",
      "Zexuan Zhong, Dan Friedman, and Danqi Chen. 2021. Factual probing is [mask]: Learning vs. learning to recall. arXiv preprint arXiv:2104.05240.\n",
      "A Dataset' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17709.6015625\n",
      "page_content='of 20-30% in the remaining edits required by implementing the prompt edits suggested by GPT-3 family models. Lu et al. [285] proposed LLMScore, a new metric which can effectively capture both image and object-level compositionality for text-to-image generation evaluation.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17709.6015625\n",
      "page_content='of 20-30% in the remaining edits required by implementing the prompt edits suggested by GPT-3 family models. Lu et al. [285] proposed LLMScore, a new metric which can effectively capture both image and object-level compositionality for text-to-image generation evaluation.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17715.537109375\n",
      "page_content='resourcekey=0-TLwzfR2O-D2aPitmn5o9VQ& In this section, we conduct comprehensive ablation usp=share_link\tstudies to get a better knowledge about different\n",
      "Supervised Methods\t\t\t\t\t\t\n",
      "RoBERTa-Large RoBERTa-GCN\t95.99 95.80\t95.55 95.68\t97.76 98.2\t96.42 96.1\t91.16 89.7\t95.38 95.10\n",
      "Zero-shot Setting\t\t\t\t\t\t\n",
      "Vanilla\t91.55\t90.72\t90.19\t89.06\t88.69\t90.04\n",
      "Zero-shot-CoT\t92.11\t91.25\t90.48\t91.24\t89.37\t90.89\n",
      "CARP\t94.41\t93.18\t93.29\t92.69\t90.03\t92.72\n",
      "Few-shot Setting\t\t\t\t\t\t\n",
      "Random Sampler\t\t\t\t\t\t\n",
      "Vanilla\t91.36\t91.48\t90.60\t90.68\t89.15\t90.65\n",
      "Zero-shot-CoT\t92.56\t92.65\t92.49\t92.03\t89.91\t91.93\n",
      "CARP\t94.41\t93.18\t93.29\t92.69\t90.03\t92.72\n",
      "SimCSE kNN-Sampler\t\t\t\t\t\t\n",
      "Vanilla\t93.90\t93.50\t94.36\t92.40\t89.59\t92.75\n",
      "Zero-shot-CoT\t94.21\t94.28\t95.07\t92.98\t90.27\t93.36\n",
      "CARP\t95.99\t95.53\t95.31\t93.84\t90.64\t94.26\n",
      "FT kNN-Sampler\t\t\t\t\t\t\n",
      "Vanilla\t94.01\t94.14\t95.57\t95.79\t90.90\t94.08\n",
      "Zero-shot-CoT\t95.48\t94.89\t95.59\t95.89\t90.17\t94.40\n",
      "CARP\t96.62\t95.97\t98.13\t96.12\t91.86\t95.74' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17715.537109375\n",
      "page_content='resourcekey=0-TLwzfR2O-D2aPitmn5o9VQ& In this section, we conduct comprehensive ablation usp=share_link\tstudies to get a better knowledge about different\n",
      "Supervised Methods\t\t\t\t\t\t\n",
      "RoBERTa-Large RoBERTa-GCN\t95.99 95.80\t95.55 95.68\t97.76 98.2\t96.42 96.1\t91.16 89.7\t95.38 95.10\n",
      "Zero-shot Setting\t\t\t\t\t\t\n",
      "Vanilla\t91.55\t90.72\t90.19\t89.06\t88.69\t90.04\n",
      "Zero-shot-CoT\t92.11\t91.25\t90.48\t91.24\t89.37\t90.89\n",
      "CARP\t94.41\t93.18\t93.29\t92.69\t90.03\t92.72\n",
      "Few-shot Setting\t\t\t\t\t\t\n",
      "Random Sampler\t\t\t\t\t\t\n",
      "Vanilla\t91.36\t91.48\t90.60\t90.68\t89.15\t90.65\n",
      "Zero-shot-CoT\t92.56\t92.65\t92.49\t92.03\t89.91\t91.93\n",
      "CARP\t94.41\t93.18\t93.29\t92.69\t90.03\t92.72\n",
      "SimCSE kNN-Sampler\t\t\t\t\t\t\n",
      "Vanilla\t93.90\t93.50\t94.36\t92.40\t89.59\t92.75\n",
      "Zero-shot-CoT\t94.21\t94.28\t95.07\t92.98\t90.27\t93.36\n",
      "CARP\t95.99\t95.53\t95.31\t93.84\t90.64\t94.26\n",
      "FT kNN-Sampler\t\t\t\t\t\t\n",
      "Vanilla\t94.01\t94.14\t95.57\t95.79\t90.90\t94.08\n",
      "Zero-shot-CoT\t95.48\t94.89\t95.59\t95.89\t90.17\t94.40\n",
      "CARP\t96.62\t95.97\t98.13\t96.12\t91.86\t95.74' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17727.943359375\n",
      "page_content='[25]\tS. Min, J. Michael, H. Hajishirzi, and L. Zettlemoyer. AmbigQA: Answering ambiguous open-domain questions. In B. Webber, T. Cohn, Y. He, and Y. Liu, editors, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 5783–5797, Online, Nov. 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.emnlp- main.466. URL https:// aclanthology.org/2020.emnlp-main.466.\n",
      "[26]\tO. Ram, Y. Levine, I. Dalmedigos, D. Muhlgay, A. Shashua, K. Leyton-Brown, and Y. Shoham. In-context retrieval-augmented language models, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17727.943359375\n",
      "page_content='[25]\tS. Min, J. Michael, H. Hajishirzi, and L. Zettlemoyer. AmbigQA: Answering ambiguous open-domain questions. In B. Webber, T. Cohn, Y. He, and Y. Liu, editors, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 5783–5797, Online, Nov. 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.emnlp- main.466. URL https:// aclanthology.org/2020.emnlp-main.466.\n",
      "[26]\tO. Ram, Y. Levine, I. Dalmedigos, D. Muhlgay, A. Shashua, K. Leyton-Brown, and Y. Shoham. In-context retrieval-augmented language models, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17730.82421875\n",
      "page_content='However, these two approaches mainly rely on the successive n tokens to separate generation and retrieve documents, which may not be semantically continuous and may cause the collected references noisy and useless. To solve this problem, some approaches such as IRCoT [191] also explore retrieving documents for every generated sentence, which is a more complete semantic structure. Furthermore, researchers find that the whole generated passages can be considered as conclusive contexts for current queries and can be used to find more relevant knowledge to generate more thorough answers. Consequently, many recent approaches [190, 212–215] have also tried to extend this periodic-retrieval paradigm to iteratively using the whole generated passages to retrieve references to re-generate the answers, until the iterations reach a pre-defined limitation. Particularly, these methods can be regarded as special periodic-retrieval readers that retrieve passages when every answer is (re)-generated.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17730.82421875\n",
      "page_content='However, these two approaches mainly rely on the successive n tokens to separate generation and retrieve documents, which may not be semantically continuous and may cause the collected references noisy and useless. To solve this problem, some approaches such as IRCoT [191] also explore retrieving documents for every generated sentence, which is a more complete semantic structure. Furthermore, researchers find that the whole generated passages can be considered as conclusive contexts for current queries and can be used to find more relevant knowledge to generate more thorough answers. Consequently, many recent approaches [190, 212–215] have also tried to extend this periodic-retrieval paradigm to iteratively using the whole generated passages to retrieve references to re-generate the answers, until the iterations reach a pre-defined limitation. Particularly, these methods can be regarded as special periodic-retrieval readers that retrieve passages when every answer is (re)-generated.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17732.123046875\n",
      "page_content='Experimental Settings. The experiment is conducted using a randomly selected subset of 50 questions from each of the following datasets: PopQA [24], 2WikiMQA [30], HotpotQA [31], and CAm-bigNQ [19]. We employ the Rewrite-Retrieve-Read RAG pipeline, and the rewriter follows the LLM-based method, specifically utilizes GPT-3.5-turbo-0613, more details are described in previous study [23]. The rewriter module is designed to generate one to three variable-length queries for each question, depending on the question’s complexity. For retrieval, we use Bing Search V7 to identify the top 10 most relevant webpage snippets for each query. These snippets encapsulate the most query-related content from each webpage. For each question, a collection of retrieved snippets serves as the external knowledge to facilitate the LLM’s in-context learning for generating response. We create two ways to present the snippets: Sequential Order, with snippets for each query following one another, and Mix Order,' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17732.123046875\n",
      "page_content='Experimental Settings. The experiment is conducted using a randomly selected subset of 50 questions from each of the following datasets: PopQA [24], 2WikiMQA [30], HotpotQA [31], and CAm-bigNQ [19]. We employ the Rewrite-Retrieve-Read RAG pipeline, and the rewriter follows the LLM-based method, specifically utilizes GPT-3.5-turbo-0613, more details are described in previous study [23]. The rewriter module is designed to generate one to three variable-length queries for each question, depending on the question’s complexity. For retrieval, we use Bing Search V7 to identify the top 10 most relevant webpage snippets for each query. These snippets encapsulate the most query-related content from each webpage. For each question, a collection of retrieved snippets serves as the external knowledge to facilitate the LLM’s in-context learning for generating response. We create two ways to present the snippets: Sequential Order, with snippets for each query following one another, and Mix Order,' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17747.04296875\n",
      "page_content='[432]\tChatGPT generated text\tPropose novel approach based on Distil-BERT and SHAP to detect and explain\tYes\tNo\tSocial Media\tEnglish\n",
      "[429]\tChatGPT generated text\tIntroduce new dataset and evaluate multiple existing detection models\tYes\t-\tGeneral, Finance, Healthcare, Legal\t, Psychology\tEnglish\n",
      "[448]\tGPT-3\tand ChatGPT-based bots\tPropose FLAIR to detect online GPT-3 and ChatGPT-based bots\tYes\tYes\tGeneral\tEnglish\n",
      "[449]\tChatGPT generated text\tClassifiers based on models like RoBERTa and T5\tYes\tNo\tGeneral\tEnglish\n",
      "[428]\tChatGPT generated text\tPropose a zero-shot approach based on local optimality\tYes\tYes\tGeneral\tEnglish\n",
      "[450]\tChatGPT generated text\tPropose an approach based on Siamese Network and binary classifier\tYes\tNo\tGeneral\tEnglish\n",
      "[451]\tChatGPT polished text\tTrains classifier and polish ratio models to detect and explain\tYes\tNo\tGeneral\tEnglish\n",
      "[452]\tGPT-3.5 generated text\tEvaluate robustness using paraphrase attacks\tNo\t-\tGeneral\tEnglish' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17747.04296875\n",
      "page_content='[432]\tChatGPT generated text\tPropose novel approach based on Distil-BERT and SHAP to detect and explain\tYes\tNo\tSocial Media\tEnglish\n",
      "[429]\tChatGPT generated text\tIntroduce new dataset and evaluate multiple existing detection models\tYes\t-\tGeneral, Finance, Healthcare, Legal\t, Psychology\tEnglish\n",
      "[448]\tGPT-3\tand ChatGPT-based bots\tPropose FLAIR to detect online GPT-3 and ChatGPT-based bots\tYes\tYes\tGeneral\tEnglish\n",
      "[449]\tChatGPT generated text\tClassifiers based on models like RoBERTa and T5\tYes\tNo\tGeneral\tEnglish\n",
      "[428]\tChatGPT generated text\tPropose a zero-shot approach based on local optimality\tYes\tYes\tGeneral\tEnglish\n",
      "[450]\tChatGPT generated text\tPropose an approach based on Siamese Network and binary classifier\tYes\tNo\tGeneral\tEnglish\n",
      "[451]\tChatGPT polished text\tTrains classifier and polish ratio models to detect and explain\tYes\tNo\tGeneral\tEnglish\n",
      "[452]\tGPT-3.5 generated text\tEvaluate robustness using paraphrase attacks\tNo\t-\tGeneral\tEnglish' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17754.744140625\n",
      "page_content='[252]\tA. Cheshkov, P. Zadorozhny, and R. Levichev, “Evaluation of chatgpt model for vulnerability detection,” arXiv preprint arXiv:2304.07232, 2023.\n",
      "[253]\tB. Yetis¸tiren, I. O¨ zsoy, M. Ayerdem, and E. Tu¨ zu¨ n, “Evaluating the code quality of ai-assisted code generation tools: An empirical study on github copilot, amazon codewhisperer, and chatgpt,” arXiv preprint arXiv:2304.10778, 2023.\n",
      "[254]\tT.-O. Li, W. Zong, Y. Wang, H. Tian, Y. Wang, and S.-C. Cheung, “Finding failure-inducing test cases with chatgpt,” arXiv preprint arXiv:2304.11686, 2023.\n",
      "[255]\tC. Liu, X. Bao, H. Zhang, N. Zhang, H. Hu, X. Zhang, and M. Yan, “Improving chatgpt prompt for code generation,” arXiv preprint arXiv:2305.08360, 2023.\n",
      "[256]\tR. A. Poldrack, T. Lu, and G. Begusˇ, “Ai-assisted coding: Experiments with gpt-4,” arXiv preprint arXiv:2304.13187, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17754.744140625\n",
      "page_content='[252]\tA. Cheshkov, P. Zadorozhny, and R. Levichev, “Evaluation of chatgpt model for vulnerability detection,” arXiv preprint arXiv:2304.07232, 2023.\n",
      "[253]\tB. Yetis¸tiren, I. O¨ zsoy, M. Ayerdem, and E. Tu¨ zu¨ n, “Evaluating the code quality of ai-assisted code generation tools: An empirical study on github copilot, amazon codewhisperer, and chatgpt,” arXiv preprint arXiv:2304.10778, 2023.\n",
      "[254]\tT.-O. Li, W. Zong, Y. Wang, H. Tian, Y. Wang, and S.-C. Cheung, “Finding failure-inducing test cases with chatgpt,” arXiv preprint arXiv:2304.11686, 2023.\n",
      "[255]\tC. Liu, X. Bao, H. Zhang, N. Zhang, H. Hu, X. Zhang, and M. Yan, “Improving chatgpt prompt for code generation,” arXiv preprint arXiv:2305.08360, 2023.\n",
      "[256]\tR. A. Poldrack, T. Lu, and G. Begusˇ, “Ai-assisted coding: Experiments with gpt-4,” arXiv preprint arXiv:2304.13187, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17781.001953125\n",
      "page_content='∗ Equal contribution. Work done during the internship at Microsoft.\n",
      "of jazz music. They could type in keywords such as “history of jazz” or “jazz pioneers” to retrieve relevant articles and sources. However, with LLMs, this student could pose a question like “Who were the key pioneers of jazz music, and how did they influence the genre?” The LLMs could then generate a summary of the relevant information and sources, potentially saving time and effort in sifting through search results.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Feng 等 - 2023 - Synergistic Interplay between Search and Large Language Models for Information Retrieval.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17781.001953125\n",
      "page_content='∗ Equal contribution. Work done during the internship at Microsoft.\n",
      "of jazz music. They could type in keywords such as “history of jazz” or “jazz pioneers” to retrieve relevant articles and sources. However, with LLMs, this student could pose a question like “Who were the key pioneers of jazz music, and how did they influence the genre?” The LLMs could then generate a summary of the relevant information and sources, potentially saving time and effort in sifting through search results.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Feng 等 - 2023 - Synergistic Interplay between Search and Large Language Models for Information Retrieval.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17783.9140625\n",
      "page_content='8.3\tReranker\n",
      "In Section 5, we have discussed the recent advanced techniques of utilizing LLMs for the reranking task. Some potential future directions in reranking are discussed as follows.\n",
      "•\tEnhancing the online availability of LLMs. Though effective, many LLMs have a massive number of parameters, making it challenging to deploy them in online applications. Besides, many reranking methods [159, 160] rely on calling LLM APIs, incurring considerable costs. Consequently, devising effective approaches (such as distilling to small models) to enhance the online applicability of LLMs emerges as a research direction worth exploring.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17783.9140625\n",
      "page_content='8.3\tReranker\n",
      "In Section 5, we have discussed the recent advanced techniques of utilizing LLMs for the reranking task. Some potential future directions in reranking are discussed as follows.\n",
      "•\tEnhancing the online availability of LLMs. Though effective, many LLMs have a massive number of parameters, making it challenging to deploy them in online applications. Besides, many reranking methods [159, 160] rely on calling LLM APIs, incurring considerable costs. Consequently, devising effective approaches (such as distilling to small models) to enhance the online applicability of LLMs emerges as a research direction worth exploring.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17796.541015625\n",
      "page_content='Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Jacob Devlin, Kenton Lee, Kristina Toutanova, Llion Jones, Matthew Kelcey, Ming-Wei Chang, Andrew M. Dai, Jakob Uszkoreit, Quoc Le, and Slav Petrov. Natural questions: A benchmark for question answering research. Transactions of the Association for Computational Linguistics, 7:452–466, 2019. doi: 10.1162/tacl_a_00276. URL https://aclanthology.org/Q19-1026.\n",
      "Yunshi Lan, Gaole He, Jinhao Jiang, Jing Jiang, Wayne Xin Zhao, and Ji-Rong Wen. A survey on complex knowledge base question answering: Methods, challenges and solutions. In Zhi-Hua Zhou (ed.), Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence, IJCAI-21, pp. 4483–4491. International Joint Conferences on Artificial Intelligence Organization, 8 2021. doi: 10.24963/ijcai.2021/611. URL https://doi.org/10.24963/ijcai.2021/611. Survey Track.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Feng 等 - 2023 - Synergistic Interplay between Search and Large Language Models for Information Retrieval.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17796.541015625\n",
      "page_content='Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Jacob Devlin, Kenton Lee, Kristina Toutanova, Llion Jones, Matthew Kelcey, Ming-Wei Chang, Andrew M. Dai, Jakob Uszkoreit, Quoc Le, and Slav Petrov. Natural questions: A benchmark for question answering research. Transactions of the Association for Computational Linguistics, 7:452–466, 2019. doi: 10.1162/tacl_a_00276. URL https://aclanthology.org/Q19-1026.\n",
      "Yunshi Lan, Gaole He, Jinhao Jiang, Jing Jiang, Wayne Xin Zhao, and Ji-Rong Wen. A survey on complex knowledge base question answering: Methods, challenges and solutions. In Zhi-Hua Zhou (ed.), Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence, IJCAI-21, pp. 4483–4491. International Joint Conferences on Artificial Intelligence Organization, 8 2021. doi: 10.24963/ijcai.2021/611. URL https://doi.org/10.24963/ijcai.2021/611. Survey Track.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Feng 等 - 2023 - Synergistic Interplay between Search and Large Language Models for Information Retrieval.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17804.3984375\n",
      "page_content='[393]\tChatGPT, GPT-4\tQuestion Answering\tZS\tHealthcare\tEnglish\n",
      "[394]\tGPT-3\tText Classification\tFS\tGeneral\tEnglish\n",
      "[395]\tChatGPT\tMedical Event Classification, Medication Identification\tZS\tHealthcare\tEnglish\n",
      "[143]\tGPT-3\tIntent Classification\tZS\tSocial Media\tEnglish\n",
      "[396]\tChatGPT\tText Classification\tZS\tGeneral, Healthcare\tEnglish\n",
      "[397]\tChatGPT\tOpen Intent Detection\tZS\tGeneral\tEnglish\n",
      "TABLE 18. Summary of research works exploring GLLMs for paraphrasing-based data augmentation.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17804.3984375\n",
      "page_content='[393]\tChatGPT, GPT-4\tQuestion Answering\tZS\tHealthcare\tEnglish\n",
      "[394]\tGPT-3\tText Classification\tFS\tGeneral\tEnglish\n",
      "[395]\tChatGPT\tMedical Event Classification, Medication Identification\tZS\tHealthcare\tEnglish\n",
      "[143]\tGPT-3\tIntent Classification\tZS\tSocial Media\tEnglish\n",
      "[396]\tChatGPT\tText Classification\tZS\tGeneral, Healthcare\tEnglish\n",
      "[397]\tChatGPT\tOpen Intent Detection\tZS\tGeneral\tEnglish\n",
      "TABLE 18. Summary of research works exploring GLLMs for paraphrasing-based data augmentation.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17817.6796875\n",
      "page_content='Dataset\tType\t# Class\t# Test Example\n",
      "DBPedia\tTopic\t14\t70000\n",
      "IMDB\tSentiment\t2\t25000\n",
      "Amazon\tSentiment\t2\t10000\n",
      "SST-2\tSentiment\t2\t872\n",
      "AG’s News\tTopic\t4\t7600\n",
      "Yahoo\tTopic\t10\t60000\n",
      "4.2.\tExperimental Settings\n",
      "Our experiments are built on Pytorch. We use RoBERTa-large (Liu et al., 2019) as the base model for all experiments and report the accuracy. For prompt-based methods, we follow the setup of KPT (Hu et al., 2022) with four manual templates and repeat the experiments with five different random seeds for each template, which significantly eliminates the randomness in experiments and makes our results convincing. For the finetuning method, we use the same five seeds as prompt-based methods for a fair comparison. For bias-based annotation, we randomly select mx200 examples for an m-class task from the task unlabeled data as the unlabeled validation set U and then annotate five examples per class as training' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17817.6796875\n",
      "page_content='Dataset\tType\t# Class\t# Test Example\n",
      "DBPedia\tTopic\t14\t70000\n",
      "IMDB\tSentiment\t2\t25000\n",
      "Amazon\tSentiment\t2\t10000\n",
      "SST-2\tSentiment\t2\t872\n",
      "AG’s News\tTopic\t4\t7600\n",
      "Yahoo\tTopic\t10\t60000\n",
      "4.2.\tExperimental Settings\n",
      "Our experiments are built on Pytorch. We use RoBERTa-large (Liu et al., 2019) as the base model for all experiments and report the accuracy. For prompt-based methods, we follow the setup of KPT (Hu et al., 2022) with four manual templates and repeat the experiments with five different random seeds for each template, which significantly eliminates the randomness in experiments and makes our results convincing. For the finetuning method, we use the same five seeds as prompt-based methods for a fair comparison. For bias-based annotation, we randomly select mx200 examples for an m-class task from the task unlabeled data as the unlabeled validation set U and then annotate five examples per class as training' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17818.634765625\n",
      "page_content='In our experiments we also investigate the necessity to add the following two texts to the system-level prompt:\n",
      "•\tIn Section 3.1, we include the sentence “Your answer should contain only the failure mode and nothing else.” to instruct the language model to avoid outputting unnecessary text (e.g. “The failure mode is ...”, etc.\n",
      "•\tIn Section 3.2 we include “Valid failure modes are: ” followed by a newline-separated list of valid labels from the dataset. This is an attempt to ensure that the model does not come up with its own failure modes, but instead outputs a failure mode code from the prescribed list.\n",
      "2.4\tEvaluation metrics\n",
      "In the same manner as [Stewart et al., 2022], we evaluate each model using Micro F1 and Macro F1 score. Micro F1 calculates an F1-Score by adding the true positives (TPs), false positives (FPs) and false negatives (FNs) from all class labels together and then calculating F1-Score:\n",
      "MicroF 1\tF 1(class1+class2+...+classn)\n",
      "(1)' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Stewart 等 - 2023 - Large Language Models for Failure Mode Classification An Investigation.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17818.634765625\n",
      "page_content='In our experiments we also investigate the necessity to add the following two texts to the system-level prompt:\n",
      "•\tIn Section 3.1, we include the sentence “Your answer should contain only the failure mode and nothing else.” to instruct the language model to avoid outputting unnecessary text (e.g. “The failure mode is ...”, etc.\n",
      "•\tIn Section 3.2 we include “Valid failure modes are: ” followed by a newline-separated list of valid labels from the dataset. This is an attempt to ensure that the model does not come up with its own failure modes, but instead outputs a failure mode code from the prescribed list.\n",
      "2.4\tEvaluation metrics\n",
      "In the same manner as [Stewart et al., 2022], we evaluate each model using Micro F1 and Macro F1 score. Micro F1 calculates an F1-Score by adding the true positives (TPs), false positives (FPs) and false negatives (FNs) from all class labels together and then calculating F1-Score:\n",
      "MicroF 1\tF 1(class1+class2+...+classn)\n",
      "(1)' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Stewart 等 - 2023 - Large Language Models for Failure Mode Classification An Investigation.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17822.46484375\n",
      "page_content='Conversely, in an ad-hoc retrieval scenario, the acquisition of query rewrite training data is often a challenge. To address this issue, researchers usually employ implicit feedback and reinforcement learning to train the query rewriter.\n",
      "3.3.3\tReinforcement Learning\n",
      "Query rewriters typically serve as intermediaries for retrieval systems, implying that they do not operate independently, and there is no specific loss attributed solely to the' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17822.46484375\n",
      "page_content='Conversely, in an ad-hoc retrieval scenario, the acquisition of query rewrite training data is often a challenge. To address this issue, researchers usually employ implicit feedback and reinforcement learning to train the query rewriter.\n",
      "3.3.3\tReinforcement Learning\n",
      "Query rewriters typically serve as intermediaries for retrieval systems, implying that they do not operate independently, and there is no specific loss attributed solely to the' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17826.3515625\n",
      "page_content='There has recently been a surge of interest in Large Language Models (LLMs), predominately as the result of the popularity of chatbot interfaces such as ChatGPT1. LLMs such as OpenAI’s GPT-3.52 have been trained on massive corpora and thus encapsulate knowledge from a wide variety of domains. It has also been shown that LLMs require little to no fine-tuning, meaning they exhibit excellent performance with barely any annotated training data [Brown et al., 2020]. Rather than focusing on developing manually-annotated datasets to train models (like with more “traditional” text classification models such as Flair [Akbik et al., 2018]), users of LLMs typically employ prompt engineering in order to craft their input prompt to elicit a particular response from the model. As a result of their excellent performance on a wide range of natural language processing tasks, LLMs have already been applied to a variety of domains. Examples include medicine [Singhal et al., 2022, Thirunavukarasu et al.,' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Stewart 等 - 2023 - Large Language Models for Failure Mode Classification An Investigation.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17826.3515625\n",
      "page_content='There has recently been a surge of interest in Large Language Models (LLMs), predominately as the result of the popularity of chatbot interfaces such as ChatGPT1. LLMs such as OpenAI’s GPT-3.52 have been trained on massive corpora and thus encapsulate knowledge from a wide variety of domains. It has also been shown that LLMs require little to no fine-tuning, meaning they exhibit excellent performance with barely any annotated training data [Brown et al., 2020]. Rather than focusing on developing manually-annotated datasets to train models (like with more “traditional” text classification models such as Flair [Akbik et al., 2018]), users of LLMs typically employ prompt engineering in order to craft their input prompt to elicit a particular response from the model. As a result of their excellent performance on a wide range of natural language processing tasks, LLMs have already been applied to a variety of domains. Examples include medicine [Singhal et al., 2022, Thirunavukarasu et al.,' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Stewart 等 - 2023 - Large Language Models for Failure Mode Classification An Investigation.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17837.005859375\n",
      "page_content='11.7\tHandle Limited Context Length\n",
      "One of the major drawbacks of GLLMs is their limited context length [52], [505], [506]. The maximum context length of GLLMs lies in the range of 2049 tokens to 32,768 tokens7. This limited context length poses a challenge and becomes a bottleneck for GLLMs to handle long documents or maintain long conservations in which the number of tokens falls beyond the maximum context length. Recently, Li [505] proposed selective context, a novel approach to effectively utilize the limited context length by filtering out the less useful content in the input text. The authors demonstrated the effectiveness of the proposed approach using the ChatGPT model for question-answering and text summarization tasks across datasets having lengthy input instances. Future research in this direction will help in the evolution of more efficient approaches which will effectively utilize the limited context length and eliminate the bottlenecks for' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17837.005859375\n",
      "page_content='11.7\tHandle Limited Context Length\n",
      "One of the major drawbacks of GLLMs is their limited context length [52], [505], [506]. The maximum context length of GLLMs lies in the range of 2049 tokens to 32,768 tokens7. This limited context length poses a challenge and becomes a bottleneck for GLLMs to handle long documents or maintain long conservations in which the number of tokens falls beyond the maximum context length. Recently, Li [505] proposed selective context, a novel approach to effectively utilize the limited context length by filtering out the less useful content in the input text. The authors demonstrated the effectiveness of the proposed approach using the ChatGPT model for question-answering and text summarization tasks across datasets having lengthy input instances. Future research in this direction will help in the evolution of more efficient approaches which will effectively utilize the limited context length and eliminate the bottlenecks for' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17845.17578125\n",
      "page_content='3. The term “document” will henceforth refer to any text-based content subject to retrieve, including both long articles and short passages.\n",
      "Traditional IR Components\n",
      "Search Context\n",
      "Candidate\n",
      "Documents\n",
      "Selected\n",
      "Documents\n",
      "Query1\n",
      "Response1\n",
      "Query2\n",
      "Response2\n",
      "(1)\n",
      "Rewriter\n",
      "___^____\n",
      "Reranker\n",
      "New Queries\n",
      "Retriever\n",
      "Large Language Models\n",
      "ChatGPT\tLLaMA Flan-T5 GLM BLOOM\n",
      "___*___\n",
      "Reader\n",
      "Q Queryn\n",
      "(2)\n",
      "Search Agent\n",
      "Response\n",
      "Fig. 1. Overview of existing studies that apply LLMs into IR. (1) LLMs can be used to enhance traditional IR components, such as query rewriter, retriever, reranker, and reader. (2) LLMs can also be used as search agents to perform multiple IR tasks.\n",
      "ponent is an integral part of new IR systems such as New Bing,4 improving users’ browsing experience and saving valuable time.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17845.17578125\n",
      "page_content='3. The term “document” will henceforth refer to any text-based content subject to retrieve, including both long articles and short passages.\n",
      "Traditional IR Components\n",
      "Search Context\n",
      "Candidate\n",
      "Documents\n",
      "Selected\n",
      "Documents\n",
      "Query1\n",
      "Response1\n",
      "Query2\n",
      "Response2\n",
      "(1)\n",
      "Rewriter\n",
      "___^____\n",
      "Reranker\n",
      "New Queries\n",
      "Retriever\n",
      "Large Language Models\n",
      "ChatGPT\tLLaMA Flan-T5 GLM BLOOM\n",
      "___*___\n",
      "Reader\n",
      "Q Queryn\n",
      "(2)\n",
      "Search Agent\n",
      "Response\n",
      "Fig. 1. Overview of existing studies that apply LLMs into IR. (1) LLMs can be used to enhance traditional IR components, such as query rewriter, retriever, reranker, and reader. (2) LLMs can also be used as search agents to perform multiple IR tasks.\n",
      "ponent is an integral part of new IR systems such as New Bing,4 improving users’ browsing experience and saving valuable time.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17846.04296875\n",
      "page_content='Acknowledgements\n",
      "This work was sponsored by the Australian Research Council under the Linkage Projects Grant LP210100129, and by the program of China Scholarships Council (No. 202308200014).\n",
      "References\n",
      "[1]\tC. An, S. Gong, M. Zhong, X. Zhao, M. Li, J. Zhang, L. Kong, and X. Qiu. L-eval: Instituting standardized evaluation for long context language models, 2023.\n",
      "[2]\tS. Borgeaud, A. Mensch, J. Hoffmann, T. Cai, E. Rutherford, K. Millican, G. B. Van Den Driessche, J.-B. Lespiau, B. Damoc, A. Clark, et al. Improving language models by retrieving from trillions of tokens. In International conference on machine learning, pages 2206–2240. PMLR, 2022.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17846.04296875\n",
      "page_content='Acknowledgements\n",
      "This work was sponsored by the Australian Research Council under the Linkage Projects Grant LP210100129, and by the program of China Scholarships Council (No. 202308200014).\n",
      "References\n",
      "[1]\tC. An, S. Gong, M. Zhong, X. Zhao, M. Li, J. Zhang, L. Kong, and X. Qiu. L-eval: Instituting standardized evaluation for long context language models, 2023.\n",
      "[2]\tS. Borgeaud, A. Mensch, J. Hoffmann, T. Cai, E. Rutherford, K. Millican, G. B. Van Den Driessche, J.-B. Lespiau, B. Damoc, A. Clark, et al. Improving language models by retrieving from trillions of tokens. In International conference on machine learning, pages 2206–2240. PMLR, 2022.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17862.70703125\n",
      "page_content='provided by upstream IR systems are sometimes too long to directly feed as input for LLMs, some compression modules are proposed to extractively or abstractively compress the retrieved contexts for LLMs to understand and generate answers for queries. We will present these reader and compressor modules in the following parts and briefly introduce the existing analysis work on retrieval-augmented generation (RAG) strategy and their applications.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17862.70703125\n",
      "page_content='provided by upstream IR systems are sometimes too long to directly feed as input for LLMs, some compression modules are proposed to extractively or abstractively compress the retrieved contexts for LLMs to understand and generate answers for queries. We will present these reader and compressor modules in the following parts and briefly introduce the existing analysis work on retrieval-augmented generation (RAG) strategy and their applications.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17889.494140625\n",
      "page_content='3\tPreliminary\n",
      "Document Retrieval: the RM Part Zero-shot document retrieval is a crucial component of search systems. Given the user query q and the document set D = {d1, ...,dn} where n is the number of document candidates, the goal of a retrieval model (RM) is to retrieve documents that are relevant to satisfy the user’s real search intent of the current query q. To accomplish such document retrieval, prior works can be categorized into two groups: sparse retrieval and dense retrieval. Both lines of research elaborate on devising the similarity function $(q, d) for each query-document pair.\n",
      "The sparse retrieval, e.g., TF-IDF and BM25, depends on lexicon overlap between query q and document d. This line of RMs (Zhou et al., 2022; Thakur et al., 2021) ranks documents D based on their relevance to a given query q by integrating term frequency and inverse document frequency. Another works (Qu et al., 2021; Ni et al., 2022; Karpukhin et al., 2020) focus on dense retrieval that' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Feng 等 - 2023 - Synergistic Interplay between Search and Large Language Models for Information Retrieval.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17889.494140625\n",
      "page_content='3\tPreliminary\n",
      "Document Retrieval: the RM Part Zero-shot document retrieval is a crucial component of search systems. Given the user query q and the document set D = {d1, ...,dn} where n is the number of document candidates, the goal of a retrieval model (RM) is to retrieve documents that are relevant to satisfy the user’s real search intent of the current query q. To accomplish such document retrieval, prior works can be categorized into two groups: sparse retrieval and dense retrieval. Both lines of research elaborate on devising the similarity function $(q, d) for each query-document pair.\n",
      "The sparse retrieval, e.g., TF-IDF and BM25, depends on lexicon overlap between query q and document d. This line of RMs (Zhou et al., 2022; Thakur et al., 2021) ranks documents D based on their relevance to a given query q by integrating term frequency and inverse document frequency. Another works (Qu et al., 2021; Ni et al., 2022; Karpukhin et al., 2020) focus on dense retrieval that' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Feng 等 - 2023 - Synergistic Interplay between Search and Large Language Models for Information Retrieval.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17900.38671875\n",
      "page_content='[197], [199]–[201], healthcare [197], [198], social media [198]–[201], dialogue [199]–[201] and e-commerce [199], [200]. Most of the research works focused on sentencelevel machine translation [132], [196]–[200], [202], [204]– [208], except a few research works focused on paragraphlevel machine translation [203], [204] and document-level machine translation [199], [201]. As advanced prompting methods allow GLLMs to perform well, some of the research works investigated the effectiveness of advanced prompting strategies like pivot [198], chain-of-thought [207] and multi-aspect prompting and selection [206]. Table 4 presents a summary of research works exploring GLLMs for machine translation across various domains and languages.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17900.38671875\n",
      "page_content='[197], [199]–[201], healthcare [197], [198], social media [198]–[201], dialogue [199]–[201] and e-commerce [199], [200]. Most of the research works focused on sentencelevel machine translation [132], [196]–[200], [202], [204]– [208], except a few research works focused on paragraphlevel machine translation [203], [204] and document-level machine translation [199], [201]. As advanced prompting methods allow GLLMs to perform well, some of the research works investigated the effectiveness of advanced prompting strategies like pivot [198], chain-of-thought [207] and multi-aspect prompting and selection [206]. Table 4 presents a summary of research works exploring GLLMs for machine translation across various domains and languages.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17920.3203125\n",
      "page_content='The Figure.7 depicts the Use Case of Conversational A\n",
      "Figure 7. Use Case of Conversational AI [9]\n",
      "4.\tResearch Opportunity and Research Challenges\n",
      "Research opportunity focuses on advancing the capabilities of natural language generation to interpret insights generated through augmented analytics. By developing a sophisticated NLG model that overcomes limitations and enhances user experience, this research aims to bridge the gap between data analysis complexity and user comprehension, leading to improved decision-making and organizational success.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kania和Mehta - 2023 - A Literature Review on Augmented Analytics and Natural Language Generation A Review of State of Art.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17920.3203125\n",
      "page_content='The Figure.7 depicts the Use Case of Conversational A\n",
      "Figure 7. Use Case of Conversational AI [9]\n",
      "4.\tResearch Opportunity and Research Challenges\n",
      "Research opportunity focuses on advancing the capabilities of natural language generation to interpret insights generated through augmented analytics. By developing a sophisticated NLG model that overcomes limitations and enhances user experience, this research aims to bridge the gap between data analysis complexity and user comprehension, leading to improved decision-making and organizational success.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kania和Mehta - 2023 - A Literature Review on Augmented Analytics and Natural Language Generation A Review of State of Art.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17920.8359375\n",
      "page_content='[440]\tChatGPT generated text\tEvaluate multiple online tools\tYes\t-\tAcademic\tEnglish, Spanish\n",
      "[443]\tGPT-3 generated text\tEvaluate human evaluators\tNo\t-\tStories, News, Recipies\tEnglish\n",
      "[442]\tChatGPT\tand GPT-4 generated text\tClassifier based on models like BERT and RoBERTa\tYes\tNo\tLaw, Medical, Dialogue, General\tEnglish\n",
      "[438]\tGPT-3.5, ChatGPT and GPT-4 generated text\tTraining free divergent N-gram Analysis\tYes\tYes\tHealthcare, Social Media, Scientific Literature\tEnglish, German\n",
      "[445]\tChatGPT generated text\tEvaluate the robustness of existing detectors\tNo\t-\tGeneral\tEnglish\n",
      "[446]\tChatGPT generated text\tEvaluate existing plagiarism tools\tNo\t-\tGeneral\tEnglish\n",
      "[447]\tChatGPT generated text\tPropose benchmark and evaluate existing detectors\tYes\t-\tGeneral\tEnglish\n",
      "[432]\tChatGPT generated text\tPropose novel approach based on Distil-BERT and SHAP to detect and explain\tYes\tNo\tSocial Media\tEnglish' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17920.8359375\n",
      "page_content='[440]\tChatGPT generated text\tEvaluate multiple online tools\tYes\t-\tAcademic\tEnglish, Spanish\n",
      "[443]\tGPT-3 generated text\tEvaluate human evaluators\tNo\t-\tStories, News, Recipies\tEnglish\n",
      "[442]\tChatGPT\tand GPT-4 generated text\tClassifier based on models like BERT and RoBERTa\tYes\tNo\tLaw, Medical, Dialogue, General\tEnglish\n",
      "[438]\tGPT-3.5, ChatGPT and GPT-4 generated text\tTraining free divergent N-gram Analysis\tYes\tYes\tHealthcare, Social Media, Scientific Literature\tEnglish, German\n",
      "[445]\tChatGPT generated text\tEvaluate the robustness of existing detectors\tNo\t-\tGeneral\tEnglish\n",
      "[446]\tChatGPT generated text\tEvaluate existing plagiarism tools\tNo\t-\tGeneral\tEnglish\n",
      "[447]\tChatGPT generated text\tPropose benchmark and evaluate existing detectors\tYes\t-\tGeneral\tEnglish\n",
      "[432]\tChatGPT generated text\tPropose novel approach based on Distil-BERT and SHAP to detect and explain\tYes\tNo\tSocial Media\tEnglish' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17965.28125\n",
      "page_content='Gu et al. [196] proposed a novel approach based on ChatGPT to enhance the quality of translation from Japanese to Chinese by effectively handling attribute clauses using a pre-edit scheme. The proposed approach, which integrates the pre-edit scheme with a novel two-step prompting strategy, enhances the translation quality by more than 35%. Peng et al. [197] explored the impact of temperature, task and domain information on the translation performance of ChatGPT. The authors showed that (i) ChatGPT performance degrades with an increase in temperature, and hence it is recommended to use a lower temperature (recommended is 0). and (ii) including task and domain information in the prompt' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17965.28125\n",
      "page_content='Gu et al. [196] proposed a novel approach based on ChatGPT to enhance the quality of translation from Japanese to Chinese by effectively handling attribute clauses using a pre-edit scheme. The proposed approach, which integrates the pre-edit scheme with a novel two-step prompting strategy, enhances the translation quality by more than 35%. Peng et al. [197] explored the impact of temperature, task and domain information on the translation performance of ChatGPT. The authors showed that (i) ChatGPT performance degrades with an increase in temperature, and hence it is recommended to use a lower temperature (recommended is 0). and (ii) including task and domain information in the prompt' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17968.3515625\n",
      "page_content='[3]\tV. Karpukhin, B. Oguz, S. Min, P. S. H. Lewis, L. Wu, S. Edunov, D. Chen, and W. Yih, “Dense passage\n",
      "[4]\n",
      "[5]\n",
      "[6]\n",
      "[7]\n",
      "[8]\n",
      "[9]\n",
      "[10]\n",
      "[11]\n",
      "[12]\n",
      "retrieval for open-domain question answering,” in Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, EMNLP 2020, Online, November 16-20, 2020, B. Webber, T. Cohn, Y. He, and Y. Liu, Eds. Association for Computational Linguistics, 2020, pp. 6769–6781.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17968.3515625\n",
      "page_content='[3]\tV. Karpukhin, B. Oguz, S. Min, P. S. H. Lewis, L. Wu, S. Edunov, D. Chen, and W. Yih, “Dense passage\n",
      "[4]\n",
      "[5]\n",
      "[6]\n",
      "[7]\n",
      "[8]\n",
      "[9]\n",
      "[10]\n",
      "[11]\n",
      "[12]\n",
      "retrieval for open-domain question answering,” in Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, EMNLP 2020, Online, November 16-20, 2020, B. Webber, T. Cohn, Y. He, and Y. Liu, Eds. Association for Computational Linguistics, 2020, pp. 6769–6781.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17970.359375\n",
      "page_content='[362]\tZ. Chen, W. Chen, C. Smiley, S. Shah, I. Borova, D. Langdon, R. Moussa, M. Beane, T.-H. Huang, B. R. Routledge et al., “Finqa: A dataset of numerical reasoning over financial data,” in Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, 2021, pp. 3697–3711.\n",
      "[363]\tV. D. Lai, N. T. Ngo, A. P. B. Veyseh, H. Man, F. Dernoncourt, T. Bui, and T. H. Nguyen, “Chatgpt beyond english: Towards a comprehensive evaluation of large language models in multilingual learning,” arXiv preprint arXiv:2304.05613, 2023.\n",
      "[364]\tT. Fang, S. Yang, K. Lan, D. F. Wong, J. Hu, L. S. Chao, and Y. Zhang, “Is chatgpt a highly fluent grammatical error correction system? a comprehensive evaluation,” arXiv preprint arXiv:2304.01746, 2023.\n",
      "[365]\tJ. Armengol-Estape´, O. de Gibert Bonet, and M. Melero, “On the multilingual capabilities of very large-scale english language models,” in Proceedings of the Thirteenth Language Resources and Evaluation Conference, 2022, pp. 3056–3068.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17970.359375\n",
      "page_content='[362]\tZ. Chen, W. Chen, C. Smiley, S. Shah, I. Borova, D. Langdon, R. Moussa, M. Beane, T.-H. Huang, B. R. Routledge et al., “Finqa: A dataset of numerical reasoning over financial data,” in Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, 2021, pp. 3697–3711.\n",
      "[363]\tV. D. Lai, N. T. Ngo, A. P. B. Veyseh, H. Man, F. Dernoncourt, T. Bui, and T. H. Nguyen, “Chatgpt beyond english: Towards a comprehensive evaluation of large language models in multilingual learning,” arXiv preprint arXiv:2304.05613, 2023.\n",
      "[364]\tT. Fang, S. Yang, K. Lan, D. F. Wong, J. Hu, L. S. Chao, and Y. Zhang, “Is chatgpt a highly fluent grammatical error correction system? a comprehensive evaluation,” arXiv preprint arXiv:2304.01746, 2023.\n",
      "[365]\tJ. Armengol-Estape´, O. de Gibert Bonet, and M. Melero, “On the multilingual capabilities of very large-scale english language models,” in Proceedings of the Thirteenth Language Resources and Evaluation Conference, 2022, pp. 3056–3068.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17978.46484375\n",
      "page_content='•\tImproving the reference quality for LLMs. To support answer generation, existing approaches usually directly feed the retrieved documents to the LLMs as references. However, since a document usually covers many topics, some passages in it may be irrelevant to the user queries and can introduce noise during LLMs’ generation. Therefore, it is necessary to explore techniques for extracting relevant snippets from retrieved documents, enhancing the performance of retrieval-augmented generation.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17978.46484375\n",
      "page_content='•\tImproving the reference quality for LLMs. To support answer generation, existing approaches usually directly feed the retrieved documents to the LLMs as references. However, since a document usually covers many topics, some passages in it may be irrelevant to the user queries and can introduce noise during LLMs’ generation. Therefore, it is necessary to explore techniques for extracting relevant snippets from retrieved documents, enhancing the performance of retrieval-augmented generation.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17982.455078125\n",
      "page_content='[358]\tChatGPT, GPT-4\tRelation Extraction\tFS\tEnglish\t-\n",
      "[352]\tChatGPT\tSentiment Analysis\tZS\tChinese\t-\n",
      "[359]\tGPT-3.5, GPT-4\tText Classification\tZS, FS\tEnglish\t-\n",
      "TABLE 15. Summary of research works exploring GLLMs for various NLP tasks in the finance domain. Here ZS represents zero-shot, and FS represents few-shot. Here ’-’ represents there is no comparison between GLLMs and domain-specific pretrained language models in the paper.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17982.455078125\n",
      "page_content='[358]\tChatGPT, GPT-4\tRelation Extraction\tFS\tEnglish\t-\n",
      "[352]\tChatGPT\tSentiment Analysis\tZS\tChinese\t-\n",
      "[359]\tGPT-3.5, GPT-4\tText Classification\tZS, FS\tEnglish\t-\n",
      "TABLE 15. Summary of research works exploring GLLMs for various NLP tasks in the finance domain. Here ZS represents zero-shot, and FS represents few-shot. Here ’-’ represents there is no comparison between GLLMs and domain-specific pretrained language models in the paper.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17991.072265625\n",
      "page_content='to facilitate the LLM’s in-context learning for generating response. We create two ways to present the snippets: Sequential Order, with snippets for each query following one another, and Mix Order, with top snippets evenly sampled from different queries. We increase the number of snippets to see how retrieval performance changes in two different snippet arrangements. The evaluation metrics are Answer Recall, which is the ratio of answer items found in the external knowledge to the total number of answer items, and Snippet Precision, which is the ratio of snippets containing any answer item to the total number of snippets used. These metrics provide a quantitative measure of retrieval performance. The experimental results are illustrated in Figure 2.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17991.072265625\n",
      "page_content='to facilitate the LLM’s in-context learning for generating response. We create two ways to present the snippets: Sequential Order, with snippets for each query following one another, and Mix Order, with top snippets evenly sampled from different queries. We increase the number of snippets to see how retrieval performance changes in two different snippet arrangements. The evaluation metrics are Answer Recall, which is the ratio of answer items found in the external knowledge to the total number of answer items, and Snippet Precision, which is the ratio of snippets containing any answer item to the total number of snippets used. These metrics provide a quantitative measure of retrieval performance. The experimental results are illustrated in Figure 2.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17991.626953125\n",
      "page_content='Clarification: Represented by [17], this module generates clarification questions to ascertain user intent, thus refining vague questions to uncover the underlying inquiry intent. We have integrated the functionalities of the Rewriter and Clarification modules into a single unit, Query Rewriter+, employing a fine-tuned Gemma-2B model to perform both tasks generatively in one step, improving efficiency.\n",
      "Post-Retrieval Process: After information retrieval, presenting all data to a Large Language Model simultaneously may exceed the context window limit. The Re-Ranking module strategically relocates content based on relevance. Our preliminary study reveals that Large Language Models (LLMs) have evolved to handle extended contexts, accommodating all retrievable information until a bottleneck is reached. Consequently, we consider this post-retrieval process primarily as a de-noising task, rather than focusing on ranking.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17991.626953125\n",
      "page_content='Clarification: Represented by [17], this module generates clarification questions to ascertain user intent, thus refining vague questions to uncover the underlying inquiry intent. We have integrated the functionalities of the Rewriter and Clarification modules into a single unit, Query Rewriter+, employing a fine-tuned Gemma-2B model to perform both tasks generatively in one step, improving efficiency.\n",
      "Post-Retrieval Process: After information retrieval, presenting all data to a Large Language Model simultaneously may exceed the context window limit. The Re-Ranking module strategically relocates content based on relevance. Our preliminary study reveals that Large Language Models (LLMs) have evolved to handle extended contexts, accommodating all retrievable information until a bottleneck is reached. Consequently, we consider this post-retrieval process primarily as a de-noising task, rather than focusing on ranking.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17999.0546875\n",
      "page_content='[174]\t——, “Rankzephyr: Effective and robust zeroshot listwise reranking is a breeze!” CoRR, vol. abs/2312.02724, 2023.\n",
      "[175]\tW. Sun, Z. Chen, X. Ma, L. Yan, S. Wang, P. Ren, Z. Chen, D. Yin, and Z. Ren, “Instruction distillation makes large language models efficient zero-shot rankers,” arXiv preprint arXiv:2311.01555, 2023.\n",
      "[176]\tC. J. C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, and G. N. Hullender, “Learning to rank using gradient descent,” in ICML, ser. ACM International Conference Proceeding Series, vol. 119. ACM, 2005, pp. 89–96.\n",
      "[177]\tJ. A. Baktash and M. Dawodi, “Gpt-4: A review on advancements and opportunities in natural language processing,” arXiv preprint arXiv:2305.03195, 2023.\n",
      "[178]\tR. G. Reddy, J. Doo, Y. Xu, M. A. Sultan, D. Swain, A. Sil, and H. Ji, “FIRST: faster improved listwise reranking with single token decoding,” CoRR, vol. abs/2406.15657, 2024.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 17999.0546875\n",
      "page_content='[174]\t——, “Rankzephyr: Effective and robust zeroshot listwise reranking is a breeze!” CoRR, vol. abs/2312.02724, 2023.\n",
      "[175]\tW. Sun, Z. Chen, X. Ma, L. Yan, S. Wang, P. Ren, Z. Chen, D. Yin, and Z. Ren, “Instruction distillation makes large language models efficient zero-shot rankers,” arXiv preprint arXiv:2311.01555, 2023.\n",
      "[176]\tC. J. C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, and G. N. Hullender, “Learning to rank using gradient descent,” in ICML, ser. ACM International Conference Proceeding Series, vol. 119. ACM, 2005, pp. 89–96.\n",
      "[177]\tJ. A. Baktash and M. Dawodi, “Gpt-4: A review on advancements and opportunities in natural language processing,” arXiv preprint arXiv:2305.03195, 2023.\n",
      "[178]\tR. G. Reddy, J. Doo, Y. Xu, M. A. Sultan, D. Swain, A. Sil, and H. Ji, “FIRST: faster improved listwise reranking with single token decoding,” CoRR, vol. abs/2406.15657, 2024.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18018.484375\n",
      "page_content='Vanilla (Brown et al., 2020)\t93.90\t93.50\t94.36\t92.40\t89.59\t94.05\n",
      "CoT (Kojima et al., 2022)\t94.21\t94.28\t95.07\t92.98\t90.27\t93.69\n",
      "CARP\t95.69\t95.25\t97.83\t96.27\t90.74\t95.16\n",
      "FT kNN-Sampler\t\t\t\t\t\t\n",
      "Vanilla (Brown et al., 2020)\t94.01\t94.14\t95.57\t95.79\t90.90\t94.08\n",
      "CoT (Kojima et al., 2022)\t95.48\t94.89\t95.59\t95.89\t90.17\t94.40\n",
      "CARP\t96.80\t95.99\t98.29\t96.82\t91.90\t95.97\n",
      "CARP (WP Vote)\t97.39\t96.40\t98.78\t96.95\t92.39\t96.38\n",
      "Table 2: Accuracy performances of different settings on benchmarks. We report mean and standard deviation results over 5 runs. The GPT-3 denotes text-davinci-003. In few-shot experiments, we sample 16 annotated examples (k=16) for every test instance. * indicates previous state-of-the-art results. \"MJ Vote\" is short for majority vote. \"WP Vote\" denotes weighted probability vote.\n",
      "new training set.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18018.484375\n",
      "page_content='Vanilla (Brown et al., 2020)\t93.90\t93.50\t94.36\t92.40\t89.59\t94.05\n",
      "CoT (Kojima et al., 2022)\t94.21\t94.28\t95.07\t92.98\t90.27\t93.69\n",
      "CARP\t95.69\t95.25\t97.83\t96.27\t90.74\t95.16\n",
      "FT kNN-Sampler\t\t\t\t\t\t\n",
      "Vanilla (Brown et al., 2020)\t94.01\t94.14\t95.57\t95.79\t90.90\t94.08\n",
      "CoT (Kojima et al., 2022)\t95.48\t94.89\t95.59\t95.89\t90.17\t94.40\n",
      "CARP\t96.80\t95.99\t98.29\t96.82\t91.90\t95.97\n",
      "CARP (WP Vote)\t97.39\t96.40\t98.78\t96.95\t92.39\t96.38\n",
      "Table 2: Accuracy performances of different settings on benchmarks. We report mean and standard deviation results over 5 runs. The GPT-3 denotes text-davinci-003. In few-shot experiments, we sample 16 annotated examples (k=16) for every test instance. * indicates previous state-of-the-art results. \"MJ Vote\" is short for majority vote. \"WP Vote\" denotes weighted probability vote.\n",
      "new training set.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18019.73046875\n",
      "page_content='﻿Enhancing Retrieval and Managing Retrieval: A Four-Module Synergy for Improved Quality and Efficiency in RAG Systems\n",
      "Yunxiao Shia, Xing Zia, Zijing Shia, Haimin Zhanga, Qiang Wua and Min Xua,* aUniversity of Technology Sydney, Broadway, Sydney, 2007, NSW, Australia.\n",
      "arXiv:2407.10670v1 [cs.CL] 15 Jul 2024' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18019.73046875\n",
      "page_content='﻿Enhancing Retrieval and Managing Retrieval: A Four-Module Synergy for Improved Quality and Efficiency in RAG Systems\n",
      "Yunxiao Shia, Xing Zia, Zijing Shia, Haimin Zhanga, Qiang Wua and Min Xua,* aUniversity of Technology Sydney, Broadway, Sydney, 2007, NSW, Australia.\n",
      "arXiv:2407.10670v1 [cs.CL] 15 Jul 2024' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18030.76953125\n",
      "page_content='[43]\tP. Liu, W. Yuan, J. Fu, Z. Jiang, H. Hayashi, and G. Neubig, “Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing,” ACM Comput. Surv., vol. 55, no. 9, pp. 195:1–195:35, 2023.\n",
      "[44]\tX. Qiu, T. Sun, Y. Xu, Y. Shao, N. Dai, and X. Huang, [56] “Pre-trained models for natural language processing: A survey,” CoRR, vol. abs/2003.08271, 2020.\n",
      "[45]\tY. Cao, S. Li, Y. Liu, Z. Yan, Y. Dai, P. S. Yu, and L. Sun, “A comprehensive survey of ai-generated content (AIGC): A history of generative AI from GAN to chatgpt,” CoRR, vol. abs/2303.04226, 2023.\n",
      "[46]\tJ. Li, T. Tang, W. X. Zhao, and J. Wen, “Pretrained language model for text generation: A survey,” in Proceedings of the Thirtieth International Joint Conference [57] on Artificial Intelligence, IJCAI 2021, Virtual Event / Montreal, Canada, 19-27 August 2021, Z. Zhou, Ed. ijcai.org, 2021, pp. 4492–4499.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18030.76953125\n",
      "page_content='[43]\tP. Liu, W. Yuan, J. Fu, Z. Jiang, H. Hayashi, and G. Neubig, “Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing,” ACM Comput. Surv., vol. 55, no. 9, pp. 195:1–195:35, 2023.\n",
      "[44]\tX. Qiu, T. Sun, Y. Xu, Y. Shao, N. Dai, and X. Huang, [56] “Pre-trained models for natural language processing: A survey,” CoRR, vol. abs/2003.08271, 2020.\n",
      "[45]\tY. Cao, S. Li, Y. Liu, Z. Yan, Y. Dai, P. S. Yu, and L. Sun, “A comprehensive survey of ai-generated content (AIGC): A history of generative AI from GAN to chatgpt,” CoRR, vol. abs/2303.04226, 2023.\n",
      "[46]\tJ. Li, T. Tang, W. X. Zhao, and J. Wen, “Pretrained language model for text generation: A survey,” in Proceedings of the Thirtieth International Joint Conference [57] on Artificial Intelligence, IJCAI 2021, Virtual Event / Montreal, Canada, 19-27 August 2021, Z. Zhou, Ed. ijcai.org, 2021, pp. 4492–4499.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18045.72265625\n",
      "page_content='intent. Section 3 has provided a comprehensive overview of these studies, so this section refrains from further elaboration. In addition to query rewriter, an intriguing avenue for exploration involves using LLMs to enhance the effectiveness of retrieval by refining lengthy documents. This intriguing area remains open for further investigation and advancement.\n",
      "4.1.2\tTraining Data Augmentation\n",
      "Due to the expensive economic and time costs of human-annotated labels, a common problem in training neural retrieval models is the lack of training data. Fortunately, the excellent capability of LLMs in text generation offers a potential solution. A key research focus lies in devising strategies to leverage LLMs’ capabilities to generate pseudorelevant signals and augment the training dataset for the retrieval task.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18045.72265625\n",
      "page_content='intent. Section 3 has provided a comprehensive overview of these studies, so this section refrains from further elaboration. In addition to query rewriter, an intriguing avenue for exploration involves using LLMs to enhance the effectiveness of retrieval by refining lengthy documents. This intriguing area remains open for further investigation and advancement.\n",
      "4.1.2\tTraining Data Augmentation\n",
      "Due to the expensive economic and time costs of human-annotated labels, a common problem in training neural retrieval models is the lack of training data. Fortunately, the excellent capability of LLMs in text generation offers a potential solution. A key research focus lies in devising strategies to leverage LLMs’ capabilities to generate pseudorelevant signals and augment the training dataset for the retrieval task.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18048.228515625\n",
      "page_content='3.3\tApproaches\n",
      "The utilization of LLMs in query rewriting can be categorized into three primary methodologies: prompting, supervised fine-tuning, and reinforcement learning. The prompting approaches employ specific prompts to guide the LLM’s output, providing flexibility and interpretability. The supervised fine-tuning techniques adapt pre-trained LLMs to the specific task of query rewriting. However, the scarcity of training data for query rewriting often poses a challenge. To address this issue, reinforcement learning methods utilize feedback from downstream applications, thereby improving the performance of query rewriters. In the following section, we will introduce these three methods in detail.\n",
      "3.3.1\tPrompting' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18048.228515625\n",
      "page_content='3.3\tApproaches\n",
      "The utilization of LLMs in query rewriting can be categorized into three primary methodologies: prompting, supervised fine-tuning, and reinforcement learning. The prompting approaches employ specific prompts to guide the LLM’s output, providing flexibility and interpretability. The supervised fine-tuning techniques adapt pre-trained LLMs to the specific task of query rewriting. However, the scarcity of training data for query rewriting often poses a challenge. To address this issue, reinforcement learning methods utilize feedback from downstream applications, thereby improving the performance of query rewriters. In the following section, we will introduce these three methods in detail.\n",
      "3.3.1\tPrompting' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18050.18359375\n",
      "page_content='This approach simultaneously considers two tasks: generating classification tokens for a given query-document pair and generating the corresponding query conditioned on the provided document. DuoT5 [143] considers a triple (q, di, dj) as the input of the T5 model and is fine-tuned to generate token “true” if document di is more relevant to query qi than document dj ,' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18050.18359375\n",
      "page_content='This approach simultaneously considers two tasks: generating classification tokens for a given query-document pair and generating the corresponding query conditioned on the provided document. DuoT5 [143] considers a triple (q, di, dj) as the input of the T5 model and is fine-tuned to generate token “true” if document di is more relevant to query qi than document dj ,' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18063.6484375\n",
      "page_content='clinical dialogue summarization as a part of MEDIQA-Chat 2023 [350] shared task. Here, the authors used Instructor [351] to select the most similar examples for few-shot ICL. Experiment results based on automatic metrics like BERTScore and ROUGE demonstrated that GPT-4 not only outperforms the LED model but also achieves first rank in the shared task. For medical text de-identification, Liu et al. [318] proposed a novel approach called “DeID-GPT”, a two-step approach based on GLLMs. In the first step, HIPAA identifiers are included in the prompt. In the second step, GLLM receives the prompt and the medical record based on which the model generates the de-identified medical record having the personal information masked. The authors observed that GPT-4 outperforms not only ChatGPT but also fine-tuned models based on BERT, RoBERTa and ClinicalBERT.\n",
      "5.2\tLegal Domain' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18063.6484375\n",
      "page_content='clinical dialogue summarization as a part of MEDIQA-Chat 2023 [350] shared task. Here, the authors used Instructor [351] to select the most similar examples for few-shot ICL. Experiment results based on automatic metrics like BERTScore and ROUGE demonstrated that GPT-4 not only outperforms the LED model but also achieves first rank in the shared task. For medical text de-identification, Liu et al. [318] proposed a novel approach called “DeID-GPT”, a two-step approach based on GLLMs. In the first step, HIPAA identifiers are included in the prompt. In the second step, GLLM receives the prompt and the medical record based on which the model generates the de-identified medical record having the personal information masked. The authors observed that GPT-4 outperforms not only ChatGPT but also fine-tuned models based on BERT, RoBERTa and ClinicalBERT.\n",
      "5.2\tLegal Domain' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18067.818359375\n",
      "page_content='•\tImproving the answer reliability of LLMs. Incorporating the retrieved references has significantly alleviated the “hallucination” problem of LLMs. However, it remains uncertain whether the LLMs refer to these supported materials during answering queries. Some studies [231] have revealed that LLMs can still provide unfaithful answers even with additional references. Therefore, the reliability of the conclusive answers might be lower compared to the ranking results provided by traditional IR systems. It is essential to investigate the influence of these references on the generation process, thereby improving the credibility of reader-based novel IR systems.\n",
      "8.5\tSearch Agent' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18067.818359375\n",
      "page_content='•\tImproving the answer reliability of LLMs. Incorporating the retrieved references has significantly alleviated the “hallucination” problem of LLMs. However, it remains uncertain whether the LLMs refer to these supported materials during answering queries. Some studies [231] have revealed that LLMs can still provide unfaithful answers even with additional references. Therefore, the reliability of the conclusive answers might be lower compared to the ranking results provided by traditional IR systems. It is essential to investigate the influence of these references on the generation process, thereby improving the credibility of reader-based novel IR systems.\n",
      "8.5\tSearch Agent' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18068.634765625\n",
      "page_content='strategy lets the model take the advantage of both the LLMs’ generalization abilities and all taskspecific evidence provided by the training dataset.\n",
      "4\tClues Collecting and Reasoning\n",
      "To enhance the models’ reasoning ability in addressing linguistic phenomenon tailored to text classification, we propose a progressive reasoning strategy that involves clue collection, reasoning and decision making. This process also mimics how human decisions: where we first collect evidence from the input, separating chaff from wheat; next we piece together local evidence to form a global picture, which leads to final decision making. Next we first given an overview of the the clue collecting and reasoning process, and then describe implementation details.\n",
      "4.1\tOverview' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18068.634765625\n",
      "page_content='strategy lets the model take the advantage of both the LLMs’ generalization abilities and all taskspecific evidence provided by the training dataset.\n",
      "4\tClues Collecting and Reasoning\n",
      "To enhance the models’ reasoning ability in addressing linguistic phenomenon tailored to text classification, we propose a progressive reasoning strategy that involves clue collection, reasoning and decision making. This process also mimics how human decisions: where we first collect evidence from the input, separating chaff from wheat; next we piece together local evidence to form a global picture, which leads to final decision making. Next we first given an overview of the the clue collecting and reasoning process, and then describe implementation details.\n",
      "4.1\tOverview' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18083.21484375\n",
      "page_content='11.10\tEnhance the Performance of GLLMs for NonEnglish Languages\n",
      "The performance of GLLMs is not impressive in the case of non-English languages, especially in the case of languages with non-Latin scripts [131], [132], [363],\n",
      "[366]\t. This is because GLLMs are mostly pretrained on English text. For example, more than 90% of text in the pretraining corpus of the GPT-3 model is from the English language [4], [366]. Some of the possible options to enhance the performance of GLLMs for non-English languages are the use of English prompts [131], [363] and optimized tokenization [365]. There is a great need for better approaches to greatly enhance the performance of GLLMs for non-English languages, which increase their adoption across the globe and benefit users from nonEnglish communities.\n",
      "12\tConclusion' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18083.21484375\n",
      "page_content='11.10\tEnhance the Performance of GLLMs for NonEnglish Languages\n",
      "The performance of GLLMs is not impressive in the case of non-English languages, especially in the case of languages with non-Latin scripts [131], [132], [363],\n",
      "[366]\t. This is because GLLMs are mostly pretrained on English text. For example, more than 90% of text in the pretraining corpus of the GPT-3 model is from the English language [4], [366]. Some of the possible options to enhance the performance of GLLMs for non-English languages are the use of English prompts [131], [363] and optimized tokenization [365]. There is a great need for better approaches to greatly enhance the performance of GLLMs for non-English languages, which increase their adoption across the globe and benefit users from nonEnglish communities.\n",
      "12\tConclusion' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18083.314453125\n",
      "page_content='Along with transfer learning, the other learning paradigms that evolved to address large labelled data requirements are semi-supervised learning [63] and multitask learning [64]. Semi-supervised learning is a learning paradigm in artificial intelligence that uses labelled and unlabelled data to train models [63]. As semi-supervised learning uses labelled and unlabelled data, it lies between unsupervised and supervised learning paradigms. As semi-supervised learning uses only a small amount of labelled data, it reduces the amount of labelled data required, like transfer learning. However, unlike transfer learning, where the distribution of source and target tasks can be different, in semi-supervised, the distribution of labelled and unlabelled data should be the same [58]. Multi-task learning is a learning paradigm which focuses on enhancing the performance of a group of tasks by leveraging the interconnections between the tasks and learning them simultaneously [63]. Unlike multi-task' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18083.314453125\n",
      "page_content='Along with transfer learning, the other learning paradigms that evolved to address large labelled data requirements are semi-supervised learning [63] and multitask learning [64]. Semi-supervised learning is a learning paradigm in artificial intelligence that uses labelled and unlabelled data to train models [63]. As semi-supervised learning uses labelled and unlabelled data, it lies between unsupervised and supervised learning paradigms. As semi-supervised learning uses only a small amount of labelled data, it reduces the amount of labelled data required, like transfer learning. However, unlike transfer learning, where the distribution of source and target tasks can be different, in semi-supervised, the distribution of labelled and unlabelled data should be the same [58]. Multi-task learning is a learning paradigm which focuses on enhancing the performance of a group of tasks by leveraging the interconnections between the tasks and learning them simultaneously [63]. Unlike multi-task' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18086.70703125\n",
      "page_content='emotion-enhanced CoT outperforms other prompting strategies. Overall, ChatGPT outperforms traditional deep learning models like CNN and RNN but still lags behind task-specific fine-tuned models. Wu et al. [137] explored models like GPT-4 and ChatGPT for radiology natural language inference task. The authors reported' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18086.70703125\n",
      "page_content='emotion-enhanced CoT outperforms other prompting strategies. Overall, ChatGPT outperforms traditional deep learning models like CNN and RNN but still lags behind task-specific fine-tuned models. Wu et al. [137] explored models like GPT-4 and ChatGPT for radiology natural language inference task. The authors reported' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18094.2734375\n",
      "page_content='CorpusLM [141]\tT5-base & Llama2-7B-Chat\tGenerative\tFine-tuning\n",
      "4.3 Limitations\n",
      "Though some efforts have been made for LLM-augmented retrieval, there are still many areas that require more detailed investigation. For example, a critical requirement for retrievers is fast response, while the main problem of existing LLMs is the huge model parameters and overlong inference time. Addressing this limitation of LLMs to ensure the response time of retrievers is a critical task. Moreover, even when employing LLMs to augment datasets (a context with lower inference time demands), the potential mismatch between LLM-generated texts and real user queries could impact retrieval effectiveness. Furthermore, as LLMs usually lack domain-specific knowledge, they need to be finetuned on task-specific datasets before applying them to downstream tasks. Therefore, developing efficient strategies to fine-tune these LLMs with numerous parameters emerges as a key concern.\n",
      "5 Reranker' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18094.2734375\n",
      "page_content='CorpusLM [141]\tT5-base & Llama2-7B-Chat\tGenerative\tFine-tuning\n",
      "4.3 Limitations\n",
      "Though some efforts have been made for LLM-augmented retrieval, there are still many areas that require more detailed investigation. For example, a critical requirement for retrievers is fast response, while the main problem of existing LLMs is the huge model parameters and overlong inference time. Addressing this limitation of LLMs to ensure the response time of retrievers is a critical task. Moreover, even when employing LLMs to augment datasets (a context with lower inference time demands), the potential mismatch between LLM-generated texts and real user queries could impact retrieval effectiveness. Furthermore, as LLMs usually lack domain-specific knowledge, they need to be finetuned on task-specific datasets before applying them to downstream tasks. Therefore, developing efficient strategies to fine-tune these LLMs with numerous parameters emerges as a key concern.\n",
      "5 Reranker' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18109.3046875\n",
      "page_content='2\tBackground\n",
      "2.1\tInformation Retrieval\n",
      "Information retrieval (IR), as an essential branch of computer science, aims to efficiently retrieve information relevant to user queries from a large repository. Generally, users interact with an IR system by submitting their queries in textual form. Subsequently, IR systems undertake the task of matching and ranking these user-supplied queries against an indexed database, thereby facilitating the retrieval of the most pertinent results.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18109.3046875\n",
      "page_content='2\tBackground\n",
      "2.1\tInformation Retrieval\n",
      "Information retrieval (IR), as an essential branch of computer science, aims to efficiently retrieve information relevant to user queries from a large repository. Generally, users interact with an IR system by submitting their queries in textual form. Subsequently, IR systems undertake the task of matching and ranking these user-supplied queries against an indexed database, thereby facilitating the retrieval of the most pertinent results.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18115.974609375\n",
      "page_content='[481]\tChatGPT, GPT-4\tText Generation\tZS\tNo\tGeneral\tEnglish\n",
      "[482]\tGPT-3.5\tText Summarization\tZS\tNo\tGeneral\tEnglish\n",
      "[483]\tChatGPT\tText Summarization, Story Generation, Data-to-Text Generation\tZS\tOptional\tGeneral\tEnglish\n",
      "[484]\tGPT-4\tOpen-ended Question Answering\tZS\tNo\tGeneral\tEnglish\n",
      "[485]\tGPT-4\tMachine Translation\tZS\tYes\tGeneral\tMultiple Languages\n",
      "[486]\tGPT-4\tOpen-ended Question Answering\tZS\tNo\tGeneral\tEnglish\n",
      "TABLE 22. Summary of research works exploring GLLM-based evaluation for natural language generation tasks. Here ZS represents zero-shot, and FS represents few-shot.\n",
      "uses BRIO [497], a contrastive learning-based method, to train smaller models like BART for text summarization and metrics like GPTScore [477] or GPTRank for evaluation. The contrastive learning training method helps the model to effectively utilize the supervision signal offered by the reference LLMs. The evaluation showed that the proposed approach helps the smaller model to outperform LLMs like GPT-3 and ChatGPT.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18115.974609375\n",
      "page_content='[481]\tChatGPT, GPT-4\tText Generation\tZS\tNo\tGeneral\tEnglish\n",
      "[482]\tGPT-3.5\tText Summarization\tZS\tNo\tGeneral\tEnglish\n",
      "[483]\tChatGPT\tText Summarization, Story Generation, Data-to-Text Generation\tZS\tOptional\tGeneral\tEnglish\n",
      "[484]\tGPT-4\tOpen-ended Question Answering\tZS\tNo\tGeneral\tEnglish\n",
      "[485]\tGPT-4\tMachine Translation\tZS\tYes\tGeneral\tMultiple Languages\n",
      "[486]\tGPT-4\tOpen-ended Question Answering\tZS\tNo\tGeneral\tEnglish\n",
      "TABLE 22. Summary of research works exploring GLLM-based evaluation for natural language generation tasks. Here ZS represents zero-shot, and FS represents few-shot.\n",
      "uses BRIO [497], a contrastive learning-based method, to train smaller models like BART for text summarization and metrics like GPTScore [477] or GPTRank for evaluation. The contrastive learning training method helps the model to effectively utilize the supervision signal offered by the reference LLMs. The evaluation showed that the proposed approach helps the smaller model to outperform LLMs like GPT-3 and ChatGPT.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18118.38671875\n",
      "page_content='However, while generating long conclusive answers, it is shown [23, 189] that only using the references retrieved by the original user intents as in once-retrieval readers may be inadequate. For example, when providing a passage about “Barack Obama”, language models may need additional knowledge about his university, which may not be included in the results of simply searching the initial query. In conclusion, language models may need extra references to support the following generation during the generating process, where multiple retrieval processes may be required. To address this, solutions such as RETRO [23] and RALM [189] have emerged, emphasizing the periodic collection of documents based on both the original queries and the concurrently generated texts (triggering a retrieval every n generated tokens). In this manner, when generating the text about the university career of Barack Obama, the LLM can receive additional documents as supplementary materials. This need for' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18118.38671875\n",
      "page_content='However, while generating long conclusive answers, it is shown [23, 189] that only using the references retrieved by the original user intents as in once-retrieval readers may be inadequate. For example, when providing a passage about “Barack Obama”, language models may need additional knowledge about his university, which may not be included in the results of simply searching the initial query. In conclusion, language models may need extra references to support the following generation during the generating process, where multiple retrieval processes may be required. To address this, solutions such as RETRO [23] and RALM [189] have emerged, emphasizing the periodic collection of documents based on both the original queries and the concurrently generated texts (triggering a retrieval every n generated tokens). In this manner, when generating the text about the university career of Barack Obama, the LLM can receive additional documents as supplementary materials. This need for' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18132.916015625\n",
      "page_content='of the cold start problem. Gao et al. [241] proposed Chat-REC, which leverages GLLMs to build conversational recommendation systems. The authors reported that Chat-REC performs well in tasks like top-k recommendations and zero-shot rating prediction. Moreover, Chat-REC enhances the conversational recommendation systems by making them more interactive and providing clear explanations.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18132.916015625\n",
      "page_content='of the cold start problem. Gao et al. [241] proposed Chat-REC, which leverages GLLMs to build conversational recommendation systems. The authors reported that Chat-REC performs well in tasks like top-k recommendations and zero-shot rating prediction. Moreover, Chat-REC enhances the conversational recommendation systems by making them more interactive and providing clear explanations.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18133.9921875\n",
      "page_content='[173]\tY. Wang, S. Mishra, P. Alipoormolabashi, Y. Kordi, A. Mirzaei, A. Naik, A. Ashok, A. S. Dhanasekaran, A. Arunkumar, D. Stap et al., “Super-naturalinstructions: Generalization via declarative instructions on 1600+ nlp tasks,” in Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, 2022, pp. 5085–5109.\n",
      "[174]\tM. Zaib, W. E. Zhang, Q. Z. Sheng, A. Mahmood, and Y. Zhang, “Conversational question answering: A survey,” Knowledge and Information Systems, vol. 64, no. 12, pp. 3151–3195, 2022.\n",
      "[175]\tY. Chali, S. A. Hasan, and S. R. Joty, “Improving graph-based random walks for complex question answering using syntactic, shallow semantic and extended string subsequence kernels,” Information Processing & Management, vol. 47, no. 6, pp. 843–855, 2011.\n",
      "[176]\tA. Torfi, R. A. Shirvani, Y. Keneshloo, N. Tavaf, and E. A. Fox, “Natural language processing advancements by deep learning: A survey,” arXiv preprint arXiv:2003.01200, 2020.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18133.9921875\n",
      "page_content='[173]\tY. Wang, S. Mishra, P. Alipoormolabashi, Y. Kordi, A. Mirzaei, A. Naik, A. Ashok, A. S. Dhanasekaran, A. Arunkumar, D. Stap et al., “Super-naturalinstructions: Generalization via declarative instructions on 1600+ nlp tasks,” in Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, 2022, pp. 5085–5109.\n",
      "[174]\tM. Zaib, W. E. Zhang, Q. Z. Sheng, A. Mahmood, and Y. Zhang, “Conversational question answering: A survey,” Knowledge and Information Systems, vol. 64, no. 12, pp. 3151–3195, 2022.\n",
      "[175]\tY. Chali, S. A. Hasan, and S. R. Joty, “Improving graph-based random walks for complex question answering using syntactic, shallow semantic and extended string subsequence kernels,” Information Processing & Management, vol. 47, no. 6, pp. 843–855, 2011.\n",
      "[176]\tA. Torfi, R. A. Shirvani, Y. Keneshloo, N. Tavaf, and E. A. Fox, “Natural language processing advancements by deep learning: A survey,” arXiv preprint arXiv:2003.01200, 2020.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18136.30859375\n",
      "page_content='TABLE 7. The comparison of existing representative methods that have a passive reader module. REALM and RAG do not use LLMs, but their frameworks have been widely applied in many following approaches.\n",
      "Methods\tBackbone models\tWhere to incorporate retrieval\tWhen to retrieve\tHow to use LLMs\n",
      "REALM [182]\tBERT\tInput layer\tIn the beginning\tFine-tuning\n",
      "RAG [183]\tBART\tInput layer\tIn the beginning\tFine-tuning\n",
      "REPLUG [184]\tGPT\tInput layer\tIn the beginning\tFine-tuning\n",
      "Atlas [185]\tT5\tInput layer\tIn the beginning\tFine-tuning\n",
      "Lazaridou et al. [186]\tGopher\tInput layer\tIn the beginning\tPrompting\n",
      "He et al. [187]\tGPT\tInput layer\tIn the beginning\tPrompting\n",
      "Chain-of-Note [188]\tLLaMA\tInput layer\tIn the beginning\tFine-tuning\n",
      "RALM [189]\tLLaMA & OPT & GPT\tInput layer\tDuring generation (every n tokens)\tPrompting\n",
      "RETRO [23]\tTransformer\tAttention layer\tDuring generation (every n tokens)\tTraining from scratch\n",
      "ITERGEN [190]\tGPT\tInput layer\tDuring generation (every answer)\tPrompting' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18136.30859375\n",
      "page_content='TABLE 7. The comparison of existing representative methods that have a passive reader module. REALM and RAG do not use LLMs, but their frameworks have been widely applied in many following approaches.\n",
      "Methods\tBackbone models\tWhere to incorporate retrieval\tWhen to retrieve\tHow to use LLMs\n",
      "REALM [182]\tBERT\tInput layer\tIn the beginning\tFine-tuning\n",
      "RAG [183]\tBART\tInput layer\tIn the beginning\tFine-tuning\n",
      "REPLUG [184]\tGPT\tInput layer\tIn the beginning\tFine-tuning\n",
      "Atlas [185]\tT5\tInput layer\tIn the beginning\tFine-tuning\n",
      "Lazaridou et al. [186]\tGopher\tInput layer\tIn the beginning\tPrompting\n",
      "He et al. [187]\tGPT\tInput layer\tIn the beginning\tPrompting\n",
      "Chain-of-Note [188]\tLLaMA\tInput layer\tIn the beginning\tFine-tuning\n",
      "RALM [189]\tLLaMA & OPT & GPT\tInput layer\tDuring generation (every n tokens)\tPrompting\n",
      "RETRO [23]\tTransformer\tAttention layer\tDuring generation (every n tokens)\tTraining from scratch\n",
      "ITERGEN [190]\tGPT\tInput layer\tDuring generation (every answer)\tPrompting' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18136.453125\n",
      "page_content='it can serve as an additional information resource in addition to healthcare professionals and reduce their burden in answering patient questions. Holmes et al. [183] compared the performances of GLLMs like ChatGPT, GPT-4 with other LLMs like Bard, BLOOMZ and medical physicists in answering related questions to Radiation Oncology Physics. The performance of GPT-4 is very impressive as the model outperforms medical physicists and other LLMs like ChatGPT, Bard and BLOOMZ. The performance of GPT-4 is further enhanced using CoT prompting, i.e., the model is prompted to arrive at the answer after step-by-step reasoning. Nori et al. [185] performed a comprehensive evaluation of the GPT-4 model on medical question answering in zero and few-shot settings. For evaluation, the authors used six datasets: two related to the United States Medical License Examination (USMLE) exam and four from the MultiMedQA benchmark [116]. The performance of GPT-4 is very impressive as it outperforms not only' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18136.453125\n",
      "page_content='it can serve as an additional information resource in addition to healthcare professionals and reduce their burden in answering patient questions. Holmes et al. [183] compared the performances of GLLMs like ChatGPT, GPT-4 with other LLMs like Bard, BLOOMZ and medical physicists in answering related questions to Radiation Oncology Physics. The performance of GPT-4 is very impressive as the model outperforms medical physicists and other LLMs like ChatGPT, Bard and BLOOMZ. The performance of GPT-4 is further enhanced using CoT prompting, i.e., the model is prompted to arrive at the answer after step-by-step reasoning. Nori et al. [185] performed a comprehensive evaluation of the GPT-4 model on medical question answering in zero and few-shot settings. For evaluation, the authors used six datasets: two related to the United States Medical License Examination (USMLE) exam and four from the MultiMedQA benchmark [116]. The performance of GPT-4 is very impressive as it outperforms not only' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18136.462890625\n",
      "page_content='•\tHigh-to-Low: demonstrations with lower similarity scores are placed closer to the test sequence.\n",
      "As shown in Table 10, performance is sensitive the ordering of the demonstrations. The low-to-high ordering achieves the best performance compared to random and high-to-low ordering.\n",
      "6.6\tQuality of the reasoning process\n",
      "In this paper, we use LLMs to generate rationable explanations instead of human editing. Therefore, the quality of generated reasoning process affects the final results. In this subsection, we sample 500 training (text, clues, reason, label) pairs and evaluate the generated reasoning process from the following perspectives:' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18136.462890625\n",
      "page_content='•\tHigh-to-Low: demonstrations with lower similarity scores are placed closer to the test sequence.\n",
      "As shown in Table 10, performance is sensitive the ordering of the demonstrations. The low-to-high ordering achieves the best performance compared to random and high-to-low ordering.\n",
      "6.6\tQuality of the reasoning process\n",
      "In this paper, we use LLMs to generate rationable explanations instead of human editing. Therefore, the quality of generated reasoning process affects the final results. In this subsection, we sample 500 training (text, clues, reason, label) pairs and evaluate the generated reasoning process from the following perspectives:' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18137.60546875\n",
      "page_content='Table 1: Examples of generated clues and reasoning for demonstrations.\n",
      "by a (text, clues, reasons, golden label word) pair. The prompt is thus given as follows:\n",
      "This is a sentiment classifier for input opinion snippets.\n",
      "List CLUES (i.e., keywords, phrases, contextual information, semantic meaning, semantic relationships, tones, references) that support the sentiment determination of the input.\n",
      "Next, deduce the diagnostic REASONING process from premises (i.e., clues, input) that support the sentiment determination.\n",
      "Finally, based on clues, the reasoning and the input, categorize the overall SENTIMENT of input as Positive or Negative.\n",
      "input: <demo-text-1>\n",
      "clues: <demo-clues-1>\n",
      "reasoning: <demo-reason-1>\n",
      "sentiment: <demo-label-word-1>\n",
      "input: <demo-text-2>\n",
      "clues: <demo-clues-2>\n",
      "reasoning: <demo-reason-2> sentiment: <demo-label-word-2>\n",
      ".....\n",
      "input: <demo-text-n>\n",
      "clues: <demo-clues-n> reasoning: <demo-reason-n> sentiment: <demo-label-word-n> input: <text>' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18137.60546875\n",
      "page_content='Table 1: Examples of generated clues and reasoning for demonstrations.\n",
      "by a (text, clues, reasons, golden label word) pair. The prompt is thus given as follows:\n",
      "This is a sentiment classifier for input opinion snippets.\n",
      "List CLUES (i.e., keywords, phrases, contextual information, semantic meaning, semantic relationships, tones, references) that support the sentiment determination of the input.\n",
      "Next, deduce the diagnostic REASONING process from premises (i.e., clues, input) that support the sentiment determination.\n",
      "Finally, based on clues, the reasoning and the input, categorize the overall SENTIMENT of input as Positive or Negative.\n",
      "input: <demo-text-1>\n",
      "clues: <demo-clues-1>\n",
      "reasoning: <demo-reason-1>\n",
      "sentiment: <demo-label-word-1>\n",
      "input: <demo-text-2>\n",
      "clues: <demo-clues-2>\n",
      "reasoning: <demo-reason-2> sentiment: <demo-label-word-2>\n",
      ".....\n",
      "input: <demo-text-n>\n",
      "clues: <demo-clues-n> reasoning: <demo-reason-n> sentiment: <demo-label-word-n> input: <text>' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18138.671875\n",
      "page_content='Maroa Mumtarin, Md Samiullah Chowdhury, and Jonathan Wood. Large language models in analyzing crash narratives– a comparative study of chatGPT, BARD and GPT-4. arXiv preprint arXiv:2308.13563, 2023.\n",
      "Sepp Hochreiter and Jürgen Schmidhuber. Long short-term memory. Neural Computation, 9(8):1735–1780, 1997.\n",
      "Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al. LLAMA: Open and efficient foundation language models. arXiv preprint arXiv:2302.13971, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Stewart 等 - 2023 - Large Language Models for Failure Mode Classification An Investigation.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18138.671875\n",
      "page_content='Maroa Mumtarin, Md Samiullah Chowdhury, and Jonathan Wood. Large language models in analyzing crash narratives– a comparative study of chatGPT, BARD and GPT-4. arXiv preprint arXiv:2308.13563, 2023.\n",
      "Sepp Hochreiter and Jürgen Schmidhuber. Long short-term memory. Neural Computation, 9(8):1735–1780, 1997.\n",
      "Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al. LLAMA: Open and efficient foundation language models. arXiv preprint arXiv:2302.13971, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Stewart 等 - 2023 - Large Language Models for Failure Mode Classification An Investigation.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18149.703125\n",
      "page_content='focused on general domain datasets, except a few focused on other domains like social media [368], [370] and news [370]. Table 16 presents a summary of research works exploring GLLMs for NLP tasks in multilingual settings.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18149.703125\n",
      "page_content='focused on general domain datasets, except a few focused on other domains like social media [368], [370] and news [370]. Table 16 presents a summary of research works exploring GLLMs for NLP tasks in multilingual settings.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18150.10546875\n",
      "page_content='[138]\tMedical Question Answering\tGPT-3.5, GPT4\tZS, FS\tHealthcare\tEnglish\tNo\n",
      "[192]\tMultiple Choice Question Answering\tGPT-3, Codex, InstructGPT\tZS\tGeneral\tEnglish\tNo\n",
      "[193]\tMedical Conversational Question Answering\tGPT-3, InstructGPT\tZS\tHealthcare\tEnglish, Chinese\tNo\n",
      "[194]\tQuestion Answering\tGPT-3\tZS\tMultiple domains including Legal\tand Health\tEnglish\tNo\n",
      "[195]\tJapanese Medical Exam Question Answering\tGPT-3, ChatGPT, GPT-4\tFS\tHealthcare\tJapanese\tNo\n",
      "TABLE 3. Summary of research works exploring GLLMs for question answering tasks. Here ZS represents zero-shot, and FS represents few-shot.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18150.10546875\n",
      "page_content='[138]\tMedical Question Answering\tGPT-3.5, GPT4\tZS, FS\tHealthcare\tEnglish\tNo\n",
      "[192]\tMultiple Choice Question Answering\tGPT-3, Codex, InstructGPT\tZS\tGeneral\tEnglish\tNo\n",
      "[193]\tMedical Conversational Question Answering\tGPT-3, InstructGPT\tZS\tHealthcare\tEnglish, Chinese\tNo\n",
      "[194]\tQuestion Answering\tGPT-3\tZS\tMultiple domains including Legal\tand Health\tEnglish\tNo\n",
      "[195]\tJapanese Medical Exam Question Answering\tGPT-3, ChatGPT, GPT-4\tFS\tHealthcare\tJapanese\tNo\n",
      "TABLE 3. Summary of research works exploring GLLMs for question answering tasks. Here ZS represents zero-shot, and FS represents few-shot.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18151.83203125\n",
      "page_content='In the case of text classification, the large language model is prompted with a task description, a predefined set of labels, examples (optional) and the test input. Here, task description, a predefined set of labels and examples constitute the context. The model understands what actually the task is from the context and then assigns the most appropriate label(s) to the given test input. The additional inputs, like examples in the context, enrich the prompt with more information which allows the model to understand the task better and then perform better.\n",
      "Paper\tTask(s)\tGLLMs Explored\tPrompt Settings\tDomain(s)\tLanguage(s)\tSOTA Results\n",
      "[125]\tStance Detection\tChatGPT\tZS, FS\tSocial Media\tEnglish\tNo\n",
      "[126]\tStress Detection, Depression Detection , Suicidal Detection\tChatGPT\tZS\tSocial Media\tEnglish\tNo\n",
      "[127]\tMental Health Analysis Tasks\tChatGPT\tZS\tSocial Media\tEnglish\tNo\n",
      "[128]\tSentiment Analysis\tChatGPT\tZS, FS\tSocial Media\tEnglish, Chinese\tNo' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18151.83203125\n",
      "page_content='In the case of text classification, the large language model is prompted with a task description, a predefined set of labels, examples (optional) and the test input. Here, task description, a predefined set of labels and examples constitute the context. The model understands what actually the task is from the context and then assigns the most appropriate label(s) to the given test input. The additional inputs, like examples in the context, enrich the prompt with more information which allows the model to understand the task better and then perform better.\n",
      "Paper\tTask(s)\tGLLMs Explored\tPrompt Settings\tDomain(s)\tLanguage(s)\tSOTA Results\n",
      "[125]\tStance Detection\tChatGPT\tZS, FS\tSocial Media\tEnglish\tNo\n",
      "[126]\tStress Detection, Depression Detection , Suicidal Detection\tChatGPT\tZS\tSocial Media\tEnglish\tNo\n",
      "[127]\tMental Health Analysis Tasks\tChatGPT\tZS\tSocial Media\tEnglish\tNo\n",
      "[128]\tSentiment Analysis\tChatGPT\tZS, FS\tSocial Media\tEnglish, Chinese\tNo' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18154.974609375\n",
      "page_content='7.2.3\tBenchmark\n",
      "Some works develop important benchmarks for interactive web-based agents [274–277]. For example, WebShop [275]\n",
      "aims to provide a scalable, interactive web-based environment for language understanding and decision-making, focusing on the task of online shopping. It first takes a raw observation from the environment and produces a new, more meaningful representation that aligns with the specific goal. Then, it dynamically predicts the next action based on the summarized observation and the interaction history. WebCanvas [277] is also an online evaluation framework designed to benchmark the performance of web agents in dynamic and evolving online environments. It aims to address the gap between existing benchmarks, which tend to capture static aspects of the web, and the real-world needs of web agents that must adapt to frequent updates in user interfaces and content.\n",
      "7.3\tLimitations' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18154.974609375\n",
      "page_content='7.2.3\tBenchmark\n",
      "Some works develop important benchmarks for interactive web-based agents [274–277]. For example, WebShop [275]\n",
      "aims to provide a scalable, interactive web-based environment for language understanding and decision-making, focusing on the task of online shopping. It first takes a raw observation from the environment and produces a new, more meaningful representation that aligns with the specific goal. Then, it dynamically predicts the next action based on the summarized observation and the interaction history. WebCanvas [277] is also an online evaluation framework designed to benchmark the performance of web agents in dynamic and evolving online environments. It aims to address the gap between existing benchmarks, which tend to capture static aspects of the web, and the real-world needs of web agents that must adapt to frequent updates in user interfaces and content.\n",
      "7.3\tLimitations' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18155.728515625\n",
      "page_content='Researchers have identified several challenges with implications for the performance and effectiveness of IR systems, such as query ambiguity and retrieval efficiency. In light of these challenges, researchers have directed their attention toward crucial modules within the retrieval process, aiming to address specific issues and effectuate corresponding enhancements. The pivotal role of these modules in ameliorating the IR pipeline and elevating system performance cannot be overstated. In this survey, we focus on the following four modules, which have been greatly enhanced by LLMs.\n",
      "Query Rewriter is an essential IR module that seeks to improve the precision and expressiveness of user queries.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18155.728515625\n",
      "page_content='Researchers have identified several challenges with implications for the performance and effectiveness of IR systems, such as query ambiguity and retrieval efficiency. In light of these challenges, researchers have directed their attention toward crucial modules within the retrieval process, aiming to address specific issues and effectuate corresponding enhancements. The pivotal role of these modules in ameliorating the IR pipeline and elevating system performance cannot be overstated. In this survey, we focus on the following four modules, which have been greatly enhanced by LLMs.\n",
      "Query Rewriter is an essential IR module that seeks to improve the precision and expressiveness of user queries.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18159.9140625\n",
      "page_content='[494]\tS. Zhou, U. Alon, S. Agarwal, and G. Neubig, “Codebertscore: Evaluating code generation with pretrained models of code,” arXiv preprint arXiv:2302.05527, 2023.\n",
      "[495]\tJ. He, W. Krys´cin´ ski, B. McCann, N. Rajani, and C. Xiong, “Ctrlsum: Towards generic controllable text summarization,” in Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, 2022, pp. 5879–5915.\n",
      "[496]\tC. Shen, L. Cheng, L. Bing, Y. You, and L. Si, “Sentbs: Sentencelevel beam search for controllable summarization,” in Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, 2022, pp. 10 256–10 265.\n",
      "[497]\tY. Liu, P. Liu, D. Radev, and G. Neubig, “Brio: Bringing order to abstractive summarization,” in Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), 2022, pp. 2890–2903.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18159.9140625\n",
      "page_content='[494]\tS. Zhou, U. Alon, S. Agarwal, and G. Neubig, “Codebertscore: Evaluating code generation with pretrained models of code,” arXiv preprint arXiv:2302.05527, 2023.\n",
      "[495]\tJ. He, W. Krys´cin´ ski, B. McCann, N. Rajani, and C. Xiong, “Ctrlsum: Towards generic controllable text summarization,” in Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, 2022, pp. 5879–5915.\n",
      "[496]\tC. Shen, L. Cheng, L. Bing, Y. You, and L. Si, “Sentbs: Sentencelevel beam search for controllable summarization,” in Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, 2022, pp. 10 256–10 265.\n",
      "[497]\tY. Liu, P. Liu, D. Radev, and G. Neubig, “Brio: Bringing order to abstractive summarization,” in Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), 2022, pp. 2890–2903.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18173.158203125\n",
      "page_content='[446]\tM. Khalil and E. Er, “Will chatgpt get you caught? rethinking of plagiarism detection,” arXiv preprint arXiv:2302.04335, 2023.\n",
      "[447]\tX. He, X. Shen, Z. Chen, M. Backes, and Y. Zhang, “Mgtbench: Benchmarking machine-generated text detection,” arXiv preprint arXiv:2303.14822, 2023.\n",
      "[448]\tH. Wang, X. Luo, W. Wang, and X. Yan, “Bot or human? detecting chatgpt imposters with a single question,” ArXiv, vol. abs/2305.06424, 2023.\n",
      "[449]\tY. Chen, H. Kang, V. Zhai, L. Li, R. Singh, and B. Ramakrishnan, “Gpt-sentinel: Distinguishing human and chatgpt generated content,” ArXiv, vol. abs/2305.07969, 2023.\n",
      "[450]\tX. Yu, Y. Qi, K. Chen, G. Chen, X. Yang, P. Zhu, W. Zhang, and N. H. Yu, “Gpt paternity test: Gpt generated text detection with gpt genetic inheritance,” ArXiv, vol. abs/2305.12519, 2023.\n",
      "[451]\tL. Yang, F. Jiang, and H. Li, “Is chatgpt involved in texts? measure the polish ratio to detect chatgpt-generated text,” ArXiv, vol. abs/2307.11380, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18173.158203125\n",
      "page_content='[446]\tM. Khalil and E. Er, “Will chatgpt get you caught? rethinking of plagiarism detection,” arXiv preprint arXiv:2302.04335, 2023.\n",
      "[447]\tX. He, X. Shen, Z. Chen, M. Backes, and Y. Zhang, “Mgtbench: Benchmarking machine-generated text detection,” arXiv preprint arXiv:2303.14822, 2023.\n",
      "[448]\tH. Wang, X. Luo, W. Wang, and X. Yan, “Bot or human? detecting chatgpt imposters with a single question,” ArXiv, vol. abs/2305.06424, 2023.\n",
      "[449]\tY. Chen, H. Kang, V. Zhai, L. Li, R. Singh, and B. Ramakrishnan, “Gpt-sentinel: Distinguishing human and chatgpt generated content,” ArXiv, vol. abs/2305.07969, 2023.\n",
      "[450]\tX. Yu, Y. Qi, K. Chen, G. Chen, X. Yang, P. Zhu, W. Zhang, and N. H. Yu, “Gpt paternity test: Gpt generated text detection with gpt genetic inheritance,” ArXiv, vol. abs/2305.12519, 2023.\n",
      "[451]\tL. Yang, F. Jiang, and H. Li, “Is chatgpt involved in texts? measure the polish ratio to detect chatgpt-generated text,” ArXiv, vol. abs/2307.11380, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18178.0\n",
      "page_content='and “false” otherwise. During inference, for each document di, it enumerates all other documents dj and uses global aggregation functions to generate the relevance score si for document di (e.g., si = Pj pi,j, where pi,j represents the probability of generating “true” when taking (q,di,dj) as the model input).' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18178.0\n",
      "page_content='and “false” otherwise. During inference, for each document di, it enumerates all other documents dj and uses global aggregation functions to generate the relevance score si for document di (e.g., si = Pj pi,j, where pi,j represents the probability of generating “true” when taking (q,di,dj) as the model input).' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18178.45703125\n",
      "page_content='ciency of responses. The integration and functionality of our proposed modules within the RAG system are illustrated in Figure 1. In summary, our main contributions are as follows:\n",
      "•\tWe highlight the significance of clarifying input text and generating various queries, which informs the propose of Query Rewriter+. Furthermore, Knowledge Filter module is introduced to mitigate irrelevant knowledge issue. The synergistic operation of these two modules consistently enhances the response accuracy of RAG systems.\n",
      "•\tWe pinpoint the problem of redundant retrieval within the current RAG system. To address this efficiency concern, we introduce the Memory Knowledge Reservoir and the Retrieval Trigger module.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18178.45703125\n",
      "page_content='ciency of responses. The integration and functionality of our proposed modules within the RAG system are illustrated in Figure 1. In summary, our main contributions are as follows:\n",
      "•\tWe highlight the significance of clarifying input text and generating various queries, which informs the propose of Query Rewriter+. Furthermore, Knowledge Filter module is introduced to mitigate irrelevant knowledge issue. The synergistic operation of these two modules consistently enhances the response accuracy of RAG systems.\n",
      "•\tWe pinpoint the problem of redundant retrieval within the current RAG system. To address this efficiency concern, we introduce the Memory Knowledge Reservoir and the Retrieval Trigger module.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18182.234375\n",
      "page_content='generation, Wang et al. [483] reported that ChatGPT as an evaluator (i) exhibits good correlations with human scores, especially in the case of story generation task and (ii) is prompt sensitive. Bai et al. [484] introduced a novel evaluation framework called Language-Model-as-an-Examiner to evaluate open-ended questions. In this framework, GLLM acts as a knowledgeable examiner, generates questions using its own knowledge and then does the reference-free evaluation. Yang et al. [485] developed the BigTrans model (based on LLaMA -13B model) with a multilingual translation capacity of more than 100 languages. GPT-4 based assessment showed that BigTrans performance is on par with ChatGPT and Google translate. Zheng et al. [486] explored GPT-4 as a judge to evaluate open-ended question answering using two newly introduced benchmarks MT-Bench and Chatbot Arena. The experiment results showed that GPT-4 achieves more than 80' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18182.234375\n",
      "page_content='generation, Wang et al. [483] reported that ChatGPT as an evaluator (i) exhibits good correlations with human scores, especially in the case of story generation task and (ii) is prompt sensitive. Bai et al. [484] introduced a novel evaluation framework called Language-Model-as-an-Examiner to evaluate open-ended questions. In this framework, GLLM acts as a knowledgeable examiner, generates questions using its own knowledge and then does the reference-free evaluation. Yang et al. [485] developed the BigTrans model (based on LLaMA -13B model) with a multilingual translation capacity of more than 100 languages. GPT-4 based assessment showed that BigTrans performance is on par with ChatGPT and Google translate. Zheng et al. [486] explored GPT-4 as a judge to evaluate open-ended question answering using two newly introduced benchmarks MT-Bench and Chatbot Arena. The experiment results showed that GPT-4 achieves more than 80' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18186.234375\n",
      "page_content='Methods\t# Examples\tGenerator\tSynthetic Data\tFilter Method\tLLMs’ tuning\n",
      "InPairs [103]\t3\tCurie\tRelevant query\tGeneration probability\tFixed\n",
      "Ma et al. [104]\t0-2\tAlpaca-LLaMA & tk-Instruct\tRelevant query\t-\tFixed\n",
      "InPairs-v2 [105]\t3\tGPT-J\tRelevant query\tRelevance score from fine-tuned monoT5-3B\tFixed\n",
      "PROMPTAGATOR [106]\t0-8\tFLAN\tRelevant query\tRound-trip filtering\tFixed\n",
      "TQGen [107]\t0\tT0\tRelevant query\tGeneration probability\tFixed\n",
      "UDAPDR [108]\t0-3\tGPT3 & FLAN-T5-XXL\tRelevant query\tRound-trip filtering\tFixed\n",
      "SPTAR [109]\t1-2\tLLaMA-7B & Vicuna-7B\tRelevant query\tBM25 filtering\tSoft Prompt tuning\n",
      "Gecko [110]\tfew-shot\tUnkown\tRelevant query\t-\tFixed\n",
      "ART [111]\t0\tT5-XL & T5-XXL\tSoft relevance labels\t-\tFixed\n",
      "Wang et al. [112]\t2\tGPT-4\tQ-PosD-NegD triplet\t-\tfixed' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18186.234375\n",
      "page_content='Methods\t# Examples\tGenerator\tSynthetic Data\tFilter Method\tLLMs’ tuning\n",
      "InPairs [103]\t3\tCurie\tRelevant query\tGeneration probability\tFixed\n",
      "Ma et al. [104]\t0-2\tAlpaca-LLaMA & tk-Instruct\tRelevant query\t-\tFixed\n",
      "InPairs-v2 [105]\t3\tGPT-J\tRelevant query\tRelevance score from fine-tuned monoT5-3B\tFixed\n",
      "PROMPTAGATOR [106]\t0-8\tFLAN\tRelevant query\tRound-trip filtering\tFixed\n",
      "TQGen [107]\t0\tT0\tRelevant query\tGeneration probability\tFixed\n",
      "UDAPDR [108]\t0-3\tGPT3 & FLAN-T5-XXL\tRelevant query\tRound-trip filtering\tFixed\n",
      "SPTAR [109]\t1-2\tLLaMA-7B & Vicuna-7B\tRelevant query\tBM25 filtering\tSoft Prompt tuning\n",
      "Gecko [110]\tfew-shot\tUnkown\tRelevant query\t-\tFixed\n",
      "ART [111]\t0\tT5-XL & T5-XXL\tSoft relevance labels\t-\tFixed\n",
      "Wang et al. [112]\t2\tGPT-4\tQ-PosD-NegD triplet\t-\tfixed' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18195.515625\n",
      "page_content='xi = [CLS] A [MASK] news: xi [SEP]\n",
      "Then M gives the predicted probabilities at the [MASK] token over the vocabulary:\n",
      "p(wx)= p([MASK] = wx), w EC (2)\n",
      "The probability of xi being classified into each candidate class is computed as:\n",
      "P(yj Ixi) = ^2 P(w|x!), 0 < j < m (3) wtv (yj)\n",
      "xi is classified into the class that obtains the highest probability.\n",
      "4We set the size of V(y) to 1 for all classes in the experiments.\n",
      "politics\n",
      "politics\n",
      "technology J\n",
      "business ]\n",
      "technology 0\n",
      "business J technology\n",
      "politics sports\n",
      "politics sports\n",
      "politics sports business\n",
      "Oil prices have continued-tQ-rise-ove^ the past few months.\n",
      "_____Sports__________\n",
      "Michael Jordan is the greatest basketball player of all time.\n",
      "Michael Jordan is the greatest basketball player of all time.\n",
      "Ci! prices have continued to rise over the past few months.\n",
      "politics sports business □\n",
      "Bias-removed Pre-trained Language Model\n",
      "unlabeled validation train\n",
      "J Labeled Examples\n",
      "Elon Musk announced the acquisition of Twitter and became its CEO.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18195.515625\n",
      "page_content='xi = [CLS] A [MASK] news: xi [SEP]\n",
      "Then M gives the predicted probabilities at the [MASK] token over the vocabulary:\n",
      "p(wx)= p([MASK] = wx), w EC (2)\n",
      "The probability of xi being classified into each candidate class is computed as:\n",
      "P(yj Ixi) = ^2 P(w|x!), 0 < j < m (3) wtv (yj)\n",
      "xi is classified into the class that obtains the highest probability.\n",
      "4We set the size of V(y) to 1 for all classes in the experiments.\n",
      "politics\n",
      "politics\n",
      "technology J\n",
      "business ]\n",
      "technology 0\n",
      "business J technology\n",
      "politics sports\n",
      "politics sports\n",
      "politics sports business\n",
      "Oil prices have continued-tQ-rise-ove^ the past few months.\n",
      "_____Sports__________\n",
      "Michael Jordan is the greatest basketball player of all time.\n",
      "Michael Jordan is the greatest basketball player of all time.\n",
      "Ci! prices have continued to rise over the past few months.\n",
      "politics sports business □\n",
      "Bias-removed Pre-trained Language Model\n",
      "unlabeled validation train\n",
      "J Labeled Examples\n",
      "Elon Musk announced the acquisition of Twitter and became its CEO.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18196.26953125\n",
      "page_content='Natural Language Generation[13]\tDecember,2020 MINUTE READ\tCem Dilmegani\tIts ability to automatically transform structured data into\thuman- readable\ttext, enabling\tThe potential for generated text to lack the depth of understanding and\tcreativity that\thuman- authored content\n",
      "\t\t\tbusinesses\tto generate large volumes\tof data-+driven narratives quickly\tand effectively for marketing and sales\tefforts, providing personalized content at scale in the age of digitalization and AI.\tcan\tprovide, leading\tto potential limitations\tin generating highly nuanced or contextually complex narratives.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kania和Mehta - 2023 - A Literature Review on Augmented Analytics and Natural Language Generation A Review of State of Art.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18196.26953125\n",
      "page_content='Natural Language Generation[13]\tDecember,2020 MINUTE READ\tCem Dilmegani\tIts ability to automatically transform structured data into\thuman- readable\ttext, enabling\tThe potential for generated text to lack the depth of understanding and\tcreativity that\thuman- authored content\n",
      "\t\t\tbusinesses\tto generate large volumes\tof data-+driven narratives quickly\tand effectively for marketing and sales\tefforts, providing personalized content at scale in the age of digitalization and AI.\tcan\tprovide, leading\tto potential limitations\tin generating highly nuanced or contextually complex narratives.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kania和Mehta - 2023 - A Literature Review on Augmented Analytics and Natural Language Generation A Review of State of Art.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18207.203125\n",
      "page_content='PT+CC, our approach also consistently obtains better performance with an improvement of 10.2% on DBPedia, 7.9% on Amazon, and an average improvement of 5.2% on all datasets. Thus, the proposed approach exceeds all baselines in true zero-shot settings. Moreover, on IMDB and SST-2, our approach even outperforms all baselines in few-shot settings. In this regard, our conjecture is that the examples labeled by our annotation and refinement algorithm are not only correct but also more correlated with the classes compared with the randomly selected examples used in few-shot methods. Comparison between few-shot PT and few-shot PT+UV demonstrates that unlabeled validation can boost the effect of prompt tuning in fewshot settings without large validation sets. In terms of stability, the standard deviation of our method is smaller than other baselines in most cases, which indicates that our method can maintain good performance with different templates and can therefore reduce human labor in' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18207.203125\n",
      "page_content='PT+CC, our approach also consistently obtains better performance with an improvement of 10.2% on DBPedia, 7.9% on Amazon, and an average improvement of 5.2% on all datasets. Thus, the proposed approach exceeds all baselines in true zero-shot settings. Moreover, on IMDB and SST-2, our approach even outperforms all baselines in few-shot settings. In this regard, our conjecture is that the examples labeled by our annotation and refinement algorithm are not only correct but also more correlated with the classes compared with the randomly selected examples used in few-shot methods. Comparison between few-shot PT and few-shot PT+UV demonstrates that unlabeled validation can boost the effect of prompt tuning in fewshot settings without large validation sets. In terms of stability, the standard deviation of our method is smaller than other baselines in most cases, which indicates that our method can maintain good performance with different templates and can therefore reduce human labor in' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18210.93359375\n",
      "page_content='[196]\tChatGPT\tZS\tGeneral\tJapanese, Chinese\tSentence\tNo\n",
      "[197]\tChatGPT\tZS\tGeneral, News, Healthcare\tEnglish, Chinese, German, Romanian\tSentence\tNo\n",
      "[198]\tChatGPT, GPT-4\tZS\tGeneral, Healthcare ,Social Media\tEnglish, Chinese, German, Romanian\tSentence\tYes\n",
      "[199]\tInstructGPT, Chat- GPT, GPT-4\tZS,FS\tNews, Social Media, ECommerce, Dialogue\tEnglish, German, Chinese\tSentence, Document\tYes\n",
      "[200]\tChatGPT\tZS, FS\tGeneral, News, Social Media, Dialogue, E-Commerce\tEnglish, French, Spanish\tSentence\tYes\n",
      "[201]\tChatGPT, GPT-4\tZS\tGeneral, Social Media, News, Dialogue\tEnglish, German, Russian\tDocument\tYes\n",
      "[202]\tChatGPT\tZS, FS\tGeneral\t102 Languages in 202 directions\tSentence\tNo\n",
      "[203]\tChatGPT\tZS\tGeneral\tEnglish, Chinese, French\tParagraph\tNo\n",
      "[132]\tChatGPT\tZS\tGeneral\tTwelve languages, including four low-resource languages\tSentence\tNo\n",
      "[204]\tGPT-3.5\tZS\tGeneral\t18 language Pairs, including Japanese, English and Polish\tSentence, Paragraph\tYes' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18210.93359375\n",
      "page_content='[196]\tChatGPT\tZS\tGeneral\tJapanese, Chinese\tSentence\tNo\n",
      "[197]\tChatGPT\tZS\tGeneral, News, Healthcare\tEnglish, Chinese, German, Romanian\tSentence\tNo\n",
      "[198]\tChatGPT, GPT-4\tZS\tGeneral, Healthcare ,Social Media\tEnglish, Chinese, German, Romanian\tSentence\tYes\n",
      "[199]\tInstructGPT, Chat- GPT, GPT-4\tZS,FS\tNews, Social Media, ECommerce, Dialogue\tEnglish, German, Chinese\tSentence, Document\tYes\n",
      "[200]\tChatGPT\tZS, FS\tGeneral, News, Social Media, Dialogue, E-Commerce\tEnglish, French, Spanish\tSentence\tYes\n",
      "[201]\tChatGPT, GPT-4\tZS\tGeneral, Social Media, News, Dialogue\tEnglish, German, Russian\tDocument\tYes\n",
      "[202]\tChatGPT\tZS, FS\tGeneral\t102 Languages in 202 directions\tSentence\tNo\n",
      "[203]\tChatGPT\tZS\tGeneral\tEnglish, Chinese, French\tParagraph\tNo\n",
      "[132]\tChatGPT\tZS\tGeneral\tTwelve languages, including four low-resource languages\tSentence\tNo\n",
      "[204]\tGPT-3.5\tZS\tGeneral\t18 language Pairs, including Japanese, English and Polish\tSentence, Paragraph\tYes' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18216.8359375\n",
      "page_content='Fig. 3: Illustration of self-supervised learning paradigm.\n",
      "tasks. These pretrained models avoid training downstream models from scratch by providing a good initialization. Moreover, downstream models initialized from pretrained models converge faster and achieve good results even with limited labelled data [60].' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18216.8359375\n",
      "page_content='Fig. 3: Illustration of self-supervised learning paradigm.\n",
      "tasks. These pretrained models avoid training downstream models from scratch by providing a good initialization. Moreover, downstream models initialized from pretrained models converge faster and achieve good results even with limited labelled data [60].' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18218.18359375\n",
      "page_content='﻿arXiv:2308.07107v4 [cs.CL] 4 Sep 2024\n",
      "Large Language Models for Information Retrieval: A Survey\n",
      "Yutao Zhu, Huaying Yuan, Shuting Wang, Jiongnan Liu, Wenhan Liu, Chenlong Deng Haonan Chen, Zheng Liu, Zhicheng Dou, and Ji-Rong Wen' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18218.18359375\n",
      "page_content='﻿arXiv:2308.07107v4 [cs.CL] 4 Sep 2024\n",
      "Large Language Models for Information Retrieval: A Survey\n",
      "Yutao Zhu, Huaying Yuan, Shuting Wang, Jiongnan Liu, Wenhan Liu, Chenlong Deng Haonan Chen, Zheng Liu, Zhicheng Dou, and Ji-Rong Wen' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18241.052734375\n",
      "page_content='•\tw/o keywords & phrases: keywords and phrases are surface evidence for making decisions such as \"like\", \"hate\".\n",
      "•\tw/o contextual information & semantic meaning:\tcontextual information and\n",
      "semantic meaning are meaning in sentences/paragraphs such as The author express his happiness.\n",
      "•\tw/o semantic relationships:\tsemantic\n",
      "relationships refer to relations between subjects such as \"emotional danger\" suggests a romantic and thrilling relationship between Idemoto and Kim that creates a positive sentiment..\n",
      "•\tw/o tones: tones are the general mood of the text such as The sentence is expressed in an objective tone.\n",
      "•\tw/o references: references are mentions of commonsense facts or books such as The reference to the popular, comedic character \"Ferris Bueller\" implies that the kid is seen in a positive light..\n",
      "Experimental results are shown in Table 9. For R8 and SST-2 datasets, keywords play the key role\n",
      "Ranking\tSimCSE\tFT\n",
      "\tCARP\t\n",
      "Random\t95.39\t95.99\n",
      "High-to-Low\t95.22\t96.71\n",
      "Low-to-High\t96.39\t96.80' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18241.052734375\n",
      "page_content='•\tw/o keywords & phrases: keywords and phrases are surface evidence for making decisions such as \"like\", \"hate\".\n",
      "•\tw/o contextual information & semantic meaning:\tcontextual information and\n",
      "semantic meaning are meaning in sentences/paragraphs such as The author express his happiness.\n",
      "•\tw/o semantic relationships:\tsemantic\n",
      "relationships refer to relations between subjects such as \"emotional danger\" suggests a romantic and thrilling relationship between Idemoto and Kim that creates a positive sentiment..\n",
      "•\tw/o tones: tones are the general mood of the text such as The sentence is expressed in an objective tone.\n",
      "•\tw/o references: references are mentions of commonsense facts or books such as The reference to the popular, comedic character \"Ferris Bueller\" implies that the kid is seen in a positive light..\n",
      "Experimental results are shown in Table 9. For R8 and SST-2 datasets, keywords play the key role\n",
      "Ranking\tSimCSE\tFT\n",
      "\tCARP\t\n",
      "Random\t95.39\t95.99\n",
      "High-to-Low\t95.22\t96.71\n",
      "Low-to-High\t96.39\t96.80' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18242.51953125\n",
      "page_content='domain-specific Chinese LLMs like Huatuo [352] and DoctorGLM [349]. Chen et al. [321] explored GLLMs like GPT-3.5 and GPT-4 on eight datasets spanning four tasks in zero and few-shot settings. The authors observed that fine-tuned PubMedBERT outperforms both the GLLMs in all the biomedical tasks except question answering. In the case of biomedical question answering, GPT-4 outperforms the fine-tuned PubMedBERT model by a large margin of 17' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18242.51953125\n",
      "page_content='domain-specific Chinese LLMs like Huatuo [352] and DoctorGLM [349]. Chen et al. [321] explored GLLMs like GPT-3.5 and GPT-4 on eight datasets spanning four tasks in zero and few-shot settings. The authors observed that fine-tuned PubMedBERT outperforms both the GLLMs in all the biomedical tasks except question answering. In the case of biomedical question answering, GPT-4 outperforms the fine-tuned PubMedBERT model by a large margin of 17' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18243.123046875\n",
      "page_content='of over 11 points and achieves the best results with CoT prompting in few-shot settings. Joshi et al. [184] evaluated ChatGPT in answering undergraduate-level computer science exam questions. For the evaluation, the authors gathered (i) questions from various computer science subjects like data structures, operating systems, machine learning and database management systems, (ii) questions from the GATE exam and (iii) programming questions from the Leetcode website. The results showed that ChatGPT is inconsistent in answering the questions, so students are not advised to rely on ChatGPT completely for their assignments and exams. Bommarito et al. [188] examined the ability of OpenAI’s text-davinci-003 (GPT-3.5) model in answering multiple choice questions from the Bar Exam. Interestingly, human participants with extensive education and specialized training achieved a 68% accuracy rate, while the GPT-3.5 model achieved a lower accuracy rate of 50.3%. Gupta et al. [190] evaluated how' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18243.123046875\n",
      "page_content='of over 11 points and achieves the best results with CoT prompting in few-shot settings. Joshi et al. [184] evaluated ChatGPT in answering undergraduate-level computer science exam questions. For the evaluation, the authors gathered (i) questions from various computer science subjects like data structures, operating systems, machine learning and database management systems, (ii) questions from the GATE exam and (iii) programming questions from the Leetcode website. The results showed that ChatGPT is inconsistent in answering the questions, so students are not advised to rely on ChatGPT completely for their assignments and exams. Bommarito et al. [188] examined the ability of OpenAI’s text-davinci-003 (GPT-3.5) model in answering multiple choice questions from the Bar Exam. Interestingly, human participants with extensive education and specialized training achieved a 68% accuracy rate, while the GPT-3.5 model achieved a lower accuracy rate of 50.3%. Gupta et al. [190] evaluated how' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18252.0546875\n",
      "page_content='Generative Retrieval: the LLM Part Generative search is a new paradigm of IR that employs neural generative models as search indices (Tay et al., 2022; Bevilacqua et al., 2022; Lee et al., 2022). Recent studies propose that LLMs further trained to follow instructions could zero-shot generalize to diverse unseen instructions (Ouyang et al., 2022; Sanh et al., 2022; Min et al., 2022; Wei et al., 2022). Therefore, we prepare textual prompts p that include instructions for the desired behavior to q and obtain a refined query q′ . Then the LLMs G such as ChatGPT (OpenAI, 2022) take in q′ and generate related knowledge passage s. This process can be illustrated as follows:\n",
      "s = G(q‘) = G(q ® p)\t(2)\n",
      "where ® is the prompt formulation operation for q and p. For each q‘, if we sample h examples via LLM G, we will obtain a knowledge collection S = {s1, s2,..., sh}.\n",
      "4\tInteR' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Feng 等 - 2023 - Synergistic Interplay between Search and Large Language Models for Information Retrieval.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18252.0546875\n",
      "page_content='Generative Retrieval: the LLM Part Generative search is a new paradigm of IR that employs neural generative models as search indices (Tay et al., 2022; Bevilacqua et al., 2022; Lee et al., 2022). Recent studies propose that LLMs further trained to follow instructions could zero-shot generalize to diverse unseen instructions (Ouyang et al., 2022; Sanh et al., 2022; Min et al., 2022; Wei et al., 2022). Therefore, we prepare textual prompts p that include instructions for the desired behavior to q and obtain a refined query q′ . Then the LLMs G such as ChatGPT (OpenAI, 2022) take in q′ and generate related knowledge passage s. This process can be illustrated as follows:\n",
      "s = G(q‘) = G(q ® p)\t(2)\n",
      "where ® is the prompt formulation operation for q and p. For each q‘, if we sample h examples via LLM G, we will obtain a knowledge collection S = {s1, s2,..., sh}.\n",
      "4\tInteR' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Feng 等 - 2023 - Synergistic Interplay between Search and Large Language Models for Information Retrieval.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18259.0625\n",
      "page_content='[333]\tX. Wang, Z. Gong, G. Wang, J. Jia, Y. Xu, J. Zhao, Q. Fan, S. Wu, W. Hu, and X. Li, “Chatgpt performs on the chinese national medical licensing examination,” 2023.\n",
      "[334]\tK. A. Carpenter and R. B. Altman, “Using gpt-3 to build a lexicon of drugs of abuse synonyms for social media pharmacovigi-lance,” Biomolecules, vol. 13, no. 2, p. 387, 2023.\n",
      "[335]\tE. Hernandez, D. Mahajan, J. Wulff, M. J. Smith, Z. Ziegler, D. Nadler, P. Szolovits, A. Johnson, E. Alsentzer et al., “Do we still need clinical language models?” in Conference on Health, Inference, and Learning. PMLR, 2023, pp. 578–597.\n",
      "[336]\tA. S. Rao, M. Pang, J. Kim, M. Kamineni, W. Lie, A. K. Prasad, A. Landman, K. Dryer, and M. D. Succi, “Assessing the utility of chatgpt throughout the entire clinical workflow,” medRxiv, pp. 2023–02, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18259.0625\n",
      "page_content='[333]\tX. Wang, Z. Gong, G. Wang, J. Jia, Y. Xu, J. Zhao, Q. Fan, S. Wu, W. Hu, and X. Li, “Chatgpt performs on the chinese national medical licensing examination,” 2023.\n",
      "[334]\tK. A. Carpenter and R. B. Altman, “Using gpt-3 to build a lexicon of drugs of abuse synonyms for social media pharmacovigi-lance,” Biomolecules, vol. 13, no. 2, p. 387, 2023.\n",
      "[335]\tE. Hernandez, D. Mahajan, J. Wulff, M. J. Smith, Z. Ziegler, D. Nadler, P. Szolovits, A. Johnson, E. Alsentzer et al., “Do we still need clinical language models?” in Conference on Health, Inference, and Learning. PMLR, 2023, pp. 578–597.\n",
      "[336]\tA. S. Rao, M. Pang, J. Kim, M. Kamineni, W. Lie, A. K. Prasad, A. Landman, K. Dryer, and M. D. Succi, “Assessing the utility of chatgpt throughout the entire clinical workflow,” medRxiv, pp. 2023–02, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18262.92578125\n",
      "page_content='Romal Thoppilan, Daniel De Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, et al. 2022. Lamda: Language models for dialog applications. arXiv preprint arXiv:2201.08239.\n",
      "Harsh Trivedi, Niranjan Balasubramanian, Tushar Khot, and Ashish Sabharwal. 2022. Interleaving retrieval with chain-of-thought reasoning for knowledgeintensive multi-step questions. arXiv preprint arXiv:2212.10509.\n",
      "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. Advances in neural information processing systems, 30.\n",
      "Zhen Wan, Fei Cheng, Zhuoyuan Mao, Qianying Liu, Haiyue Song, Jiwei Li, and Sadao Kurohashi. 2023. Gpt-re: In-context learning for relation extraction using large language models. arXiv preprint arXiv:2305.02105.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18262.92578125\n",
      "page_content='Romal Thoppilan, Daniel De Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, et al. 2022. Lamda: Language models for dialog applications. arXiv preprint arXiv:2201.08239.\n",
      "Harsh Trivedi, Niranjan Balasubramanian, Tushar Khot, and Ashish Sabharwal. 2022. Interleaving retrieval with chain-of-thought reasoning for knowledgeintensive multi-step questions. arXiv preprint arXiv:2212.10509.\n",
      "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. Advances in neural information processing systems, 30.\n",
      "Zhen Wan, Fei Cheng, Zhuoyuan Mao, Qianying Liu, Haiyue Song, Jiwei Li, and Sadao Kurohashi. 2023. Gpt-re: In-context learning for relation extraction using large language models. arXiv preprint arXiv:2305.02105.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18264.712890625\n",
      "page_content='[431]\tL. De Angelis, F. Baglivo, G. Arzilli, G. P. Privitera, P. Ferragina, A. E. Tozzi, and C. Rizzo, “Chatgpt and the rise of large language models: the new ai-driven infodemic threat in public health,” Frontiers in Public Health, vol. 11, p. 1166120, 2023.\n",
      "[432]\tS. Mitrovi’c, D. Andreoletti, and O. Ayoub, “Chatgpt or human? detect and explain. explaining decisions of machine learning model for detecting short chatgpt-generated text,” ArXiv, vol. abs/2301.13852, 2023.\n",
      "[433]\tC. A. Gao, F. M. Howard, N. S. Markov, E. C. Dyer, S. Ramesh, Y. Luo, and A. T. Pearson, “Comparing scientific abstracts generated by chatgpt to real abstracts with detectors and blinded human reviewers,” NPJ Digital Medicine, vol. 6, no. 1, p. 75, 2023.\n",
      "[434]\tD. R. Cotton, P. A. Cotton, and J. R. Shipway, “Chatting and cheating: Ensuring academic integrity in the era of chatgpt,” Innovations in Education and Teaching International, pp. 1–12, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18264.712890625\n",
      "page_content='[431]\tL. De Angelis, F. Baglivo, G. Arzilli, G. P. Privitera, P. Ferragina, A. E. Tozzi, and C. Rizzo, “Chatgpt and the rise of large language models: the new ai-driven infodemic threat in public health,” Frontiers in Public Health, vol. 11, p. 1166120, 2023.\n",
      "[432]\tS. Mitrovi’c, D. Andreoletti, and O. Ayoub, “Chatgpt or human? detect and explain. explaining decisions of machine learning model for detecting short chatgpt-generated text,” ArXiv, vol. abs/2301.13852, 2023.\n",
      "[433]\tC. A. Gao, F. M. Howard, N. S. Markov, E. C. Dyer, S. Ramesh, Y. Luo, and A. T. Pearson, “Comparing scientific abstracts generated by chatgpt to real abstracts with detectors and blinded human reviewers,” NPJ Digital Medicine, vol. 6, no. 1, p. 75, 2023.\n",
      "[434]\tD. R. Cotton, P. A. Cotton, and J. R. Shipway, “Chatting and cheating: Ensuring academic integrity in the era of chatgpt,” Innovations in Education and Teaching International, pp. 1–12, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18268.724609375\n",
      "page_content='One way to achieve this ability is to design a pipeline that combines a series of modules and assigns different roles to them. Such a pre-defined pipeline mimics users’ behaviors on the web by breaking it into several sub-tasks which are performed by different modules. However, this kind of static agent cannot deal with the complex nature of users’ behavior sequences on the web and may face challenges when interacting with real-world environments. An alternative solution is to allow LLMs to freely explore the web and make interactions themselves, namely letting the LLM itself decide what action it will take next based on the feedback from the environment (or humans). These agents have more flexibility and act more like human beings.\n",
      "7.1\tStatic Agent' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18268.724609375\n",
      "page_content='One way to achieve this ability is to design a pipeline that combines a series of modules and assigns different roles to them. Such a pre-defined pipeline mimics users’ behaviors on the web by breaking it into several sub-tasks which are performed by different modules. However, this kind of static agent cannot deal with the complex nature of users’ behavior sequences on the web and may face challenges when interacting with real-world environments. An alternative solution is to allow LLMs to freely explore the web and make interactions themselves, namely letting the LLM itself decide what action it will take next based on the feedback from the environment (or humans). These agents have more flexibility and act more like human beings.\n",
      "7.1\tStatic Agent' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18276.74609375\n",
      "page_content='BERT, RoBERTa, ELECTRA\n",
      "---* GPT-1, GPT-2\n",
      "---► BART, PEGASUS\n",
      "Fig. 4: Evolution of self-supervised learning in natural language processing.\n",
      "ever, unlike supervised learning, which offers supervision based on human-labelled data, self-supervised learning offers supervision based on automatically generated data. Supervised learning is mostly used to train downstream models with task-specific data, while selfsupervised learning is used to train pretrained models to offer good initialization to downstream models. Similarly, self-supervised learning has similarities and dissimilarities with unsupervised learning [1]. Both selfsupervised learning and unsupervised learning make use of unlabelled data without requiring any labelled data. However, unlike self-supervised learning, which focuses on learning rich data representations using pseudo supervision, the main focus of unsupervised learning is to identify the hidden patterns in the data without any supervision.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18276.74609375\n",
      "page_content='BERT, RoBERTa, ELECTRA\n",
      "---* GPT-1, GPT-2\n",
      "---► BART, PEGASUS\n",
      "Fig. 4: Evolution of self-supervised learning in natural language processing.\n",
      "ever, unlike supervised learning, which offers supervision based on human-labelled data, self-supervised learning offers supervision based on automatically generated data. Supervised learning is mostly used to train downstream models with task-specific data, while selfsupervised learning is used to train pretrained models to offer good initialization to downstream models. Similarly, self-supervised learning has similarities and dissimilarities with unsupervised learning [1]. Both selfsupervised learning and unsupervised learning make use of unlabelled data without requiring any labelled data. However, unlike self-supervised learning, which focuses on learning rich data representations using pseudo supervision, the main focus of unsupervised learning is to identify the hidden patterns in the data without any supervision.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18281.71875\n",
      "page_content='[461]\tH. Liu, R. Ning, Z. Teng, J. Liu, Q. Zhou, and Y. Zhang, “Evaluating the logical reasoning ability of chatgpt and gpt-4,” arXiv preprint arXiv:2304.03439, 2023.\n",
      "[462]\tA. Liu, X. Hu, L. Wen, and P. S. Yu, “A comprehensive evaluation of chatgpt’s zero-shot text-to-sql capability,” arXiv preprint arXiv:2303.13547, 2023.\n",
      "[463]\tE. Mitchell, Y. Lee, A. Khazatsky, C. D. Manning, and C. Finn, “Detectgpt: Zero-shot machine-generated text detection using probability curvature,” arXiv preprint arXiv:2301.11305, 2023.\n",
      "[464]\tS. Goyal, S. Doddapaneni, M. M. Khapra, and B. Ravindran, “A survey of adversarial defences and robustness in nlp,” ACM Computing Surveys, 2022.\n",
      "[465]\tS. Qiu, Q. Liu, S. Zhou, and W. Huang, “Adversarial attack and defense technologies in natural language processing: A survey,” Neurocomputing, vol. 492, pp. 278–307, 2022.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18281.71875\n",
      "page_content='[461]\tH. Liu, R. Ning, Z. Teng, J. Liu, Q. Zhou, and Y. Zhang, “Evaluating the logical reasoning ability of chatgpt and gpt-4,” arXiv preprint arXiv:2304.03439, 2023.\n",
      "[462]\tA. Liu, X. Hu, L. Wen, and P. S. Yu, “A comprehensive evaluation of chatgpt’s zero-shot text-to-sql capability,” arXiv preprint arXiv:2303.13547, 2023.\n",
      "[463]\tE. Mitchell, Y. Lee, A. Khazatsky, C. D. Manning, and C. Finn, “Detectgpt: Zero-shot machine-generated text detection using probability curvature,” arXiv preprint arXiv:2301.11305, 2023.\n",
      "[464]\tS. Goyal, S. Doddapaneni, M. M. Khapra, and B. Ravindran, “A survey of adversarial defences and robustness in nlp,” ACM Computing Surveys, 2022.\n",
      "[465]\tS. Qiu, Q. Liu, S. Zhou, and W. Huang, “Adversarial attack and defense technologies in natural language processing: A survey,” Neurocomputing, vol. 492, pp. 278–307, 2022.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18283.37890625\n",
      "page_content='Large language models (LLMs) have recently emerged as transformative forces across various research fields, such as natural language processing (NLP) [33–35], recommender systems [36–39], finance [40], and even molecule discovery [41]. These cutting-edge LLMs are primarily based on the Transformer architecture and undergo extensive pretraining on diverse textual sources, including web pages, research articles, books, and codes. As their scale continues to expand (including both model size and data volume), LLMs have demonstrated remarkable advances in their capabilities. On the one hand, LLMs have exhibited unprecedented proficiency in language understanding and generation, resulting in responses that are more human-like and better aligned with human intentions. On the other hand,\n",
      "4. New Bing, https://www.bing.com/new' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18283.37890625\n",
      "page_content='Large language models (LLMs) have recently emerged as transformative forces across various research fields, such as natural language processing (NLP) [33–35], recommender systems [36–39], finance [40], and even molecule discovery [41]. These cutting-edge LLMs are primarily based on the Transformer architecture and undergo extensive pretraining on diverse textual sources, including web pages, research articles, books, and codes. As their scale continues to expand (including both model size and data volume), LLMs have demonstrated remarkable advances in their capabilities. On the one hand, LLMs have exhibited unprecedented proficiency in language understanding and generation, resulting in responses that are more human-like and better aligned with human intentions. On the other hand,\n",
      "4. New Bing, https://www.bing.com/new' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18284.92578125\n",
      "page_content='To obtain useful references for LLMs to generate responses for user queries, an intuitive way is to retrieve the top documents based on the queries themselves in the beginning. For example, REALM [182] adopts this strategy by directly attending the document contents to the original queries to predict the final answers based on masked language modeling. RAG [183] follows this strategy but applies the generative language modeling paradigm. However, these two approaches only use language models with limited parameters, such as BERT and BART. Recent approaches such as REPLUG [184] and Atlas [185] have improved them by leveraging LLMs such as GPTs, T5s, and LLaMAs for response generation. To yield better answer generation performances, these models usually fine-tune LLMs on QA tasks. However, due to the limited computing resources, many methods [186, 187, 195, 198] choose to prompt LLMs for generation as they could use larger LMs in this way. Furthermore, to improve the quality of the' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18284.92578125\n",
      "page_content='To obtain useful references for LLMs to generate responses for user queries, an intuitive way is to retrieve the top documents based on the queries themselves in the beginning. For example, REALM [182] adopts this strategy by directly attending the document contents to the original queries to predict the final answers based on masked language modeling. RAG [183] follows this strategy but applies the generative language modeling paradigm. However, these two approaches only use language models with limited parameters, such as BERT and BART. Recent approaches such as REPLUG [184] and Atlas [185] have improved them by leveraging LLMs such as GPTs, T5s, and LLaMAs for response generation. To yield better answer generation performances, these models usually fine-tune LLMs on QA tasks. However, due to the limited computing resources, many methods [186, 187, 195, 198] choose to prompt LLMs for generation as they could use larger LMs in this way. Furthermore, to improve the quality of the' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18285.7734375\n",
      "page_content='4.2\tTask Setting\n",
      "We evaluate the efficacy of our proposed methodologies under opendomain QA task. This evaluation leverages three distinct opendomain QA datasets that do not require logical reasoning. These include: (i) The Natural Questions (NQ) dataset [18], which is a real-world queries compiled from search engines. (ii) PopQA [24], a dataset with a long-tail distribution, emphasizing less popular topics within Wikidata. (iii) AmbigNQ [25], an enhanced version of NQ that transforms ambiguous questions into a set of discrete, yet closely related queries. Additionally, we incorporate two benchmark datasets that require logical reasoning: (iv) 2WIKIMQA [30] and (v) HotPotQA [31]. Due to the costs associated with API calls for LLMs and Bing Search, and following common practices[16, 34, 23, 33], we test on a stratified sample of 300 questions from each dataset rather than the entire test dataset.\n",
      "2 https://github.com/tloen/alpaca-lora\n",
      "3 https://huggingface.co/google/gemma-2b' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18285.7734375\n",
      "page_content='4.2\tTask Setting\n",
      "We evaluate the efficacy of our proposed methodologies under opendomain QA task. This evaluation leverages three distinct opendomain QA datasets that do not require logical reasoning. These include: (i) The Natural Questions (NQ) dataset [18], which is a real-world queries compiled from search engines. (ii) PopQA [24], a dataset with a long-tail distribution, emphasizing less popular topics within Wikidata. (iii) AmbigNQ [25], an enhanced version of NQ that transforms ambiguous questions into a set of discrete, yet closely related queries. Additionally, we incorporate two benchmark datasets that require logical reasoning: (iv) 2WIKIMQA [30] and (v) HotPotQA [31]. Due to the costs associated with API calls for LLMs and Bing Search, and following common practices[16, 34, 23, 33], we test on a stratified sample of 300 questions from each dataset rather than the entire test dataset.\n",
      "2 https://github.com/tloen/alpaca-lora\n",
      "3 https://huggingface.co/google/gemma-2b' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18288.12890625\n",
      "page_content='1.4\t. Role of Natural Language Processing (NLP) in Augmented Analytics\n",
      "Natural Language Processing (NLP) is an AI and ML subfield that focuses on technology's interface with human communication, enabling machines to understand and produce natural language. It enhances knowledge about text, enabling analysis, comprehension, and generation of language. NLP is used in various applications like text categorization, sentiment analysis, translation, speech recognition, and question answering. It has led to the development of text mining technologies such as information extraction, summarization, classification, clustering, and opinion mining. NLP also encompasses voice recognition, natural language understanding (NLU), and natural language generation (NLG) for tasks like translating spoken words, interpreting meaning, and generating coherent text.\n",
      "1.5\tNatural Language Generation (NLG)\n",
      "Natural Language Generation is a software process that Converts organized data into human–readable.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kania和Mehta - 2023 - A Literature Review on Augmented Analytics and Natural Language Generation A Review of State of Art.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18288.12890625\n",
      "page_content='1.4\t. Role of Natural Language Processing (NLP) in Augmented Analytics\n",
      "Natural Language Processing (NLP) is an AI and ML subfield that focuses on technology's interface with human communication, enabling machines to understand and produce natural language. It enhances knowledge about text, enabling analysis, comprehension, and generation of language. NLP is used in various applications like text categorization, sentiment analysis, translation, speech recognition, and question answering. It has led to the development of text mining technologies such as information extraction, summarization, classification, clustering, and opinion mining. NLP also encompasses voice recognition, natural language understanding (NLU), and natural language generation (NLG) for tasks like translating spoken words, interpreting meaning, and generating coherent text.\n",
      "1.5\tNatural Language Generation (NLG)\n",
      "Natural Language Generation is a software process that Converts organized data into human–readable.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kania和Mehta - 2023 - A Literature Review on Augmented Analytics and Natural Language Generation A Review of State of Art.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18291.400390625\n",
      "page_content='Our survey provides an insightful exploration of the intersection between LLMs and IR systems, covering key perspectives such as query rewriters, retrievers, rerankers, and readers (as shown in Figure 1).5 We also include some recent studies that leverage LLMs as search agents to perform various IR tasks. This analysis enhances our understanding of LLMs’ potential and limitations in advancing the IR field. For this survey, we create a Github repository by collecting the relevant papers and resources about applying LLMs for IR tasks (LLM4IR).6 We will continue to update the repository with newer papers. This survey will also be periodically updated according to the development of this area. We notice that there are several surveys for PLMs, LLMs, and their applications (e.g., AIGC or recommender systems) [43–49]. Compared with them, we focus on the techniques and methods for developing and applying LLMs for IR systems. In addition, we suggest reading the strategy' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18291.400390625\n",
      "page_content='Our survey provides an insightful exploration of the intersection between LLMs and IR systems, covering key perspectives such as query rewriters, retrievers, rerankers, and readers (as shown in Figure 1).5 We also include some recent studies that leverage LLMs as search agents to perform various IR tasks. This analysis enhances our understanding of LLMs’ potential and limitations in advancing the IR field. For this survey, we create a Github repository by collecting the relevant papers and resources about applying LLMs for IR tasks (LLM4IR).6 We will continue to update the repository with newer papers. This survey will also be periodically updated according to the development of this area. We notice that there are several surveys for PLMs, LLMs, and their applications (e.g., AIGC or recommender systems) [43–49]. Compared with them, we focus on the techniques and methods for developing and applying LLMs for IR systems. In addition, we suggest reading the strategy' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18293.13671875\n",
      "page_content='5.2\tUtilizing LLMs as Unsupervised Rerankers\n",
      "As the size of LLMs scales up (e.g., exceeding 10 billion parameters), it becomes increasingly difficult to fine-tune the\n",
      "(Relevance Generation)\n",
      "(Query Generation)\n",
      "(a) Pointwise method\n",
      "Prompt\n",
      "Given a query #{query}, which of the following two documents is more relevant to the query?\n",
      "Document 1: #{document_1};\tDocument 2: #{document_2}\n",
      "Output Document 1 or Document 2:\n",
      "Output\n",
      "Document 1 / Document 2\n",
      "(c) Pairwise method\n",
      "Fig. 5. Three types of unsupervised reranking methods: (a) pointwise methods that consist of relevance generation (upper) and query generation (lower), (b) listwise methods, and (c) pairwise methods.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18293.13671875\n",
      "page_content='5.2\tUtilizing LLMs as Unsupervised Rerankers\n",
      "As the size of LLMs scales up (e.g., exceeding 10 billion parameters), it becomes increasingly difficult to fine-tune the\n",
      "(Relevance Generation)\n",
      "(Query Generation)\n",
      "(a) Pointwise method\n",
      "Prompt\n",
      "Given a query #{query}, which of the following two documents is more relevant to the query?\n",
      "Document 1: #{document_1};\tDocument 2: #{document_2}\n",
      "Output Document 1 or Document 2:\n",
      "Output\n",
      "Document 1 / Document 2\n",
      "(c) Pairwise method\n",
      "Fig. 5. Three types of unsupervised reranking methods: (a) pointwise methods that consist of relevance generation (upper) and query generation (lower), (b) listwise methods, and (c) pairwise methods.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18301.42578125\n",
      "page_content='Although listwise methods have yielded promising performance, they still suffer from some weaknesses: (1) The performance of listwise methods is highly sensitive to the document order in the prompt. When the document order is randomly shuffled, listwise methods perform even worse than BM25 [159], revealing positional bias issues in the listwise ranking of LLMs. (2) The use of sliding windows limits the number of documents that can be ranked each time, and the dependency between adjacent windows prevents parallelization of LLM inference, thereby reducing the efficiency of reranking. Recently, some studies have attempted to mitigate these issues. Tang et al. [161] introduce a permutation self-consistency method, which involves shuffling the list in the prompt and aggregating the generated results to achieve a more accurate and a positionally unbiased ranking. Chen et al. [162] introduce a tournament mechanism into listwise ranking and propose TourRank, which parallelizes the reranking' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18301.42578125\n",
      "page_content='Although listwise methods have yielded promising performance, they still suffer from some weaknesses: (1) The performance of listwise methods is highly sensitive to the document order in the prompt. When the document order is randomly shuffled, listwise methods perform even worse than BM25 [159], revealing positional bias issues in the listwise ranking of LLMs. (2) The use of sliding windows limits the number of documents that can be ranked each time, and the dependency between adjacent windows prevents parallelization of LLM inference, thereby reducing the efficiency of reranking. Recently, some studies have attempted to mitigate these issues. Tang et al. [161] introduce a permutation self-consistency method, which involves shuffling the list in the prompt and aggregating the generated results to achieve a more accurate and a positionally unbiased ranking. Chen et al. [162] introduce a tournament mechanism into listwise ranking and propose TourRank, which parallelizes the reranking' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18305.7890625\n",
      "page_content='E.\tJ. Hu, Y. Shen, P. Wallis, Z. Allen-Zhu, Y. Li, S. Wang, L. Wang, and W. Chen, “Lora: Low-rank adaptation of large language models,” in The Tenth International Conference on Learning Representations, ICLR 2022, Virtual Event, April 25-29, 2022. OpenReview.net, 2022.\n",
      "X.\tL. Li and P. Liang, “Prefix-tuning: Optimizing continuous prompts for generation,” in Proceedings of the 59th Annual Meeting of the Association for Com-\n",
      "[63]\n",
      "[64]\n",
      "[65]\n",
      "[66]\n",
      "[67]\n",
      "[68]\n",
      "[69]\n",
      "[70]\n",
      "[71]\n",
      "[72]\n",
      "[73]\n",
      "[74]\n",
      "[75]\n",
      "[76]\n",
      "putational Linguistics and the 11th International Joint Conference on Natural Language Processing, ACL/IJCNLP 2021, (Volume 1: Long Papers), Virtual Event, August 16, 2021, C. Zong, F. Xia, W. Li, and R. Navigli, Eds. Association for Computational Linguistics, 2021, pp. 4582–4597.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18305.7890625\n",
      "page_content='E.\tJ. Hu, Y. Shen, P. Wallis, Z. Allen-Zhu, Y. Li, S. Wang, L. Wang, and W. Chen, “Lora: Low-rank adaptation of large language models,” in The Tenth International Conference on Learning Representations, ICLR 2022, Virtual Event, April 25-29, 2022. OpenReview.net, 2022.\n",
      "X.\tL. Li and P. Liang, “Prefix-tuning: Optimizing continuous prompts for generation,” in Proceedings of the 59th Annual Meeting of the Association for Com-\n",
      "[63]\n",
      "[64]\n",
      "[65]\n",
      "[66]\n",
      "[67]\n",
      "[68]\n",
      "[69]\n",
      "[70]\n",
      "[71]\n",
      "[72]\n",
      "[73]\n",
      "[74]\n",
      "[75]\n",
      "[76]\n",
      "putational Linguistics and the 11th International Joint Conference on Natural Language Processing, ACL/IJCNLP 2021, (Volume 1: Long Papers), Virtual Event, August 16, 2021, C. Zong, F. Xia, W. Li, and R. Navigli, Eds. Association for Computational Linguistics, 2021, pp. 4582–4597.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18308.123046875\n",
      "page_content='PS1: The Information Plateaus of Single Query. From the analysis of Answer Recall in sequential order, it is observed that as the number of snippets increases, the Answer Recall metric improves, but they commonly plateauing before reaching 10 and 20 snippets (red dashed line). This phenomenon indicates there exist an upper limit to the retrievable useful information of a single query. This suggests there is a threshold beyond which additional information retrieved by the same query does not contribute too much to better retrieval quality.\n",
      "PS2: The Effect of Using Multiple Queries. The analysis of An-\n",
      "Figure 2: PS1 & PS2. Analysis of Information Plateaus in Retrieving Knowledge and Overcoming the Bottlenecks with New Queries.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18308.123046875\n",
      "page_content='PS1: The Information Plateaus of Single Query. From the analysis of Answer Recall in sequential order, it is observed that as the number of snippets increases, the Answer Recall metric improves, but they commonly plateauing before reaching 10 and 20 snippets (red dashed line). This phenomenon indicates there exist an upper limit to the retrievable useful information of a single query. This suggests there is a threshold beyond which additional information retrieved by the same query does not contribute too much to better retrieval quality.\n",
      "PS2: The Effect of Using Multiple Queries. The analysis of An-\n",
      "Figure 2: PS1 & PS2. Analysis of Information Plateaus in Retrieving Knowledge and Overcoming the Bottlenecks with New Queries.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18308.361328125\n",
      "page_content='Fig. 2: Real-life examples of knowledge transfer (transfer learning). Examples are inspired from [58]\n",
      "target task (or domain) with limited data. For example, consider the task of sentiment analysis of reviews of different products. It is highly expensive to annotate large data separately for each product. In such cases, transfer learning helps to adapt the model trained on one product reviews to perform well on other product reviews without requiring large labelled data [62].' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18308.361328125\n",
      "page_content='Fig. 2: Real-life examples of knowledge transfer (transfer learning). Examples are inspired from [58]\n",
      "target task (or domain) with limited data. For example, consider the task of sentiment analysis of reviews of different products. It is highly expensive to annotate large data separately for each product. In such cases, transfer learning helps to adapt the model trained on one product reviews to perform well on other product reviews without requiring large labelled data [62].' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18318.078125\n",
      "page_content='[468]\tGPT-3.5, ChatGPT\tText Summarization, Dialogue Generation, Story Generation, Paraphrase Generation\tZS\tNo\tGeneral\tEnglish\n",
      "[474]\tGPT-3.5, ChatGPT\tMachine Translation\tZS, FS\tYes\tGeneral\tEnglish, Chinese, German\n",
      "[475]\tChatGPT\tText Summarization\tZS\tNo\tGeneral\tEnglish\n",
      "[476]\tChatGPT\tText Summarization\tZS\tNo\tGeneral\tEnglish\n",
      "[285]\tGPT-4\tText-to-Image Synthesis\tZS\tN/A\tGeneral\tEnglish\n",
      "[426]\tGPT-4\tMachine Translation\tZS\tYes\tGeneral\tEnglish, German, Russian\n",
      "[477]\tGPT-3, GPT-3.5\tDialogue Generation, Machine Translation, Text Summarization, Data-to-Text Generation\tZS, FS\tNo\tGeneral\tEnglish, Chinese\n",
      "[478]\tGPT-3, ChatGPT\tText Summarization\tZS\tNo\tGeneral\tEnglish\n",
      "[479]\tChatGPT\tText Summarization\tZS\tNo\tGeneral\tEnglish\n",
      "[480]\tGPT-3.5\tMachine Translation, Text Summarization, Image Caption\tZS\tYes\tGeneral\tEnglish\n",
      "[481]\tChatGPT, GPT-4\tText Generation\tZS\tNo\tGeneral\tEnglish\n",
      "[482]\tGPT-3.5\tText Summarization\tZS\tNo\tGeneral\tEnglish' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18318.078125\n",
      "page_content='[468]\tGPT-3.5, ChatGPT\tText Summarization, Dialogue Generation, Story Generation, Paraphrase Generation\tZS\tNo\tGeneral\tEnglish\n",
      "[474]\tGPT-3.5, ChatGPT\tMachine Translation\tZS, FS\tYes\tGeneral\tEnglish, Chinese, German\n",
      "[475]\tChatGPT\tText Summarization\tZS\tNo\tGeneral\tEnglish\n",
      "[476]\tChatGPT\tText Summarization\tZS\tNo\tGeneral\tEnglish\n",
      "[285]\tGPT-4\tText-to-Image Synthesis\tZS\tN/A\tGeneral\tEnglish\n",
      "[426]\tGPT-4\tMachine Translation\tZS\tYes\tGeneral\tEnglish, German, Russian\n",
      "[477]\tGPT-3, GPT-3.5\tDialogue Generation, Machine Translation, Text Summarization, Data-to-Text Generation\tZS, FS\tNo\tGeneral\tEnglish, Chinese\n",
      "[478]\tGPT-3, ChatGPT\tText Summarization\tZS\tNo\tGeneral\tEnglish\n",
      "[479]\tChatGPT\tText Summarization\tZS\tNo\tGeneral\tEnglish\n",
      "[480]\tGPT-3.5\tMachine Translation, Text Summarization, Image Caption\tZS\tYes\tGeneral\tEnglish\n",
      "[481]\tChatGPT, GPT-4\tText Generation\tZS\tNo\tGeneral\tEnglish\n",
      "[482]\tGPT-3.5\tText Summarization\tZS\tNo\tGeneral\tEnglish' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18319.228515625\n",
      "page_content='Memory: Modules in this category leverage historically similar question-answer records to enhance current problem-solving capabilities, reflecting an evolutionary learning process within the agent [35]. Drawing on this concept, we employ a parameter-free caching mechanism to expand the knowledge boundaries of RAG-based question-answering, effectively improving response efficiency.\n",
      "Retrieve Trigger: Understanding the parameterized knowledge boundaries of LLMs is crucial for optimizing the timing of knowledge retrieval. Calibration-based judgment methods have proven both efficient and practical. However, our study explores a nonparametric knowledge domain within a continuously expanding RAG system. This is the first attempt to design a Retrieve Trigger specifically for such scenarios. Our exploration focuses on identifying appropriate thresholds that balance accuracy and efficiency.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18319.228515625\n",
      "page_content='Memory: Modules in this category leverage historically similar question-answer records to enhance current problem-solving capabilities, reflecting an evolutionary learning process within the agent [35]. Drawing on this concept, we employ a parameter-free caching mechanism to expand the knowledge boundaries of RAG-based question-answering, effectively improving response efficiency.\n",
      "Retrieve Trigger: Understanding the parameterized knowledge boundaries of LLMs is crucial for optimizing the timing of knowledge retrieval. Calibration-based judgment methods have proven both efficient and practical. However, our study explores a nonparametric knowledge domain within a continuously expanding RAG system. This is the first attempt to design a Retrieve Trigger specifically for such scenarios. Our exploration focuses on identifying appropriate thresholds that balance accuracy and efficiency.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18331.431640625\n",
      "page_content='In addition to the above studies, pseudo query generation methods are also introduced in other application scenarios, such as conversational dense retrieval [90] and multilingual dense retrieval [114].\n",
      "•\tRelevance label generation. In some downstream tasks of retrieval, such as question-answering, the collection of questions is also sufficient. However, the relevance labels connecting these questions with the passages of supporting evidence are very limited. In this context, leveraging the capability of LLMs for relevance label generation is a promising approach that can augment the training corpus for retrievers. A recent method, ART [111], exemplifies this approach. It first retrieves the top-relevant passages for each question. Then, it employs an LLM to produce the generation probabilities of the question conditioned on these top\n",
      "Few-shot prompt\n",
      "Example 1:' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18331.431640625\n",
      "page_content='In addition to the above studies, pseudo query generation methods are also introduced in other application scenarios, such as conversational dense retrieval [90] and multilingual dense retrieval [114].\n",
      "•\tRelevance label generation. In some downstream tasks of retrieval, such as question-answering, the collection of questions is also sufficient. However, the relevance labels connecting these questions with the passages of supporting evidence are very limited. In this context, leveraging the capability of LLMs for relevance label generation is a promising approach that can augment the training corpus for retrievers. A recent method, ART [111], exemplifies this approach. It first retrieves the top-relevant passages for each question. Then, it employs an LLM to produce the generation probabilities of the question conditioned on these top\n",
      "Few-shot prompt\n",
      "Example 1:' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18336.46875\n",
      "page_content='[188]\tM. Bommarito II and D. M. Katz, “Gpt takes the bar exam,” arXiv preprint arXiv:2212.14402, 2022.\n",
      "[189]\tJ. Pereira, R. Fidalgo, R. Lotufo, and R. Nogueira, “Visconde: Multi-document qa with gpt-3 and neural reranking,” in European Conference on Information Retrieval. Springer, 2023, pp. 534–543.\n",
      "[190]\tR. Gupta, I. Herzog, J. B. Park, J. Weisberger, P. Firouzbakht, V. Ocon, J. Chao, E. S. Lee, and B. A. Mailey, “Performance of chatgpt on the plastic surgery inservice training examination,” Aesthetic surgery journal, p. sjad128, 2023.\n",
      "[191]\tY. Tanaka, T. Nakata, K. Aiga, T. Etani, R. Muramatsu, S. Katagiri, H. Kawai, F. Higashino, M. Enomoto, M. Noda et al., “Performance of generative pretrained transformer on the national medical licensing examination in japan,” medRxiv, pp. 2023–04, 2023.\n",
      "[192]\tJ. Robinson and D. Wingate, “Leveraging large language models for multiple choice question answering,” in The Eleventh International Conference on Learning Representations, 2022.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18336.46875\n",
      "page_content='[188]\tM. Bommarito II and D. M. Katz, “Gpt takes the bar exam,” arXiv preprint arXiv:2212.14402, 2022.\n",
      "[189]\tJ. Pereira, R. Fidalgo, R. Lotufo, and R. Nogueira, “Visconde: Multi-document qa with gpt-3 and neural reranking,” in European Conference on Information Retrieval. Springer, 2023, pp. 534–543.\n",
      "[190]\tR. Gupta, I. Herzog, J. B. Park, J. Weisberger, P. Firouzbakht, V. Ocon, J. Chao, E. S. Lee, and B. A. Mailey, “Performance of chatgpt on the plastic surgery inservice training examination,” Aesthetic surgery journal, p. sjad128, 2023.\n",
      "[191]\tY. Tanaka, T. Nakata, K. Aiga, T. Etani, R. Muramatsu, S. Katagiri, H. Kawai, F. Higashino, M. Enomoto, M. Noda et al., “Performance of generative pretrained transformer on the national medical licensing examination in japan,” medRxiv, pp. 2023–04, 2023.\n",
      "[192]\tJ. Robinson and D. Wingate, “Leveraging large language models for multiple choice question answering,” in The Eleventh International Conference on Learning Representations, 2022.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18337.748046875\n",
      "page_content='technology □\n",
      "politics □ sports business 3\n",
      "Figure 2: The framework of our approach applied to AG’s News (a four-class topic classification dataset, we use “politics”, “sports”, “business” and “technology” as label words). We calibrate the PLM’s original predictions on the unlabeled examples with model bias, and use calibrated predictions to annotate and refine training examples.\n",
      "However, as shown in the previous sections, due to the model bias, certain label words consistently obtain high probabilities, regardless of the semantics of the PLM’s input, which leads to many input texts being misclassified into their corresponding classes. To address this, we incorporate model bias into the data annotation process, and we propose a method to measure model bias during training with unlabeled examples.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18337.748046875\n",
      "page_content='technology □\n",
      "politics □ sports business 3\n",
      "Figure 2: The framework of our approach applied to AG’s News (a four-class topic classification dataset, we use “politics”, “sports”, “business” and “technology” as label words). We calibrate the PLM’s original predictions on the unlabeled examples with model bias, and use calibrated predictions to annotate and refine training examples.\n",
      "However, as shown in the previous sections, due to the model bias, certain label words consistently obtain high probabilities, regardless of the semantics of the PLM’s input, which leads to many input texts being misclassified into their corresponding classes. To address this, we incorporate model bias into the data annotation process, and we propose a method to measure model bias during training with unlabeled examples.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18343.359375\n",
      "page_content='7.2\tDynamic Agent\n",
      "Researches of dynamic agent can be further categorized into agent design, framework and system, and benchmark.\n",
      "7.2.1\tAgent Design\n",
      "Instead of statically arranging LLMs in a pipeline, We-bGPT [24] takes an alternate approach by training LLMs to use search engines automatically. This is achieved through the application of a reinforcement learning framework, within which a simulated environment is constructed for GPT-3 models. Specifically, the WebGPT model employs special tokens to execute actions such as querying, scrolling through rankings, and quoting references on search engines. This innovative approach allows the GPT-3 model to use' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18343.359375\n",
      "page_content='7.2\tDynamic Agent\n",
      "Researches of dynamic agent can be further categorized into agent design, framework and system, and benchmark.\n",
      "7.2.1\tAgent Design\n",
      "Instead of statically arranging LLMs in a pipeline, We-bGPT [24] takes an alternate approach by training LLMs to use search engines automatically. This is achieved through the application of a reinforcement learning framework, within which a simulated environment is constructed for GPT-3 models. Specifically, the WebGPT model employs special tokens to execute actions such as querying, scrolling through rankings, and quoting references on search engines. This innovative approach allows the GPT-3 model to use' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18369.681640625\n",
      "page_content='4.9\tCoding Tasks\n",
      "Overview. Software engineering is a discipline which deals with designing, developing, testing, and maintaining software systems [272]. To create software systems, software engineers use a variety of programming languages, development tools, and technologies. To aid software engineers and enhance their productivity, the research community focused on automating a number of coding tasks like code generation from natural language descriptions, code repair, code explanation gen-' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18369.681640625\n",
      "page_content='4.9\tCoding Tasks\n",
      "Overview. Software engineering is a discipline which deals with designing, developing, testing, and maintaining software systems [272]. To create software systems, software engineers use a variety of programming languages, development tools, and technologies. To aid software engineers and enhance their productivity, the research community focused on automating a number of coding tasks like code generation from natural language descriptions, code repair, code explanation gen-' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18372.0\n",
      "page_content='[115]\tA. Neelakantan, T. Xu, R. Puri, A. Radford, J. M. Han, J. Tworek, Q. Yuan, N. Tezak, J. W. Kim, C. Hal-lacy, J. Heidecke, P. Shyam, B. Power, T. E. Nekoul, G. Sastry, G. Krueger, D. Schnurr, F. P. Such, K. Hsu, M. Thompson, T. Khan, T. Sherbakov, J. Jang, P. Welin-der, and L. Weng, “Text and code embeddings by contrastive pre-training,” CoRR, vol. abs/2201.10005, 2022.\n",
      "[116]\tJ. Ni, C. Qu, J. Lu, Z. Dai, G. H. A´ brego, J. Ma, V. Y. Zhao, Y. Luan, K. B. Hall, M. Chang, and Y. Yang, “Large dual encoders are generalizable retrievers,” in EMNLP. Association for Computational Linguistics, 2022, pp. 9844–9855.\n",
      "[117]\tN. Muennighoff, “SGPT: GPT sentence embeddings for semantic search,” CoRR, vol. abs/2202.08904, 2022.\n",
      "[118]\tB. Peng, C. Li, P. He, M. Galley, and J. Gao, “Instruction tuning with GPT-4,” CoRR, vol. abs/2304.03277, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18372.0\n",
      "page_content='[115]\tA. Neelakantan, T. Xu, R. Puri, A. Radford, J. M. Han, J. Tworek, Q. Yuan, N. Tezak, J. W. Kim, C. Hal-lacy, J. Heidecke, P. Shyam, B. Power, T. E. Nekoul, G. Sastry, G. Krueger, D. Schnurr, F. P. Such, K. Hsu, M. Thompson, T. Khan, T. Sherbakov, J. Jang, P. Welin-der, and L. Weng, “Text and code embeddings by contrastive pre-training,” CoRR, vol. abs/2201.10005, 2022.\n",
      "[116]\tJ. Ni, C. Qu, J. Lu, Z. Dai, G. H. A´ brego, J. Ma, V. Y. Zhao, Y. Luan, K. B. Hall, M. Chang, and Y. Yang, “Large dual encoders are generalizable retrievers,” in EMNLP. Association for Computational Linguistics, 2022, pp. 9844–9855.\n",
      "[117]\tN. Muennighoff, “SGPT: GPT sentence embeddings for semantic search,” CoRR, vol. abs/2202.08904, 2022.\n",
      "[118]\tB. Peng, C. Li, P. He, M. Galley, and J. Gao, “Instruction tuning with GPT-4,” CoRR, vol. abs/2304.03277, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18372.41796875\n",
      "page_content='In practice, it is costly to generate a substantial number of pseudo queries through LLMs. Balancing the generation costs and the quality of generated samples has become an urgent problem. To tackle this, UDAPDR [108] is proposed, which first produces a limited set of synthetic queries using LLMs for the target domain. These high-quality examples are subsequently used as prompts for a smaller model to generate a large number of queries, thereby constructing the training set for that specific domain. It is worth noting that the aforementioned studies primarily rely on fixed LLMs with frozen parameters. Empirically, optimizing LLMs’ parameters can significantly improve their performance on downstream tasks. Unfortunately, this pursuit is impeded by the prohibitively high demand for computational resources. To overcome this obstacle, SPTAR [109] introduces a soft prompt tuning technique that only optimizes the prompts’ embedding layer during the training process. This approach allows' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18372.41796875\n",
      "page_content='In practice, it is costly to generate a substantial number of pseudo queries through LLMs. Balancing the generation costs and the quality of generated samples has become an urgent problem. To tackle this, UDAPDR [108] is proposed, which first produces a limited set of synthetic queries using LLMs for the target domain. These high-quality examples are subsequently used as prompts for a smaller model to generate a large number of queries, thereby constructing the training set for that specific domain. It is worth noting that the aforementioned studies primarily rely on fixed LLMs with frozen parameters. Empirically, optimizing LLMs’ parameters can significantly improve their performance on downstream tasks. Unfortunately, this pursuit is impeded by the prohibitively high demand for computational resources. To overcome this obstacle, SPTAR [109] introduces a soft prompt tuning technique that only optimizes the prompts’ embedding layer during the training process. This approach allows' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18380.755859375\n",
      "page_content='To address the issue of redundant retrieval, we introduce the Memory Knowledge Reservoir, a non-parametric module that enhances the RAG system’s knowledge base through a caching mechanism. This module facilitates rapid information retrieval for recurring queries, thereby eliminating redundant external knowledge search. To avoid the situation that the retrieved cached information is insufficient, we design the Retrieval Trigger, which employs a simple and effective calibration-based approach, to determine whether to engage external knowledge retrieval.\n",
      "These four modular advancements work synergistically to enhance the RAG framework, significantly improving the accuracy and effi-\n",
      "ciency of responses. The integration and functionality of our proposed modules within the RAG system are illustrated in Figure 1. In summary, our main contributions are as follows:' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18380.755859375\n",
      "page_content='To address the issue of redundant retrieval, we introduce the Memory Knowledge Reservoir, a non-parametric module that enhances the RAG system’s knowledge base through a caching mechanism. This module facilitates rapid information retrieval for recurring queries, thereby eliminating redundant external knowledge search. To avoid the situation that the retrieved cached information is insufficient, we design the Retrieval Trigger, which employs a simple and effective calibration-based approach, to determine whether to engage external knowledge retrieval.\n",
      "These four modular advancements work synergistically to enhance the RAG framework, significantly improving the accuracy and effi-\n",
      "ciency of responses. The integration and functionality of our proposed modules within the RAG system are illustrated in Figure 1. In summary, our main contributions are as follows:' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18383.185546875\n",
      "page_content='[290]\tM. Ranjit, G. Ganapathy, R. Manuel, and T. Ganu, “Retrieval augmented chest x-ray report generation using openai gpt models,” arXiv preprint arXiv:2305.03660, 2023.\n",
      "[291]\tS. S. Kalakonda, S. Maheshwari, and R. K. Sarvadevabhatla, “Action-gpt: Leveraging large-scale language models for improved and generalized zero shot action generation,” arXiv preprint arXiv:2211.15603, 2022.\n",
      "[292]\tC. Wu, S. Yin, W. Qi, X. Wang, Z. Tang, and N. Duan, “Visual chatgpt: Talking, drawing and editing with visual foundation models,” arXiv preprint arXiv:2303.04671, 2023.\n",
      "[293]\tZ. Yang, L. Li, J. Wang, K. Lin, E. Azarnasab, F. Ahmed, Z. Liu, C. Liu, M. Zeng, and L. Wang, “Mm-react: Prompting chatgpt for multimodal reasoning and action,” arXiv preprint arXiv:2303.11381, 2023.\n",
      "[294]\tJ. Li, H. Li, Z. Pan, and G. Pan, “Prompt chatgpt in mner: Improved multimodal named entity recognition method based on auxiliary refining knowledge from chatgpt,” arXiv preprint arXiv:2305.12212, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18383.185546875\n",
      "page_content='[290]\tM. Ranjit, G. Ganapathy, R. Manuel, and T. Ganu, “Retrieval augmented chest x-ray report generation using openai gpt models,” arXiv preprint arXiv:2305.03660, 2023.\n",
      "[291]\tS. S. Kalakonda, S. Maheshwari, and R. K. Sarvadevabhatla, “Action-gpt: Leveraging large-scale language models for improved and generalized zero shot action generation,” arXiv preprint arXiv:2211.15603, 2022.\n",
      "[292]\tC. Wu, S. Yin, W. Qi, X. Wang, Z. Tang, and N. Duan, “Visual chatgpt: Talking, drawing and editing with visual foundation models,” arXiv preprint arXiv:2303.04671, 2023.\n",
      "[293]\tZ. Yang, L. Li, J. Wang, K. Lin, E. Azarnasab, F. Ahmed, Z. Liu, C. Liu, M. Zeng, and L. Wang, “Mm-react: Prompting chatgpt for multimodal reasoning and action,” arXiv preprint arXiv:2303.11381, 2023.\n",
      "[294]\tJ. Li, H. Li, Z. Pan, and G. Pan, “Prompt chatgpt in mner: Improved multimodal named entity recognition method based on auxiliary refining knowledge from chatgpt,” arXiv preprint arXiv:2305.12212, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18385.35546875\n",
      "page_content='3.1\tRewriting Scenarios\n",
      "In the realm of IR, a query rewriter is primarily designed to serve two distinct scenarios: ad-hoc retrieval and con-\n",
      "TABLE 1. Overview of existing LLM-based query rewriting methods. “Knowledge” denotes the source of information the method employs for query rewriting. “SFT” and “RL” denotes supervised fine-tuning and reinforcement learning, respectively. “Q”, “K”, and “A” refer to question, keyword, and answer-incorporated passages, respectively.\n",
      "Scenario Knowledge\t\tApproach\tFormat\tMethod\n",
      "\tLLMs\tPrompting\tA\tHyDE [75]\n",
      "\tLLM\tPrompting\tA\tJagerman et al. [76]\n",
      "\tLLM\tPrompting\tA\tQuery2Doc [65]\n",
      "\tLLM\tPrompting\tA\tBaek et al. [77]\n",
      "\tLLM\tPrompting\tQ\tAlaofi et al. [78]\n",
      "\tLLM\tPrompting\tK\tLi et al. [79]\n",
      "\tLLM\tRL\tK\tMa et al. [80]\n",
      "Ad-hoc\tLLM\tSFT & RL\tK\tBEQUE [81]\n",
      "\tLLM + Corpora\tPrompting\tK\tGRF+PRF [82]\n",
      "\tLLM + Corpora\tPrompting\tA\tGRM [83]\n",
      "\tLLM + Corpora\tPrompting\tA\tInteR [84]\n",
      "\tLLM + Corpora\tPrompting\tA\tLameR [85]\n",
      "\tLLM + Corpora\tPrompting\tA\tCSQE [86]' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18385.35546875\n",
      "page_content='3.1\tRewriting Scenarios\n",
      "In the realm of IR, a query rewriter is primarily designed to serve two distinct scenarios: ad-hoc retrieval and con-\n",
      "TABLE 1. Overview of existing LLM-based query rewriting methods. “Knowledge” denotes the source of information the method employs for query rewriting. “SFT” and “RL” denotes supervised fine-tuning and reinforcement learning, respectively. “Q”, “K”, and “A” refer to question, keyword, and answer-incorporated passages, respectively.\n",
      "Scenario Knowledge\t\tApproach\tFormat\tMethod\n",
      "\tLLMs\tPrompting\tA\tHyDE [75]\n",
      "\tLLM\tPrompting\tA\tJagerman et al. [76]\n",
      "\tLLM\tPrompting\tA\tQuery2Doc [65]\n",
      "\tLLM\tPrompting\tA\tBaek et al. [77]\n",
      "\tLLM\tPrompting\tQ\tAlaofi et al. [78]\n",
      "\tLLM\tPrompting\tK\tLi et al. [79]\n",
      "\tLLM\tRL\tK\tMa et al. [80]\n",
      "Ad-hoc\tLLM\tSFT & RL\tK\tBEQUE [81]\n",
      "\tLLM + Corpora\tPrompting\tK\tGRF+PRF [82]\n",
      "\tLLM + Corpora\tPrompting\tA\tGRM [83]\n",
      "\tLLM + Corpora\tPrompting\tA\tInteR [84]\n",
      "\tLLM + Corpora\tPrompting\tA\tLameR [85]\n",
      "\tLLM + Corpora\tPrompting\tA\tCSQE [86]' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18391.88671875\n",
      "page_content='6. https://neoteric.eu/blog/how-much-does-it-cost-to-use-gpt-\n",
      "models-gpt-3-pricing-explained\n",
      "uses cache to avoid querying GLLM for similar queries, which eventually reduces overall inference costs. Similarly, Cheng et al. [504] proposed batch prompting, which involves GLLM inference in batches rather than processing one sample individually. The authors demonstrated that the proposed prompting strategy reduces Codex model inference cost across ten datasets with little or no degradation in the performance. Future research in this direction will result in much better approaches which will further reduce the GLLM inference costs and make GLLM usage more affordable for companies.\n",
      "11.6\tEnhance Performance in Domain-Specific NLP Tasks' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18391.88671875\n",
      "page_content='6. https://neoteric.eu/blog/how-much-does-it-cost-to-use-gpt-\n",
      "models-gpt-3-pricing-explained\n",
      "uses cache to avoid querying GLLM for similar queries, which eventually reduces overall inference costs. Similarly, Cheng et al. [504] proposed batch prompting, which involves GLLM inference in batches rather than processing one sample individually. The authors demonstrated that the proposed prompting strategy reduces Codex model inference cost across ten datasets with little or no degradation in the performance. Future research in this direction will result in much better approaches which will further reduce the GLLM inference costs and make GLLM usage more affordable for companies.\n",
      "11.6\tEnhance Performance in Domain-Specific NLP Tasks' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18408.37890625\n",
      "page_content='research community focused on developing large language models using self-supervised learning at a large scale [4], [40]– [42], [68]. To summarize, self-supervised is undergoing a rapid evolution and is also treated as a significant element in achieving near human-level intelligence [22].' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18408.37890625\n",
      "page_content='research community focused on developing large language models using self-supervised learning at a large scale [4], [40]– [42], [68]. To summarize, self-supervised is undergoing a rapid evolution and is also treated as a significant element in achieving near human-level intelligence [22].' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18409.859375\n",
      "page_content='until the iterations reach a pre-defined limitation. Particularly, these methods can be regarded as special periodic-retrieval readers that retrieve passages when every answer is (re)-generated. Since the LLMs can receive more comprehensive and relevant references with the iterations increase, these methods that combine RAG and generation-augmented retrieval strategies can generate more accurate answers but consume more computation costs.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18409.859375\n",
      "page_content='until the iterations reach a pre-defined limitation. Particularly, these methods can be regarded as special periodic-retrieval readers that retrieve passages when every answer is (re)-generated. Since the LLMs can receive more comprehensive and relevant references with the iterations increase, these methods that combine RAG and generation-augmented retrieval strategies can generate more accurate answers but consume more computation costs.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18409.998046875\n",
      "page_content='4https://www.iso.org/standard/64076.html\n",
      "•\tleaking fluid, Leaking\n",
      "•\ttoo hot, Overheating\n",
      "•\ttriping, Electrical\n",
      "•\tnot starting, Failure to start on demand\n",
      "This open data set and the model presented in [Stewart et al., 2022] represent the state-of-the-art for FMC in the literature at this point in time and hence are used for comparative purposes.\n",
      "2.2\tModels\n",
      "We evaluate the following models:\n",
      "1.\tFlair: A Flair-based [Akbik et al., 2018] text classification model, trained on the annotated dataset.\n",
      "2.\tGPT-3.5: The off-the-shelf GPT-3.5-Turbo model from OpenAI.\n",
      "3.\tGPT-3.5 (Fine-tuned): The GPT-3.5-Turbo model, fine-tuned on the annotated dataset.\n",
      "The Flair model is a Bidirectional Long Short-Term Memory-based [Hochreiter and Schmidhuber, 1997] text classification model that takes a sequence of text as input, and predicts a single label. This is the same model as used in [Stewart et al., 2022], and further implementation details are available in the respective paper.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Stewart 等 - 2023 - Large Language Models for Failure Mode Classification An Investigation.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18409.998046875\n",
      "page_content='4https://www.iso.org/standard/64076.html\n",
      "•\tleaking fluid, Leaking\n",
      "•\ttoo hot, Overheating\n",
      "•\ttriping, Electrical\n",
      "•\tnot starting, Failure to start on demand\n",
      "This open data set and the model presented in [Stewart et al., 2022] represent the state-of-the-art for FMC in the literature at this point in time and hence are used for comparative purposes.\n",
      "2.2\tModels\n",
      "We evaluate the following models:\n",
      "1.\tFlair: A Flair-based [Akbik et al., 2018] text classification model, trained on the annotated dataset.\n",
      "2.\tGPT-3.5: The off-the-shelf GPT-3.5-Turbo model from OpenAI.\n",
      "3.\tGPT-3.5 (Fine-tuned): The GPT-3.5-Turbo model, fine-tuned on the annotated dataset.\n",
      "The Flair model is a Bidirectional Long Short-Term Memory-based [Hochreiter and Schmidhuber, 1997] text classification model that takes a sequence of text as input, and predicts a single label. This is the same model as used in [Stewart et al., 2022], and further implementation details are available in the respective paper.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Stewart 等 - 2023 - Large Language Models for Failure Mode Classification An Investigation.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18413.95703125\n",
      "page_content='score =\n",
      "||| X logp(qi|q<i,d, P),\n",
      "(2)\n",
      "5.2.1 Pointwise methods\n",
      "The pointwise methods measure the relevance between a query and a single document, and can be categorized into two types: relevance generation [150–152, 157] and query generation [153, 154, 156].\n",
      "The upper part in Figure 5 (a) shows an example of relevance generation based on a given prompt, where LLMs output a binary label (“Yes” or “No”) based on whether the document is relevant to the query. Following [13], the querydocument relevance score f (q,d) can be calculated based on the log-likelihood of token “Yes” and “No” with a softmax function:\n",
      "f (q, d) =\n",
      "exp(SY)\n",
      "exp(SY) + exp(SN) ’\n",
      "(1)' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18413.95703125\n",
      "page_content='score =\n",
      "||| X logp(qi|q<i,d, P),\n",
      "(2)\n",
      "5.2.1 Pointwise methods\n",
      "The pointwise methods measure the relevance between a query and a single document, and can be categorized into two types: relevance generation [150–152, 157] and query generation [153, 154, 156].\n",
      "The upper part in Figure 5 (a) shows an example of relevance generation based on a given prompt, where LLMs output a binary label (“Yes” or “No”) based on whether the document is relevant to the query. Following [13], the querydocument relevance score f (q,d) can be calculated based on the log-likelihood of token “Yes” and “No” with a softmax function:\n",
      "f (q, d) =\n",
      "exp(SY)\n",
      "exp(SY) + exp(SN) ’\n",
      "(1)' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18423.720703125\n",
      "page_content='results to achieve a more accurate and a positionally unbiased ranking. Chen et al. [162] introduce a tournament mechanism into listwise ranking and propose TourRank, which parallelizes the reranking process through intelligent grouping and use a tournament-like points system to reduce the impact of the initial document order. Parry et al. [163] propose a parallelizable partitioning algorithm for listwise ranking, which also aims at mitigating efficiency issues. Reddy et al. [178] propose a novel listwise reranking approach which leverages the output logits of the first generated identifier to derive a ranked passage list.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18423.720703125\n",
      "page_content='results to achieve a more accurate and a positionally unbiased ranking. Chen et al. [162] introduce a tournament mechanism into listwise ranking and propose TourRank, which parallelizes the reranking process through intelligent grouping and use a tournament-like points system to reduce the impact of the initial document order. Parry et al. [163] propose a parallelizable partitioning algorithm for listwise ranking, which also aims at mitigating efficiency issues. Reddy et al. [178] propose a novel listwise reranking approach which leverages the output logits of the first generated identifier to derive a ranked passage list.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18439.849609375\n",
      "page_content='since model parameters are untuned. Conversely, we consider model bias while annotating examples and propose unlabeled validation to measure and eliminate model bias during training.\n",
      "3.\tOur Approach\n",
      "Our approach annotates examples with high quality from unlabeled examples based on prompt tuning and uses unlabeled examples to measure model bias on label words during training. The overview of our approach is illustrated in Figure 2. In this section, we first introduce the background of prompt tuning (Section 3.1), then present the process of annotating and refining examples (Section 3.2, 3.3), and finally, we describe how unlabeled examples can be used to eliminate model bias (Section 3.4).\n",
      "3.1.\tProblem Definition' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18439.849609375\n",
      "page_content='since model parameters are untuned. Conversely, we consider model bias while annotating examples and propose unlabeled validation to measure and eliminate model bias during training.\n",
      "3.\tOur Approach\n",
      "Our approach annotates examples with high quality from unlabeled examples based on prompt tuning and uses unlabeled examples to measure model bias on label words during training. The overview of our approach is illustrated in Figure 2. In this section, we first introduce the background of prompt tuning (Section 3.1), then present the process of annotating and refining examples (Section 3.2, 3.3), and finally, we describe how unlabeled examples can be used to eliminate model bias (Section 3.4).\n",
      "3.1.\tProblem Definition' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18443.322265625\n",
      "page_content='B. Lester, R. Al-Rfou, and N. Constant, “The power of scale for parameter-efficient prompt tuning,” in Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021, Virtual Event / Punta Cana, Dominican Republic, 7-11 November, 2021, M. Moens, X. Huang, L. Specia, and S. W. Yih, Eds. Association for Computational Linguistics, 2021, pp. 3045–3059.\n",
      "T. Dettmers, A. Pagnoni, A. Holtzman, and L. Zettle-moyer, “Qlora: Efficient finetuning of quantized llms,” CoRR, vol. abs/2305.14314, 2023.\n",
      "L. Wang, N. Yang, and F. Wei, “Query2doc: Query expansion with large language models,” pp. 9414– 9423, 2023.\n",
      "H. K. Azad and A. Deepak, “Query expansion techniques for information retrieval: A survey,” Inf. Process. Manag., vol. 56, no. 5, pp. 1698–1735, 2019.\n",
      "H. J. Peat and P. Willett, “The limitations of term co-occurrence data for query expansion in document retrieval systems,” J. Am. Soc. Inf. Sci., vol. 42, no. 5, pp. 378–383, 1991.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18443.322265625\n",
      "page_content='B. Lester, R. Al-Rfou, and N. Constant, “The power of scale for parameter-efficient prompt tuning,” in Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021, Virtual Event / Punta Cana, Dominican Republic, 7-11 November, 2021, M. Moens, X. Huang, L. Specia, and S. W. Yih, Eds. Association for Computational Linguistics, 2021, pp. 3045–3059.\n",
      "T. Dettmers, A. Pagnoni, A. Holtzman, and L. Zettle-moyer, “Qlora: Efficient finetuning of quantized llms,” CoRR, vol. abs/2305.14314, 2023.\n",
      "L. Wang, N. Yang, and F. Wei, “Query2doc: Query expansion with large language models,” pp. 9414– 9423, 2023.\n",
      "H. K. Azad and A. Deepak, “Query expansion techniques for information retrieval: A survey,” Inf. Process. Manag., vol. 56, no. 5, pp. 1698–1735, 2019.\n",
      "H. J. Peat and P. Willett, “The limitations of term co-occurrence data for query expansion in document retrieval systems,” J. Am. Soc. Inf. Sci., vol. 42, no. 5, pp. 378–383, 1991.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18446.630859375\n",
      "page_content='We design several metrics to evaluate the resource cost of perquestion, include the average time spent in the RAG pipeline (Time Cost), the average number of external knowledge instances (External Knowledge), the average number of memory knowledge instances (Memory Knowledge), the average number of knowledge instances filtered out (Irrelevant Knowledge), and the performance metric Hit Rate. These metrics are recorded during the question-answering process.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18446.630859375\n",
      "page_content='We design several metrics to evaluate the resource cost of perquestion, include the average time spent in the RAG pipeline (Time Cost), the average number of external knowledge instances (External Knowledge), the average number of memory knowledge instances (Memory Knowledge), the average number of knowledge instances filtered out (Irrelevant Knowledge), and the performance metric Hit Rate. These metrics are recorded during the question-answering process.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18459.75\n",
      "page_content='Rajpoot et al. [358] assessed the effectiveness of Chat-GPT and GPT-4 for financial relation extraction in fewshot settings. As the choice of examples is crucial in few-shot ICL, the authors explored learning free and learning-based retriever for example selection. The authors observed that GPT-4 outperforms ChatGPT by a decent margin, and the learning-based retriever performs better than the learning-free retriever.\n",
      "6\tMultilingual Performance of GLLMs' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18459.75\n",
      "page_content='Rajpoot et al. [358] assessed the effectiveness of Chat-GPT and GPT-4 for financial relation extraction in fewshot settings. As the choice of examples is crucial in few-shot ICL, the authors explored learning free and learning-based retriever for example selection. The authors observed that GPT-4 outperforms ChatGPT by a decent margin, and the learning-based retriever performs better than the learning-free retriever.\n",
      "6\tMultilingual Performance of GLLMs' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18463.634765625\n",
      "page_content='[19]\tD. Lee, S. Kim, M. Lee, H. Lee, J. Park, S.-W. Lee, and K. Jung. Asking clarification questions to handle ambiguity in open-domain QA. In H. Bouamor, J. Pino, and K. Bali, editors, Findings of the Association for Computational Linguistics: EMNLP 2023, pages 11526–11544, Singapore, Dec. 2023. Association for Computational Linguistics. doi: 10.18653/v1/2023.findings- emnlp.772. URL https://aclanthology.org/ 2023.findings-emnlp.772.\n",
      "[20]\tP. Lewis, E. Perez, A. Piktus, F. Petroni, V. Karpukhin, N. Goyal, H. Küttler, M. Lewis, W.-t. Yih, T. Rocktäschel, et al. Retrieval-augmented generation for knowledge-intensive nlp tasks. Advances in Neural Information Processing Systems, 33:9459–9474, 2020.\n",
      "[21]\tX. Li, E. Nie, and S. Liang. From classification to generation: Insights into crosslingual retrieval augmented icl, 2023.\n",
      "[22]\tJ. Liu, J. Jin, Z. Wang, J. Cheng, Z. Dou, and J.-R. Wen. Reta-llm: A retrieval-augmented large language model toolkit. arXiv preprint arXiv:2306.05212, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18463.634765625\n",
      "page_content='[19]\tD. Lee, S. Kim, M. Lee, H. Lee, J. Park, S.-W. Lee, and K. Jung. Asking clarification questions to handle ambiguity in open-domain QA. In H. Bouamor, J. Pino, and K. Bali, editors, Findings of the Association for Computational Linguistics: EMNLP 2023, pages 11526–11544, Singapore, Dec. 2023. Association for Computational Linguistics. doi: 10.18653/v1/2023.findings- emnlp.772. URL https://aclanthology.org/ 2023.findings-emnlp.772.\n",
      "[20]\tP. Lewis, E. Perez, A. Piktus, F. Petroni, V. Karpukhin, N. Goyal, H. Küttler, M. Lewis, W.-t. Yih, T. Rocktäschel, et al. Retrieval-augmented generation for knowledge-intensive nlp tasks. Advances in Neural Information Processing Systems, 33:9459–9474, 2020.\n",
      "[21]\tX. Li, E. Nie, and S. Liang. From classification to generation: Insights into crosslingual retrieval augmented icl, 2023.\n",
      "[22]\tJ. Liu, J. Jin, Z. Wang, J. Cheng, Z. Dou, and J.-R. Wen. Reta-llm: A retrieval-augmented large language model toolkit. arXiv preprint arXiv:2306.05212, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18465.25\n",
      "page_content='[347]\tJ. H. Choi, K. E. Hickman, A. Monahan, and D. Schwarcz, “Chatgpt goes to law school,” Available at SSRN, 2023.\n",
      "[348]\tX. Cai, S. Liu, J. Han, L. Yang, Z. Liu, and T. Liu, “Chestxray-bert: A pretrained language model for chest radiology report summarization,” IEEE Transactions on Multimedia, 2021.\n",
      "[349]\tH. Xiong, S. Wang, Y. Zhu, Z. Zhao, Y. Liu, Q. Wang, and D. Shen, “Doctorglm: Fine-tuning your chinese doctor is not a herculean task,” arXiv preprint arXiv:2304.01097, 2023.\n",
      "[350]\tA. B. Abacha, W.-w. Yim, G. Adams, N. Snider, and M. Yetisgen-Yildiz, “Overview of the mediqa-chat 2023 shared tasks on the summarization & generation of doctor-patient conversations,” in Proceedings of the 5th Clinical Natural Language Processing Workshop, 2023, pp. 503–513.\n",
      "[351]\tH. Su, J. Kasai, Y. Wang, Y. Hu, M. Ostendorf, W.-t. Yih, N. A. Smith, L. Zettlemoyer, T. Yu et al., “One embedder, any task: Instruction-finetuned text embeddings,” arXiv preprint arXiv:2212.09741, 2022.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18465.25\n",
      "page_content='[347]\tJ. H. Choi, K. E. Hickman, A. Monahan, and D. Schwarcz, “Chatgpt goes to law school,” Available at SSRN, 2023.\n",
      "[348]\tX. Cai, S. Liu, J. Han, L. Yang, Z. Liu, and T. Liu, “Chestxray-bert: A pretrained language model for chest radiology report summarization,” IEEE Transactions on Multimedia, 2021.\n",
      "[349]\tH. Xiong, S. Wang, Y. Zhu, Z. Zhao, Y. Liu, Q. Wang, and D. Shen, “Doctorglm: Fine-tuning your chinese doctor is not a herculean task,” arXiv preprint arXiv:2304.01097, 2023.\n",
      "[350]\tA. B. Abacha, W.-w. Yim, G. Adams, N. Snider, and M. Yetisgen-Yildiz, “Overview of the mediqa-chat 2023 shared tasks on the summarization & generation of doctor-patient conversations,” in Proceedings of the 5th Clinical Natural Language Processing Workshop, 2023, pp. 503–513.\n",
      "[351]\tH. Su, J. Kasai, Y. Wang, Y. Hu, M. Ostendorf, W.-t. Yih, N. A. Smith, L. Zettlemoyer, T. Yu et al., “One embedder, any task: Instruction-finetuned text embeddings,” arXiv preprint arXiv:2212.09741, 2022.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18466.36328125\n",
      "page_content='a significant step towards generating comprehensive responses instead of mere document lists. The integration of LLMs into IR systems has brought about a fundamental change in how users engage with information and knowledge. From query rewriter to retrieval, reranking, and reader modules, LLMs have enriched each aspect of the IR process with advanced linguistic comprehension, semantic representation, and context-sensitive handling. As this field continues to progress, the journey of LLMs in IR portends a future characterized by more personalized, precise, and user-centric search encounters.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18466.36328125\n",
      "page_content='a significant step towards generating comprehensive responses instead of mere document lists. The integration of LLMs into IR systems has brought about a fundamental change in how users engage with information and knowledge. From query rewriter to retrieval, reranking, and reader modules, LLMs have enriched each aspect of the IR process with advanced linguistic comprehension, semantic representation, and context-sensitive handling. As this field continues to progress, the journey of LLMs in IR portends a future characterized by more personalized, precise, and user-centric search encounters.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18472.01171875\n",
      "page_content='the generated reasoning text is fluent. And scores of logic faithful are larger than 93%, which is in line with our expectation that LLMs can generate reasonable explanations.\n",
      "7\tConclusion\n",
      "In this paper, we introduce Clue And Reasoning Prompting (CARP) for text classification task. CARP yields new SOTA performances on 4 out of 5 widely-used text-classification benchmarks. More importantly, we find that CARP delivers impressive abilities on low-resource and domainadaption setups. In the future, we would like to explore CARP on more natural language understanding tasks.\n",
      "References\n",
      "Samuel R. Bowman, Gabor Angeli, Christopher Potts, and Christopher D. Manning. 2015. A large annotated corpus for learning natural language inference. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP). Association for Computational Linguistics.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18472.01171875\n",
      "page_content='the generated reasoning text is fluent. And scores of logic faithful are larger than 93%, which is in line with our expectation that LLMs can generate reasonable explanations.\n",
      "7\tConclusion\n",
      "In this paper, we introduce Clue And Reasoning Prompting (CARP) for text classification task. CARP yields new SOTA performances on 4 out of 5 widely-used text-classification benchmarks. More importantly, we find that CARP delivers impressive abilities on low-resource and domainadaption setups. In the future, we would like to explore CARP on more natural language understanding tasks.\n",
      "References\n",
      "Samuel R. Bowman, Gabor Angeli, Christopher Potts, and Christopher D. Manning. 2015. A large annotated corpus for learning natural language inference. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP). Association for Computational Linguistics.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18472.3515625\n",
      "page_content='Figure 3 presents the self-supervised learning paradigm. In the pretraining phase, the labels are automatically generated based on the description of pretraining tasks, and the models learn universal knowledge using the pseudo supervision offered by\n",
      "one or more pretraining tasks. Pretraining helps the models to gain strong background knowledge, which allows the models to provide a good initialization to downstream models. The initialization from pretrained models enhances the downstream models in terms of generalization, performance, and robustness and makes them data efficient. After pretraining, pretrained language models can be easily adapted to downstream tasks with limited labelled data, and large language models can be used to solve downstream tasks using in-context learning without any task-specific fine-tuning.\n",
      "2.3.3\tEvolution of Self-Supervised Learning' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18472.3515625\n",
      "page_content='Figure 3 presents the self-supervised learning paradigm. In the pretraining phase, the labels are automatically generated based on the description of pretraining tasks, and the models learn universal knowledge using the pseudo supervision offered by\n",
      "one or more pretraining tasks. Pretraining helps the models to gain strong background knowledge, which allows the models to provide a good initialization to downstream models. The initialization from pretrained models enhances the downstream models in terms of generalization, performance, and robustness and makes them data efficient. After pretraining, pretrained language models can be easily adapted to downstream tasks with limited labelled data, and large language models can be used to solve downstream tasks using in-context learning without any task-specific fine-tuning.\n",
      "2.3.3\tEvolution of Self-Supervised Learning' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18473.6328125\n",
      "page_content='machine-generated text. In general, smaller models serve as more effective universal text detectors. These models exhibit better accuracy in identifying text produced by both small and larger models. For example, OPT-125M achieves better results compared to the GPT-J 6B model in detecting ChatGPT-generated text.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18473.6328125\n",
      "page_content='machine-generated text. In general, smaller models serve as more effective universal text detectors. These models exhibit better accuracy in identifying text produced by both small and larger models. For example, OPT-125M achieves better results compared to the GPT-J 6B model in detecting ChatGPT-generated text.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18478.5625\n",
      "page_content='﻿A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4\n",
      "Katikapalli Subramanyam Kalyan Akmmus AI, Trichy, India\n",
      "Email: kalyan@akmmusai.pro, Website: https:// www.akmmusai.pro' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18478.5625\n",
      "page_content='﻿A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4\n",
      "Katikapalli Subramanyam Kalyan Akmmus AI, Trichy, India\n",
      "Email: kalyan@akmmusai.pro, Website: https:// www.akmmusai.pro' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18479.0078125\n",
      "page_content='[290]\tGPT-3.5, ChatGPT, GPT-4\tChest X-Ray Report Generation\tZS\tImage + Language\tHealthcare\n",
      "[283]\tGPT-3\tKnowledge-based Visual Question Answering\tFS\tImage + Language\tGeneral\n",
      "[299]\tGPT-3.5\tFive Video Understanding Tasks\tZS\tVideo + Language\tGeneral\n",
      "[301]\tGPT-4\tGenerate Instructions\tZS\tAudio + Language\tGeneral\n",
      "[285]\tGPT-3.5, GPT-4\tEvaluator for Text-to-Image Generation\tZS\tImage + Language\tGeneral\n",
      "[286]\tGPT-3, GPT-3.5\tEditing in Text-to-Image Generation\tFS\tImage + Language\tGeneral\n",
      "[294]\tChatGPT\tMultimodal Named Entity Recognition\tFS\tImage + Language\tGeneral\n",
      "[295]\tGPT-3\tFive vision language tasks (four classification tasks and one question answering task)\tFS\tImage + Language\tGeneral\n",
      "[288]\tGPT-4\tText-to-Video Generation\tZS\tVideo + Language\tGeneral\n",
      "[179]\tGPT-3\tKnowledge-based Visual Question Answering\tFS\tImage + Language\tGeneral\n",
      "[296]\tGPT-3.5, ChatGPT, GPT-4\tLayout Generation\tFS\tImage + Language\tGeneral' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18479.0078125\n",
      "page_content='[290]\tGPT-3.5, ChatGPT, GPT-4\tChest X-Ray Report Generation\tZS\tImage + Language\tHealthcare\n",
      "[283]\tGPT-3\tKnowledge-based Visual Question Answering\tFS\tImage + Language\tGeneral\n",
      "[299]\tGPT-3.5\tFive Video Understanding Tasks\tZS\tVideo + Language\tGeneral\n",
      "[301]\tGPT-4\tGenerate Instructions\tZS\tAudio + Language\tGeneral\n",
      "[285]\tGPT-3.5, GPT-4\tEvaluator for Text-to-Image Generation\tZS\tImage + Language\tGeneral\n",
      "[286]\tGPT-3, GPT-3.5\tEditing in Text-to-Image Generation\tFS\tImage + Language\tGeneral\n",
      "[294]\tChatGPT\tMultimodal Named Entity Recognition\tFS\tImage + Language\tGeneral\n",
      "[295]\tGPT-3\tFive vision language tasks (four classification tasks and one question answering task)\tFS\tImage + Language\tGeneral\n",
      "[288]\tGPT-4\tText-to-Video Generation\tZS\tVideo + Language\tGeneral\n",
      "[179]\tGPT-3\tKnowledge-based Visual Question Answering\tFS\tImage + Language\tGeneral\n",
      "[296]\tGPT-3.5, ChatGPT, GPT-4\tLayout Generation\tFS\tImage + Language\tGeneral' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18480.609375\n",
      "page_content='generated machine reading comprehension dataset,” in CoCo@NIPS, ser. CEUR Workshop Proceedings, vol. 1773. CEUR-WS.org, 2016.\n",
      "[100]\tT. Kwiatkowski, J. Palomaki, O. Redfield, M. Collins, A. P. Parikh, C. Alberti, D. Epstein, I. Polosukhin, J. Devlin, K. Lee, K. Toutanova, L. Jones, M. Kelcey, M. Chang, A. M. Dai, J. Uszkoreit, Q. Le, and S. Petrov, “Natural questions: a benchmark for question answering research,” Trans. Assoc. Comput. Linguistics, vol. 7, pp. 452–466, 2019.\n",
      "[101]\tR. Rafailov, A. Sharma, E. Mitchell, C. D. Manning, S. Ermon, and C. Finn, “Direct preference optimization: Your language model is secretly a reward model,” in Advances in Neural Information Processing Systems 36: Annual Conference on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA, December 10 - 16, 2023, A. Oh, T. Naumann, A. Globerson, K. Saenko, M. Hardt, and S. Levine, Eds., 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18480.609375\n",
      "page_content='generated machine reading comprehension dataset,” in CoCo@NIPS, ser. CEUR Workshop Proceedings, vol. 1773. CEUR-WS.org, 2016.\n",
      "[100]\tT. Kwiatkowski, J. Palomaki, O. Redfield, M. Collins, A. P. Parikh, C. Alberti, D. Epstein, I. Polosukhin, J. Devlin, K. Lee, K. Toutanova, L. Jones, M. Kelcey, M. Chang, A. M. Dai, J. Uszkoreit, Q. Le, and S. Petrov, “Natural questions: a benchmark for question answering research,” Trans. Assoc. Comput. Linguistics, vol. 7, pp. 452–466, 2019.\n",
      "[101]\tR. Rafailov, A. Sharma, E. Mitchell, C. D. Manning, S. Ermon, and C. Finn, “Direct preference optimization: Your language model is secretly a reward model,” in Advances in Neural Information Processing Systems 36: Annual Conference on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA, December 10 - 16, 2023, A. Oh, T. Naumann, A. Globerson, K. Saenko, M. Hardt, and S. Levine, Eds., 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18496.7890625\n",
      "page_content='In all the above discussed research works, the performance of GLLMs is impressive but still lags behind SOTA results. Sun et al. [144] showed that it is possible to achieve SOTA results in text classification tasks with the newly designed clue And reasoning prompting (CARP) prompting strategy. CARP involves a progressive reasoning approach for handling complex linguistic phenomena, and it involves three steps: finding clues based on input, generating reasoning steps based on the input and the generated clues, and then arriving at the final output based on the input, generated clues and reasoning steps. Experiment results showed that the results are impressive as InstructGPT with CARP prompting strategy using just 16 examples achieves SOTA results on four text classification datasets.\n",
      "4.2\tInformation Extraction' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18496.7890625\n",
      "page_content='In all the above discussed research works, the performance of GLLMs is impressive but still lags behind SOTA results. Sun et al. [144] showed that it is possible to achieve SOTA results in text classification tasks with the newly designed clue And reasoning prompting (CARP) prompting strategy. CARP involves a progressive reasoning approach for handling complex linguistic phenomena, and it involves three steps: finding clues based on input, generating reasoning steps based on the input and the generated clues, and then arriving at the final output based on the input, generated clues and reasoning steps. Experiment results showed that the results are impressive as InstructGPT with CARP prompting strategy using just 16 examples achieves SOTA results on four text classification datasets.\n",
      "4.2\tInformation Extraction' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18507.23828125\n",
      "page_content='We evaluate InteR on public large-scale retrieval benchmarks involving web search and low-resource retrieval tasks following prior work (Gao et al., 2023). The experimental results show that InteR can conduct zero-shot retrieval with overall better performance than state-of-the-art methods, even those using relevance judgment1, and achieves new state-of-the-art zero-shot retrieval performance.\n",
      "Overall, our main contributions can be summarized as follows:\n",
      "•\tWe introduce InteR, a novel IR framework bridging two cutting-edge IR products, search systems and large language models, while enjoying their strengths and circumventing their limitations.\n",
      "•\tWe propose iterative information refinement via synergy between retrieval models and large language models, resulting in improved retrieval quality.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Feng 等 - 2023 - Synergistic Interplay between Search and Large Language Models for Information Retrieval.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18507.23828125\n",
      "page_content='We evaluate InteR on public large-scale retrieval benchmarks involving web search and low-resource retrieval tasks following prior work (Gao et al., 2023). The experimental results show that InteR can conduct zero-shot retrieval with overall better performance than state-of-the-art methods, even those using relevance judgment1, and achieves new state-of-the-art zero-shot retrieval performance.\n",
      "Overall, our main contributions can be summarized as follows:\n",
      "•\tWe introduce InteR, a novel IR framework bridging two cutting-edge IR products, search systems and large language models, while enjoying their strengths and circumventing their limitations.\n",
      "•\tWe propose iterative information refinement via synergy between retrieval models and large language models, resulting in improved retrieval quality.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Feng 等 - 2023 - Synergistic Interplay between Search and Large Language Models for Information Retrieval.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18507.56640625\n",
      "page_content='A naive strategy for implementing this function is to heuristically provide LLMs with documents relevant to the user queries or the previously generated texts to support the following generation. However, this passive approach limits LLMs to merely collecting documents from IR systems without active engagement. An alternative solution is to train LLMs to interact proactively with search engines. For example, LLMs can formulate their own queries instead of relying solely on user queries or generated texts for references. According to the way LLMs utilize IR systems in the reader module, we can categorize them into passive readers and active readers. Each approach has its advantages and challenges for implementing LLM-powered answer generation in IR systems. Furthermore, since the documents provided by upstream IR systems are sometimes too long to directly feed as input for LLMs, some compression modules are proposed to extractively or abstractively compress the retrieved contexts for' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18507.56640625\n",
      "page_content='A naive strategy for implementing this function is to heuristically provide LLMs with documents relevant to the user queries or the previously generated texts to support the following generation. However, this passive approach limits LLMs to merely collecting documents from IR systems without active engagement. An alternative solution is to train LLMs to interact proactively with search engines. For example, LLMs can formulate their own queries instead of relying solely on user queries or generated texts for references. According to the way LLMs utilize IR systems in the reader module, we can categorize them into passive readers and active readers. Each approach has its advantages and challenges for implementing LLM-powered answer generation in IR systems. Furthermore, since the documents provided by upstream IR systems are sometimes too long to directly feed as input for LLMs, some compression modules are proposed to extractively or abstractively compress the retrieved contexts for' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18521.125\n",
      "page_content='2.2.2\tWhat is Transfer Learning?\n",
      "Transfer Learning in the context of artificial intelligence involves existing knowledge transfer from one task (or domain) to another different but related task (or domain) [58], [61]. Transfer learning avoids training a model from scratch and helps improve the model’s performance on the target task (or domain) by leveraging already existing knowledge. Transfer learning is largely based on the idea that when two tasks (or domains) are similar, the knowledge from the source task (or domain) with sufficient data can be used to enhance the performance of the\n",
      "Fig. 2: Real-life examples of knowledge transfer (transfer learning). Examples are inspired from [58]' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18521.125\n",
      "page_content='2.2.2\tWhat is Transfer Learning?\n",
      "Transfer Learning in the context of artificial intelligence involves existing knowledge transfer from one task (or domain) to another different but related task (or domain) [58], [61]. Transfer learning avoids training a model from scratch and helps improve the model’s performance on the target task (or domain) by leveraging already existing knowledge. Transfer learning is largely based on the idea that when two tasks (or domains) are similar, the knowledge from the source task (or domain) with sufficient data can be used to enhance the performance of the\n",
      "Fig. 2: Real-life examples of knowledge transfer (transfer learning). Examples are inspired from [58]' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18521.318359375\n",
      "page_content='FT RoBERTa\t51.20\t52.11\t53.58\t68.29\t88.37\n",
      "ivn? MR\tGPT-3 Vanilla\t86.04\t88.68\t88.99\t89.80\t90.18\n",
      "\tGPT-3 Zero-shot-CoT\t86.26\t89.00\t90.01\t90.16\t90.89\n",
      "\tGPT-3 CRAP\t86.54\t87.19\t89.63\t90.01\t91.20\n",
      "Table 4: Experimental results on low-resource (n example per class) settings. We compare fine-tuned RoBERTa-Large with 16-shots GPT-3 setting. For GPT-3, we use SimCSE (Gao et al., 2021) to retrieve 16 annotated examples from the low-resource train set. \"cls\" represents GPT-3 makes decisions by generating label words; \"reason-cls\" denotes that GPT-3 first generates the reasoning process and then makes decisions; \"clue-reason-cls\" represents that GPT-3 finds clues in the given text, then explain the reasoning process and finally makes decisions.\n",
      "5.4\tDomain Adaptation\n",
      "It is unclear whether it is essential to train models on the specific dataset for retrieving demonstrations. In this subsection, we conduct an analysis on using demonstrations from out-ofdistribution datasets.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18521.318359375\n",
      "page_content='FT RoBERTa\t51.20\t52.11\t53.58\t68.29\t88.37\n",
      "ivn? MR\tGPT-3 Vanilla\t86.04\t88.68\t88.99\t89.80\t90.18\n",
      "\tGPT-3 Zero-shot-CoT\t86.26\t89.00\t90.01\t90.16\t90.89\n",
      "\tGPT-3 CRAP\t86.54\t87.19\t89.63\t90.01\t91.20\n",
      "Table 4: Experimental results on low-resource (n example per class) settings. We compare fine-tuned RoBERTa-Large with 16-shots GPT-3 setting. For GPT-3, we use SimCSE (Gao et al., 2021) to retrieve 16 annotated examples from the low-resource train set. \"cls\" represents GPT-3 makes decisions by generating label words; \"reason-cls\" denotes that GPT-3 first generates the reasoning process and then makes decisions; \"clue-reason-cls\" represents that GPT-3 finds clues in the given text, then explain the reasoning process and finally makes decisions.\n",
      "5.4\tDomain Adaptation\n",
      "It is unclear whether it is essential to train models on the specific dataset for retrieving demonstrations. In this subsection, we conduct an analysis on using demonstrations from out-ofdistribution datasets.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18532.53515625\n",
      "page_content='4.1\tLeveraging LLMs to Generate Search Data\n",
      "In light of the quality and quantity of search data, there are two prevalent perspectives on how to improve retrieval performance via LLMs. The first perspective revolves around search data refinement methods, which concentrate on reformulating input queries to precisely present user intents. The second perspective involves training data augmentation methods, which leverage LLMs’ generation ability to enlarge the training data for dense retrieval models, particularly in zero- or few-shot scenarios.\n",
      "4.1.1\tSearch Data Refinement' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18532.53515625\n",
      "page_content='4.1\tLeveraging LLMs to Generate Search Data\n",
      "In light of the quality and quantity of search data, there are two prevalent perspectives on how to improve retrieval performance via LLMs. The first perspective revolves around search data refinement methods, which concentrate on reformulating input queries to precisely present user intents. The second perspective involves training data augmentation methods, which leverage LLMs’ generation ability to enlarge the training data for dense retrieval models, particularly in zero- or few-shot scenarios.\n",
      "4.1.1\tSearch Data Refinement' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18533.357421875\n",
      "page_content='•\tJin et al. [241] analyze the impacts of knowledge conflict among retrieved references and LLM’s internal knowledge. and find that LLMs follow the majority rule while facing this phenomenon.\n",
      "•\tCho et al. [242], Xue et al. [243], and Chaudhari et al. [244] explore the attacking technique towards LLM-based retrieval augmented generation by poisoning retrieved passages. They find that even introducing some typos in the references may also affect the answer generation.\n",
      "•\tWang et al. [245] construct an in-domain reader evaluation dataset. They deeply analyze the effectiveness of the retrieval augmented generation paradigm under the long-tail and in-domain situations.\n",
      "•\tCuconasu et al. [246] compare the performances between readers based on base LLMs and “instructed” LLMs. Different from previous popular belief, They find base\n",
      "models outperform their corresponding instruction-tuned versions.\n",
      "6.5\tApplications' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18533.357421875\n",
      "page_content='•\tJin et al. [241] analyze the impacts of knowledge conflict among retrieved references and LLM’s internal knowledge. and find that LLMs follow the majority rule while facing this phenomenon.\n",
      "•\tCho et al. [242], Xue et al. [243], and Chaudhari et al. [244] explore the attacking technique towards LLM-based retrieval augmented generation by poisoning retrieved passages. They find that even introducing some typos in the references may also affect the answer generation.\n",
      "•\tWang et al. [245] construct an in-domain reader evaluation dataset. They deeply analyze the effectiveness of the retrieval augmented generation paradigm under the long-tail and in-domain situations.\n",
      "•\tCuconasu et al. [246] compare the performances between readers based on base LLMs and “instructed” LLMs. Different from previous popular belief, They find base\n",
      "models outperform their corresponding instruction-tuned versions.\n",
      "6.5\tApplications' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18537.34375\n",
      "page_content='Shen et al. [476] explored how effective ChatGPT can be as a zero-shot evaluator for abstractive summarization systems using different evaluation methods like likert scaling [495] and head-to-head comparisons [496]. Extensive analysis showed that likert scaling implemented as a multiple-choice question gives the best and most stable results. Liu et al. [478] designed a novel approach which\n",
      "Paper\tGLLMs Explored\tTask(s)\tPrompt Settings\tReferences Required\tDomain(s)\tLanguage(s)\n",
      "[470]\tChatGPT\tCode Generation\tZS\tOptional\tProgramming\tFive Programming Languages\n",
      "[471]\tChatGPT\tText Style Transfer\tZS\tYes\tGeneral\tEnglish\n",
      "[472]\tChatGPT, GPT-4\tText Summarization, Dialogue Generation\tZS\tNo\tGeneral\tEnglish\n",
      "[473]\tGPT,\tGPT-3.5, ChatGPT, GPT-4\tMachine Translation\tZS\tOptional\tGeneral\tEnglish, German, Chinese, Russian\n",
      "[468]\tGPT-3.5, ChatGPT\tText Summarization, Dialogue Generation, Story Generation, Paraphrase Generation\tZS\tNo\tGeneral\tEnglish' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18537.34375\n",
      "page_content='Shen et al. [476] explored how effective ChatGPT can be as a zero-shot evaluator for abstractive summarization systems using different evaluation methods like likert scaling [495] and head-to-head comparisons [496]. Extensive analysis showed that likert scaling implemented as a multiple-choice question gives the best and most stable results. Liu et al. [478] designed a novel approach which\n",
      "Paper\tGLLMs Explored\tTask(s)\tPrompt Settings\tReferences Required\tDomain(s)\tLanguage(s)\n",
      "[470]\tChatGPT\tCode Generation\tZS\tOptional\tProgramming\tFive Programming Languages\n",
      "[471]\tChatGPT\tText Style Transfer\tZS\tYes\tGeneral\tEnglish\n",
      "[472]\tChatGPT, GPT-4\tText Summarization, Dialogue Generation\tZS\tNo\tGeneral\tEnglish\n",
      "[473]\tGPT,\tGPT-3.5, ChatGPT, GPT-4\tMachine Translation\tZS\tOptional\tGeneral\tEnglish, German, Chinese, Russian\n",
      "[468]\tGPT-3.5, ChatGPT\tText Summarization, Dialogue Generation, Story Generation, Paraphrase Generation\tZS\tNo\tGeneral\tEnglish' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18556.083984375\n",
      "page_content='(b)\n",
      "This is an overall sentiment classifier for movie reviews.\n",
      "First, present CLUES (i.e., keywords, phrases, contextual information, semantic relations, semantic meaning, tones, references) that support the sentiment determination of input.\n",
      "Second, deduce a diagnostic REASONING process from premises (i.e., clues, input) that supports the sentiment determination (Limit the number of words to 130).\n",
      "Third, determine the overall SENTIMENT of INPUT as Positive or Negative considering CLUES, the REASONING process and the INPUT.\n",
      "INPUT: noyce films it more as a shocking history lesson than as drama.\n",
      "CLUES: - Positive: \"more,\" \"shocking,\" \"history lesson,\" \"drama.\" - Negative: None.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18556.083984375\n",
      "page_content='(b)\n",
      "This is an overall sentiment classifier for movie reviews.\n",
      "First, present CLUES (i.e., keywords, phrases, contextual information, semantic relations, semantic meaning, tones, references) that support the sentiment determination of input.\n",
      "Second, deduce a diagnostic REASONING process from premises (i.e., clues, input) that supports the sentiment determination (Limit the number of words to 130).\n",
      "Third, determine the overall SENTIMENT of INPUT as Positive or Negative considering CLUES, the REASONING process and the INPUT.\n",
      "INPUT: noyce films it more as a shocking history lesson than as drama.\n",
      "CLUES: - Positive: \"more,\" \"shocking,\" \"history lesson,\" \"drama.\" - Negative: None.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18557.203125\n",
      "page_content='Passage:\n",
      "2In our preliminary study, we observed that concatenating each si ∈ S multiple times to q can lead to improved performance, as the query is the most crucial component in IR.\n",
      "We propose using an iterative IR pipeline, with each iteration consisting of the four steps listed below:\n",
      "1.\tInvoke LLM to conditionally generate knowledge collection S with prompt q′ on Eq. 4. The retrieved document set D is derived from previous RM step and set as empty in the beginning.\n",
      "2.\tConstruct the updated input for RM with knowledge collection S and query q to compute the similarity of each document d.\n",
      "3.\tInvoke RM to retrieve the top-k most “relevant” documents as D on Eq. 3.\n",
      "4.\tFormulate a new prompt q′ by combining the retrieved document set D with query q.\n",
      "The iterative nature of this multi-step process enables the refinement of information through the synergy between the RMs and the LLMs, which can be executed repeatedly M times to further enhance the quality of results.\n",
      "5\tExperiments' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Feng 等 - 2023 - Synergistic Interplay between Search and Large Language Models for Information Retrieval.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18557.203125\n",
      "page_content='Passage:\n",
      "2In our preliminary study, we observed that concatenating each si ∈ S multiple times to q can lead to improved performance, as the query is the most crucial component in IR.\n",
      "We propose using an iterative IR pipeline, with each iteration consisting of the four steps listed below:\n",
      "1.\tInvoke LLM to conditionally generate knowledge collection S with prompt q′ on Eq. 4. The retrieved document set D is derived from previous RM step and set as empty in the beginning.\n",
      "2.\tConstruct the updated input for RM with knowledge collection S and query q to compute the similarity of each document d.\n",
      "3.\tInvoke RM to retrieve the top-k most “relevant” documents as D on Eq. 3.\n",
      "4.\tFormulate a new prompt q′ by combining the retrieved document set D with query q.\n",
      "The iterative nature of this multi-step process enables the refinement of information through the synergy between the RMs and the LLMs, which can be executed repeatedly M times to further enhance the quality of results.\n",
      "5\tExperiments' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Feng 等 - 2023 - Synergistic Interplay between Search and Large Language Models for Information Retrieval.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18558.478515625\n",
      "page_content='Pretrained language models are treated as narrow AI systems as they are adapted through fine-tuning and then used for specific downstream tasks. However, the main focus of the research community is to develop artificial general intelligence systems [43], [100] which are not narrowly focused on specific tasks but have the ability for general problem-solving and can handle even the unseen tasks by utilizing the existing knowledge like' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18558.478515625\n",
      "page_content='Pretrained language models are treated as narrow AI systems as they are adapted through fine-tuning and then used for specific downstream tasks. However, the main focus of the research community is to develop artificial general intelligence systems [43], [100] which are not narrowly focused on specific tasks but have the ability for general problem-solving and can handle even the unseen tasks by utilizing the existing knowledge like' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18561.416015625\n",
      "page_content='[222]\tO. Yoran, T. Wolfson, B. Bogin, U. Katz, D. Deutch, and J. Berant, “Answering questions by meta-reasoning over multiple chains of thought,” in Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, EMNLP 2023, Singapore, December 6-10, 2023, H. Bouamor, J. Pino, and K. Bali, Eds. Association for Computational Linguistics, 2023, pp. 5942–5966.\n",
      "[223]\tM. A. Arefeen, B. Debnath, and S. Chakradhar, “Leancontext: Cost-efficient domain-specific question answering using llms,” CoRR, vol. abs/2309.00841, 2023.\n",
      "[224]\tF. Xu, W. Shi, and E. Choi, “RECOMP: improving retrieval-augmented lms with compression and selective augmentation,” CoRR, vol. abs/2310.04408, 2023.\n",
      "[225]\tZ. Wang, J. Araki, Z. Jiang, M. R. Parvez, and G. Neubig, “Learning to filter context for retrieval-augmented generation,” CoRR, vol. abs/2311.08377, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18561.416015625\n",
      "page_content='[222]\tO. Yoran, T. Wolfson, B. Bogin, U. Katz, D. Deutch, and J. Berant, “Answering questions by meta-reasoning over multiple chains of thought,” in Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, EMNLP 2023, Singapore, December 6-10, 2023, H. Bouamor, J. Pino, and K. Bali, Eds. Association for Computational Linguistics, 2023, pp. 5942–5966.\n",
      "[223]\tM. A. Arefeen, B. Debnath, and S. Chakradhar, “Leancontext: Cost-efficient domain-specific question answering using llms,” CoRR, vol. abs/2309.00841, 2023.\n",
      "[224]\tF. Xu, W. Shi, and E. Choi, “RECOMP: improving retrieval-augmented lms with compression and selective augmentation,” CoRR, vol. abs/2310.04408, 2023.\n",
      "[225]\tZ. Wang, J. Araki, Z. Jiang, M. R. Parvez, and G. Neubig, “Learning to filter context for retrieval-augmented generation,” CoRR, vol. abs/2311.08377, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18594.40625\n",
      "page_content='work on fewshot learning uses a large validation set, which is unavailable in true low-data settings, to select the prompt and other model-specific hyperparameters (Perez et al., 2021), we present unlabeled validation to measure and eliminate model bias on label words while utilizing only unlabeled examples as a validation set. It is worth noting that the proposed approach does not require any pre-labeled examples, i.e., our method shows effectiveness in true zero-shot settings.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18594.40625\n",
      "page_content='work on fewshot learning uses a large validation set, which is unavailable in true low-data settings, to select the prompt and other model-specific hyperparameters (Perez et al., 2021), we present unlabeled validation to measure and eliminate model bias on label words while utilizing only unlabeled examples as a validation set. It is worth noting that the proposed approach does not require any pre-labeled examples, i.e., our method shows effectiveness in true zero-shot settings.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18598.177734375\n",
      "page_content='Combining pre-trained language models (PLMs) and manual templates is a common practice for text classification in zero-shot scenarios. However, the effect of this approach is highly volatile, ranging from random guesses to near state-of-the-art results, depending on the quality of the manual templates. In this paper, we show that this instability stems from the fact that language models tend toward predicting certain label words of text classification, and manual templates can influence this tendency. To address this, we develop a novel pipeline for annotating and filtering a few examples from unlabeled examples. Moreover, we propose a new method to measure model bias on label words that utilizes unlabeled examples as a validation set when tuning language models. Our approach does not require any pre-labeled examples. Experimental results on six text classification tasks demonstrate that the proposed approach significantly outperforms standard prompt learning in zero-shot settings,' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18598.177734375\n",
      "page_content='Combining pre-trained language models (PLMs) and manual templates is a common practice for text classification in zero-shot scenarios. However, the effect of this approach is highly volatile, ranging from random guesses to near state-of-the-art results, depending on the quality of the manual templates. In this paper, we show that this instability stems from the fact that language models tend toward predicting certain label words of text classification, and manual templates can influence this tendency. To address this, we develop a novel pipeline for annotating and filtering a few examples from unlabeled examples. Moreover, we propose a new method to measure model bias on label words that utilizes unlabeled examples as a validation set when tuning language models. Our approach does not require any pre-labeled examples. Experimental results on six text classification tasks demonstrate that the proposed approach significantly outperforms standard prompt learning in zero-shot settings,' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18602.2578125\n",
      "page_content='The ability to generate text with human-like fluency resulted in the wide adoption of GLLMs in various real-world applications like writing assistants, coding assistants, and chatbots [428]. There is a growing concern regarding the misuse of these models for various illegal activities [429], like fake news on social media platforms [430], [431], fake reviews on e-commerce websites [432], fake research papers [433], academic fraud [434], etc. The performance of existing approaches like DetectGPT, Ze-roGPT, OpenAI detector, ChatGPT-detector-roberta and ChatGPT-qa-detector-roberta is not satisfactory [437], [444]. Moreover, the existing approaches are not robust to various attacks like paraphrasing, synonym word replacement and writing style modification [445], [452]. So, there is a great need for better approaches which can reliably detect GLLM generated text and also robust to various attacks, including paraphrasing. With reliable and robust detection approaches, the misuse of GLLMs' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18602.2578125\n",
      "page_content='The ability to generate text with human-like fluency resulted in the wide adoption of GLLMs in various real-world applications like writing assistants, coding assistants, and chatbots [428]. There is a growing concern regarding the misuse of these models for various illegal activities [429], like fake news on social media platforms [430], [431], fake reviews on e-commerce websites [432], fake research papers [433], academic fraud [434], etc. The performance of existing approaches like DetectGPT, Ze-roGPT, OpenAI detector, ChatGPT-detector-roberta and ChatGPT-qa-detector-roberta is not satisfactory [437], [444]. Moreover, the existing approaches are not robust to various attacks like paraphrasing, synonym word replacement and writing style modification [445], [452]. So, there is a great need for better approaches which can reliably detect GLLM generated text and also robust to various attacks, including paraphrasing. With reliable and robust detection approaches, the misuse of GLLMs' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18615.458984375\n",
      "page_content='6.6\tLimitations\n",
      "Several IR systems applying the RAG strategy, such as New Bing and Langchain, have already entered commercial use. However, there are also some challenges in this novel retrieval-augmented content generation system. These include challenges such as effective query reformulation, optimal retrieval frequency, correct document comprehension, accurate passage extraction, and effective content summarization. It is crucial to address these challenges to effectively realize the potential of LLMs in this paradigm.\n",
      "7\tSearch Agent' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18615.458984375\n",
      "page_content='6.6\tLimitations\n",
      "Several IR systems applying the RAG strategy, such as New Bing and Langchain, have already entered commercial use. However, there are also some challenges in this novel retrieval-augmented content generation system. These include challenges such as effective query reformulation, optimal retrieval frequency, correct document comprehension, accurate passage extraction, and effective content summarization. It is crucial to address these challenges to effectively realize the potential of LLMs in this paradigm.\n",
      "7\tSearch Agent' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18619.3984375\n",
      "page_content='8\tFuture Direction\n",
      "In this survey, we comprehensively reviewed recent advancements in LLM-enhanced IR systems and discussed their limitations. Since the integration of LLMs into IR systems is still in its early stages, there are still many opportunities and challenges. In this section, we summarize the potential future directions in terms of the four modules in an IR system we just discussed, namely query rewriter, retriever, reranker, and reader. In addition, as evaluation has also emerged as an important aspect, we will also introduce the corresponding research problems that need to be addressed in the future. Another discussion about important research topics on applying LLMs to IR can be found in a recent perspective paper [50].\n",
      "8.1\tQuery Rewriter' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18619.3984375\n",
      "page_content='8\tFuture Direction\n",
      "In this survey, we comprehensively reviewed recent advancements in LLM-enhanced IR systems and discussed their limitations. Since the integration of LLMs into IR systems is still in its early stages, there are still many opportunities and challenges. In this section, we summarize the potential future directions in terms of the four modules in an IR system we just discussed, namely query rewriter, retriever, reranker, and reader. In addition, as evaluation has also emerged as an important aspect, we will also introduce the corresponding research problems that need to be addressed in the future. Another discussion about important research topics on applying LLMs to IR can be found in a recent perspective paper [50].\n",
      "8.1\tQuery Rewriter' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18628.755859375\n",
      "page_content='[248]\tJ. Zhang, K. Bao, Y. Zhang, W. Wang, F. Feng, and X. He, “Is chat-gpt fair for recommendation? evaluating fairness in large language model recommendation,” arXiv preprint arXiv:2305.07609, 2023.\n",
      "[249]\tY. Hou, J. Zhang, Z. Lin, H. Lu, R. Xie, J. McAuley, and W. X. Zhao, “Large language models are zero-shot rankers for recommender systems,” arXiv preprint arXiv:2305.08845, 2023.\n",
      "[250]\tS. Mysore, A. McCallum, and H. Zamani, “Large language model augmented narrative driven recommendations,” arXiv preprint arXiv:2306.02250, 2023.\n",
      "[251]\tC. S. Xia and L. Zhang, “Keep the conversation going: Fixing 162 out of 337 bugs for 0.42 each using chatgpt,” arXiv preprint arXiv:2304.00385, 2023.\n",
      "[252]\tA. Cheshkov, P. Zadorozhny, and R. Levichev, “Evaluation of chatgpt model for vulnerability detection,” arXiv preprint arXiv:2304.07232, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18628.755859375\n",
      "page_content='[248]\tJ. Zhang, K. Bao, Y. Zhang, W. Wang, F. Feng, and X. He, “Is chat-gpt fair for recommendation? evaluating fairness in large language model recommendation,” arXiv preprint arXiv:2305.07609, 2023.\n",
      "[249]\tY. Hou, J. Zhang, Z. Lin, H. Lu, R. Xie, J. McAuley, and W. X. Zhao, “Large language models are zero-shot rankers for recommender systems,” arXiv preprint arXiv:2305.08845, 2023.\n",
      "[250]\tS. Mysore, A. McCallum, and H. Zamani, “Large language model augmented narrative driven recommendations,” arXiv preprint arXiv:2306.02250, 2023.\n",
      "[251]\tC. S. Xia and L. Zhang, “Keep the conversation going: Fixing 162 out of 337 bugs for 0.42 each using chatgpt,” arXiv preprint arXiv:2304.00385, 2023.\n",
      "[252]\tA. Cheshkov, P. Zadorozhny, and R. Levichev, “Evaluation of chatgpt model for vulnerability detection,” arXiv preprint arXiv:2304.07232, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18634.9453125\n",
      "page_content='be insensitive to subtle differences in generated outputs. For example, if a generated output has minor semantic differences from the reference answer but is otherwise similar, traditional methods might overlook these nuanced distinctions. (3) Lack of ability to evaluate factuality: LLMs are prone to generating “hallucination” problems [284–287]. The hallucinated texts can closely resemble the oracle texts in terms of vocabulary usage, sentence structures, and patterns, while having non-factual content. Existing methods are hard to identify such problems, while the incorporation of additional knowledge sources such as knowledge bases or reference texts could potentially aid in addressing this challenge.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18634.9453125\n",
      "page_content='be insensitive to subtle differences in generated outputs. For example, if a generated output has minor semantic differences from the reference answer but is otherwise similar, traditional methods might overlook these nuanced distinctions. (3) Lack of ability to evaluate factuality: LLMs are prone to generating “hallucination” problems [284–287]. The hallucinated texts can closely resemble the oracle texts in terms of vocabulary usage, sentence structures, and patterns, while having non-factual content. Existing methods are hard to identify such problems, while the incorporation of additional knowledge sources such as knowledge bases or reference texts could potentially aid in addressing this challenge.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18638.619140625\n",
      "page_content='[118]\tR. Li, L. B. Allal, Y. Zi, N. Muennighoff, D. Kocetkov, C. Mou, M. Marone, C. Akiki, J. Li, J. Chim et al., “Starcoder: may the source be with you!” arXiv preprint arXiv:2305.06161, 2023.\n",
      "[119]\tB. Rozie` re, J. Gehring, F. Gloeckle, S. Sootla, I. Gat, X. E. Tan, Y. Adi, J. Liu, T. Remez, J. Rapin et al., “Code llama: Open foundation models for code,” arXiv preprint arXiv:2308.12950, 2023.\n",
      "[120]\tE. Nijkamp, B. Pang, H. Hayashi, L. Tu, H. Wang, Y. Zhou, S. Savarese, and C. Xiong, “Codegen: An open large language model for code with multi-turn program synthesis,” in The Eleventh International Conference on Learning Representations, 2022.\n",
      "[121]\tE. Nijkamp, H. Hayashi, C. Xiong, S. Savarese, and Y. Zhou, “Codegen2: Lessons for training llms on programming and natural languages,” arXiv preprint arXiv:2305.02309, 2023.\n",
      "[122]\tA. Radford, R. Jozefowicz, and I. Sutskever, “Learning to generate reviews and discovering sentiment,” arXiv preprint arXiv:1704.01444, 2017.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18638.619140625\n",
      "page_content='[118]\tR. Li, L. B. Allal, Y. Zi, N. Muennighoff, D. Kocetkov, C. Mou, M. Marone, C. Akiki, J. Li, J. Chim et al., “Starcoder: may the source be with you!” arXiv preprint arXiv:2305.06161, 2023.\n",
      "[119]\tB. Rozie` re, J. Gehring, F. Gloeckle, S. Sootla, I. Gat, X. E. Tan, Y. Adi, J. Liu, T. Remez, J. Rapin et al., “Code llama: Open foundation models for code,” arXiv preprint arXiv:2308.12950, 2023.\n",
      "[120]\tE. Nijkamp, B. Pang, H. Hayashi, L. Tu, H. Wang, Y. Zhou, S. Savarese, and C. Xiong, “Codegen: An open large language model for code with multi-turn program synthesis,” in The Eleventh International Conference on Learning Representations, 2022.\n",
      "[121]\tE. Nijkamp, H. Hayashi, C. Xiong, S. Savarese, and Y. Zhou, “Codegen2: Lessons for training llms on programming and natural languages,” arXiv preprint arXiv:2305.02309, 2023.\n",
      "[122]\tA. Radford, R. Jozefowicz, and I. Sutskever, “Learning to generate reviews and discovering sentiment,” arXiv preprint arXiv:1704.01444, 2017.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18641.431640625\n",
      "page_content='[442]\tH. Zhan, X. He, Q. Xu, Y. Wu, and P. Stenetorp, “G3detector: General gpt-generated text detector,” arXiv preprint arXiv:2305.12680, 2023.\n",
      "[443]\tE. Clark, T. August, S. Serrano, N. Haduong, S. Gururangan, and N. A. Smith, “All that’s ‘human’is not gold: Evaluating human evaluation of generated text,” in Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), 2021, pp. 7282–7296.\n",
      "[444]\tA. Pegoraro, K. Kumari, H. Fereidooni, and A.-R. Sadeghi, “To chatgpt, or not to chatgpt: That is the question!” arXiv preprint arXiv:2304.01487, 2023.\n",
      "[445]\tZ. Shi, Y. Wang, F. Yin, X. Chen, K.-W. Chang, and C.-J. Hsieh, “Red teaming language model detectors with language models,” arXiv preprint arXiv:2305.19713, 2023.\n",
      "[446]\tM. Khalil and E. Er, “Will chatgpt get you caught? rethinking of plagiarism detection,” arXiv preprint arXiv:2302.04335, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18641.431640625\n",
      "page_content='[442]\tH. Zhan, X. He, Q. Xu, Y. Wu, and P. Stenetorp, “G3detector: General gpt-generated text detector,” arXiv preprint arXiv:2305.12680, 2023.\n",
      "[443]\tE. Clark, T. August, S. Serrano, N. Haduong, S. Gururangan, and N. A. Smith, “All that’s ‘human’is not gold: Evaluating human evaluation of generated text,” in Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), 2021, pp. 7282–7296.\n",
      "[444]\tA. Pegoraro, K. Kumari, H. Fereidooni, and A.-R. Sadeghi, “To chatgpt, or not to chatgpt: That is the question!” arXiv preprint arXiv:2304.01487, 2023.\n",
      "[445]\tZ. Shi, Y. Wang, F. Yin, X. Chen, K.-W. Chang, and C.-J. Hsieh, “Red teaming language model detectors with language models,” arXiv preprint arXiv:2305.19713, 2023.\n",
      "[446]\tM. Khalil and E. Er, “Will chatgpt get you caught? rethinking of plagiarism detection,” arXiv preprint arXiv:2302.04335, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18646.09765625\n",
      "page_content='[423]\tChatGPT\tTopic Classification\tZS\tNews, Social Media\tEnglish\n",
      "[424]\tChatGPT\tNeural Machine Translation\tZS\tGeneral\tMultiple Languages\n",
      "[425]\tGPT-3, Codex\tTable Question Answering\tZS\tGeneral\tEnglish\n",
      "[426]\tGPT-4\tText Generation Evaluation\tZS\tGeneral\tMultiple Languages\n",
      "TABLE 19. Summary of research works exploring GLLMs for data generation-based data augmentation. Here ZS represents zero-shot and FS represents few-shot.\n",
      "7.2.2\tData Generation' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18646.09765625\n",
      "page_content='[423]\tChatGPT\tTopic Classification\tZS\tNews, Social Media\tEnglish\n",
      "[424]\tChatGPT\tNeural Machine Translation\tZS\tGeneral\tMultiple Languages\n",
      "[425]\tGPT-3, Codex\tTable Question Answering\tZS\tGeneral\tEnglish\n",
      "[426]\tGPT-4\tText Generation Evaluation\tZS\tGeneral\tMultiple Languages\n",
      "TABLE 19. Summary of research works exploring GLLMs for data generation-based data augmentation. Here ZS represents zero-shot and FS represents few-shot.\n",
      "7.2.2\tData Generation' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18659.08203125\n",
      "page_content='[359]\tL. Loukas, I. Stogiannidis, P. Malakasiotis, and S. Vassos, “Breaking the bank with chatgpt: Few-shot text classification for finance,” arXiv preprint arXiv:2308.14634, 2023.\n",
      "[360]\tI. Chalkidis, A. Jana, D. Hartung, M. Bommarito, I. Androut-sopoulos, D. Katz, and N. Aletras, “Lexglue: A benchmark dataset for legal language understanding in english,” in Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), 2022, pp. 4310–4330.\n",
      "[361]\tJ. Wei, X. Wang, D. Schuurmans, M. Bosma, F. Xia, E. Chi, Q. V. Le, D. Zhou et al., “Chain-of-thought prompting elicits reasoning in large language models,” Advances in Neural Information Processing Systems, vol. 35, pp. 24 824–24 837, 2022.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18659.08203125\n",
      "page_content='[359]\tL. Loukas, I. Stogiannidis, P. Malakasiotis, and S. Vassos, “Breaking the bank with chatgpt: Few-shot text classification for finance,” arXiv preprint arXiv:2308.14634, 2023.\n",
      "[360]\tI. Chalkidis, A. Jana, D. Hartung, M. Bommarito, I. Androut-sopoulos, D. Katz, and N. Aletras, “Lexglue: A benchmark dataset for legal language understanding in english,” in Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), 2022, pp. 4310–4330.\n",
      "[361]\tJ. Wei, X. Wang, D. Schuurmans, M. Bosma, F. Xia, E. Chi, Q. V. Le, D. Zhou et al., “Chain-of-thought prompting elicits reasoning in large language models,” Advances in Neural Information Processing Systems, vol. 35, pp. 24 824–24 837, 2022.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18660.443359375\n",
      "page_content='5.4\tMain Results\n",
      "Web Search In Table 1, we show zero-shot retrieval results on TREC DL’19 and TREC DL’20 with baselines. We can find that InteR with selected LLMs can outperform state-of-the-art zero-shot baseline HyDE with significant improvement on most metrics. Specifically, InteR with gpt-3.5-turbo has an > 8% absolute MAP gain and > 5% absolute nDCG@10 gain on both web search benchmarks. Moreover, InteR is also superior to models with relevance judgment on most metrics, which verifies the generalization ability of InteR on large-scale retrieval. Note that our approach does not involve any training process and merely leverages off-the-shelf RMs and LLMs, which is simpler in practice but shown to be more effective.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Feng 等 - 2023 - Synergistic Interplay between Search and Large Language Models for Information Retrieval.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18660.443359375\n",
      "page_content='5.4\tMain Results\n",
      "Web Search In Table 1, we show zero-shot retrieval results on TREC DL’19 and TREC DL’20 with baselines. We can find that InteR with selected LLMs can outperform state-of-the-art zero-shot baseline HyDE with significant improvement on most metrics. Specifically, InteR with gpt-3.5-turbo has an > 8% absolute MAP gain and > 5% absolute nDCG@10 gain on both web search benchmarks. Moreover, InteR is also superior to models with relevance judgment on most metrics, which verifies the generalization ability of InteR on large-scale retrieval. Note that our approach does not involve any training process and merely leverages off-the-shelf RMs and LLMs, which is simpler in practice but shown to be more effective.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Feng 等 - 2023 - Synergistic Interplay between Search and Large Language Models for Information Retrieval.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18680.57421875\n",
      "page_content='L. Gao, X. Ma, J. Lin, and J. Callan, “Precise zero-shot dense retrieval without relevance labels,” CoRR, vol. abs/2212.10496, 2022.\n",
      "R. Jagerman, H. Zhuang, Z. Qin, X. Wang, and M. Bendersky, “Query expansion by prompting large lan-\n",
      "[77]\n",
      "[78]\n",
      "[79]\n",
      "[80]\n",
      "[81]\n",
      "[82]\n",
      "[83]\n",
      "[84]\n",
      "[85]\n",
      "[86]\n",
      "[87]\n",
      "[88]\n",
      "[89]\n",
      "guage models,” CoRR, vol. abs/2305.03653, 2023.\n",
      "I. Baek, J. Lee, J. Yang, and H. Lee, “Crafting the path: Robust query rewriting for information retrieval,” CoRR, vol. abs/2407.12529, 2024.\n",
      "M. Alaofi, L. Gallagher, M. Sanderson, F. Scholer, and P. Thomas, “Can generative llms create query variants for test collections? an exploratory study,” in Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR 2023, Taipei, Taiwan, July 23-27, 2023, H. Chen, W. E. Duh, H. Huang, M. P. Kato, J. Mothe, and B. Poblete, Eds. ACM, 2023, pp. 1869–1873.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18680.57421875\n",
      "page_content='L. Gao, X. Ma, J. Lin, and J. Callan, “Precise zero-shot dense retrieval without relevance labels,” CoRR, vol. abs/2212.10496, 2022.\n",
      "R. Jagerman, H. Zhuang, Z. Qin, X. Wang, and M. Bendersky, “Query expansion by prompting large lan-\n",
      "[77]\n",
      "[78]\n",
      "[79]\n",
      "[80]\n",
      "[81]\n",
      "[82]\n",
      "[83]\n",
      "[84]\n",
      "[85]\n",
      "[86]\n",
      "[87]\n",
      "[88]\n",
      "[89]\n",
      "guage models,” CoRR, vol. abs/2305.03653, 2023.\n",
      "I. Baek, J. Lee, J. Yang, and H. Lee, “Crafting the path: Robust query rewriting for information retrieval,” CoRR, vol. abs/2407.12529, 2024.\n",
      "M. Alaofi, L. Gallagher, M. Sanderson, F. Scholer, and P. Thomas, “Can generative llms create query variants for test collections? an exploratory study,” in Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR 2023, Taipei, Taiwan, July 23-27, 2023, H. Chen, W. E. Duh, H. Huang, M. P. Kato, J. Mothe, and B. Poblete, Eds. ACM, 2023, pp. 1869–1873.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18681.130859375\n",
      "page_content='are continually achieved with adoption of more advanced LLMs [112, 123, 124]. To date, LLM-based embedders have dominated all major text retrieval benchmarks, e.g., currently, the leading methods on MTEB [125] are all back-ended by LLMs.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18681.130859375\n",
      "page_content='are continually achieved with adoption of more advanced LLMs [112, 123, 124]. To date, LLM-based embedders have dominated all major text retrieval benchmarks, e.g., currently, the leading methods on MTEB [125] are all back-ended by LLMs.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18681.578125\n",
      "page_content='•\tMallen et al. [234] argue that always retrieving references to support LLMs to generate answers hurts the question-answering performance. The reason is that LLMs themselves may have adequate knowledge while answering questions about popular entities and the retrieved noisy passages may interfere and bias the answering process. To overcome this challenge, they devise a simple strategy that only retrieves references while the popularity of entities in the query is quite low. By this means, the efficacy and efficiency of RAG both improve. Ding et al. [235] pay attention to the same phenomenon and propose to paraphrase several perturbed questions for LLMs to answer according to their internal knowledge and perform a consistency check to decide whether to retrieve external information. [236–238] also focus on this problem using triplets extracted from the knowledge graph and the confidence of LLMs. [239, 240] solve this problem by training LLMs or small language models to judge whether' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18681.578125\n",
      "page_content='•\tMallen et al. [234] argue that always retrieving references to support LLMs to generate answers hurts the question-answering performance. The reason is that LLMs themselves may have adequate knowledge while answering questions about popular entities and the retrieved noisy passages may interfere and bias the answering process. To overcome this challenge, they devise a simple strategy that only retrieves references while the popularity of entities in the query is quite low. By this means, the efficacy and efficiency of RAG both improve. Ding et al. [235] pay attention to the same phenomenon and propose to paraphrase several perturbed questions for LLMs to answer according to their internal knowledge and perform a consistency check to decide whether to retrieve external information. [236–238] also focus on this problem using triplets extracted from the knowledge graph and the confidence of LLMs. [239, 240] solve this problem by training LLMs or small language models to judge whether' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18681.892578125\n",
      "page_content='References\n",
      "Thurston Sexton, Melinda Hodkiewicz, Michael P Brundage, et al. Categorization errors for data entry in maintenance work-orders. In Proceedings of the Annual Conference of the PHM Society, volume 11, 2019.\n",
      "Glen D Murphy. Improving the quality of manually acquired data: Applying the theory of planned behaviour to data quality. Reliability Engineering & System Safety, 94(12):1881–1886, 2009.\n",
      "Kerrie Unsworth, Elisa Adriasola, Amber Johnston-Billings, Alina Dmitrieva, and Melinda Hodkiewicz. Goal hierarchy: Improving asset data quality by improving motivation. Reliability Engineering & System Safety, 96(11):1474–1481, 2011.\n",
      "Roger Molina, Kerrie Unsworth, Melinda Hodkiewicz, and Elisa Adriasola. Are managerial pressure, technological control and intrinsic motivation effective in improving data quality? Reliability Engineering & System Safety, 119: 26–34, 2013.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Stewart 等 - 2023 - Large Language Models for Failure Mode Classification An Investigation.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18681.892578125\n",
      "page_content='References\n",
      "Thurston Sexton, Melinda Hodkiewicz, Michael P Brundage, et al. Categorization errors for data entry in maintenance work-orders. In Proceedings of the Annual Conference of the PHM Society, volume 11, 2019.\n",
      "Glen D Murphy. Improving the quality of manually acquired data: Applying the theory of planned behaviour to data quality. Reliability Engineering & System Safety, 94(12):1881–1886, 2009.\n",
      "Kerrie Unsworth, Elisa Adriasola, Amber Johnston-Billings, Alina Dmitrieva, and Melinda Hodkiewicz. Goal hierarchy: Improving asset data quality by improving motivation. Reliability Engineering & System Safety, 96(11):1474–1481, 2011.\n",
      "Roger Molina, Kerrie Unsworth, Melinda Hodkiewicz, and Elisa Adriasola. Are managerial pressure, technological control and intrinsic motivation effective in improving data quality? Reliability Engineering & System Safety, 119: 26–34, 2013.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Stewart 等 - 2023 - Large Language Models for Failure Mode Classification An Investigation.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18684.353515625\n",
      "page_content='[458]\tK. Zhu, J. Wang, J. Zhou, Z. Wang, H. Chen, Y. Wang, L. Yang, W. Ye, N. Z. Gong, Y. Zhang et al., “Promptbench: Towards evaluating the robustness of large language models on adversarial prompts,” arXiv preprint arXiv:2306.04528, 2023.\n",
      "[459]\tA. Shirafuji, Y. Watanobe, T. Ito, M. Morishita, Y. Nakamura, Y. Oda, and J. Suzuki, “Exploring the robustness of large language models for solving programming problems,” arXiv preprint arXiv:2306.14583, 2023.\n",
      "[460]\tR. Han, T. Peng, C. Yang, B. Wang, L. Liu, and X. Wan, “Is information extraction solved by chatgpt? an analysis of performance, evaluation criteria, robustness and errors,” arXiv preprint arXiv:2305.14450, 2023.\n",
      "[461]\tH. Liu, R. Ning, Z. Teng, J. Liu, Q. Zhou, and Y. Zhang, “Evaluating the logical reasoning ability of chatgpt and gpt-4,” arXiv preprint arXiv:2304.03439, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18684.353515625\n",
      "page_content='[458]\tK. Zhu, J. Wang, J. Zhou, Z. Wang, H. Chen, Y. Wang, L. Yang, W. Ye, N. Z. Gong, Y. Zhang et al., “Promptbench: Towards evaluating the robustness of large language models on adversarial prompts,” arXiv preprint arXiv:2306.04528, 2023.\n",
      "[459]\tA. Shirafuji, Y. Watanobe, T. Ito, M. Morishita, Y. Nakamura, Y. Oda, and J. Suzuki, “Exploring the robustness of large language models for solving programming problems,” arXiv preprint arXiv:2306.14583, 2023.\n",
      "[460]\tR. Han, T. Peng, C. Yang, B. Wang, L. Liu, and X. Wan, “Is information extraction solved by chatgpt? an analysis of performance, evaluation criteria, robustness and errors,” arXiv preprint arXiv:2305.14450, 2023.\n",
      "[461]\tH. Liu, R. Ning, Z. Teng, J. Liu, Q. Zhou, and Y. Zhang, “Evaluating the logical reasoning ability of chatgpt and gpt-4,” arXiv preprint arXiv:2304.03439, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18684.451171875\n",
      "page_content='Abstract. Retrieval-augmented generation (RAG) techniques leverage the in-context learning capabilities of large language models (LLMs) to produce more accurate and relevant responses. Originating from the simple ’retrieve-then-read’ approach, the RAG framework has evolved into a highly flexible and modular paradigm. A critical component, the Query Rewriter module, enhances knowledge retrieval by generating a search-friendly query. This method aligns input questions more closely with the knowledge base. Our research identifies opportunities to enhance the Query Rewriter module to Query Rewriter+ by generating multiple queries to overcome the Information Plateaus associated with a single query and by rewriting questions to eliminate Ambiguity, thereby clarifying the underlying intent. We also find that current RAG systems exhibit issues with Irrelevant Knowledge; to overcome this, we propose the Knowledge Filter. These two modules are both based on the instructional-tuned Gemma-2B' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18684.451171875\n",
      "page_content='Abstract. Retrieval-augmented generation (RAG) techniques leverage the in-context learning capabilities of large language models (LLMs) to produce more accurate and relevant responses. Originating from the simple ’retrieve-then-read’ approach, the RAG framework has evolved into a highly flexible and modular paradigm. A critical component, the Query Rewriter module, enhances knowledge retrieval by generating a search-friendly query. This method aligns input questions more closely with the knowledge base. Our research identifies opportunities to enhance the Query Rewriter module to Query Rewriter+ by generating multiple queries to overcome the Information Plateaus associated with a single query and by rewriting questions to eliminate Ambiguity, thereby clarifying the underlying intent. We also find that current RAG systems exhibit issues with Irrelevant Knowledge; to overcome this, we propose the Knowledge Filter. These two modules are both based on the instructional-tuned Gemma-2B' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18693.693359375\n",
      "page_content='3\tQuery Rewriter\n",
      "Query rewriter, functioning as an essential preprocessing component for search engines, increases the accuracy of retrieval systems through the refinement of initial queries [66]. This mechanism, also known as query expansion or reformulation, holds a pivotal position in search engine operations. In the context of ad-hoc retrieval, the design of a query rewriter aims to mitigate the vocabulary mismatch problem by enriching original queries with semantically related terms. As conversational search evolves, query rewriters have evolved to interpret user intent and previous dialogues, thereby enabling context-sensitive queries. In this survey, the term “query rewriter ” is used to refer to any technique that improves retrieval performance through query modification.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18693.693359375\n",
      "page_content='3\tQuery Rewriter\n",
      "Query rewriter, functioning as an essential preprocessing component for search engines, increases the accuracy of retrieval systems through the refinement of initial queries [66]. This mechanism, also known as query expansion or reformulation, holds a pivotal position in search engine operations. In the context of ad-hoc retrieval, the design of a query rewriter aims to mitigate the vocabulary mismatch problem by enriching original queries with semantically related terms. As conversational search evolves, query rewriters have evolved to interpret user intent and previous dialogues, thereby enabling context-sensitive queries. In this survey, the term “query rewriter ” is used to refer to any technique that improves retrieval performance through query modification.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18695.51953125\n",
      "page_content='more effective than MTurk crowd-workers as (i) Chat-GPT achieves 25 points more than crowd-workers in terms of accuracy, (ii) ChatGPT is approximately 30 times cheaper, and (iii) intercoder agreement of ChatGPT is more than crowd-workers. He et al. [374] proposed a novel approach called “explain then annotate” to enhance the performance of GLLMs as text data annotators. The proposed approach involves two steps: (i) GLLM generates explanations for the demonstrations and then (ii) annotates the data by leveraging annotation guidelines, demonstrations and explanations through CoT prompting. Evaluation on three binary text classification tasks revealed that GPT-3.5 outperforms crowdworkers on one task and matches the performance of crowd-workers on the other two tasks. Tornberg et al. [375] demonstrated that zero-shot GPT-4 outperforms human annotators in labelling political English tweets. Further analysis demonstrated that GPT-4 possesses the ability to accurately label tweets that' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18695.51953125\n",
      "page_content='more effective than MTurk crowd-workers as (i) Chat-GPT achieves 25 points more than crowd-workers in terms of accuracy, (ii) ChatGPT is approximately 30 times cheaper, and (iii) intercoder agreement of ChatGPT is more than crowd-workers. He et al. [374] proposed a novel approach called “explain then annotate” to enhance the performance of GLLMs as text data annotators. The proposed approach involves two steps: (i) GLLM generates explanations for the demonstrations and then (ii) annotates the data by leveraging annotation guidelines, demonstrations and explanations through CoT prompting. Evaluation on three binary text classification tasks revealed that GPT-3.5 outperforms crowdworkers on one task and matches the performance of crowd-workers on the other two tasks. Tornberg et al. [375] demonstrated that zero-shot GPT-4 outperforms human annotators in labelling political English tweets. Further analysis demonstrated that GPT-4 possesses the ability to accurately label tweets that' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18702.810546875\n",
      "page_content='Your output must always be a JSON object only, do not explain yourself or output anything else. Be creative!\n",
      "(3) Framework of complete example generation\n",
      "Fig. 4. Three typical frameworks for LLM-based data augmentation in the retrieval task (right), along with their prompt examples (left). Note that the methods of relevance label generation do not treat questions as inputs but regard their generation probabilities conditioned on the retrieved passages as soft relevance labels.\n",
      "passages. After a normalization process, these probabilities serve as soft relevance labels for the training of the retriever.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18702.810546875\n",
      "page_content='Your output must always be a JSON object only, do not explain yourself or output anything else. Be creative!\n",
      "(3) Framework of complete example generation\n",
      "Fig. 4. Three typical frameworks for LLM-based data augmentation in the retrieval task (right), along with their prompt examples (left). Note that the methods of relevance label generation do not treat questions as inputs but regard their generation probabilities conditioned on the retrieved passages as soft relevance labels.\n",
      "passages. After a normalization process, these probabilities serve as soft relevance labels for the training of the retriever.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18703.09375\n",
      "page_content='[382]\tY. Xu, R. Xu, D. Iter, Y. Liu, S. Wang, C. Zhu, and M. Zeng, “Inheritsumm: A general, versatile and compact summarizer by distilling from gpt,” arXiv preprint arXiv:2305.13083, 2023.\n",
      "[383]\tM. Alizadeh, M. Kubli, Z. Samei, S. Dehghani, J. D. Bermeo, M. Korobeynikova, and F. Gilardi, “Open-source large language models outperform crowd workers and approach chatgpt in textannotation tasks,” arXiv preprint arXiv:2307.02179, 2023.\n",
      "[384]\tS. Thapa, U. Naseem, and M. Nasim, “From humans to machines: can chatgpt-like llms effectively replace human annotators in nlp tasks,” in Workshop Proceedings of the 17th International AAAI Conference on Web and Social Media, 2023.\n",
      "[385]\tJ. S. Murthy, G. Siddesh, and K. Srinivasa, “Twitsenti: a realtime twitter sentiment analysis and visualization framework,” Journal of Information & Knowledge Management, vol. 18, no. 02, p. 1950013, 2019.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18703.09375\n",
      "page_content='[382]\tY. Xu, R. Xu, D. Iter, Y. Liu, S. Wang, C. Zhu, and M. Zeng, “Inheritsumm: A general, versatile and compact summarizer by distilling from gpt,” arXiv preprint arXiv:2305.13083, 2023.\n",
      "[383]\tM. Alizadeh, M. Kubli, Z. Samei, S. Dehghani, J. D. Bermeo, M. Korobeynikova, and F. Gilardi, “Open-source large language models outperform crowd workers and approach chatgpt in textannotation tasks,” arXiv preprint arXiv:2307.02179, 2023.\n",
      "[384]\tS. Thapa, U. Naseem, and M. Nasim, “From humans to machines: can chatgpt-like llms effectively replace human annotators in nlp tasks,” in Workshop Proceedings of the 17th International AAAI Conference on Web and Social Media, 2023.\n",
      "[385]\tJ. S. Murthy, G. Siddesh, and K. Srinivasa, “Twitsenti: a realtime twitter sentiment analysis and visualization framework,” Journal of Information & Knowledge Management, vol. 18, no. 02, p. 1950013, 2019.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18703.1640625\n",
      "page_content='models outperform their corresponding instruction-tuned versions.\n",
      "6.5\tApplications\n",
      "Recently, researchers [247–253] have applied the RAG strategy to areas such as clinical QA, medical QA, and financial QA to enhance LLMs with external knowledge and to develop domain-specific applications. For example, ATLANTIC [248] adapts Atlas to the scientific domain to derive a science QA system. Besides, some approaches [254] also apply techniques in federated learning such as multiparty computation to perform personal RAG with privacy protection.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18703.1640625\n",
      "page_content='models outperform their corresponding instruction-tuned versions.\n",
      "6.5\tApplications\n",
      "Recently, researchers [247–253] have applied the RAG strategy to areas such as clinical QA, medical QA, and financial QA to enhance LLMs with external knowledge and to develop domain-specific applications. For example, ATLANTIC [248] adapts Atlas to the scientific domain to derive a science QA system. Besides, some approaches [254] also apply techniques in federated learning such as multiparty computation to perform personal RAG with privacy protection.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18708.1875\n",
      "page_content='•\tText generation evaluation. The wide application of LLMs in IR has led to a notable enhancement in their generation capability. Consequently, there is an imperative demand for novel evaluation strategies to effectively evaluate the performance of passage or answer generation. Previous evaluation metrics for text generation have several limitations, including: (1) Dependency on lexical matching: methods such as BLEU [282] or ROUGE [283] primarily evaluate the quality of generated outputs based on n-gram matching. This approach cannot account for lexical diversity and contextual semantics. As a result, models may favor generating common phrases or sentence structures rather than producing creative and novel content. (2) Insensitivity to subtle differences: existing evaluation methods may be insensitive to subtle differences in generated outputs. For example, if a generated output has minor semantic differences from the reference answer but is otherwise similar, traditional methods' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18708.1875\n",
      "page_content='•\tText generation evaluation. The wide application of LLMs in IR has led to a notable enhancement in their generation capability. Consequently, there is an imperative demand for novel evaluation strategies to effectively evaluate the performance of passage or answer generation. Previous evaluation metrics for text generation have several limitations, including: (1) Dependency on lexical matching: methods such as BLEU [282] or ROUGE [283] primarily evaluate the quality of generated outputs based on n-gram matching. This approach cannot account for lexical diversity and contextual semantics. As a result, models may favor generating common phrases or sentence structures rather than producing creative and novel content. (2) Insensitivity to subtle differences: existing evaluation methods may be insensitive to subtle differences in generated outputs. For example, if a generated output has minor semantic differences from the reference answer but is otherwise similar, traditional methods' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18708.234375\n",
      "page_content='In the above strategy, the retrieval systems supply documents to LLMs in a periodic manner. However, retrieving documents in a mandatory frequency may mismatch the retrieval timing and can be costly. Recently, FLARE [192] has addressed this problem by automatically determining the timing of retrieval according to the probability of generating texts. Since the probability can serve as an indicator of LLMs’ confidence during text generation [216, 217], a low probability for a generated term could suggest that LLMs require additional knowledge. Specifically, when the probability of a term falls below a predefined threshold, FLARE employs IR systems to retrieve references in accordance with the ongoing generated sentences, while removing these low-probability terms. FLARE adopts this strategy of prompting LLMs for answer generation solely based on the probabilities of generating terms, avoiding the need for finetuning while still maintaining effectiveness. Besides, selfRAG [193] tends to' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18708.234375\n",
      "page_content='In the above strategy, the retrieval systems supply documents to LLMs in a periodic manner. However, retrieving documents in a mandatory frequency may mismatch the retrieval timing and can be costly. Recently, FLARE [192] has addressed this problem by automatically determining the timing of retrieval according to the probability of generating texts. Since the probability can serve as an indicator of LLMs’ confidence during text generation [216, 217], a low probability for a generated term could suggest that LLMs require additional knowledge. Specifically, when the probability of a term falls below a predefined threshold, FLARE employs IR systems to retrieve references in accordance with the ongoing generated sentences, while removing these low-probability terms. FLARE adopts this strategy of prompting LLMs for answer generation solely based on the probabilities of generating terms, avoiding the need for finetuning while still maintaining effectiveness. Besides, selfRAG [193] tends to' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18714.59375\n",
      "page_content='To provide a comprehensive understanding of this topic, Table 4 summarizes the common and unique characteristics of the LLM-based retrievers discussed above.\n",
      "TABLE 4. The comparison of retrievers that leverage LLMs as the foundation. “KD” is short for “Knowledge Distillation”.\n",
      "Methods\tBackbone\tArchitecture\tLLM’s tuning\n",
      "cpt-text [115]\tGPT-series\tDense\tPre-training & Fine-tuning\n",
      "GTR [116]\tT5\tDense\tPre-training & Fine-tuning\n",
      "RepLLaMA [122]\tLLAMA\tDense\tFine-tuning\n",
      "TART-full [129]\tT0 & Flan-T5\tDense\tFine-tuning & Prompting\n",
      "TART-dual [129]\tContriever\tDense\tKD & Prompting\n",
      "DSI [136]\tT5\tGenerative\tFine-tuning\n",
      "LLM-URL [137]\tGPT-3\tGenerative\tPrompting\n",
      "CorpusLM [141]\tT5-base & Llama2-7B-Chat\tGenerative\tFine-tuning\n",
      "4.3 Limitations' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18714.59375\n",
      "page_content='To provide a comprehensive understanding of this topic, Table 4 summarizes the common and unique characteristics of the LLM-based retrievers discussed above.\n",
      "TABLE 4. The comparison of retrievers that leverage LLMs as the foundation. “KD” is short for “Knowledge Distillation”.\n",
      "Methods\tBackbone\tArchitecture\tLLM’s tuning\n",
      "cpt-text [115]\tGPT-series\tDense\tPre-training & Fine-tuning\n",
      "GTR [116]\tT5\tDense\tPre-training & Fine-tuning\n",
      "RepLLaMA [122]\tLLAMA\tDense\tFine-tuning\n",
      "TART-full [129]\tT0 & Flan-T5\tDense\tFine-tuning & Prompting\n",
      "TART-dual [129]\tContriever\tDense\tKD & Prompting\n",
      "DSI [136]\tT5\tGenerative\tFine-tuning\n",
      "LLM-URL [137]\tGPT-3\tGenerative\tPrompting\n",
      "CorpusLM [141]\tT5-base & Llama2-7B-Chat\tGenerative\tFine-tuning\n",
      "4.3 Limitations' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18718.970703125\n",
      "page_content='[276]\tW. Ahmad, S. Chakraborty, B. Ray, and K.-W. Chang, “Unified pre-training for program understanding and generation,” in Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, 2021, pp. 2655–2668.\n",
      "[277]\tD. Zan, B. Chen, D. Yang, Z. Lin, M. Kim, B. Guan, Y. Wang, W. Chen, and J.-G. Lou, “Cert: Continual pre-training on sketches for library-oriented code generation,” arXiv preprint arXiv:2206.06888, 2022.\n",
      "[278]\tR. Just, D. Jalali, and M. D. Ernst, “Defects4j: A database of existing faults to enable controlled testing studies for java programs,” in Proceedings of the 2014 international symposium on software testing and analysis, 2014, pp. 437–440.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18718.970703125\n",
      "page_content='[276]\tW. Ahmad, S. Chakraborty, B. Ray, and K.-W. Chang, “Unified pre-training for program understanding and generation,” in Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, 2021, pp. 2655–2668.\n",
      "[277]\tD. Zan, B. Chen, D. Yang, Z. Lin, M. Kim, B. Guan, Y. Wang, W. Chen, and J.-G. Lou, “Cert: Continual pre-training on sketches for library-oriented code generation,” arXiv preprint arXiv:2206.06888, 2022.\n",
      "[278]\tR. Just, D. Jalali, and M. D. Ernst, “Defects4j: A database of existing faults to enable controlled testing studies for java programs,” in Proceedings of the 2014 international symposium on software testing and analysis, 2014, pp. 437–440.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18719.03125\n",
      "page_content='Liu et al. [245] evaluated the performance of ChatGPT in five recommendation tasks, which include predicting ratings, direct recommendation, sequence recommendation, generating explanations, and summarizing reviews. Based on the evaluation of Amazon beauty datasets, the authors reported that (i) ChatGPT is much better in rating prediction compared to other tasks like direct and sequence recommendation. and (ii) ChatGPT achieves new SOTA results in generating explanations based on human evaluation. Hou et al. [249] demonstrated that GLLMs possess strong potential for zero-shot ranking tasks, showcasing performance that is comparable to or even superior to traditional recommendation models. Here, the authors designed the prompts in a way that important information like candidate items, sequential interaction history and ranking instruction is included. Zhiyuli [244] proposed BookGPT, a novel framework which leverages GLLMs like ChatGPT for book recommendation. Specifically, the' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18719.03125\n",
      "page_content='Liu et al. [245] evaluated the performance of ChatGPT in five recommendation tasks, which include predicting ratings, direct recommendation, sequence recommendation, generating explanations, and summarizing reviews. Based on the evaluation of Amazon beauty datasets, the authors reported that (i) ChatGPT is much better in rating prediction compared to other tasks like direct and sequence recommendation. and (ii) ChatGPT achieves new SOTA results in generating explanations based on human evaluation. Hou et al. [249] demonstrated that GLLMs possess strong potential for zero-shot ranking tasks, showcasing performance that is comparable to or even superior to traditional recommendation models. Here, the authors designed the prompts in a way that important information like candidate items, sequential interaction history and ranking instruction is included. Zhiyuli [244] proposed BookGPT, a novel framework which leverages GLLMs like ChatGPT for book recommendation. Specifically, the' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18720.115234375\n",
      "page_content='4\tRetriever\n",
      "In an IR system, the retriever serves as the first-pass document filter to collect broadly relevant documents for user queries. Given the enormous amounts of documents in an IR system, the retriever ’s efficiency in locating relevant documents is essential for maintaining search engine performance. Meanwhile, a high recall is also important for the retriever, as the retrieved documents are then fed into the ranker to generate final results for users, which determines the ranking quality of search engines.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18720.115234375\n",
      "page_content='4\tRetriever\n",
      "In an IR system, the retriever serves as the first-pass document filter to collect broadly relevant documents for user queries. Given the enormous amounts of documents in an IR system, the retriever ’s efficiency in locating relevant documents is essential for maintaining search engine performance. Meanwhile, a high recall is also important for the retriever, as the retrieved documents are then fed into the ranker to generate final results for users, which determines the ranking quality of search engines.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18733.55859375\n",
      "page_content='and modern neural architectures (such as language models with powerful language understanding capacity). Meanwhile, the emergence of large language models (LLMs), typified by ChatGPT and GPT-4, has revolutionized natural language processing due to their remarkable language understanding, generation, generalization, and reasoning abilities. Consequently, recent research has sought to leverage LLMs to improve IR systems. Given the rapid evolution of this research trajectory, it is necessary to consolidate existing methodologies and provide nuanced insights through a comprehensive overview. In this survey, we delve into the confluence of LLMs and IR systems, including crucial aspects such as query rewriters, retrievers, rerankers, and readers. Additionally, we explore promising directions, such as search agents, within this expanding field.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18733.55859375\n",
      "page_content='and modern neural architectures (such as language models with powerful language understanding capacity). Meanwhile, the emergence of large language models (LLMs), typified by ChatGPT and GPT-4, has revolutionized natural language processing due to their remarkable language understanding, generation, generalization, and reasoning abilities. Consequently, recent research has sought to leverage LLMs to improve IR systems. Given the rapid evolution of this research trajectory, it is necessary to consolidate existing methodologies and provide nuanced insights through a comprehensive overview. In this survey, we delve into the confluence of LLMs and IR systems, including crucial aspects such as query rewriters, retrievers, rerankers, and readers. Additionally, we explore promising directions, such as search agents, within this expanding field.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18739.6015625\n",
      "page_content='[418]\tB. Peng, C. Li, P. He, M. Galley, and J. Gao, “Instruction tuning with gpt-4,” arXiv preprint arXiv:2304.03277, 2023.\n",
      "[419]\tI. Malkiel, U. Alon, Y. Yehuda, S. Keren, O. Barkan, R. Ronen, and N. Koenigstein, “Gpt-calls: Enhancing call segmentation and tagging by generating synthetic conversations via large language models,” arXiv preprint arXiv:2306.07941, 2023.\n",
      "[420]\tJ. P. Wahle, T. Ruas, F. Kirstein, and B. Gipp, “How large language models are transforming machine-paraphrase plagiarism,” in Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, 2022, pp. 952–963.\n",
      "[421]\tA. Michail, S. Konstantinou, and S. Clematide, “Uzh clyp at semeval-2023 task 9: Head-first fine-tuning and chatgpt data generation for cross-lingual learning in tweet intimacy prediction,” arXiv preprint arXiv:2303.01194, 2023.\n",
      "[422]\tR. Tang, X. Han, X. Jiang, and X. Hu, “Does synthetic data generation of llms help clinical text mining?” arXiv preprint arXiv:2303.04360, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18739.6015625\n",
      "page_content='[418]\tB. Peng, C. Li, P. He, M. Galley, and J. Gao, “Instruction tuning with gpt-4,” arXiv preprint arXiv:2304.03277, 2023.\n",
      "[419]\tI. Malkiel, U. Alon, Y. Yehuda, S. Keren, O. Barkan, R. Ronen, and N. Koenigstein, “Gpt-calls: Enhancing call segmentation and tagging by generating synthetic conversations via large language models,” arXiv preprint arXiv:2306.07941, 2023.\n",
      "[420]\tJ. P. Wahle, T. Ruas, F. Kirstein, and B. Gipp, “How large language models are transforming machine-paraphrase plagiarism,” in Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, 2022, pp. 952–963.\n",
      "[421]\tA. Michail, S. Konstantinou, and S. Clematide, “Uzh clyp at semeval-2023 task 9: Head-first fine-tuning and chatgpt data generation for cross-lingual learning in tweet intimacy prediction,” arXiv preprint arXiv:2303.01194, 2023.\n",
      "[422]\tR. Tang, X. Han, X. Jiang, and X. Hu, “Does synthetic data generation of llms help clinical text mining?” arXiv preprint arXiv:2303.04360, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18754.421875\n",
      "page_content='Sheng-Chieh Lin, Jheng-Hong Yang, and Jimmy Lin. In-batch negatives for knowledge distillation with tightly-coupled teachers for dense retrieval. In Proceedings of the 6th Workshop on Representation Learning for NLP (RepL4NLP-2021), pp. 163–173, Online, August 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.repl4nlp-1.17. URL https: //aclanthology.org/2021.repl4nlp-1.17.\n",
      "Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. Roberta: A robustly optimized BERT pretraining approach. CoRR, abs/1907.11692, 2019. URL http://arxiv.org/abs/1907.11692.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Feng 等 - 2023 - Synergistic Interplay between Search and Large Language Models for Information Retrieval.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18754.421875\n",
      "page_content='Sheng-Chieh Lin, Jheng-Hong Yang, and Jimmy Lin. In-batch negatives for knowledge distillation with tightly-coupled teachers for dense retrieval. In Proceedings of the 6th Workshop on Representation Learning for NLP (RepL4NLP-2021), pp. 163–173, Online, August 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.repl4nlp-1.17. URL https: //aclanthology.org/2021.repl4nlp-1.17.\n",
      "Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. Roberta: A robustly optimized BERT pretraining approach. CoRR, abs/1907.11692, 2019. URL http://arxiv.org/abs/1907.11692.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Feng 等 - 2023 - Synergistic Interplay between Search and Large Language Models for Information Retrieval.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18755.462890625\n",
      "page_content='[434]\tD. R. Cotton, P. A. Cotton, and J. R. Shipway, “Chatting and cheating: Ensuring academic integrity in the era of chatgpt,” Innovations in Education and Teaching International, pp. 1–12, 2023.\n",
      "[435]\tP. C. Theocharopoulos, P. Anagnostou, A. Tsoukala, S. V. Georgakopoulos, S. K. Tasoulis, and V. P. Plagianakos, “Detection of fake generated scientific abstracts,” arXiv preprint arXiv:2304.06148, 2023.\n",
      "[436]\tW. Zaitsu and M. Jin, “Distinguishing chatgpt (-3.5,-4)-generated and human-written papers through japanese stylometric analysis,” arXiv preprint arXiv:2304.05534, 2023.\n",
      "[437]\tP. Yu, J. Chen, X. Feng, and Z. Xia, “Cheat: A large-scale dataset for detecting chatgpt-written abstracts,” arXiv preprint arXiv:2304.12008, 2023.\n",
      "[438]\tX. Yang, W. Cheng, L. Petzold, W. Y. Wang, and H. Chen, “Dna-gpt: Divergent n-gram analysis for training-free detection of gpt-generated text,” arXiv preprint arXiv:2305.17359, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18755.462890625\n",
      "page_content='[434]\tD. R. Cotton, P. A. Cotton, and J. R. Shipway, “Chatting and cheating: Ensuring academic integrity in the era of chatgpt,” Innovations in Education and Teaching International, pp. 1–12, 2023.\n",
      "[435]\tP. C. Theocharopoulos, P. Anagnostou, A. Tsoukala, S. V. Georgakopoulos, S. K. Tasoulis, and V. P. Plagianakos, “Detection of fake generated scientific abstracts,” arXiv preprint arXiv:2304.06148, 2023.\n",
      "[436]\tW. Zaitsu and M. Jin, “Distinguishing chatgpt (-3.5,-4)-generated and human-written papers through japanese stylometric analysis,” arXiv preprint arXiv:2304.05534, 2023.\n",
      "[437]\tP. Yu, J. Chen, X. Feng, and Z. Xia, “Cheat: A large-scale dataset for detecting chatgpt-written abstracts,” arXiv preprint arXiv:2304.12008, 2023.\n",
      "[438]\tX. Yang, W. Cheng, L. Petzold, W. Y. Wang, and H. Chen, “Dna-gpt: Divergent n-gram analysis for training-free detection of gpt-generated text,” arXiv preprint arXiv:2305.17359, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18755.734375\n",
      "page_content='[17]\tG. Kim, S. Kim, B. Jeon, J. Park, and J. Kang. Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models. In H. Bouamor, J. Pino, and K. Bali, editors, Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 996–1009, Singapore, Dec. 2023. Association for Computational Linguistics. doi: 10.18653/v1/2023.emnlp-main.63. URL https://aclanthology.org/2023.emnlp-main.63.\n",
      "[18]\tT. Kwiatkowski, J. Palomaki, O. Redfield, M. Collins, A. Parikh, C. Alberti, D. Epstein, I. Polosukhin, J. Devlin, K. Lee, K. Toutanova, L. Jones, M. Kelcey, M.-W. Chang, A. M. Dai, J. Uszkoreit, Q. Le, and S. Petrov. Natural questions: A benchmark for question answering research. Transactions of the Association for Computational Linguistics, 7:452–466, 2019. doi: 10.1162/tacl_a_00276. URL https: //aclanthology.org/Q19-1026.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18755.734375\n",
      "page_content='[17]\tG. Kim, S. Kim, B. Jeon, J. Park, and J. Kang. Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models. In H. Bouamor, J. Pino, and K. Bali, editors, Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 996–1009, Singapore, Dec. 2023. Association for Computational Linguistics. doi: 10.18653/v1/2023.emnlp-main.63. URL https://aclanthology.org/2023.emnlp-main.63.\n",
      "[18]\tT. Kwiatkowski, J. Palomaki, O. Redfield, M. Collins, A. Parikh, C. Alberti, D. Epstein, I. Polosukhin, J. Devlin, K. Lee, K. Toutanova, L. Jones, M. Kelcey, M.-W. Chang, A. M. Dai, J. Uszkoreit, Q. Le, and S. Petrov. Natural questions: A benchmark for question answering research. Transactions of the Association for Computational Linguistics, 7:452–466, 2019. doi: 10.1162/tacl_a_00276. URL https: //aclanthology.org/Q19-1026.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18765.466796875\n",
      "page_content='[330]\tV. Nair, E. Schumacher, and A. Kannan, “Generating medically-accurate summaries of patient-provider dialogue: A multistage approach using large language models,” arXiv preprint arXiv:2305.05982, 2023.\n",
      "[331]\tC. Shaib, M. L. Li, S. Joseph, I. J. Marshall, J. J. Li, and B. C. Wallace, “Summarizing, simplifying, and synthesizing medical evidence using gpt-3 (with varying success),” arXiv preprint arXiv:2305.06299, 2023.\n",
      "[332]\tJ. Xu, L. Lu, S. Yang, B. Liang, X. Peng, J. Pang, J. Ding, X. Shi, L. Yang, H. Song et al., “Medgpteval: A dataset and benchmark to evaluate responses of large language models in medicine,” arXiv preprint arXiv:2305.07340, 2023.\n",
      "[333]\tX. Wang, Z. Gong, G. Wang, J. Jia, Y. Xu, J. Zhao, Q. Fan, S. Wu, W. Hu, and X. Li, “Chatgpt performs on the chinese national medical licensing examination,” 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18765.466796875\n",
      "page_content='[330]\tV. Nair, E. Schumacher, and A. Kannan, “Generating medically-accurate summaries of patient-provider dialogue: A multistage approach using large language models,” arXiv preprint arXiv:2305.05982, 2023.\n",
      "[331]\tC. Shaib, M. L. Li, S. Joseph, I. J. Marshall, J. J. Li, and B. C. Wallace, “Summarizing, simplifying, and synthesizing medical evidence using gpt-3 (with varying success),” arXiv preprint arXiv:2305.06299, 2023.\n",
      "[332]\tJ. Xu, L. Lu, S. Yang, B. Liang, X. Peng, J. Pang, J. Ding, X. Shi, L. Yang, H. Song et al., “Medgpteval: A dataset and benchmark to evaluate responses of large language models in medicine,” arXiv preprint arXiv:2305.07340, 2023.\n",
      "[333]\tX. Wang, Z. Gong, G. Wang, J. Jia, Y. Xu, J. Zhao, Q. Fan, S. Wu, W. Hu, and X. Li, “Chatgpt performs on the chinese national medical licensing examination,” 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18768.02734375\n",
      "page_content='•\tTransfer learning helps to reduce the requirement of labelled data. (Data efficiency)\n",
      "•\tTransfer learning avoids training models from scratch by providing a good initialization from existing related models. (Faster training and development)\n",
      "•\tTransfer learning helps to enhance the performance on the target task (or domain) by reusing existing knowledge. (Enhance target task performance)\n",
      "•\tTransfer learning is explored across AI areas like computer vision, natural language processing, and speech processing. (Versatile)\n",
      "In conclusion, transfer learning is a powerful learning paradigm in artificial intelligence that has benefits regarding data efficiency, speed, performance, adaptability, and real-world practicality.\n",
      "2.2.3\tTransfer Learning vs Other Learning Paradigms' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18768.02734375\n",
      "page_content='•\tTransfer learning helps to reduce the requirement of labelled data. (Data efficiency)\n",
      "•\tTransfer learning avoids training models from scratch by providing a good initialization from existing related models. (Faster training and development)\n",
      "•\tTransfer learning helps to enhance the performance on the target task (or domain) by reusing existing knowledge. (Enhance target task performance)\n",
      "•\tTransfer learning is explored across AI areas like computer vision, natural language processing, and speech processing. (Versatile)\n",
      "In conclusion, transfer learning is a powerful learning paradigm in artificial intelligence that has benefits regarding data efficiency, speed, performance, adaptability, and real-world practicality.\n",
      "2.2.3\tTransfer Learning vs Other Learning Paradigms' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18774.205078125\n",
      "page_content='We are relying on the model’s knowledge of maintenance that it has gleaned from its massive training corpora in order to task it to perform failure mode classification. The GPT-3.5 (Fine-tuned) model, on the other hand, is fine-tuned on the annotated dataset of 502 (observation, label) pairs, and validated on the 62-pair validation set.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Stewart 等 - 2023 - Large Language Models for Failure Mode Classification An Investigation.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18774.205078125\n",
      "page_content='We are relying on the model’s knowledge of maintenance that it has gleaned from its massive training corpora in order to task it to perform failure mode classification. The GPT-3.5 (Fine-tuned) model, on the other hand, is fine-tuned on the annotated dataset of 502 (observation, label) pairs, and validated on the 62-pair validation set.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Stewart 等 - 2023 - Large Language Models for Failure Mode Classification An Investigation.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18775.033203125\n",
      "page_content='label words. As shown in Figure 3, although the example does not fit into any class, the relative probability of class 1 is close to 1 after normalization, putting it in the forward position in subsequent top-n selection. To improve annotation accuracy, we propose absolute probability refinement, which introduces an additional condition to top-n selection. Specifically, we set a probability threshold for each class. During top-n selection, we filter out examples with absolute probability lower than the probability threshold of their class. By incorporating absolute probability into the annotation, we enhance the correlation between the selected training examples and their classes.\n",
      "3.4. Unlabeled Validation' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18775.033203125\n",
      "page_content='label words. As shown in Figure 3, although the example does not fit into any class, the relative probability of class 1 is close to 1 after normalization, putting it in the forward position in subsequent top-n selection. To improve annotation accuracy, we propose absolute probability refinement, which introduces an additional condition to top-n selection. Specifically, we set a probability threshold for each class. During top-n selection, we filter out examples with absolute probability lower than the probability threshold of their class. By incorporating absolute probability into the annotation, we enhance the correlation between the selected training examples and their classes.\n",
      "3.4. Unlabeled Validation' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18775.474609375\n",
      "page_content='PS4: The Effect of Rewriting Questions. Figure 3 presents a bar graph comparing various metrics for original and rewritten questions in the CAmbigNQ dataset. Rewriting questions improves Exact Match (EM), Precision, and F1 Score—whether or not retrieval augmentation technique is used. However, the recall decreases with rewritten questions. This occurs because the CAmbigNQ dataset labels include all possible answers, and LLMs tend to provide all possible responses to vague questions. The Rewritten questions are more well-intended, prompting LLMs to generate specific answers.\n",
      "Summary. Based on above results from a series of experiments on' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18775.474609375\n",
      "page_content='PS4: The Effect of Rewriting Questions. Figure 3 presents a bar graph comparing various metrics for original and rewritten questions in the CAmbigNQ dataset. Rewriting questions improves Exact Match (EM), Precision, and F1 Score—whether or not retrieval augmentation technique is used. However, the recall decreases with rewritten questions. This occurs because the CAmbigNQ dataset labels include all possible answers, and LLMs tend to provide all possible responses to vague questions. The Rewritten questions are more well-intended, prompting LLMs to generate specific answers.\n",
      "Summary. Based on above results from a series of experiments on' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18781.63671875\n",
      "page_content='[85]\tS. Leivaditi, J. Rossi, and E. Kanoulas, “A benchmark for lease contract review,” arXiv preprint arXiv:2010.10386, 2020.\n",
      "[86]\tZ. Feng, D. Guo, D. Tang, N. Duan, X. Feng, M. Gong, L. Shou, B. Qin, T. Liu, D. Jiang et al., “Codebert: A pre-trained model for programming and natural languages,” in Findings of the Association for Computational Linguistics: EMNLP 2020, 2020, pp. 1536–1547.\n",
      "[87]\tY. Wang, W. Wang, S. Joty, and S. C. Hoi, “Codet5: Identifier-aware unified pre-trained encoder-decoder models for code understanding and generation,” in Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, 2021, pp. 8696–8708.\n",
      "[88]\tY. Wang, H. Le, A. D. Gotmare, N. D. Bui, J. Li, and S. C. Hoi, “Codet5+: Open code large language models for code understanding and generation,” arXiv preprint arXiv:2305.07922, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18781.63671875\n",
      "page_content='[85]\tS. Leivaditi, J. Rossi, and E. Kanoulas, “A benchmark for lease contract review,” arXiv preprint arXiv:2010.10386, 2020.\n",
      "[86]\tZ. Feng, D. Guo, D. Tang, N. Duan, X. Feng, M. Gong, L. Shou, B. Qin, T. Liu, D. Jiang et al., “Codebert: A pre-trained model for programming and natural languages,” in Findings of the Association for Computational Linguistics: EMNLP 2020, 2020, pp. 1536–1547.\n",
      "[87]\tY. Wang, W. Wang, S. Joty, and S. C. Hoi, “Codet5: Identifier-aware unified pre-trained encoder-decoder models for code understanding and generation,” in Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, 2021, pp. 8696–8708.\n",
      "[88]\tY. Wang, H. Le, A. D. Gotmare, N. D. Bui, J. Li, and S. C. Hoi, “Codet5+: Open code large language models for code understanding and generation,” arXiv preprint arXiv:2305.07922, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18799.61328125\n",
      "page_content='[176]\tA. Torfi, R. A. Shirvani, Y. Keneshloo, N. Tavaf, and E. A. Fox, “Natural language processing advancements by deep learning: A survey,” arXiv preprint arXiv:2003.01200, 2020.\n",
      "[177]\tD. Nunes, R. Primi, R. Pires, R. Lotufo, and R. Nogueira, “Evaluating gpt-3.5 and gpt-4 models on brazilian university admission exams,” arXiv preprint arXiv:2303.17003, 2023.\n",
      "[178]\tY. Tan, D. Min, Y. Li, W. Li, N. Hu, Y. Chen, and G. Qi, “Evaluation of chatgpt as a question answering system for answering complex questions,” arXiv preprint arXiv:2303.07992, 2023.\n",
      "[179]\tZ. Yang, Z. Gan, J. Wang, X. Hu, Y. Lu, Z. Liu, and L. Wang, “An empirical study of gpt-3 for few-shot knowledge-based vqa,” in Proceedings of the AAAI Conference on Artificial Intelligence, vol. 36, no. 3, 2022, pp. 3081–3089.\n",
      "[180]\tP. Srivastava, T. Ganu, and S. Guha, “Towards zero-shot and few-shot table question answering using gpt-3,” arXiv preprint arXiv:2210.17284, 2022.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18799.61328125\n",
      "page_content='[176]\tA. Torfi, R. A. Shirvani, Y. Keneshloo, N. Tavaf, and E. A. Fox, “Natural language processing advancements by deep learning: A survey,” arXiv preprint arXiv:2003.01200, 2020.\n",
      "[177]\tD. Nunes, R. Primi, R. Pires, R. Lotufo, and R. Nogueira, “Evaluating gpt-3.5 and gpt-4 models on brazilian university admission exams,” arXiv preprint arXiv:2303.17003, 2023.\n",
      "[178]\tY. Tan, D. Min, Y. Li, W. Li, N. Hu, Y. Chen, and G. Qi, “Evaluation of chatgpt as a question answering system for answering complex questions,” arXiv preprint arXiv:2303.07992, 2023.\n",
      "[179]\tZ. Yang, Z. Gan, J. Wang, X. Hu, Y. Lu, Z. Liu, and L. Wang, “An empirical study of gpt-3 for few-shot knowledge-based vqa,” in Proceedings of the AAAI Conference on Artificial Intelligence, vol. 36, no. 3, 2022, pp. 3081–3089.\n",
      "[180]\tP. Srivastava, T. Ganu, and S. Guha, “Towards zero-shot and few-shot table question answering using gpt-3,” arXiv preprint arXiv:2210.17284, 2022.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18802.380859375\n",
      "page_content='In all the above discussed research works, the performances of GLLMs are just satisfactory but not on par or beyond the performances of commercial machine translation systems. Some of the research works [198]– [201], [204], [205], [207], [208] showed that it is possible to outperform commercial machine translation systems using GLLMs. For example, Jiao et al. [198] investigated the translation capabilities of GLLMs like ChatGPT and GPT-4 and compared the performance with commercial systems like Google Translate, DeepL Translate and Tencent TranSmart. Extensive evaluation of multiple datasets showed that (i) the performance of GLLMs is on par with commercial systems in the case of high resources languages only, and (ii) the translation quality of low-resource languages can be enhanced using a novel pivot prompting strategy, which involves translating into high resource language before translating into the target low resource language. The naive prompts are unable to elicit the' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18802.380859375\n",
      "page_content='In all the above discussed research works, the performances of GLLMs are just satisfactory but not on par or beyond the performances of commercial machine translation systems. Some of the research works [198]– [201], [204], [205], [207], [208] showed that it is possible to outperform commercial machine translation systems using GLLMs. For example, Jiao et al. [198] investigated the translation capabilities of GLLMs like ChatGPT and GPT-4 and compared the performance with commercial systems like Google Translate, DeepL Translate and Tencent TranSmart. Extensive evaluation of multiple datasets showed that (i) the performance of GLLMs is on par with commercial systems in the case of high resources languages only, and (ii) the translation quality of low-resource languages can be enhanced using a novel pivot prompting strategy, which involves translating into high resource language before translating into the target low resource language. The naive prompts are unable to elicit the' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18806.009765625\n",
      "page_content='Augmented Analytics\tFebruary,2019\tFachmedien Wiesbaden GmbH\tThe\tpaper provides\tan extensive examination of augmented analytics, including\tits definition, differentiation from traditional BI\tand advanced analytics, historical shift in\tBI\tand analytics,\tAI\tAnalytics is not specifically mentioned in the provided text. A common limitation of AI in analytics is the potential for biased\tor erroneous results due to biased\tor incomplete training data.\n",
      "\t\t\ttechniques used, analytics cycle\tphases, specific\tAI applications, recognition of expertise\tand stakeholder involvement, addressing AI limitations, and identifying research opportunities in information systems.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kania和Mehta - 2023 - A Literature Review on Augmented Analytics and Natural Language Generation A Review of State of Art.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18806.009765625\n",
      "page_content='Augmented Analytics\tFebruary,2019\tFachmedien Wiesbaden GmbH\tThe\tpaper provides\tan extensive examination of augmented analytics, including\tits definition, differentiation from traditional BI\tand advanced analytics, historical shift in\tBI\tand analytics,\tAI\tAnalytics is not specifically mentioned in the provided text. A common limitation of AI in analytics is the potential for biased\tor erroneous results due to biased\tor incomplete training data.\n",
      "\t\t\ttechniques used, analytics cycle\tphases, specific\tAI applications, recognition of expertise\tand stakeholder involvement, addressing AI limitations, and identifying research opportunities in information systems.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kania和Mehta - 2023 - A Literature Review on Augmented Analytics and Natural Language Generation A Review of State of Art.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18814.77734375\n",
      "page_content='Research works exploring GLLM-based evaluation. The NLP researchers proposed various GLLM-based evaluation frameworks to evaluate the outputs of various NLG tasks like code generation [470], text style transfer [471], text summarization [468], [472], [475]– [480], [482], [483], dialogue generation [468], [472], [477], machine translation [426], [473], [474], [477], [480], [485], story generation [468], [483], paraphrase generation [468], text-to-image synthesis [285], data-to-text generation [477], [483], image captioning [480], text generation [481], open-ended question answering [484], [486]. Most of the research works proposed evaluation frameworks using direct prompting, while some of the research works introduced evaluation frameworks based on advanced prompting strategies like chain-of-thoughts [470], [472] and error analysis prompting [474]. Some of the proposed evaluation frameworks work with and without references [470], [473], [483], while some of them require references' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18814.77734375\n",
      "page_content='Research works exploring GLLM-based evaluation. The NLP researchers proposed various GLLM-based evaluation frameworks to evaluate the outputs of various NLG tasks like code generation [470], text style transfer [471], text summarization [468], [472], [475]– [480], [482], [483], dialogue generation [468], [472], [477], machine translation [426], [473], [474], [477], [480], [485], story generation [468], [483], paraphrase generation [468], text-to-image synthesis [285], data-to-text generation [477], [483], image captioning [480], text generation [481], open-ended question answering [484], [486]. Most of the research works proposed evaluation frameworks using direct prompting, while some of the research works introduced evaluation frameworks based on advanced prompting strategies like chain-of-thoughts [470], [472] and error analysis prompting [474]. Some of the proposed evaluation frameworks work with and without references [470], [473], [483], while some of them require references' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18815.37890625\n",
      "page_content='[118]\tB. Peng, C. Li, P. He, M. Galley, and J. Gao, “Instruction tuning with GPT-4,” CoRR, vol. abs/2304.03277, 2023.\n",
      "[119]\tA. Q. Jiang, A. Sablayrolles, A. Mensch, C. Bamford, D. S. Chaplot, D. de Las Casas, F. Bressand, G. Lengyel, G. Lample, L. Saulnier, L. R. Lavaud, M. Lachaux, P. Stock, T. L. Scao, T. Lavril, T. Wang, T. Lacroix, and W. E. Sayed, “Mistral 7b,” CoRR, vol. abs/2310.06825, 2023.\n",
      "[120]\tS. Gunasekar, Y. Zhang, J. Aneja, C. C. T. Mendes, A. D. Giorno, S. Gopi, M. Javaheripi, P. Kauffmann, G. de Rosa, O. Saarikivi, A. Salim, S. Shah, H. S. Behl, X. Wang, S. Bubeck, R. Eldan, A. T. Kalai, Y. T. Lee, and Y. Li, “Textbooks are all you need,” CoRR, vol. abs/2306.11644, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18815.37890625\n",
      "page_content='[118]\tB. Peng, C. Li, P. He, M. Galley, and J. Gao, “Instruction tuning with GPT-4,” CoRR, vol. abs/2304.03277, 2023.\n",
      "[119]\tA. Q. Jiang, A. Sablayrolles, A. Mensch, C. Bamford, D. S. Chaplot, D. de Las Casas, F. Bressand, G. Lengyel, G. Lample, L. Saulnier, L. R. Lavaud, M. Lachaux, P. Stock, T. L. Scao, T. Lavril, T. Wang, T. Lacroix, and W. E. Sayed, “Mistral 7b,” CoRR, vol. abs/2310.06825, 2023.\n",
      "[120]\tS. Gunasekar, Y. Zhang, J. Aneja, C. C. T. Mendes, A. D. Giorno, S. Gopi, M. Javaheripi, P. Kauffmann, G. de Rosa, O. Saarikivi, A. Salim, S. Shah, H. S. Behl, X. Wang, S. Bubeck, R. Eldan, A. T. Kalai, Y. T. Lee, and Y. Li, “Textbooks are all you need,” CoRR, vol. abs/2306.11644, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18821.69140625\n",
      "page_content='Retriever, as discussed here, is typically employed in the early stages of IR for document recall. The evolution of retrieval technologies reflects a constant pursuit of more effective and efficient methods to address the challenges posed by ever-growing text collections. In numerous experiments on IR systems over the years, the classical “bag-of-words” model BM25 [29] has demonstrated its robust performance and high efficiency. In the wake of the neural IR paradigm’s ascendancy, prevalent approaches have primarily revolved around projecting queries and documents into high-dimensional vector spaces, and subsequently computing their relevance scores through inner product calculations. This paradigmatic shift enables a more efficient understanding of query-document relationships, leveraging the power of vector representations to capture semantic similarities.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18821.69140625\n",
      "page_content='Retriever, as discussed here, is typically employed in the early stages of IR for document recall. The evolution of retrieval technologies reflects a constant pursuit of more effective and efficient methods to address the challenges posed by ever-growing text collections. In numerous experiments on IR systems over the years, the classical “bag-of-words” model BM25 [29] has demonstrated its robust performance and high efficiency. In the wake of the neural IR paradigm’s ascendancy, prevalent approaches have primarily revolved around projecting queries and documents into high-dimensional vector spaces, and subsequently computing their relevance scores through inner product calculations. This paradigmatic shift enables a more efficient understanding of query-document relationships, leveraging the power of vector representations to capture semantic similarities.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18831.19140625\n",
      "page_content='[192]\tJ. Robinson and D. Wingate, “Leveraging large language models for multiple choice question answering,” in The Eleventh International Conference on Learning Representations, 2022.\n",
      "[193]\tY. Weng, B. Li, F. Xia, M. Zhu, B. Sun, S. He, K. Liu, and J. Zhao, “Large language models need holistically thought in medical conversational qa,” arXiv preprint arXiv:2305.05410, 2023.\n",
      "[194]\tS. Lin, J. Hilton, and O. Evans, “Truthfulqa: Measuring how models mimic human falsehoods,” in Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), 2022, pp. 3214–3252.\n",
      "[195]\tJ. Kasai, Y. Kasai, K. Sakaguchi, Y. Yamada, and D. Radev, “Evaluating gpt-4 and chatgpt on japanese medical licensing examinations,” arXiv preprint arXiv:2303.18027, 2023.\n",
      "[196]\tW. Gu, “Linguistically informed chatgpt prompts to enhance japanese-chinese machine translation: A case study on attributive clauses,” arXiv preprint arXiv:2303.15587, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18831.19140625\n",
      "page_content='[192]\tJ. Robinson and D. Wingate, “Leveraging large language models for multiple choice question answering,” in The Eleventh International Conference on Learning Representations, 2022.\n",
      "[193]\tY. Weng, B. Li, F. Xia, M. Zhu, B. Sun, S. He, K. Liu, and J. Zhao, “Large language models need holistically thought in medical conversational qa,” arXiv preprint arXiv:2305.05410, 2023.\n",
      "[194]\tS. Lin, J. Hilton, and O. Evans, “Truthfulqa: Measuring how models mimic human falsehoods,” in Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), 2022, pp. 3214–3252.\n",
      "[195]\tJ. Kasai, Y. Kasai, K. Sakaguchi, Y. Yamada, and D. Radev, “Evaluating gpt-4 and chatgpt on japanese medical licensing examinations,” arXiv preprint arXiv:2303.18027, 2023.\n",
      "[196]\tW. Gu, “Linguistically informed chatgpt prompts to enhance japanese-chinese machine translation: A case study on attributive clauses,” arXiv preprint arXiv:2303.15587, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18853.23046875\n",
      "page_content='Pan et al. [218] reported that ChatGPT exhibits better performance in dialogue state tracking compared to spoken language understanding. Further, the authors showed that the performance of ChatGPT can be enhanced by (i) using a multi-turn interactive prompt for dialogue state tracking and (ii) providing additional details like slot names, examples and descriptions for slot filling in spoken language understanding. Zhao et al. [219] explored the emotion dialogue capabilities of ChatGPT by evaluating the model on five different tasks, namely emotion recognition, emotion cause recognition, dialogue act classification (emotion dialogue understanding), empathetic response generation and emotion support generation. It is reported that' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18853.23046875\n",
      "page_content='Pan et al. [218] reported that ChatGPT exhibits better performance in dialogue state tracking compared to spoken language understanding. Further, the authors showed that the performance of ChatGPT can be enhanced by (i) using a multi-turn interactive prompt for dialogue state tracking and (ii) providing additional details like slot names, examples and descriptions for slot filling in spoken language understanding. Zhao et al. [219] explored the emotion dialogue capabilities of ChatGPT by evaluating the model on five different tasks, namely emotion recognition, emotion cause recognition, dialogue act classification (emotion dialogue understanding), empathetic response generation and emotion support generation. It is reported that' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18865.013671875\n",
      "page_content='[4]\tL. Lakshmanan, “Why large language models like Chatgpt are bullshit artists,” Medium, 16-\tDec-2022. Available:\n",
      "[5]\thttps://web.archive.org/web/20221217075021/https://becominghuman.ai/why-large-\n",
      "language-models-like-chatgpt-are-bullshit-artists-c4d5bb850852.\n",
      "[6]\tD. Q. I. N. D. I. A. Online, “Six limitations of Conversational Artificial Intelligence,” DATAQUEST, 24-May-2022 Available: https://www.dqindia.com/six-limitations-conversational-artificial-intelligence/.\n",
      "[7]\tC. Hashemi-Pour, “What is conversational ai?,” Enterprise AI,\t18-May-2022.\n",
      "Available:\thttps://www.techtarget.com/searchenterpriseai/definition/conversational-\n",
      "AI.\n",
      "[8]\tMark, “31+ best chat GPT use cases in various industries with applications,” MLYearning,\t03-Mar-2023. Available: https://www.mlyearning.org/chat-gpt-use-\n",
      "cases/.\n",
      "[9]\t“LAMDA,”\tWikipedia,\t11-Apr-2023.\tAvailable:\n",
      "https://en.wikipedia.org/wiki/LaMDA.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kania和Mehta - 2023 - A Literature Review on Augmented Analytics and Natural Language Generation A Review of State of Art.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18865.013671875\n",
      "page_content='[4]\tL. Lakshmanan, “Why large language models like Chatgpt are bullshit artists,” Medium, 16-\tDec-2022. Available:\n",
      "[5]\thttps://web.archive.org/web/20221217075021/https://becominghuman.ai/why-large-\n",
      "language-models-like-chatgpt-are-bullshit-artists-c4d5bb850852.\n",
      "[6]\tD. Q. I. N. D. I. A. Online, “Six limitations of Conversational Artificial Intelligence,” DATAQUEST, 24-May-2022 Available: https://www.dqindia.com/six-limitations-conversational-artificial-intelligence/.\n",
      "[7]\tC. Hashemi-Pour, “What is conversational ai?,” Enterprise AI,\t18-May-2022.\n",
      "Available:\thttps://www.techtarget.com/searchenterpriseai/definition/conversational-\n",
      "AI.\n",
      "[8]\tMark, “31+ best chat GPT use cases in various industries with applications,” MLYearning,\t03-Mar-2023. Available: https://www.mlyearning.org/chat-gpt-use-\n",
      "cases/.\n",
      "[9]\t“LAMDA,”\tWikipedia,\t11-Apr-2023.\tAvailable:\n",
      "https://en.wikipedia.org/wiki/LaMDA.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kania和Mehta - 2023 - A Literature Review on Augmented Analytics and Natural Language Generation A Review of State of Art.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18865.724609375\n",
      "page_content='new training set.\n",
      "We conduct experiments on five widely-used datasets, including SST-2 (Socher et al., 2013), R8, R524, AGNews (Zhang et al., 2015) and Movie Review (MR) (Pang and Lee, 2005). More details of the benchmarks and low-resource datasets can be found in Appendix ??.\n",
      "For zero-shot and few-shot experiments, we use InstructGPT-3 (Ouyang et al., 2022) (text-davinci-003, 175B) as the backbone. Due to the input token limitation, we use k = 16 for few-shot setups. Prompts on the five datasets are shown in Appendix ??. Model hyper-parameters can be found in Table 3 5.\n",
      "We use Vanilla to denote the conventional ICL approach where LLMs are directly prompted to generate labels. We use CoT (Kojima et al., 2022)\n",
      "4R8 and R52 are original from https://www.cs.umb. edu/~smimarog/textmining/datasets/\n",
      "5 During experiments, we find that CARP is robust with different hyper-parameters. Experimental results can be found in Appendix B.2' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18865.724609375\n",
      "page_content='new training set.\n",
      "We conduct experiments on five widely-used datasets, including SST-2 (Socher et al., 2013), R8, R524, AGNews (Zhang et al., 2015) and Movie Review (MR) (Pang and Lee, 2005). More details of the benchmarks and low-resource datasets can be found in Appendix ??.\n",
      "For zero-shot and few-shot experiments, we use InstructGPT-3 (Ouyang et al., 2022) (text-davinci-003, 175B) as the backbone. Due to the input token limitation, we use k = 16 for few-shot setups. Prompts on the five datasets are shown in Appendix ??. Model hyper-parameters can be found in Table 3 5.\n",
      "We use Vanilla to denote the conventional ICL approach where LLMs are directly prompted to generate labels. We use CoT (Kojima et al., 2022)\n",
      "4R8 and R52 are original from https://www.cs.umb. edu/~smimarog/textmining/datasets/\n",
      "5 During experiments, we find that CARP is robust with different hyper-parameters. Experimental results can be found in Appendix B.2' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18866.125\n",
      "page_content='[239]\tY. Xie, J. Gao, P. Zhou, Q. Ye, Y. Hua, J. Kim, F. Wu, and S. Kim, “Rethinking multi-interest learning for candidate matching in recommender systems,” arXiv preprint arXiv:2302.14532, 2023.\n",
      "[240]\tM. Dong, X. Zeng, L. Koehl, and J. Zhang, “An interactive knowledge-based recommender system for fashion product design in the big data environment,” Information Sciences, vol. 540, pp. 469–488, 2020.\n",
      "[241]\tY. Gao, T. Sheng, Y. Xiang, Y. Xiong, H. Wang, and J. Zhang, “Chat-rec: Towards interactive and explainable llms-augmented recommender system,” arXiv preprint arXiv:2303.14524, 2023.\n",
      "[242]\tF. Zhu, Y. Wang, C. Chen, J. Zhou, L. Li, and G. Liu, “Crossdomain recommendation: challenges, progress, and prospects,” arXiv preprint arXiv:2103.01696, 2021.\n",
      "[243]\tL. Wang and E.-P. Lim, “Zero-shot next-item recommendation using large pretrained language models,” arXiv preprint arXiv:2304.03153, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18866.125\n",
      "page_content='[239]\tY. Xie, J. Gao, P. Zhou, Q. Ye, Y. Hua, J. Kim, F. Wu, and S. Kim, “Rethinking multi-interest learning for candidate matching in recommender systems,” arXiv preprint arXiv:2302.14532, 2023.\n",
      "[240]\tM. Dong, X. Zeng, L. Koehl, and J. Zhang, “An interactive knowledge-based recommender system for fashion product design in the big data environment,” Information Sciences, vol. 540, pp. 469–488, 2020.\n",
      "[241]\tY. Gao, T. Sheng, Y. Xiang, Y. Xiong, H. Wang, and J. Zhang, “Chat-rec: Towards interactive and explainable llms-augmented recommender system,” arXiv preprint arXiv:2303.14524, 2023.\n",
      "[242]\tF. Zhu, Y. Wang, C. Chen, J. Zhou, L. Li, and G. Liu, “Crossdomain recommendation: challenges, progress, and prospects,” arXiv preprint arXiv:2103.01696, 2021.\n",
      "[243]\tL. Wang and E.-P. Lim, “Zero-shot next-item recommendation using large pretrained language models,” arXiv preprint arXiv:2304.03153, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18870.421875\n",
      "page_content='[163]\tA. Parry, S. MacAvaney, and D. Ganguly, “Top-down partitioning for efficient list-wise ranking,” CoRR, vol. abs/2405.14589, 2024.\n",
      "[164]\tZ. Qin, R. Jagerman, K. Hui, H. Zhuang, J. Wu, J. Shen, T. Liu, J. Liu, D. Metzler, X. Wang, and M. Bendersky, “Large language models are effective text rankers with pairwise ranking prompting,” CoRR, vol. abs/2306.17563, 2023.\n",
      "[165]\tS. Zhuang, H. Zhuang, B. Koopman, and G. Zuccon, “A setwise approach for effective and highly efficient zero-shot ranking with large language models,” CoRR, vol. abs/2310.09497, 2023.\n",
      "[166]\tJ. Luo, X. Chen, B. He, and L. Sun, “Prp-graph: Pairwise ranking prompting to llms with graph aggregation for effective text re-ranking,” in ACL (1). Association for Computational Linguistics, 2024, pp. 5766–5776.\n",
      "[167]\tL. Yan, Z. Qin, H. Zhuang, R. Jagerman, X. Wang,' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18870.421875\n",
      "page_content='[163]\tA. Parry, S. MacAvaney, and D. Ganguly, “Top-down partitioning for efficient list-wise ranking,” CoRR, vol. abs/2405.14589, 2024.\n",
      "[164]\tZ. Qin, R. Jagerman, K. Hui, H. Zhuang, J. Wu, J. Shen, T. Liu, J. Liu, D. Metzler, X. Wang, and M. Bendersky, “Large language models are effective text rankers with pairwise ranking prompting,” CoRR, vol. abs/2306.17563, 2023.\n",
      "[165]\tS. Zhuang, H. Zhuang, B. Koopman, and G. Zuccon, “A setwise approach for effective and highly efficient zero-shot ranking with large language models,” CoRR, vol. abs/2310.09497, 2023.\n",
      "[166]\tJ. Luo, X. Chen, B. He, and L. Sun, “Prp-graph: Pairwise ranking prompting to llms with graph aggregation for effective text re-ranking,” in ACL (1). Association for Computational Linguistics, 2024, pp. 5766–5776.\n",
      "[167]\tL. Yan, Z. Qin, H. Zhuang, R. Jagerman, X. Wang,' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18870.78125\n",
      "page_content='Initially, we randomly selected 100 questions from the AmbigNQ dataset to generate responses using our proposed method. Unlike previous sections, we set the parameter n in the Knowledge Retriever module to 5. Instead of utilizing webpage snippets as the content of knowledge instances, we visited the searched URLs and read the entire webpage text, filtering out irrelevant information using the BM25 algorithm. After the response finished, the webpage content was then cached in the Memory Knowledge Reservoir. Subsequently, we selected an additional 200 questions from AmbigNQ that are semantically similar to the previously solved questions. These questions were answered with the support of the Memory Knowledge Reservoir and the Retrieval Trigger module, with the popularity threshold θ set as 3.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18870.78125\n",
      "page_content='Initially, we randomly selected 100 questions from the AmbigNQ dataset to generate responses using our proposed method. Unlike previous sections, we set the parameter n in the Knowledge Retriever module to 5. Instead of utilizing webpage snippets as the content of knowledge instances, we visited the searched URLs and read the entire webpage text, filtering out irrelevant information using the BM25 algorithm. After the response finished, the webpage content was then cached in the Memory Knowledge Reservoir. Subsequently, we selected an additional 200 questions from AmbigNQ that are semantically similar to the previously solved questions. These questions were answered with the support of the Memory Knowledge Reservoir and the Retrieval Trigger module, with the popularity threshold θ set as 3.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18882.14453125\n",
      "page_content='4. New Bing, https://www.bing.com/new\n",
      "the larger LLMs have shown impressive emergent abilities when dealing with complex tasks [42], such as generalization and reasoning skills. Leveraging the impressive power of LLMs can undoubtedly improve the performance of IR systems. By incorporating these advanced language models, IR systems can provide users with more accurate responses, ultimately reshaping the landscape of information access and retrieval.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18882.14453125\n",
      "page_content='4. New Bing, https://www.bing.com/new\n",
      "the larger LLMs have shown impressive emergent abilities when dealing with complex tasks [42], such as generalization and reasoning skills. Leveraging the impressive power of LLMs can undoubtedly improve the performance of IR systems. By incorporating these advanced language models, IR systems can provide users with more accurate responses, ultimately reshaping the landscape of information access and retrieval.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18885.044921875\n",
      "page_content='Hong et al. [288] proposed DirecT2V for text-to-video generation, which leverages GPT-4 model as a framelevel director. Here, the GPT-4 model generates descriptions for each frame based on a single prompt, and then the Text-to-Image model is used to generate frames based on these descriptions. Feng et al. [296] developed\n",
      "Paper\tGLLMs Explored\tTask(s)\tPrompt Settings\tMultimodality\tDomain\n",
      "[291]\tGPT-3\tText-based Action Generation\tZS\tImage + Language\tGeneral\n",
      "[292]\tChatGPT\tTwenty Two Vision Language Tasks\tZS\tImage + Language\tGeneral\n",
      "[282]\tGPT-3\tKnowledge-based Visual Question Answering\tFS\tImage + Language\tGeneral\n",
      "[300]\tChatGPT\tAudio Labelling\tZS\tAudio + Language\tGeneral\n",
      "[293]\tChatGPT\tMulti-Image Reasoning, Multi-hop Document Understanding, Open-World Concept Understanding, Video Summarization\tZS\tImage + Language\tGeneral\n",
      "[290]\tGPT-3.5, ChatGPT, GPT-4\tChest X-Ray Report Generation\tZS\tImage + Language\tHealthcare\n",
      "[283]\tGPT-3\tKnowledge-based Visual Question Answering\tFS\tImage + Language\tGeneral' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18885.044921875\n",
      "page_content='Hong et al. [288] proposed DirecT2V for text-to-video generation, which leverages GPT-4 model as a framelevel director. Here, the GPT-4 model generates descriptions for each frame based on a single prompt, and then the Text-to-Image model is used to generate frames based on these descriptions. Feng et al. [296] developed\n",
      "Paper\tGLLMs Explored\tTask(s)\tPrompt Settings\tMultimodality\tDomain\n",
      "[291]\tGPT-3\tText-based Action Generation\tZS\tImage + Language\tGeneral\n",
      "[292]\tChatGPT\tTwenty Two Vision Language Tasks\tZS\tImage + Language\tGeneral\n",
      "[282]\tGPT-3\tKnowledge-based Visual Question Answering\tFS\tImage + Language\tGeneral\n",
      "[300]\tChatGPT\tAudio Labelling\tZS\tAudio + Language\tGeneral\n",
      "[293]\tChatGPT\tMulti-Image Reasoning, Multi-hop Document Understanding, Open-World Concept Understanding, Video Summarization\tZS\tImage + Language\tGeneral\n",
      "[290]\tGPT-3.5, ChatGPT, GPT-4\tChest X-Ray Report Generation\tZS\tImage + Language\tHealthcare\n",
      "[283]\tGPT-3\tKnowledge-based Visual Question Answering\tFS\tImage + Language\tGeneral' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18890.25\n",
      "page_content='[151]\tH. Zhuang, Z. Qin, K. Hui, J. Wu, L. Yan, X. Wang, and M. Bendersky, “Beyond yes and no: Improving zeroshot LLM rankers via scoring fine-grained relevance labels,” CoRR, vol. abs/2310.14122, 2023.\n",
      "[152]\tF. Guo, W. Li, H. Zhuang, Y. Luo, Y. Li, L. Yan, and Y. Zhang, “Generating diverse criteria on-the-fly to improve point-wise LLM rankers,” CoRR, vol. abs/2404.11960, 2024.\n",
      "[153]\tD. S. Sachan, M. Lewis, M. Joshi, A. Aghajanyan, W. Yih, J. Pineau, and L. Zettlemoyer, “Improving passage retrieval with zero-shot question generation,” in EMNLP. Association for Computational Linguistics, 2022, pp. 3781–3797.\n",
      "[154]\tS. Zhuang, B. Liu, B. Koopman, and G. Zuccon,\n",
      "“Open-source large language models are strong zeroshot query likelihood models for document ranking,” in Findings of the Association for Computational Linguistics: EMNLP 2023, Singapore, December 6-10, 2023, H. Bouamor, J. Pino, and K. Bali, Eds. Association for Computational Linguistics, 2023, pp. 8807–8817.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18890.25\n",
      "page_content='[151]\tH. Zhuang, Z. Qin, K. Hui, J. Wu, L. Yan, X. Wang, and M. Bendersky, “Beyond yes and no: Improving zeroshot LLM rankers via scoring fine-grained relevance labels,” CoRR, vol. abs/2310.14122, 2023.\n",
      "[152]\tF. Guo, W. Li, H. Zhuang, Y. Luo, Y. Li, L. Yan, and Y. Zhang, “Generating diverse criteria on-the-fly to improve point-wise LLM rankers,” CoRR, vol. abs/2404.11960, 2024.\n",
      "[153]\tD. S. Sachan, M. Lewis, M. Joshi, A. Aghajanyan, W. Yih, J. Pineau, and L. Zettlemoyer, “Improving passage retrieval with zero-shot question generation,” in EMNLP. Association for Computational Linguistics, 2022, pp. 3781–3797.\n",
      "[154]\tS. Zhuang, B. Liu, B. Koopman, and G. Zuccon,\n",
      "“Open-source large language models are strong zeroshot query likelihood models for document ranking,” in Findings of the Association for Computational Linguistics: EMNLP 2023, Singapore, December 6-10, 2023, H. Bouamor, J. Pino, and K. Bali, Eds. Association for Computational Linguistics, 2023, pp. 8807–8817.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18898.998046875\n",
      "page_content='References\n",
      "Raviteja Anantha, Svitlana Vakulenko, Zhucheng Tu, Shayne Longpre, Stephen Pulman, and Srinivas Chappidi. Open-domain question answering goes conversational via question rewriting. In Kristina Toutanova, Anna Rumshisky, Luke Zettlemoyer, Dilek Hakkani-Tur, Iz Beltagy, Steven Bethard, Ryan Cotterell, Tanmoy Chakraborty, and Yichao Zhou (eds.), Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 520–534, Online, June 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.naacl-main.44. URL https://aclanthology.org/2021. naacl-main.44.\n",
      "Payal Bajaj, Daniel Campos, Nick Craswell, Li Deng, Jianfeng Gao, Xiaodong Liu, Rangan Ma-jumder, Andrew McNamara, Bhaskar Mitra, Tri Nguyen, et al. Ms marco: A human generated machine reading comprehension dataset. arXiv preprint arXiv:1611.09268, 2016.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Feng 等 - 2023 - Synergistic Interplay between Search and Large Language Models for Information Retrieval.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18898.998046875\n",
      "page_content='References\n",
      "Raviteja Anantha, Svitlana Vakulenko, Zhucheng Tu, Shayne Longpre, Stephen Pulman, and Srinivas Chappidi. Open-domain question answering goes conversational via question rewriting. In Kristina Toutanova, Anna Rumshisky, Luke Zettlemoyer, Dilek Hakkani-Tur, Iz Beltagy, Steven Bethard, Ryan Cotterell, Tanmoy Chakraborty, and Yichao Zhou (eds.), Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 520–534, Online, June 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.naacl-main.44. URL https://aclanthology.org/2021. naacl-main.44.\n",
      "Payal Bajaj, Daniel Campos, Nick Craswell, Li Deng, Jianfeng Gao, Xiaodong Liu, Rangan Ma-jumder, Andrew McNamara, Bhaskar Mitra, Tri Nguyen, et al. Ms marco: A human generated machine reading comprehension dataset. arXiv preprint arXiv:1611.09268, 2016.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Feng 等 - 2023 - Synergistic Interplay between Search and Large Language Models for Information Retrieval.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18900.09765625\n",
      "page_content='To address these limitations, we propose a more general and taskspecific approach. This involves parameter-efficient LoRA [12] finetuning of the Gemma-2B model for Ge(•), utilizing a high-quality dataset that is semi-automatically constructed through LLMs’ generation and human’s quality validation. This dataset comprises instances (p, s, Q), each rigorously validated to ensure that responses derived from s are more accurate in hitting the labeled answer compared to those obtained by directly asking the LLM with p. Additionally, we manually verify the quality of generated queries Q to ensure the reliability. The prompt template for generating (s, Q) is as follows:' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18900.09765625\n",
      "page_content='To address these limitations, we propose a more general and taskspecific approach. This involves parameter-efficient LoRA [12] finetuning of the Gemma-2B model for Ge(•), utilizing a high-quality dataset that is semi-automatically constructed through LLMs’ generation and human’s quality validation. This dataset comprises instances (p, s, Q), each rigorously validated to ensure that responses derived from s are more accurate in hitting the labeled answer compared to those obtained by directly asking the LLM with p. Additionally, we manually verify the quality of generated queries Q to ensure the reliability. The prompt template for generating (s, Q) is as follows:' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18903.939453125\n",
      "page_content='TABLE 16. Summary of research works exploring GLLMs for NLP tasks in multilingual settings. Here, ZS represents zero-shot, and FS represents few-shot.\n",
      "ChatGPT degrades in the case of low-resource languages, particularly in the case of languages with nonLatin scripts. Das et al. [368] assessed the effectiveness of ChatGPT for emoji-based hate speech detection in multilingual settings. The authors reported that ChatGPT exhibits good performance but tends to misclassify abusive content as hate speech for non-English languages in the case of non-protected groups. Moreover, Armengol et al. [365] reported that the performance of GPT-3 can be improved in the case of low-resource languages with optimized tokenization.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18903.939453125\n",
      "page_content='TABLE 16. Summary of research works exploring GLLMs for NLP tasks in multilingual settings. Here, ZS represents zero-shot, and FS represents few-shot.\n",
      "ChatGPT degrades in the case of low-resource languages, particularly in the case of languages with nonLatin scripts. Das et al. [368] assessed the effectiveness of ChatGPT for emoji-based hate speech detection in multilingual settings. The authors reported that ChatGPT exhibits good performance but tends to misclassify abusive content as hate speech for non-English languages in the case of non-protected groups. Moreover, Armengol et al. [365] reported that the performance of GPT-3 can be improved in the case of low-resource languages with optimized tokenization.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18910.107421875\n",
      "page_content='1 * indicates equal contributions.\n",
      "2 ♦Zhejiang University, * Shannon.AI, * Amazon ’Nanyang Technological University, ‘ Chongqing University {xiaofei_sun, wufei, jiwei_li}@zju.edu.cn\n",
      "1\tIntroduction\n",
      "Large language models (LLMs) (Radford et al., 2019a; Xue et al., 2020; Zhang et al., 2022a; Rae et al., 2021; Brown et al., 2020; Chowdhery et al., 2022; Ouyang et al., 2022; Thoppilan et al., 2022) have shown the ability for in-context learning (ICL). Given a few demonstration examples, LLMs are prompted to generate results for a new test example, and have achieved performance comparable to supervised baselines or even state-of-the-art results in a variety of natural language processing (NLP) tasks such as question answering (Trivedi et al., 2022), natural language inference, (Schick and Schütze, 2020), named entity recognition (Wang et al., 2023), relation extraction (Wan et al., 2023) and information extraction (Han et al., 2021).' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18910.107421875\n",
      "page_content='1 * indicates equal contributions.\n",
      "2 ♦Zhejiang University, * Shannon.AI, * Amazon ’Nanyang Technological University, ‘ Chongqing University {xiaofei_sun, wufei, jiwei_li}@zju.edu.cn\n",
      "1\tIntroduction\n",
      "Large language models (LLMs) (Radford et al., 2019a; Xue et al., 2020; Zhang et al., 2022a; Rae et al., 2021; Brown et al., 2020; Chowdhery et al., 2022; Ouyang et al., 2022; Thoppilan et al., 2022) have shown the ability for in-context learning (ICL). Given a few demonstration examples, LLMs are prompted to generate results for a new test example, and have achieved performance comparable to supervised baselines or even state-of-the-art results in a variety of natural language processing (NLP) tasks such as question answering (Trivedi et al., 2022), natural language inference, (Schick and Schütze, 2020), named entity recognition (Wang et al., 2023), relation extraction (Wan et al., 2023) and information extraction (Han et al., 2021).' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18913.03125\n",
      "page_content='s = G(q‘) = G(q ® p)\t(2)\n",
      "where ® is the prompt formulation operation for q and p. For each q‘, if we sample h examples via LLM G, we will obtain a knowledge collection S = {s1, s2,..., sh}.\n",
      "4\tInteR\n",
      "On top of the preliminaries, we introduce InteR, a novel IR framework that iteratively performs information refinement through synergy between RMs and LLMs. The overview is shown in Figure 1. During each iteration, the RM part and LLM part refine their information in the query through interplay with knowledge collection (via LLMs) or retrieved documents (via RMs) from previous iteration. Specifically, in RM part, InteR refines the information stored in query q with knowledge collection S generated by LLM for better document retrieval. While in LLM part, InteR refines the information in original query q with retrieved document D from RM for better invoking LLM to generate most relevant knowledge. This two-step procedure can be repeated multiple times in an iterative refinement style.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Feng 等 - 2023 - Synergistic Interplay between Search and Large Language Models for Information Retrieval.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18913.03125\n",
      "page_content='s = G(q‘) = G(q ® p)\t(2)\n",
      "where ® is the prompt formulation operation for q and p. For each q‘, if we sample h examples via LLM G, we will obtain a knowledge collection S = {s1, s2,..., sh}.\n",
      "4\tInteR\n",
      "On top of the preliminaries, we introduce InteR, a novel IR framework that iteratively performs information refinement through synergy between RMs and LLMs. The overview is shown in Figure 1. During each iteration, the RM part and LLM part refine their information in the query through interplay with knowledge collection (via LLMs) or retrieved documents (via RMs) from previous iteration. Specifically, in RM part, InteR refines the information stored in query q with knowledge collection S generated by LLM for better document retrieval. While in LLM part, InteR refines the information in original query q with retrieved document D from RM for better invoking LLM to generate most relevant knowledge. This two-step procedure can be repeated multiple times in an iterative refinement style.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Feng 等 - 2023 - Synergistic Interplay between Search and Large Language Models for Information Retrieval.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18919.171875\n",
      "page_content='The non fine-tuned model also has difficulties producing consistent failure mode labels when dealing with uncertainty. When the model is unable to classify the observation, it responds in a variety of different ways, for example “Insufficient information”, “N/A”, “None”, “No failure mode detected.”, “No failure mode provided.”, and so on. Attempting to resolve all possible variations of these phrases into a single classification (such as “Unknown” or “Other”) is a non-trivial task, and thus the outputs of this model are not readily applicable to downstream tasks.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Stewart 等 - 2023 - Large Language Models for Failure Mode Classification An Investigation.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18919.171875\n",
      "page_content='The non fine-tuned model also has difficulties producing consistent failure mode labels when dealing with uncertainty. When the model is unable to classify the observation, it responds in a variety of different ways, for example “Insufficient information”, “N/A”, “None”, “No failure mode detected.”, “No failure mode provided.”, and so on. Attempting to resolve all possible variations of these phrases into a single classification (such as “Unknown” or “Other”) is a non-trivial task, and thus the outputs of this model are not readily applicable to downstream tasks.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Stewart 等 - 2023 - Large Language Models for Failure Mode Classification An Investigation.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18919.818359375\n",
      "page_content='Some of the research works [373]–[375], [383] showed that GLLMs as data annotators can outperform human annotators. Gilardi et al. [373] investigated the effectiveness of ChatGPT as an annotator in zero-shot settings for four text classification tasks involving tweets and news articles. The authors reported that ChatGPT is' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18919.818359375\n",
      "page_content='Some of the research works [373]–[375], [383] showed that GLLMs as data annotators can outperform human annotators. Gilardi et al. [373] investigated the effectiveness of ChatGPT as an annotator in zero-shot settings for four text classification tasks involving tweets and news articles. The authors reported that ChatGPT is' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18938.484375\n",
      "page_content='[265]\tY. Qin, Z. Cai, D. Jin, L. Yan, S. Liang, K. Zhu, Y. Lin, X. Han, N. Ding, H. Wang, R. Xie, F. Qi, Z. Liu, M. Sun, and J. Zhou, “Webcpm: Interactive web search for chinese long-form question answering,” in Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2023, Toronto, Canada, July 9-14, 2023, A. Rogers, J. L. Boyd-Graber, and N. Okazaki, Eds. Association for Computational Linguistics, 2023, pp. 8968–8988.\n",
      "[266]\tR. Lo, A. Sridhar, F. F. Xu, H. Zhu, and S. Zhou, “Hierarchical prompting assists large language model on web navigation,” in Findings of the Association for Computational Linguistics: EMNLP 2023, Singapore, December 6-10, 2023, H. Bouamor, J. Pino, and K. Bali, Eds. Association for Computational Linguistics, 2023, pp. 10 217–10 244.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18938.484375\n",
      "page_content='[265]\tY. Qin, Z. Cai, D. Jin, L. Yan, S. Liang, K. Zhu, Y. Lin, X. Han, N. Ding, H. Wang, R. Xie, F. Qi, Z. Liu, M. Sun, and J. Zhou, “Webcpm: Interactive web search for chinese long-form question answering,” in Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2023, Toronto, Canada, July 9-14, 2023, A. Rogers, J. L. Boyd-Graber, and N. Okazaki, Eds. Association for Computational Linguistics, 2023, pp. 8968–8988.\n",
      "[266]\tR. Lo, A. Sridhar, F. F. Xu, H. Zhu, and S. Zhou, “Hierarchical prompting assists large language model on web navigation,” in Findings of the Association for Computational Linguistics: EMNLP 2023, Singapore, December 6-10, 2023, H. Bouamor, J. Pino, and K. Bali, Eds. Association for Computational Linguistics, 2023, pp. 10 217–10 244.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18950.80078125\n",
      "page_content='[279]\tD. Lin, J. Koppel, A. Chen, and A. Solar-Lezama, “Quixbugs: A multi-lingual program repair benchmark set based on the quixey challenge,” in Proceedings Companion of the 2017 ACM SIGPLAN international conference on systems, programming, languages, and applications: software for humanity, 2017, pp. 55–56.\n",
      "[280]\tA. Sundar and L. Heck, “Multimodal conversational ai: A survey of datasets and approaches,” in Proceedings of the 4th Workshop on NLP for Conversational AI, 2022, pp. 131–147.\n",
      "[281]\tP. Xu, X. Zhu, and D. A. Clifton, “Multimodal learning with transformers: A survey,” IEEE Transactions on Pattern Analysis and Machine Intelligence, 2023.\n",
      "[282]\tZ. Shao, Z. Yu, M. Wang, and J. Yu, “Prompting large language models with answer heuristics for knowledge-based visual question answering,” in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2023, pp. 14 974–14 983.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18950.80078125\n",
      "page_content='[279]\tD. Lin, J. Koppel, A. Chen, and A. Solar-Lezama, “Quixbugs: A multi-lingual program repair benchmark set based on the quixey challenge,” in Proceedings Companion of the 2017 ACM SIGPLAN international conference on systems, programming, languages, and applications: software for humanity, 2017, pp. 55–56.\n",
      "[280]\tA. Sundar and L. Heck, “Multimodal conversational ai: A survey of datasets and approaches,” in Proceedings of the 4th Workshop on NLP for Conversational AI, 2022, pp. 131–147.\n",
      "[281]\tP. Xu, X. Zhu, and D. A. Clifton, “Multimodal learning with transformers: A survey,” IEEE Transactions on Pattern Analysis and Machine Intelligence, 2023.\n",
      "[282]\tZ. Shao, Z. Yu, M. Wang, and J. Yu, “Prompting large language models with answer heuristics for knowledge-based visual question answering,” in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2023, pp. 14 974–14 983.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18951.90234375\n",
      "page_content='context information, leading to more accurate and context-aware retrieval [27, 51]. In recent years, the neural IR paradigm has gained considerable attention in the research community [30, 52, 53]. By harnessing the powerful representation capabilities of neural networks, this paradigm can capture semantic relationships between queries and documents, thereby significantly enhancing retrieval performance.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18951.90234375\n",
      "page_content='context information, leading to more accurate and context-aware retrieval [27, 51]. In recent years, the neural IR paradigm has gained considerable attention in the research community [30, 52, 53]. By harnessing the powerful representation capabilities of neural networks, this paradigm can capture semantic relationships between queries and documents, thereby significantly enhancing retrieval performance.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18954.4921875\n",
      "page_content='Research works exploring GLLMs for various coding tasks. The research community explored GLLMs for coding tasks across various languages like Java [251], [252], [255], [260], [263], [264], [266], [267], [269], [270], Python [253], [254], [256]–[258], [260], [262], [263], [265], [267], [268], [271], PHP [260], GO [260], Ruby [260], JavaScript [260], C [261], [268], C++ [259], [268], Julia [268], and MATLAB [268]. Most of the research works focused on Python and Java languages, while a few research works focused on other languages like GO, PHP, GO, Ruby, JavaScript, C, C++, Julia and MATLAB. The assessment is done in zero and few-shot settings using mostly direct prompts. Table 9 presents a summary of research works exploring GLLMs for various coding tasks.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18954.4921875\n",
      "page_content='Research works exploring GLLMs for various coding tasks. The research community explored GLLMs for coding tasks across various languages like Java [251], [252], [255], [260], [263], [264], [266], [267], [269], [270], Python [253], [254], [256]–[258], [260], [262], [263], [265], [267], [268], [271], PHP [260], GO [260], Ruby [260], JavaScript [260], C [261], [268], C++ [259], [268], Julia [268], and MATLAB [268]. Most of the research works focused on Python and Java languages, while a few research works focused on other languages like GO, PHP, GO, Ruby, JavaScript, C, C++, Julia and MATLAB. The assessment is done in zero and few-shot settings using mostly direct prompts. Table 9 presents a summary of research works exploring GLLMs for various coding tasks.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18958.98828125\n",
      "page_content='[309]\tPlanning in Human-Robot Interaction\tGPT-3.5\tZS\tEnglish\tNo\n",
      "[310]\tPlan Extraction\tGPT-3.5\tFS\tEnglish\tNo\n",
      "[311]\tPlanning\tInstructGPT, ChatGPT\tFS\tEnglish\tNo\n",
      "TABLE 12. Summary of research works exploring GLLMs for planning. Here ZS represents zero-shot, and FS represents few-shot.\n",
      "then be used by automated systems. Olmo et al. [308] explored the GPT-3 model for plan extraction in fewshot settings from the natural language descriptions of workflows and showed that GPT-3 model outperforms existing SOTA models in some cases. Xie et al. [310] explored GPT-3.5 models to extract plans from natural language descriptions. The authors reported that the models are poor planners on their own, which is in line with the existing works [312]–[314] and are better at extracting plans from natural language. However, these models are sensitive to prompts and also struggle in the case of tasks involving spatial or numerical reasoning.\n",
      "5\tPerformance of GLLMs in Specific Domains' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18958.98828125\n",
      "page_content='[309]\tPlanning in Human-Robot Interaction\tGPT-3.5\tZS\tEnglish\tNo\n",
      "[310]\tPlan Extraction\tGPT-3.5\tFS\tEnglish\tNo\n",
      "[311]\tPlanning\tInstructGPT, ChatGPT\tFS\tEnglish\tNo\n",
      "TABLE 12. Summary of research works exploring GLLMs for planning. Here ZS represents zero-shot, and FS represents few-shot.\n",
      "then be used by automated systems. Olmo et al. [308] explored the GPT-3 model for plan extraction in fewshot settings from the natural language descriptions of workflows and showed that GPT-3 model outperforms existing SOTA models in some cases. Xie et al. [310] explored GPT-3.5 models to extract plans from natural language descriptions. The authors reported that the models are poor planners on their own, which is in line with the existing works [312]–[314] and are better at extracting plans from natural language. However, these models are sensitive to prompts and also struggle in the case of tasks involving spatial or numerical reasoning.\n",
      "5\tPerformance of GLLMs in Specific Domains' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18961.8828125\n",
      "page_content='Calibration of Prompt Tuning. The language models are usually trained with multiple large general corpora of plain text. When applying the language model to a specific downstream task, the property of the model’s predicted probabilities is typically not correlated with the correctness probabilities, i.e., the language model is not calibrated for the downstream task. Jiang et al. (2021) observe that the predicted probabilities of BART, T5, GPT-2 are not calibrated on QA tasks and improve the prediction accuracy by fine-tuning and modifying the model’s output. Zhao et al. (2021) consider three factors (common token bias, majority label bias and recency bias) leading to the model bias on certain answers. To reduce the influence of model bias on correctness, Zhao et al. (2021) concatenate meaningless strings into the prompt to measure model bias, and then uses model bias to adjust the model predictions on real inputs. Holtzman et al. (2021) find that language models divide the probability' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18961.8828125\n",
      "page_content='Calibration of Prompt Tuning. The language models are usually trained with multiple large general corpora of plain text. When applying the language model to a specific downstream task, the property of the model’s predicted probabilities is typically not correlated with the correctness probabilities, i.e., the language model is not calibrated for the downstream task. Jiang et al. (2021) observe that the predicted probabilities of BART, T5, GPT-2 are not calibrated on QA tasks and improve the prediction accuracy by fine-tuning and modifying the model’s output. Zhao et al. (2021) consider three factors (common token bias, majority label bias and recency bias) leading to the model bias on certain answers. To reduce the influence of model bias on correctness, Zhao et al. (2021) concatenate meaningless strings into the prompt to measure model bias, and then uses model bias to adjust the model predictions on real inputs. Holtzman et al. (2021) find that language models divide the probability' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18966.8203125\n",
      "page_content='Reader has evolved as a crucial module with the rapid development of LLM technologies. Its ability to comprehend real-time user intent and generate dynamic responses based on the retrieved text has revolutionized the presentation of IR results. In comparison to presenting a list of candidate documents, the reader module organizes answer texts more intuitively, simulating the natural way humans access information. To enhance the credibility of generated responses, the integration of references into generated responses has been an effective technique of the reader module.\n",
      "Furthermore, researchers explore unifying the above modules to develop a novel LLM-driven search model known as the Search Agent. The search agent is distinguished by its simulation of an automated search and result understanding process, which furnishes users with accurate' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18966.8203125\n",
      "page_content='Reader has evolved as a crucial module with the rapid development of LLM technologies. Its ability to comprehend real-time user intent and generate dynamic responses based on the retrieved text has revolutionized the presentation of IR results. In comparison to presenting a list of candidate documents, the reader module organizes answer texts more intuitively, simulating the natural way humans access information. To enhance the credibility of generated responses, the integration of references into generated responses has been an effective technique of the reader module.\n",
      "Furthermore, researchers explore unifying the above modules to develop a novel LLM-driven search model known as the Search Agent. The search agent is distinguished by its simulation of an automated search and result understanding process, which furnishes users with accurate' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18969.61328125\n",
      "page_content='6\tMultilingual Performance of GLLMs\n",
      "Overview. GLLMs are pretrained over large volumes of text data from multiple languages. For example, the corpus used to pretrain the GPT-3 model includes text from around 90 languages, and the percentage of English text is more than 90% [4], [366]. In the beginning, most of the research focused on assessing the performance of GLLMs on English datasets only. However, it is essential to evaluate these models on datasets from non-English languages, especially low-resource languages, to know how effective GLLMs are for non-English languages, and the insights gained from the comprehensive evaluation help to further improve these models towards nonEnglish languages.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18969.61328125\n",
      "page_content='6\tMultilingual Performance of GLLMs\n",
      "Overview. GLLMs are pretrained over large volumes of text data from multiple languages. For example, the corpus used to pretrain the GPT-3 model includes text from around 90 languages, and the percentage of English text is more than 90% [4], [366]. In the beginning, most of the research focused on assessing the performance of GLLMs on English datasets only. However, it is essential to evaluate these models on datasets from non-English languages, especially low-resource languages, to know how effective GLLMs are for non-English languages, and the insights gained from the comprehensive evaluation help to further improve these models towards nonEnglish languages.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18971.736328125\n",
      "page_content='(i)\tDirect: Ask the LLM directly with the original question.\n",
      "(ii)\tRewriter-Retriever-Reader: Prior to retrieval, a Query Rewriter module is employed to generate a query that fetches external knowledge. The external knowledge, along with the original question, is used to prompt the response generation.\n",
      "(iii)\tRewriter+-Retriever-Reader: Prior to retrieval, the Enhanced Query Rewriter module is utilized, generating multiple queries to acquire external knowledge and clarify the original question. Responses are generated using both the rewritten question and all retrieved external knowledge.\n",
      "(iv)\tRewriter+-Retriever-Filter-Reader: Applied before retrieval, the Enhanced Query Rewriter module generates multiple queries and clarifies the original question. A Knowledge Filter is used to discard external knowledge unrelated to the rewritten question. The final response is then generated using the filtered external knowledge and the rewritten question.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18971.736328125\n",
      "page_content='(i)\tDirect: Ask the LLM directly with the original question.\n",
      "(ii)\tRewriter-Retriever-Reader: Prior to retrieval, a Query Rewriter module is employed to generate a query that fetches external knowledge. The external knowledge, along with the original question, is used to prompt the response generation.\n",
      "(iii)\tRewriter+-Retriever-Reader: Prior to retrieval, the Enhanced Query Rewriter module is utilized, generating multiple queries to acquire external knowledge and clarify the original question. Responses are generated using both the rewritten question and all retrieved external knowledge.\n",
      "(iv)\tRewriter+-Retriever-Filter-Reader: Applied before retrieval, the Enhanced Query Rewriter module generates multiple queries and clarifies the original question. A Knowledge Filter is used to discard external knowledge unrelated to the rewritten question. The final response is then generated using the filtered external knowledge and the rewritten question.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18975.51953125\n",
      "page_content='to have university-trained reliability engineers review each of these codes manually given the volume. The opportunity for AI to assist in failure mode classification is therefore an active research area [Sexton et al., 2018, Akhbardeh et al., 2020, Sala et al., 2022, Stewart et al., 2022, Usuga-Cadavid et al., 2022].' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Stewart 等 - 2023 - Large Language Models for Failure Mode Classification An Investigation.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18975.51953125\n",
      "page_content='to have university-trained reliability engineers review each of these codes manually given the volume. The opportunity for AI to assist in failure mode classification is therefore an active research area [Sexton et al., 2018, Akhbardeh et al., 2020, Sala et al., 2022, Stewart et al., 2022, Usuga-Cadavid et al., 2022].' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Stewart 等 - 2023 - Large Language Models for Failure Mode Classification An Investigation.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18980.85546875\n",
      "page_content='Recently, LLMs have exhibited extraordinary abilities in language understanding, text generation, and reasoning. This has motivated researchers to use these abilities to tackle the aforementioned challenges and aid in developing superior retrieval models. Roughly, these studies can be categorized into two groups: (1) leveraging LLMs to generate search data, and (2) employing LLMs to enhance model architecture.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18980.85546875\n",
      "page_content='Recently, LLMs have exhibited extraordinary abilities in language understanding, text generation, and reasoning. This has motivated researchers to use these abilities to tackle the aforementioned challenges and aid in developing superior retrieval models. Roughly, these studies can be categorized into two groups: (1) leveraging LLMs to generate search data, and (2) employing LLMs to enhance model architecture.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18982.39453125\n",
      "page_content='classification problem and proposed a novel approach based on finetuned RoBERTa model. The authors reported that the proposed approach exhibits good performance and also has the ability to detect the text generated using a detection evasion technique. Mitrovic et al. [432] proposed a novel approach based on DistilBERT [92] and SHAP [454] to detect the machine-generated text and explain the reasoning. The proposed approach achieves an accuracy of 79%, and based on the explanations, the authors observed that ChatGPT-generated text maintains a polite tone, lacks specific details and generally refrains from expressing emotions.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18982.39453125\n",
      "page_content='classification problem and proposed a novel approach based on finetuned RoBERTa model. The authors reported that the proposed approach exhibits good performance and also has the ability to detect the text generated using a detection evasion technique. Mitrovic et al. [432] proposed a novel approach based on DistilBERT [92] and SHAP [454] to detect the machine-generated text and explain the reasoning. The proposed approach achieves an accuracy of 79%, and based on the explanations, the authors observed that ChatGPT-generated text maintains a polite tone, lacks specific details and generally refrains from expressing emotions.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18986.26953125\n",
      "page_content='Seq2Seq models [13], [14]. However, the drawbacks of these models like the inability to (i) capture long-term dependencies and (ii) leverage GPUs fully because of sequential processing (except in the case of CNN), resulted in the evolution of advanced deep learning models like Transformers [15], which are fully attention based without any recurrent and convolution layers.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18986.26953125\n",
      "page_content='Seq2Seq models [13], [14]. However, the drawbacks of these models like the inability to (i) capture long-term dependencies and (ii) leverage GPUs fully because of sequential processing (except in the case of CNN), resulted in the evolution of advanced deep learning models like Transformers [15], which are fully attention based without any recurrent and convolution layers.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18987.55078125\n",
      "page_content='5.3\tImplementation Details\n",
      "As for the LLM part, we evaluate our proposed method on two options: closed-source models and open-source models. In the case of closed-source models, we employ the gpt-3.5-turbo, as it is popular and accessible to the general public3. As for the open-source models, our choice fell upon the Vicuna models (Chiang et al., 2023) derived from instruction tuning with LLaMa-1/2 (Touvron et al., 2023a;b). Specifically, we assessed the most promising 13B version of Vicuna from LLaMa-2, namely, Vicuna-13B-v1.5. Additionally, we evaluated the current best-performing 33B version of Vicuna derived from LLaMa-1, which is Vicuna-33B-v1.3. As for the RM part, we consider BM25 for retrieval since it is much faster. For each q‘, we sample h = 10 knowledge examples via\n",
      "3We utilize the March 1, 2023 version of the gpt-3.5-turbo to avoid any interference caused by upgrading.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Feng 等 - 2023 - Synergistic Interplay between Search and Large Language Models for Information Retrieval.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18987.55078125\n",
      "page_content='5.3\tImplementation Details\n",
      "As for the LLM part, we evaluate our proposed method on two options: closed-source models and open-source models. In the case of closed-source models, we employ the gpt-3.5-turbo, as it is popular and accessible to the general public3. As for the open-source models, our choice fell upon the Vicuna models (Chiang et al., 2023) derived from instruction tuning with LLaMa-1/2 (Touvron et al., 2023a;b). Specifically, we assessed the most promising 13B version of Vicuna from LLaMa-2, namely, Vicuna-13B-v1.5. Additionally, we evaluated the current best-performing 33B version of Vicuna derived from LLaMa-1, which is Vicuna-33B-v1.3. As for the RM part, we consider BM25 for retrieval since it is much faster. For each q‘, we sample h = 10 knowledge examples via\n",
      "3We utilize the March 1, 2023 version of the gpt-3.5-turbo to avoid any interference caused by upgrading.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Feng 等 - 2023 - Synergistic Interplay between Search and Large Language Models for Information Retrieval.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18997.33984375\n",
      "page_content='[179]\tGPT-3\tKnowledge-based Visual Question Answering\tFS\tImage + Language\tGeneral\n",
      "[296]\tGPT-3.5, ChatGPT, GPT-4\tLayout Generation\tFS\tImage + Language\tGeneral\n",
      "[302]\tChatGPT, GPT-4\tMultimodal tasks covering text, video, audio and images\tZS\tMultimodal covering text, video, audio and images\tGeneral\n",
      "[287]\tGPT-3.5, ChatGPT, GPT-4\tControlled Text-to-Image Generation\tZS\tImage + Language\tGeneral\n",
      "[297]\tChatGPT\tParaphrasing\tZS\tImage + Language\tGeneral\n",
      "[289]\tChatGPT\tAudio Understanding and Generation Tasks\tZS\tMultimodal covering text, audio and images\tGeneral\n",
      "[298]\tGPT-4\tGenerate Instruction Tuning Dataset\tFS\tImage + Language\tHealthcare\n",
      "[284]\tGPT-3\tKnowledge-based Visual Question Answering\tFS\tImage + Language\tGeneral\n",
      "TABLE 10. Summary of research works exploring GLLMs for various multimodal AI tasks. Here ZS represents zero-shot, and FS represents few-shot.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 18997.33984375\n",
      "page_content='[179]\tGPT-3\tKnowledge-based Visual Question Answering\tFS\tImage + Language\tGeneral\n",
      "[296]\tGPT-3.5, ChatGPT, GPT-4\tLayout Generation\tFS\tImage + Language\tGeneral\n",
      "[302]\tChatGPT, GPT-4\tMultimodal tasks covering text, video, audio and images\tZS\tMultimodal covering text, video, audio and images\tGeneral\n",
      "[287]\tGPT-3.5, ChatGPT, GPT-4\tControlled Text-to-Image Generation\tZS\tImage + Language\tGeneral\n",
      "[297]\tChatGPT\tParaphrasing\tZS\tImage + Language\tGeneral\n",
      "[289]\tChatGPT\tAudio Understanding and Generation Tasks\tZS\tMultimodal covering text, audio and images\tGeneral\n",
      "[298]\tGPT-4\tGenerate Instruction Tuning Dataset\tFS\tImage + Language\tHealthcare\n",
      "[284]\tGPT-3\tKnowledge-based Visual Question Answering\tFS\tImage + Language\tGeneral\n",
      "TABLE 10. Summary of research works exploring GLLMs for various multimodal AI tasks. Here ZS represents zero-shot, and FS represents few-shot.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19003.728515625\n",
      "page_content='Abstract—As a primary means of information acquisition, information retrieval (IR) systems, such as search engines, have integrated themselves into our daily lives. These systems also serve as components of dialogue, question-answering, and recommender systems. The trajectory of IR has evolved dynamically from its origins in term-based methods to its integration with advanced neural models. While the neural models excel at capturing complex contextual signals and semantic nuances, thereby reshaping the IR landscape, they still face challenges such as data scarcity, interpretability, and the generation of contextually plausible yet potentially inaccurate responses. This evolution requires a combination of both traditional methods (such as term-based sparse retrieval methods with rapid response) and modern neural architectures (such as language models with powerful language understanding capacity). Meanwhile, the emergence of large language models (LLMs), typified by ChatGPT and GPT-4,' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19003.728515625\n",
      "page_content='Abstract—As a primary means of information acquisition, information retrieval (IR) systems, such as search engines, have integrated themselves into our daily lives. These systems also serve as components of dialogue, question-answering, and recommender systems. The trajectory of IR has evolved dynamically from its origins in term-based methods to its integration with advanced neural models. While the neural models excel at capturing complex contextual signals and semantic nuances, thereby reshaping the IR landscape, they still face challenges such as data scarcity, interpretability, and the generation of contextually plausible yet potentially inaccurate responses. This evolution requires a combination of both traditional methods (such as term-based sparse retrieval methods with rapid response) and modern neural architectures (such as language models with powerful language understanding capacity). Meanwhile, the emergence of large language models (LLMs), typified by ChatGPT and GPT-4,' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19004.41796875\n",
      "page_content='Comparing the Rewriter+-Retriever-Reader setup with the Rewriter-Retriever-Reader setup validates the superiority of the proposed Question Rewriter+ module. Additionally, comparing the Rewriter+-Retriever-Filter-Reader setup with the Rewriter+-Retriever-Reader setup demonstrates the effectiveness of the 4-step RAG pipeline incorporating the Knowledge Filter.\n",
      "4.4\tResults' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19004.41796875\n",
      "page_content='Comparing the Rewriter+-Retriever-Reader setup with the Rewriter-Retriever-Reader setup validates the superiority of the proposed Question Rewriter+ module. Additionally, comparing the Rewriter+-Retriever-Filter-Reader setup with the Rewriter+-Retriever-Reader setup demonstrates the effectiveness of the 4-step RAG pipeline incorporating the Knowledge Filter.\n",
      "4.4\tResults' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19008.197265625\n",
      "page_content='Some of the research works explored GPT-3 family models for other tasks like data labelling [300], generating instructions [301], data generation [297], prompt editing [286] and evaluation [285] while developing multimodal AI systems. Mei et al. [300] used ChatGPT to rewrite those noisy audio captions and developed Wav-Caps, an audio captions dataset of 400k instances. The authors reported that the models trained on WavCaps' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19008.197265625\n",
      "page_content='Some of the research works explored GPT-3 family models for other tasks like data labelling [300], generating instructions [301], data generation [297], prompt editing [286] and evaluation [285] while developing multimodal AI systems. Mei et al. [300] used ChatGPT to rewrite those noisy audio captions and developed Wav-Caps, an audio captions dataset of 400k instances. The authors reported that the models trained on WavCaps' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19012.69921875\n",
      "page_content='Paper\tDetect\tApproach\tSatisfactory Performance\tTraining Free\tDomain(s)\tLanguage(s)\n",
      "[444]\tChatGPT generated text\tEvaluate multiple online tools\tNo\t-\tMultiple domains\tEnglish\n",
      "[435]\tGPT-3 generated text\tClassifiers based on machine learning models like LR, SVM and deep learning models like LSTM and BERT\tYes\tNo\tScientific Literature\tEnglish\n",
      "[436]\tChatGPT\tand GPT-4 generated text\tClassifier based on random forest and stylometric features\tYes\tNo\tScientific Literature\tJapanese\n",
      "[439]\tGPT-3\tand ChatGPT generated text\tClassifier based on models like SVM and RoBERTa\tYes\tNo\tAcademic\tEnglish\n",
      "[437]\tChatGPT generated text\tClassifier based on models like RoBERTa\tNo\tNo\tScientific Literature\tEnglish\n",
      "[441]\tChatGPT generated text\tClassifier based on models like BERT\tYes\tNo\tHealthcare\tEnglish\n",
      "[440]\tChatGPT generated text\tEvaluate multiple online tools\tYes\t-\tAcademic\tEnglish, Spanish\n",
      "[443]\tGPT-3 generated text\tEvaluate human evaluators\tNo\t-\tStories, News, Recipies\tEnglish' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19012.69921875\n",
      "page_content='Paper\tDetect\tApproach\tSatisfactory Performance\tTraining Free\tDomain(s)\tLanguage(s)\n",
      "[444]\tChatGPT generated text\tEvaluate multiple online tools\tNo\t-\tMultiple domains\tEnglish\n",
      "[435]\tGPT-3 generated text\tClassifiers based on machine learning models like LR, SVM and deep learning models like LSTM and BERT\tYes\tNo\tScientific Literature\tEnglish\n",
      "[436]\tChatGPT\tand GPT-4 generated text\tClassifier based on random forest and stylometric features\tYes\tNo\tScientific Literature\tJapanese\n",
      "[439]\tGPT-3\tand ChatGPT generated text\tClassifier based on models like SVM and RoBERTa\tYes\tNo\tAcademic\tEnglish\n",
      "[437]\tChatGPT generated text\tClassifier based on models like RoBERTa\tNo\tNo\tScientific Literature\tEnglish\n",
      "[441]\tChatGPT generated text\tClassifier based on models like BERT\tYes\tNo\tHealthcare\tEnglish\n",
      "[440]\tChatGPT generated text\tEvaluate multiple online tools\tYes\t-\tAcademic\tEnglish, Spanish\n",
      "[443]\tGPT-3 generated text\tEvaluate human evaluators\tNo\t-\tStories, News, Recipies\tEnglish' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19018.90234375\n",
      "page_content='the survey papers written by Yin et al. [54] and Huan et al. [50] provide a review of multi-modal LLMs and the safety and trustworthiness of LLMs, respectively. However, there is no existing survey paper which provides a comprehensive survey of GPT-3 family large language models. With the ever-rising popularity of GPT-3 family large language models like GPT-3, InstructGPT, ChatGPT, GPT-4 etc. and a lot of research works using these models, there is a strong need for a survey paper which focuses exclusively on GPT-3 family large language models.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19018.90234375\n",
      "page_content='the survey papers written by Yin et al. [54] and Huan et al. [50] provide a review of multi-modal LLMs and the safety and trustworthiness of LLMs, respectively. However, there is no existing survey paper which provides a comprehensive survey of GPT-3 family large language models. With the ever-rising popularity of GPT-3 family large language models like GPT-3, InstructGPT, ChatGPT, GPT-4 etc. and a lot of research works using these models, there is a strong need for a survey paper which focuses exclusively on GPT-3 family large language models.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19021.3203125\n",
      "page_content='The analysis of the trade-off between response quality and efficiency for answering historically similar questions across different τ settings is presented in Table 2. A significant finding is that the Time Cost metric reaches minimum when setting the similarity threshold τ = 0.6. This is accompanied by the External Knowledge metric being very small, approximately 4.39, which is roughly equivalent to one query search. This suggests that this configuration predominantly leverages memory knowledge rather than external sources for generating responses, thereby enhancing response efficiency. Remarkably, at the τ = 0.6 setup, the quality of the responses is not heavily affected and remains very close to that achieved by relying entirely on external knowledge at τ = 1.0. This suggests that deploying the Memory Knowledge module can achieve a significant reduction in response time—by approximately 46%—without substantially compromising the quality of the answers. Furthermore, adjusting the' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19021.3203125\n",
      "page_content='The analysis of the trade-off between response quality and efficiency for answering historically similar questions across different τ settings is presented in Table 2. A significant finding is that the Time Cost metric reaches minimum when setting the similarity threshold τ = 0.6. This is accompanied by the External Knowledge metric being very small, approximately 4.39, which is roughly equivalent to one query search. This suggests that this configuration predominantly leverages memory knowledge rather than external sources for generating responses, thereby enhancing response efficiency. Remarkably, at the τ = 0.6 setup, the quality of the responses is not heavily affected and remains very close to that achieved by relying entirely on external knowledge at τ = 1.0. This suggests that deploying the Memory Knowledge module can achieve a significant reduction in response time—by approximately 46%—without substantially compromising the quality of the answers. Furthermore, adjusting the' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19026.2265625\n",
      "page_content='[318]\tZ. Liu, X. Yu, L. Zhang, Z. Wu, C. Cao, H. Dai, L. Zhao, W. Liu, D. Shen, Q. Li et al., “Deid-gpt: Zero-shot medical text deidentification by gpt-4,” arXiv preprint arXiv:2303.11032, 2023.\n",
      "[319]\tJ. Giorgi, A. Toma, R. Xie, S. Chen, K. An, G. Zheng, and B. Wang, “Wanglab at mediqa-chat 2023: Clinical note generation from doctor-patient conversations using large language models,” in Proceedings of the 5th Clinical Natural Language Processing Workshop, 2023, pp. 323–334.\n",
      "[320]\tH. Nori, N. King, S. M. McKinney, D. Carignan, and E. Horvitz, “Capabilities of gpt-4 on medical challenge problems,” ArXiv, vol. abs/2303.13375, 2023.\n",
      "[321]\tQ. Chen, J. Du, Y. Hu, V. K. Keloth, X. Peng, K. Raja, R. Zhang, Z. Lu, and H. Xu, “Large language models in biomedical natural language processing: benchmarks, baselines, and recommendations,” arXiv preprint arXiv:2305.16326, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19026.2265625\n",
      "page_content='[318]\tZ. Liu, X. Yu, L. Zhang, Z. Wu, C. Cao, H. Dai, L. Zhao, W. Liu, D. Shen, Q. Li et al., “Deid-gpt: Zero-shot medical text deidentification by gpt-4,” arXiv preprint arXiv:2303.11032, 2023.\n",
      "[319]\tJ. Giorgi, A. Toma, R. Xie, S. Chen, K. An, G. Zheng, and B. Wang, “Wanglab at mediqa-chat 2023: Clinical note generation from doctor-patient conversations using large language models,” in Proceedings of the 5th Clinical Natural Language Processing Workshop, 2023, pp. 323–334.\n",
      "[320]\tH. Nori, N. King, S. M. McKinney, D. Carignan, and E. Horvitz, “Capabilities of gpt-4 on medical challenge problems,” ArXiv, vol. abs/2303.13375, 2023.\n",
      "[321]\tQ. Chen, J. Du, Y. Hu, V. K. Keloth, X. Peng, K. Raja, R. Zhang, Z. Lu, and H. Xu, “Large language models in biomedical natural language processing: benchmarks, baselines, and recommendations,” arXiv preprint arXiv:2305.16326, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19033.0703125\n",
      "page_content='Mike Lewis, Yinhan Liu, Naman Goyal, Mar-jan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, and Luke Zettle-moyer. 2020. BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 7871–7880, Online. Association for Computational Linguistics.\n",
      "Xiao Liu, Kaixuan Ji, Yicheng Fu, Weng Tam, Zhengxiao Du, Zhilin Yang, and Jie Tang. 2022. P-tuning: Prompt tuning can be comparable to fine-tuning across scales and tasks. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 61–68, Dublin, Ireland. Association for Computational Linguistics.\n",
      "Xiao Liu, Yanan Zheng, Zhengxiao Du, Ming Ding, Yujie Qian, Zhilin Yang, and Jie Tang. 2021. GPT understands, too. CoRR, abs/2103.10385.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19033.0703125\n",
      "page_content='Mike Lewis, Yinhan Liu, Naman Goyal, Mar-jan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, and Luke Zettle-moyer. 2020. BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 7871–7880, Online. Association for Computational Linguistics.\n",
      "Xiao Liu, Kaixuan Ji, Yicheng Fu, Weng Tam, Zhengxiao Du, Zhilin Yang, and Jie Tang. 2022. P-tuning: Prompt tuning can be comparable to fine-tuning across scales and tasks. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 61–68, Dublin, Ireland. Association for Computational Linguistics.\n",
      "Xiao Liu, Yanan Zheng, Zhengxiao Du, Ming Ding, Yujie Qian, Zhilin Yang, and Jie Tang. 2021. GPT understands, too. CoRR, abs/2103.10385.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19035.857421875\n",
      "page_content='INPUT: noyce films it more as a shocking history lesson than as drama.\n",
      "CLUES: - Positive: \"more,\" \"shocking,\" \"history lesson,\" \"drama.\" - Negative: None.\n",
      "REASONING: The input contains positive words such as \"more,\" \"shocking,\" and \"drama,\" which suggest that the sentiment is positive. Additionally, the phrase \"history lesson\" implies that the film is educational and informative, which is generally seen as a positive thing. Therefore, the sentiment of the input is positive.\n",
      "SENTIMENT: Positive\n",
      "INPUT: press the delete key\n",
      "CLUES: - Positive: None. - Negative: \"delete key.\"\n",
      "REASONING: The input contains the phrase \"delete key,\" which implies that something is being removed or erased. This is generally seen as a negative action, suggesting that the sentiment of the input is negative.\n",
      "SENTIMENT: Negative\n",
      "(c)' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19035.857421875\n",
      "page_content='INPUT: noyce films it more as a shocking history lesson than as drama.\n",
      "CLUES: - Positive: \"more,\" \"shocking,\" \"history lesson,\" \"drama.\" - Negative: None.\n",
      "REASONING: The input contains positive words such as \"more,\" \"shocking,\" and \"drama,\" which suggest that the sentiment is positive. Additionally, the phrase \"history lesson\" implies that the film is educational and informative, which is generally seen as a positive thing. Therefore, the sentiment of the input is positive.\n",
      "SENTIMENT: Positive\n",
      "INPUT: press the delete key\n",
      "CLUES: - Positive: None. - Negative: \"delete key.\"\n",
      "REASONING: The input contains the phrase \"delete key,\" which implies that something is being removed or erased. This is generally seen as a negative action, suggesting that the sentiment of the input is negative.\n",
      "SENTIMENT: Negative\n",
      "(c)' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19037.4765625\n",
      "page_content='English datasets, except a few research works focused on other languages like Chinese [128], Slovenian [131], Indonesian [132], Javanese [132], and Buginese [132]. A brief summary of research works exploring GLLMs for various text classification problems is presented in Table 1.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19037.4765625\n",
      "page_content='English datasets, except a few research works focused on other languages like Chinese [128], Slovenian [131], Indonesian [132], Javanese [132], and Buginese [132]. A brief summary of research works exploring GLLMs for various text classification problems is presented in Table 1.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19037.8203125\n",
      "page_content='-\tEach retrieval task should cover a wide range of queries, and should not be too specific.\n",
      "Your output should always be a Python list of strings only, with about 20 elements, and each element corresponds to a distinct retrieval task in one sentence. Do not explain yourself or output anything else. Be creative!\n",
      "Example 1:\n",
      "Provided a scientific claim as query, retrieve documents that help verify or refute the claim. ?\n",
      "Example N:\n",
      "Search for documents that answer a FAQ-style query on children's nutrition.\n",
      "(a) Framework of pseudo query generation\n",
      "Generation prompt\n",
      "(2) Framework of relevance label generation\n",
      "You have been assigned a retrieval task: {#Task}\n",
      "Your mission is to write one text retrieval example for this task in JSON format. The JSON object must contain the following keys:\n",
      "-\t\"user_query\": a string, a random user sea rch query specified by the retrieval task.\n",
      "-\t\"positive_document\": a string, a relevant document for the user query.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19037.8203125\n",
      "page_content='-\tEach retrieval task should cover a wide range of queries, and should not be too specific.\n",
      "Your output should always be a Python list of strings only, with about 20 elements, and each element corresponds to a distinct retrieval task in one sentence. Do not explain yourself or output anything else. Be creative!\n",
      "Example 1:\n",
      "Provided a scientific claim as query, retrieve documents that help verify or refute the claim. ?\n",
      "Example N:\n",
      "Search for documents that answer a FAQ-style query on children's nutrition.\n",
      "(a) Framework of pseudo query generation\n",
      "Generation prompt\n",
      "(2) Framework of relevance label generation\n",
      "You have been assigned a retrieval task: {#Task}\n",
      "Your mission is to write one text retrieval example for this task in JSON format. The JSON object must contain the following keys:\n",
      "-\t\"user_query\": a string, a random user sea rch query specified by the retrieval task.\n",
      "-\t\"positive_document\": a string, a relevant document for the user query.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19044.701171875\n",
      "page_content='Dec-only\tQ-PEFT [147], Zhang et al. [148], PE-Rank [149]\n",
      "\t\tLiang et al. [150], Zhuang et al. [151], Guo et al. [152], Sachan et al. [153],\n",
      "Unsupervised Rerankers\tPointwise\tZhuang et al. [154], Sun et al. [155], Co-Prompt [156], DemoRank [157], PARADE [158] RankGPT [159], Ma et al. [160],\n",
      "\tListwise\tTang et al. [161], TourRank [162], Parry et al. [163]\n",
      "\tPairwise\tPRP [164], Zhuang et al. [165], PRP-Graph [166], Yan et al. [167]\n",
      "Data\t\tExaRanker [168], ExaRanker-Open [169], InPars-Light [170], Askari et al. [171],\n",
      "\t\tAskari et al. [172], RankVicuna [173],\n",
      "Augmentation\t\tRankZephyr [174], Sun et al. [175]\n",
      "the backbone model structure, we can categorize existing supervised rerankers as: (1) encoder-only, (2) encoder-decoder, and (3) decoder-only.\n",
      "5.1.1\tEncoder-only' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19044.701171875\n",
      "page_content='Dec-only\tQ-PEFT [147], Zhang et al. [148], PE-Rank [149]\n",
      "\t\tLiang et al. [150], Zhuang et al. [151], Guo et al. [152], Sachan et al. [153],\n",
      "Unsupervised Rerankers\tPointwise\tZhuang et al. [154], Sun et al. [155], Co-Prompt [156], DemoRank [157], PARADE [158] RankGPT [159], Ma et al. [160],\n",
      "\tListwise\tTang et al. [161], TourRank [162], Parry et al. [163]\n",
      "\tPairwise\tPRP [164], Zhuang et al. [165], PRP-Graph [166], Yan et al. [167]\n",
      "Data\t\tExaRanker [168], ExaRanker-Open [169], InPars-Light [170], Askari et al. [171],\n",
      "\t\tAskari et al. [172], RankVicuna [173],\n",
      "Augmentation\t\tRankZephyr [174], Sun et al. [175]\n",
      "the backbone model structure, we can categorize existing supervised rerankers as: (1) encoder-only, (2) encoder-decoder, and (3) decoder-only.\n",
      "5.1.1\tEncoder-only' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19054.234375\n",
      "page_content='2.3.2\tWhat is Self-Supervised Learning?\n",
      "Self-supervised learning, a promising learning paradigm in artificial intelligence, helps models from different modalities like language, speech or image to learn background knowledge from large volumes of unlabeled data [21], [22]. Unlike supervised learning, which relies on large volumes of labelled data, self-supervised learning pretrains the models at scale based on the pseudo supervision offered by one or more pretraining tasks. Here, the pseudo supervision stems from the labels, which are automatically generated without human intervention based on the description of the pretraining task. In general, self-supervised learning involves one or more pretraining tasks [1], [3]. Moreover, the efficiency of selfsupervised learning is heavily influenced by the choice of pretraining task [1], [24], [26].' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19054.234375\n",
      "page_content='2.3.2\tWhat is Self-Supervised Learning?\n",
      "Self-supervised learning, a promising learning paradigm in artificial intelligence, helps models from different modalities like language, speech or image to learn background knowledge from large volumes of unlabeled data [21], [22]. Unlike supervised learning, which relies on large volumes of labelled data, self-supervised learning pretrains the models at scale based on the pseudo supervision offered by one or more pretraining tasks. Here, the pseudo supervision stems from the labels, which are automatically generated without human intervention based on the description of the pretraining task. In general, self-supervised learning involves one or more pretraining tasks [1], [3]. Moreover, the efficiency of selfsupervised learning is heavily influenced by the choice of pretraining task [1], [24], [26].' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19054.46875\n",
      "page_content='During pretraining, the GPT-3 model is optimized based on the casual language modeling objective, which involves predicting the next word based on the previous words. In-context learning during inference can be viewed as conditional text generation, where the model generates the output by conditioning on the given prompt. The model performs text generation during pretraining and inference, but it does vanilla text generation during pretraining and conditional text generation during inference. During pretraining, the model conditions on the previous words and generates the next word, i.e., vanilla text generation. However, during incontext learning, the model conditions on the prompt and generates the answer rather than generating the next words, i.e., conditional text generation. So, there is a gap between pretraining and in-context learning at inference. Due to this, in many cases during inference, the GPT-3 model fails to understand the given prompt and tends to generate the next' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19054.46875\n",
      "page_content='During pretraining, the GPT-3 model is optimized based on the casual language modeling objective, which involves predicting the next word based on the previous words. In-context learning during inference can be viewed as conditional text generation, where the model generates the output by conditioning on the given prompt. The model performs text generation during pretraining and inference, but it does vanilla text generation during pretraining and conditional text generation during inference. During pretraining, the model conditions on the previous words and generates the next word, i.e., vanilla text generation. However, during incontext learning, the model conditions on the prompt and generates the answer rather than generating the next words, i.e., conditional text generation. So, there is a gap between pretraining and in-context learning at inference. Due to this, in many cases during inference, the GPT-3 model fails to understand the given prompt and tends to generate the next' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19057.828125\n",
      "page_content='journey is marked by the ascendancy of neural models [3, 30– 32]. These models excel at capturing intricate contextual cues and semantic nuances, reshaping the landscape of IR. However, these neural models still face challenges such as data scarcity, interpretability, and the potential generation of plausible yet inaccurate responses. Thus, the evolution of IR continues to be a journey of balancing traditional strengths (such as the BM25 algorithm’s high efficiency) with the remarkable capability (such as semantic understanding) brought about by modern neural architectures.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19057.828125\n",
      "page_content='journey is marked by the ascendancy of neural models [3, 30– 32]. These models excel at capturing intricate contextual cues and semantic nuances, reshaping the landscape of IR. However, these neural models still face challenges such as data scarcity, interpretability, and the potential generation of plausible yet inaccurate responses. Thus, the evolution of IR continues to be a journey of balancing traditional strengths (such as the BM25 algorithm’s high efficiency) with the remarkable capability (such as semantic understanding) brought about by modern neural architectures.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19059.328125\n",
      "page_content='6.3\tCompressor\n",
      "Existing LLMs, especially open-sourced ones, such as LLaMA and Flan-T5, have limited input lengths (usually 4,096 or 8,192 tokens). However, the documents or web pages retrieved by upstream IR systems are usually long. Therefore, it is difficult to concatenate all the retrieved documents and feed them into LLMs to generate answers. Though some approaches manage to solve these problems by aggregating the answers supported by each reference as the final answers, this strategy neglects the potential relations between retrieved passages. A more straightforward way is to directly compress the retrieved documents into short input tokens or even dense vectors [223–229].' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19059.328125\n",
      "page_content='6.3\tCompressor\n",
      "Existing LLMs, especially open-sourced ones, such as LLaMA and Flan-T5, have limited input lengths (usually 4,096 or 8,192 tokens). However, the documents or web pages retrieved by upstream IR systems are usually long. Therefore, it is difficult to concatenate all the retrieved documents and feed them into LLMs to generate answers. Though some approaches manage to solve these problems by aggregating the answers supported by each reference as the final answers, this strategy neglects the potential relations between retrieved passages. A more straightforward way is to directly compress the retrieved documents into short input tokens or even dense vectors [223–229].' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19061.1640625\n",
      "page_content='﻿arXiv:2305.07402v3 [cs.CL] 12 Dec 2023\n",
      "Synergistic Interplay between Search and Large Language Models for Information ReTRIEVAL\n",
      "Jiazhan Feng1∗, Chongyang Tao2∗, Xiubo Geng2, Tao Shen3, Can Xu2, Guodong Long3 Dongyan Zhao1, Daxin Jiang2\n",
      "1\tWICT, Peking University, {fengjiazhan,zhaody}@pku.edu.cn\n",
      "2\tMicrosoft Cooperation, {chotao,xigeng,caxu,djiang}@microsoft.com\n",
      "3\tAAII, School of CS, FEIT, UTS, {tao.shen,guodong.long}@uts.edu.au\n",
      "Ab stract' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Feng 等 - 2023 - Synergistic Interplay between Search and Large Language Models for Information Retrieval.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19061.1640625\n",
      "page_content='﻿arXiv:2305.07402v3 [cs.CL] 12 Dec 2023\n",
      "Synergistic Interplay between Search and Large Language Models for Information ReTRIEVAL\n",
      "Jiazhan Feng1∗, Chongyang Tao2∗, Xiubo Geng2, Tao Shen3, Can Xu2, Guodong Long3 Dongyan Zhao1, Daxin Jiang2\n",
      "1\tWICT, Peking University, {fengjiazhan,zhaody}@pku.edu.cn\n",
      "2\tMicrosoft Cooperation, {chotao,xigeng,caxu,djiang}@microsoft.com\n",
      "3\tAAII, School of CS, FEIT, UTS, {tao.shen,guodong.long}@uts.edu.au\n",
      "Ab stract' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Feng 等 - 2023 - Synergistic Interplay between Search and Large Language Models for Information Retrieval.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19082.572265625\n",
      "page_content='4.3\tIterative Interplay B etween RM and LLM\n",
      "In this section, we explain how iterative refinement can be used to improve both RM and LLM parts. This iterative procedure can be interpreted as exploiting the current query q and previous-generated knowledge collection S to retrieve another document set D with RM part for the subsequent stage of LLM step. Then, the LLM part leverages the retrieved documents D from previous stage of RM and synthesizes the knowledge collection S for next RM step. A critical point is that we take LLM as the starting point and use only q and let D be empty as the initial RM input. Therefore, the prompt of first LLM step is formulated as:\n",
      "Please write a passage to answer the question.\n",
      "Question: {query}\n",
      "Passage:\n",
      "2In our preliminary study, we observed that concatenating each si ∈ S multiple times to q can lead to improved performance, as the query is the most crucial component in IR.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Feng 等 - 2023 - Synergistic Interplay between Search and Large Language Models for Information Retrieval.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19082.572265625\n",
      "page_content='4.3\tIterative Interplay B etween RM and LLM\n",
      "In this section, we explain how iterative refinement can be used to improve both RM and LLM parts. This iterative procedure can be interpreted as exploiting the current query q and previous-generated knowledge collection S to retrieve another document set D with RM part for the subsequent stage of LLM step. Then, the LLM part leverages the retrieved documents D from previous stage of RM and synthesizes the knowledge collection S for next RM step. A critical point is that we take LLM as the starting point and use only q and let D be empty as the initial RM input. Therefore, the prompt of first LLM step is formulated as:\n",
      "Please write a passage to answer the question.\n",
      "Question: {query}\n",
      "Passage:\n",
      "2In our preliminary study, we observed that concatenating each si ∈ S multiple times to q can lead to improved performance, as the query is the most crucial component in IR.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Feng 等 - 2023 - Synergistic Interplay between Search and Large Language Models for Information Retrieval.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19089.59765625\n",
      "page_content='[Question]: {Question is here.}\n",
      "[Knowledge]: {The judging knowledge is here.}\n",
      "[Format]: {The explanation.}**{The NLI result.}\n",
      "Considering that LLMs are primarily designed for text regression rather than classification, using only j as a label for instructional tuning for Gemma-2B would prevent the LLM from accurately performing classification tasks in a generative manner. Therefore, we also incorporate the concise explanation e as part of the label, in addition to the NLI classification result j .\n",
      "3.3\tMemory Knowledge Reservoir' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19089.59765625\n",
      "page_content='[Question]: {Question is here.}\n",
      "[Knowledge]: {The judging knowledge is here.}\n",
      "[Format]: {The explanation.}**{The NLI result.}\n",
      "Considering that LLMs are primarily designed for text regression rather than classification, using only j as a label for instructional tuning for Gemma-2B would prevent the LLM from accurately performing classification tasks in a generative manner. Therefore, we also incorporate the concise explanation e as part of the label, in addition to the NLI classification result j .\n",
      "3.3\tMemory Knowledge Reservoir' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19090.365234375\n",
      "page_content='7.2\tData Augmentation ................. 35\n",
      "7.2.1\tParaphrasing ............ 36\n",
      "7.2.2\tData Generation ......... 37\n",
      "8\tDetecting GLLM Generated Text\t38\n",
      "9\tRobustness of GLLMs\t40\n",
      "10\tGLLMs as Evaluators\t42\n",
      "11\tFuture Research Directions\t44\n",
      "11.1\tEnhance Robustness of GLLMs . .\t.\t44\n",
      "11.2\tRed Teaming ....................... 44\n",
      "11.3\tState-Of-The-Art Results Across\n",
      "NLP Tasks ........................ 44\n",
      "11.4\tRobust Approaches to Detect GLLM Generated Text ........................... 45\n",
      "11.5\tReduce Inference Costs ............ 45\n",
      "11.6\tEnhance Performance in Domain-\n",
      "Specific NLP Tasks ............... 45\n",
      "11.7\tHandle Limited Context Length . .\t.\t45\n",
      "11.8\tEnsure Fair Evaluation of GLLMs\t.\t46\n",
      "11.9\tReduce Hallucinations ............. 46\n",
      "11.10\tEnhance the Performance of GLLMs\n",
      "for Non-English Languages ........ 46\n",
      "12 Conclusion\t46\n",
      "References\t46\n",
      "1\tIntroduction' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19090.365234375\n",
      "page_content='7.2\tData Augmentation ................. 35\n",
      "7.2.1\tParaphrasing ............ 36\n",
      "7.2.2\tData Generation ......... 37\n",
      "8\tDetecting GLLM Generated Text\t38\n",
      "9\tRobustness of GLLMs\t40\n",
      "10\tGLLMs as Evaluators\t42\n",
      "11\tFuture Research Directions\t44\n",
      "11.1\tEnhance Robustness of GLLMs . .\t.\t44\n",
      "11.2\tRed Teaming ....................... 44\n",
      "11.3\tState-Of-The-Art Results Across\n",
      "NLP Tasks ........................ 44\n",
      "11.4\tRobust Approaches to Detect GLLM Generated Text ........................... 45\n",
      "11.5\tReduce Inference Costs ............ 45\n",
      "11.6\tEnhance Performance in Domain-\n",
      "Specific NLP Tasks ............... 45\n",
      "11.7\tHandle Limited Context Length . .\t.\t45\n",
      "11.8\tEnsure Fair Evaluation of GLLMs\t.\t46\n",
      "11.9\tReduce Hallucinations ............. 46\n",
      "11.10\tEnhance the Performance of GLLMs\n",
      "for Non-English Languages ........ 46\n",
      "12 Conclusion\t46\n",
      "References\t46\n",
      "1\tIntroduction' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19092.10546875\n",
      "page_content='•\tSequential Computation - RNN and its variants process the input sequence token by token, i.e. sequentially. This sequential computation is a bottleneck for these models to leverage parallel computing capability in advanced computing hardware like GPUs and TPUs. This sequential computation also slows\n",
      "down training and inference processes, especially for long sequences.\n",
      "2.1.3\tTransformer Description' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19092.10546875\n",
      "page_content='•\tSequential Computation - RNN and its variants process the input sequence token by token, i.e. sequentially. This sequential computation is a bottleneck for these models to leverage parallel computing capability in advanced computing hardware like GPUs and TPUs. This sequential computation also slows\n",
      "down training and inference processes, especially for long sequences.\n",
      "2.1.3\tTransformer Description' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19098.16796875\n",
      "page_content='[241]\tZ. Jin, P. Cao, Y. Chen, K. Liu, X. Jiang, J. Xu, Q. Li, and J. Zhao, “Tug-of-war between knowledge: Exploring and resolving knowledge conflicts in retrieval-augmented language models,” in Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation, LREC/COLING 2024, 20-25 May, 2024, Torino, Italy, N. Calzolari, M. Kan, V. Hoste, A. Lenci, S. Sakti, and N. Xue, Eds. ELRA and ICCL, 2024, pp. 16 867–16 878.\n",
      "[242]\tS. Cho, S. Jeong, J. Seo, T. Hwang, and J. C. Park, “Typos that broke the rag’s back: Genetic attack on RAG pipeline by simulating documents in the wild via low-level perturbations,” CoRR, vol. abs/2404.13948, 2024.\n",
      "[243]\tJ. Xue, M. Zheng, Y. Hu, F. Liu, X. Chen, and Q. Lou, “Badrag: Identifying vulnerabilities in retrieval augmented generation of large language models,” CoRR, vol. abs/2406.00083, 2024.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19098.16796875\n",
      "page_content='[241]\tZ. Jin, P. Cao, Y. Chen, K. Liu, X. Jiang, J. Xu, Q. Li, and J. Zhao, “Tug-of-war between knowledge: Exploring and resolving knowledge conflicts in retrieval-augmented language models,” in Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation, LREC/COLING 2024, 20-25 May, 2024, Torino, Italy, N. Calzolari, M. Kan, V. Hoste, A. Lenci, S. Sakti, and N. Xue, Eds. ELRA and ICCL, 2024, pp. 16 867–16 878.\n",
      "[242]\tS. Cho, S. Jeong, J. Seo, T. Hwang, and J. C. Park, “Typos that broke the rag’s back: Genetic attack on RAG pipeline by simulating documents in the wild via low-level perturbations,” CoRR, vol. abs/2404.13948, 2024.\n",
      "[243]\tJ. Xue, M. Zheng, Y. Hu, F. Liu, X. Chen, and Q. Lou, “Badrag: Identifying vulnerabilities in retrieval augmented generation of large language models,” CoRR, vol. abs/2406.00083, 2024.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19109.19921875\n",
      "page_content='[132]\tChatGPT\tZS\tGeneral\tTwelve languages, including four low-resource languages\tSentence\tNo\n",
      "[204]\tGPT-3.5\tZS\tGeneral\t18 language Pairs, including Japanese, English and Polish\tSentence, Paragraph\tYes\n",
      "[205]\tGPT-3.5\tZS, FS\tGeneral\tEnglish, Arabic, Chinese, German, Spanish\tSentence\tYes\n",
      "[206]\tGPT-3.5\tZS, FS\tGeneral\tEnglish, Chinese, Japanese, German, French\tSentence\tNo\n",
      "[207]\tGPT-3.5, GPT-4\tZS\tGeneral\tEnglish, German, Chinese\tSentence\tYes\n",
      "[208]\tGPT-3.5\tZS\tGeneral\tEnglish, German, Russian\tSentence\tYes\n",
      "TABLE 4. Summary of research works exploring GLLMs for machine translation. Here ZS represents zero-shot, and FS represents few-shot.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19109.19921875\n",
      "page_content='[132]\tChatGPT\tZS\tGeneral\tTwelve languages, including four low-resource languages\tSentence\tNo\n",
      "[204]\tGPT-3.5\tZS\tGeneral\t18 language Pairs, including Japanese, English and Polish\tSentence, Paragraph\tYes\n",
      "[205]\tGPT-3.5\tZS, FS\tGeneral\tEnglish, Arabic, Chinese, German, Spanish\tSentence\tYes\n",
      "[206]\tGPT-3.5\tZS, FS\tGeneral\tEnglish, Chinese, Japanese, German, French\tSentence\tNo\n",
      "[207]\tGPT-3.5, GPT-4\tZS\tGeneral\tEnglish, German, Chinese\tSentence\tYes\n",
      "[208]\tGPT-3.5\tZS\tGeneral\tEnglish, German, Russian\tSentence\tYes\n",
      "TABLE 4. Summary of research works exploring GLLMs for machine translation. Here ZS represents zero-shot, and FS represents few-shot.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19119.84375\n",
      "page_content='Methods with relevance judgment Moreover, we also incorporate several systems that utilize fine-tuning on extensive query-document relevance data, such as MS-MARCO, as references (denoted as w/ relevance judgment). This group encompasses some commonly used fully-supervised retrieval methods, including DeepCT (Dai & Callan, 2019), DPR (Karpukhin et al., 2020), ANCE (Xiong et al., 2021), and the fine-tuned Contriever (Izacard et al., 2022) (denoted as ContrieverFT).\n",
      "5.3\tImplementation Details' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Feng 等 - 2023 - Synergistic Interplay between Search and Large Language Models for Information Retrieval.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19119.84375\n",
      "page_content='Methods with relevance judgment Moreover, we also incorporate several systems that utilize fine-tuning on extensive query-document relevance data, such as MS-MARCO, as references (denoted as w/ relevance judgment). This group encompasses some commonly used fully-supervised retrieval methods, including DeepCT (Dai & Callan, 2019), DPR (Karpukhin et al., 2020), ANCE (Xiong et al., 2021), and the fine-tuned Contriever (Izacard et al., 2022) (denoted as ContrieverFT).\n",
      "5.3\tImplementation Details' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Feng 等 - 2023 - Synergistic Interplay between Search and Large Language Models for Information Retrieval.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19121.970703125\n",
      "page_content='7.2.1\tParaphrasing\n",
      "Research works exploring GLLMs for paraphrasingbased data augmentation. The research community explored GLLMs for paraphrasing in various NLP tasks like intent classification [143], [390], [397], machine translation [391], named entity recognition [392], question answering [393], medical event classification [395], medication identification [395] etc. GLLM-based paraphrasing is explored in multiple domains like general [390]–[392], [394], [396], [397], news [392], social media [143], [392] and healthcare [392], [393], [395], [396]. Table 18 presents a summary of research works exploring GLLMs for paraphrasing-based data augmentation.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19121.970703125\n",
      "page_content='7.2.1\tParaphrasing\n",
      "Research works exploring GLLMs for paraphrasingbased data augmentation. The research community explored GLLMs for paraphrasing in various NLP tasks like intent classification [143], [390], [397], machine translation [391], named entity recognition [392], question answering [393], medical event classification [395], medication identification [395] etc. GLLM-based paraphrasing is explored in multiple domains like general [390]–[392], [394], [396], [397], news [392], social media [143], [392] and healthcare [392], [393], [395], [396]. Table 18 presents a summary of research works exploring GLLMs for paraphrasing-based data augmentation.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19135.5625\n",
      "page_content='Traditional query rewriting strategies primarily include techniques such as utilizing lexical knowledge bases [67– 71] and pseudo-relevance feedback [72–74]. However, these methods are limited due to the inadequate capabilities of knowledge models and the presence of noisy signals from coarse matching between the query and the top-k retrieved documents. LLMs, pretrained on vast datasets, demonstrate considerable advancements in the breadth of knowledge and language understanding, positioning them as an excellent resource for query rewriting tasks. In the subsequent sections, we provide a comprehensive review of recent research that applies LLMs to query rewriting.\n",
      "3.1\tRewriting Scenarios\n",
      "In the realm of IR, a query rewriter is primarily designed to serve two distinct scenarios: ad-hoc retrieval and con-' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19135.5625\n",
      "page_content='Traditional query rewriting strategies primarily include techniques such as utilizing lexical knowledge bases [67– 71] and pseudo-relevance feedback [72–74]. However, these methods are limited due to the inadequate capabilities of knowledge models and the presence of noisy signals from coarse matching between the query and the top-k retrieved documents. LLMs, pretrained on vast datasets, demonstrate considerable advancements in the breadth of knowledge and language understanding, positioning them as an excellent resource for query rewriting tasks. In the subsequent sections, we provide a comprehensive review of recent research that applies LLMs to query rewriting.\n",
      "3.1\tRewriting Scenarios\n",
      "In the realm of IR, a query rewriter is primarily designed to serve two distinct scenarios: ad-hoc retrieval and con-' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19142.94140625\n",
      "page_content='crafting nuanced, multi-faceted queries for improving the comprehensive search of relevant information. The second subtask is rewriting the input text into a more intention-clear question. Given that both subtasks can be conceptualized as text-to-text task, we have designed them to be executed concurrently for high efficiency. This is achieved through parameter-efficient fine-tuning of the Gemma-2B model, serving as the backbone of the Query Rewriter+. The model is trained on a meticulously constructed supervised dataset, enabling it to efficiently generate both appropriate queries and rewritten question from an original input text. To address the issue of retrieving irrelevant knowledge, we introduce the Knowledge Filter module, which performs the Natural Language Inference (NLI) task to sift through retrieved information and assess its relevance. This NLI model is also based on Gemma-2B and fine-tuned on a carefully designed dataset. The synergistic use of these two modules' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19142.94140625\n",
      "page_content='crafting nuanced, multi-faceted queries for improving the comprehensive search of relevant information. The second subtask is rewriting the input text into a more intention-clear question. Given that both subtasks can be conceptualized as text-to-text task, we have designed them to be executed concurrently for high efficiency. This is achieved through parameter-efficient fine-tuning of the Gemma-2B model, serving as the backbone of the Query Rewriter+. The model is trained on a meticulously constructed supervised dataset, enabling it to efficiently generate both appropriate queries and rewritten question from an original input text. To address the issue of retrieving irrelevant knowledge, we introduce the Knowledge Filter module, which performs the Natural Language Inference (NLI) task to sift through retrieved information and assess its relevance. This NLI model is also based on Gemma-2B and fine-tuned on a carefully designed dataset. The synergistic use of these two modules' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19152.59765625\n",
      "page_content='Thurston Sexton, Melinda Hodkiewicz, Michael P Brundage, and Thomas Smoker. Benchmarking for keyword extraction methodologies in maintenance work orders. In Proceedings of the Annual Conference of the PHM Society, volume 10, 2018.\n",
      "Farhad Akhbardeh, Travis Desell, and Marcos Zampieri. NLP tools for predictive maintenance records in maintnet. In Proceedings of the 1st conference of the Asia-Pacific chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing: System demonstrations, pages 26–32, 2020.\n",
      "Roberto Sala, Fabiana Pirola, Giuditta Pezzotta, and Sergio Cavalieri. NLP-based insights discovery for industrial asset and service improvement: an analysis of maintenance reports. IFAC-PapersOnLine, 55(2):522–527, 2022.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Stewart 等 - 2023 - Large Language Models for Failure Mode Classification An Investigation.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19152.59765625\n",
      "page_content='Thurston Sexton, Melinda Hodkiewicz, Michael P Brundage, and Thomas Smoker. Benchmarking for keyword extraction methodologies in maintenance work orders. In Proceedings of the Annual Conference of the PHM Society, volume 10, 2018.\n",
      "Farhad Akhbardeh, Travis Desell, and Marcos Zampieri. NLP tools for predictive maintenance records in maintnet. In Proceedings of the 1st conference of the Asia-Pacific chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing: System demonstrations, pages 26–32, 2020.\n",
      "Roberto Sala, Fabiana Pirola, Giuditta Pezzotta, and Sergio Cavalieri. NLP-based insights discovery for industrial asset and service improvement: an analysis of maintenance reports. IFAC-PapersOnLine, 55(2):522–527, 2022.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Stewart 等 - 2023 - Large Language Models for Failure Mode Classification An Investigation.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19153.681640625\n",
      "page_content='[397]\tChatGPT\tOpen Intent Detection\tZS\tGeneral\tEnglish\n",
      "TABLE 18. Summary of research works exploring GLLMs for paraphrasing-based data augmentation.\n",
      "to character-level data augmentation, word-level data augmentation approaches involve deletion, replacement, exchange or insertion of words at random positions [405], [406]. Sentence-level approaches like back translation and paraphrasing generate augmented instances by rewriting the sentence [407], [408]. Overall, the main drawbacks of existing data augmentation approaches are (i) lack of sufficient diversity in the augmented instances and (ii) often struggle to guarantee the accurate labelling of the augmented data [396]. To address these drawbacks, the research community focused on leveraging the exceptional generating abilities of GLLMs for data augmentation to ensure sufficient diversity and correct labelling in the augmented data.\n",
      "7.2.1\tParaphrasing' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19153.681640625\n",
      "page_content='[397]\tChatGPT\tOpen Intent Detection\tZS\tGeneral\tEnglish\n",
      "TABLE 18. Summary of research works exploring GLLMs for paraphrasing-based data augmentation.\n",
      "to character-level data augmentation, word-level data augmentation approaches involve deletion, replacement, exchange or insertion of words at random positions [405], [406]. Sentence-level approaches like back translation and paraphrasing generate augmented instances by rewriting the sentence [407], [408]. Overall, the main drawbacks of existing data augmentation approaches are (i) lack of sufficient diversity in the augmented instances and (ii) often struggle to guarantee the accurate labelling of the augmented data [396]. To address these drawbacks, the research community focused on leveraging the exceptional generating abilities of GLLMs for data augmentation to ensure sufficient diversity and correct labelling in the augmented data.\n",
      "7.2.1\tParaphrasing' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19160.8828125\n",
      "page_content='Research works exploring GLLMs for machine translation. In recent times, GLLMs like ChatGPT and GPT-4 demonstrated remarkable performances in both natural language understanding and generation tasks. A good machine translation system requires strong natural language understanding and generation skills. As ChatGPT and GPT-4 possess strong natural language understanding and generation skills, the research community investigated the effectiveness of these models for machine translation across various domains like news' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19160.8828125\n",
      "page_content='Research works exploring GLLMs for machine translation. In recent times, GLLMs like ChatGPT and GPT-4 demonstrated remarkable performances in both natural language understanding and generation tasks. A good machine translation system requires strong natural language understanding and generation skills. As ChatGPT and GPT-4 possess strong natural language understanding and generation skills, the research community investigated the effectiveness of these models for machine translation across various domains like news' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19166.87890625\n",
      "page_content='Clue Generation For a given training example <text> paired with the label word <label-word> (e.g., positive), we ask LLM to generate clues that indicate the label:\n",
      "List CLUES (i.e., keywords, phrases, contextual information, semantic meaning, semantic relationships, tones, references) that support the sentiment determination of the input (limit to 15 words).\n",
      "INPUT: <text>\n",
      "SENTIMENT: <label-word>\n",
      "Reasoning Generation Based on clues generated clues, the input, and the label, we ask LLMs to generate reasoning details3:\n",
      "Based on the input and clues, articulate the diagnostic reasoning process that supports the sentiment determination of the input.\n",
      "INPUT: <text>\n",
      "LABEL: <label-word>\n",
      "CLUES: <clues>\n",
      "REASONING:\n",
      "Given the generated clues and reasonings for all training examples, at test time, when K-nearest examples are selected demonstrations, its corresponding clues and reasons are concatenated to the demonstration. In this way, each demonstration example is composed' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19166.87890625\n",
      "page_content='Clue Generation For a given training example <text> paired with the label word <label-word> (e.g., positive), we ask LLM to generate clues that indicate the label:\n",
      "List CLUES (i.e., keywords, phrases, contextual information, semantic meaning, semantic relationships, tones, references) that support the sentiment determination of the input (limit to 15 words).\n",
      "INPUT: <text>\n",
      "SENTIMENT: <label-word>\n",
      "Reasoning Generation Based on clues generated clues, the input, and the label, we ask LLMs to generate reasoning details3:\n",
      "Based on the input and clues, articulate the diagnostic reasoning process that supports the sentiment determination of the input.\n",
      "INPUT: <text>\n",
      "LABEL: <label-word>\n",
      "CLUES: <clues>\n",
      "REASONING:\n",
      "Given the generated clues and reasonings for all training examples, at test time, when K-nearest examples are selected demonstrations, its corresponding clues and reasons are concatenated to the demonstration. In this way, each demonstration example is composed' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19168.330078125\n",
      "page_content='that including normalized protein names in the prompt enhances the performance of the model. However, finetuned PubMedBERT model outperforms GPT-4 model with an F1-score of 86.47.\n",
      "Yuan et al. [152] demonstrated that advanced prompting strategies like event ranking and chain-of-thought improve the performance of ChatGPT compared to vanilla prompting in temporal relation extraction. However, ChatGPT lags behind traditional neural networks like LSTM and fine-tuned pre-trained language models, which indicates the toughness of the temporal relation extraction task. Wang et al. [138] evaluated the performances of the latest LLMs like GPT-3.5, GPT-4, and Bard models on entity extraction and relation classification in the clinical domain. Experiment results showed that GPT-4 with self-question prompting outperforms other LLMs on most of the datasets. Li et al. [162] compared the performances of both natural language and code' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19168.330078125\n",
      "page_content='that including normalized protein names in the prompt enhances the performance of the model. However, finetuned PubMedBERT model outperforms GPT-4 model with an F1-score of 86.47.\n",
      "Yuan et al. [152] demonstrated that advanced prompting strategies like event ranking and chain-of-thought improve the performance of ChatGPT compared to vanilla prompting in temporal relation extraction. However, ChatGPT lags behind traditional neural networks like LSTM and fine-tuned pre-trained language models, which indicates the toughness of the temporal relation extraction task. Wang et al. [138] evaluated the performances of the latest LLMs like GPT-3.5, GPT-4, and Bard models on entity extraction and relation classification in the clinical domain. Experiment results showed that GPT-4 with self-question prompting outperforms other LLMs on most of the datasets. Li et al. [162] compared the performances of both natural language and code' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19168.49609375\n",
      "page_content='4.10\tMultimodal AI Tasks\n",
      "Overview. Traditional AI systems are designed to handle data from a single modality such as text, image, audio or video. As real-world data is often multimodal, researchers focused on developing multi-modal AI systems which can leverage input data from multiple modalities to generate more accurate results. Multimodal AI systems leverage techniques from different areas of AI, like natural language processing, computer vision, speech processing etc., to process multi-modal input data effectively [280], [281]. Multi-Modal AI systems can perform a variety of understanding and generation tasks like visual question answering [179], [282]–[284],\n",
      "text-to-image generation [285]–[287], text-to-video generation [288], text-to-speech synthesis [289], speech-to-text synthesis [289], image captioning [290] etc.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19168.49609375\n",
      "page_content='4.10\tMultimodal AI Tasks\n",
      "Overview. Traditional AI systems are designed to handle data from a single modality such as text, image, audio or video. As real-world data is often multimodal, researchers focused on developing multi-modal AI systems which can leverage input data from multiple modalities to generate more accurate results. Multimodal AI systems leverage techniques from different areas of AI, like natural language processing, computer vision, speech processing etc., to process multi-modal input data effectively [280], [281]. Multi-Modal AI systems can perform a variety of understanding and generation tasks like visual question answering [179], [282]–[284],\n",
      "text-to-image generation [285]–[287], text-to-video generation [288], text-to-speech synthesis [289], speech-to-text synthesis [289], image captioning [290] etc.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19177.818359375\n",
      "page_content='[269]\tG. Destefanis, S. Bartolucci, and M. Ortu, “A preliminary analysis on the code generation capabilities of gpt-3.5 and bard ai models for java functions,” arXiv preprint arXiv:2305.09402, 2023.\n",
      "[270]\tZ. Yuan, Y. Lou, M. Liu, S. Ding, K. Wang, Y. Chen, and X. Peng, “No more manual tests? evaluating and improving chatgpt for unit test generation,” ArXiv, vol. abs/2305.04207, 2023.\n",
      "[271]\tT. Phung, V.-A. Padurean, J. P. Cambronero, S. Gulwani, T. Kohn, R. Majumdar, A. K. Singla, and G. Soares, “Generative ai for programming education: Benchmarking chatgpt, gpt-4, and human tutors,” ArXiv, vol. abs/2306.17156, 2023.\n",
      "[272]\tX. Hou, Y. Zhao, Y. Liu, Z. Yang, K. Wang, L. Li, X. Luo, D. Lo, J. Grundy, and H. Wang, “Large language models for software engineering: A systematic literature review,” arXiv preprint arXiv:2308.10620, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19177.818359375\n",
      "page_content='[269]\tG. Destefanis, S. Bartolucci, and M. Ortu, “A preliminary analysis on the code generation capabilities of gpt-3.5 and bard ai models for java functions,” arXiv preprint arXiv:2305.09402, 2023.\n",
      "[270]\tZ. Yuan, Y. Lou, M. Liu, S. Ding, K. Wang, Y. Chen, and X. Peng, “No more manual tests? evaluating and improving chatgpt for unit test generation,” ArXiv, vol. abs/2305.04207, 2023.\n",
      "[271]\tT. Phung, V.-A. Padurean, J. P. Cambronero, S. Gulwani, T. Kohn, R. Majumdar, A. K. Singla, and G. Soares, “Generative ai for programming education: Benchmarking chatgpt, gpt-4, and human tutors,” ArXiv, vol. abs/2306.17156, 2023.\n",
      "[272]\tX. Hou, Y. Zhao, Y. Liu, Z. Yang, K. Wang, L. Li, X. Luo, D. Lo, J. Grundy, and H. Wang, “Large language models for software engineering: A systematic literature review,” arXiv preprint arXiv:2308.10620, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19180.8046875\n",
      "page_content='proposed to be integrated into the RAG’s framework to improve the practicality in complex application scenario. This integration of various modules into the RAG pipeline leading to the emergence of a modular RAG paradigm [11], transforming the RAG framework into a highly flexible system.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19180.8046875\n",
      "page_content='proposed to be integrated into the RAG’s framework to improve the practicality in complex application scenario. This integration of various modules into the RAG pipeline leading to the emergence of a modular RAG paradigm [11], transforming the RAG framework into a highly flexible system.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19185.98046875\n",
      "page_content='fication task, we randomly sample m × k examples from task unlabeled data as the unlabeled valida-\n",
      "m\n",
      "T = U {O -n [ xi ]}\n",
      "i=1\n",
      "(6)\n",
      "tion set U . For each example, xi , in U, we reformulate it into PLM’s input format with the template and then calculate the probability distribution pi over m classes. We formalize model bias on label words\n",
      "where Xi represents the examples categorized to class i.\n",
      "as follows:\n",
      "Pb =\n",
      "Emxk-1 i=0\n",
      "pi\n",
      "m×k\n",
      "(4)\n",
      "As demonstrated in Figure 1, the probabilities on each label word vary greatly (e.g., in Figure 1(a), the probabilities of “politics” and “business” are 0.06 and 0.46, respectively). This bias indicates that the model is more likely to label exam-\n",
      "3.3. Absolute Probability Refinement' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19185.98046875\n",
      "page_content='fication task, we randomly sample m × k examples from task unlabeled data as the unlabeled valida-\n",
      "m\n",
      "T = U {O -n [ xi ]}\n",
      "i=1\n",
      "(6)\n",
      "tion set U . For each example, xi , in U, we reformulate it into PLM’s input format with the template and then calculate the probability distribution pi over m classes. We formalize model bias on label words\n",
      "where Xi represents the examples categorized to class i.\n",
      "as follows:\n",
      "Pb =\n",
      "Emxk-1 i=0\n",
      "pi\n",
      "m×k\n",
      "(4)\n",
      "As demonstrated in Figure 1, the probabilities on each label word vary greatly (e.g., in Figure 1(a), the probabilities of “politics” and “business” are 0.06 and 0.46, respectively). This bias indicates that the model is more likely to label exam-\n",
      "3.3. Absolute Probability Refinement' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19207.453125\n",
      "page_content='MicroF 1\tF 1(class1+class2+...+classn)\n",
      "(1)\n",
      "Macro f1, on the other hand, simply averages the F1-Score of each class. Given N is the number of class labels, it is calculated as follows:\n",
      "MacroF 1 =\tn£N F 1classn\n",
      "N\n",
      "(2)\n",
      "3 Results\n",
      "This section aims to answer the following questions:\n",
      "1.\tHow best to use an off-the-shelf Large Language Model (LLM) to perform Failure Mode Classification (FMC)?\n",
      "2.\tIs it necessary to fine-tune the LLM to perform FMC?\n",
      "3.\tAre LLMs more effective at FMC than text classification models?\n",
      "4.\tWhat are some barriers one may face when using LLMs for FMC?\n",
      "3.1\tHow best to use an off-the-shelf LLM to perform Failure Mode Classification?\n",
      "To address the first research question we begin by investigating the use of a simple system-level prompt of “Determine the failure mode of the observation provided by the user.”. Upon feeding this prompt into the model, along with\n",
      "7https://platform.openai.com/docs/guides/fine-tuning/fine-tuning-examples\n",
      "Observation\tLLM output' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Stewart 等 - 2023 - Large Language Models for Failure Mode Classification An Investigation.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19207.453125\n",
      "page_content='MicroF 1\tF 1(class1+class2+...+classn)\n",
      "(1)\n",
      "Macro f1, on the other hand, simply averages the F1-Score of each class. Given N is the number of class labels, it is calculated as follows:\n",
      "MacroF 1 =\tn£N F 1classn\n",
      "N\n",
      "(2)\n",
      "3 Results\n",
      "This section aims to answer the following questions:\n",
      "1.\tHow best to use an off-the-shelf Large Language Model (LLM) to perform Failure Mode Classification (FMC)?\n",
      "2.\tIs it necessary to fine-tune the LLM to perform FMC?\n",
      "3.\tAre LLMs more effective at FMC than text classification models?\n",
      "4.\tWhat are some barriers one may face when using LLMs for FMC?\n",
      "3.1\tHow best to use an off-the-shelf LLM to perform Failure Mode Classification?\n",
      "To address the first research question we begin by investigating the use of a simple system-level prompt of “Determine the failure mode of the observation provided by the user.”. Upon feeding this prompt into the model, along with\n",
      "7https://platform.openai.com/docs/guides/fine-tuning/fine-tuning-examples\n",
      "Observation\tLLM output' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Stewart 等 - 2023 - Large Language Models for Failure Mode Classification An Investigation.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19217.94921875\n",
      "page_content='[214]\tA. Fan, S. Bhosale, H. Schwenk, Z. Ma, A. El-Kishky, S. Goyal, M. Baines, O. C¸ elebi, G. Wenzek, V. Chaudhary, N. Goyal, T. Birch, V. Liptchinsky, S. Edunov, E. Grave, M. Auli, and A. Joulin, “Beyond english-centric multilingual machine translation,” ArXiv, vol. abs/2010.11125, 2020.\n",
      "[215]\tM. R. Costa-jussa` , J. Cross, O. C¸ elebi, M. Elbayad, K. Heafield, K. Heffernan, E. Kalbassi, J. Lam, D. Licht, J. Maillard et al., “No language left behind: Scaling human-centered machine translation,” arXiv preprint arXiv:2207.04672, 2022.\n",
      "[216]\tR. Mart´ınez-Cruz, A. J. Lo´ pez-Lo´ pez, and J. Portela, “Chatgpt vs state-of-the-art models: A benchmarking study in keyphrase generation task,” arXiv preprint arXiv:2304.14177, 2023.\n",
      "[217]\tM. Song, H. Jiang, S. Shi, S. Yao, S. Lu, Y. Feng, H. Liu, and L. Jing, “Is chatgpt a good keyphrase generator? a preliminary study,” arXiv preprint arXiv:2303.13001, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19217.94921875\n",
      "page_content='[214]\tA. Fan, S. Bhosale, H. Schwenk, Z. Ma, A. El-Kishky, S. Goyal, M. Baines, O. C¸ elebi, G. Wenzek, V. Chaudhary, N. Goyal, T. Birch, V. Liptchinsky, S. Edunov, E. Grave, M. Auli, and A. Joulin, “Beyond english-centric multilingual machine translation,” ArXiv, vol. abs/2010.11125, 2020.\n",
      "[215]\tM. R. Costa-jussa` , J. Cross, O. C¸ elebi, M. Elbayad, K. Heafield, K. Heffernan, E. Kalbassi, J. Lam, D. Licht, J. Maillard et al., “No language left behind: Scaling human-centered machine translation,” arXiv preprint arXiv:2207.04672, 2022.\n",
      "[216]\tR. Mart´ınez-Cruz, A. J. Lo´ pez-Lo´ pez, and J. Portela, “Chatgpt vs state-of-the-art models: A benchmarking study in keyphrase generation task,” arXiv preprint arXiv:2304.14177, 2023.\n",
      "[217]\tM. Song, H. Jiang, S. Shi, S. Yao, S. Lu, Y. Feng, H. Liu, and L. Jing, “Is chatgpt a good keyphrase generator? a preliminary study,” arXiv preprint arXiv:2303.13001, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19226.458984375\n",
      "page_content='eration, code hints generation, code completion, code document generation, test cases generation, code vulnerability detection, code refactoring, etc. The evolution of pre-trained source code models has paved the way for achieving cutting-edge results across coding tasks [455]. Some of the popular pretrained source code models are CodeBERT [86], CodeGPT [273], CoTexT [274], Graph-CodeBERT [275], CodeT5 [87], CodeT5+ [88], PLBART [276], PyCodeGPT [277] etc. Inspired by the success of GLLMs in NLP tasks, the research community focused on assessing the performances of these models in coding tasks also.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19226.458984375\n",
      "page_content='eration, code hints generation, code completion, code document generation, test cases generation, code vulnerability detection, code refactoring, etc. The evolution of pre-trained source code models has paved the way for achieving cutting-edge results across coding tasks [455]. Some of the popular pretrained source code models are CodeBERT [86], CodeGPT [273], CoTexT [274], Graph-CodeBERT [275], CodeT5 [87], CodeT5+ [88], PLBART [276], PyCodeGPT [277] etc. Inspired by the success of GLLMs in NLP tasks, the research community focused on assessing the performances of these models in coding tasks also.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19229.72265625\n",
      "page_content='query rewriting process. In such a context, Reinforcement Learning (RL) presents an alternative training mechanism for the query rewriter. Query rewriters can receive feedback signals from ranking models [88] or downstream LLM readers [80]. For instance, ranking scores can be utilized to construct good-bad pairs for DPO [101] training. Ma et al. [80] proposed a method that first generates answers from LLMs and then uses the QA evaluation results as training signals. In a similar manner, BEQUE [81] introduced an offline feedback system capable of providing a quality score for each query based on the set of products it retrieved. Such an application of Reinforcement Learning mechanisms aligns the objective of query rewriters more closely with the goals of downstream tasks, thereby enhancing the overall performance of the system.\n",
      "3.4\tLimitations' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19229.72265625\n",
      "page_content='query rewriting process. In such a context, Reinforcement Learning (RL) presents an alternative training mechanism for the query rewriter. Query rewriters can receive feedback signals from ranking models [88] or downstream LLM readers [80]. For instance, ranking scores can be utilized to construct good-bad pairs for DPO [101] training. Ma et al. [80] proposed a method that first generates answers from LLMs and then uses the QA evaluation results as training signals. In a similar manner, BEQUE [81] introduced an offline feedback system capable of providing a quality score for each query based on the set of products it retrieved. Such an application of Reinforcement Learning mechanisms aligns the objective of query rewriters more closely with the goals of downstream tasks, thereby enhancing the overall performance of the system.\n",
      "3.4\tLimitations' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19231.87109375\n",
      "page_content='Some of the research works explored GLLMs for more challenging tasks in question answering like tabular question answering [180], knowledge-based complex question answering [178], multiple choice code question answering [187], multi-document question answering [189] and conversational question answering [193]. Srivastava et al. [180] evaluated the effectiveness of GPT-3 for question answering on tabular data in zero and few-shot settings. Here the model is prompted with unstructured passage text, tabular data in JSON format, examples (in the case of few-shot) and the question. The authors reported that GPT-3 displayed its ability to successfully locate the table, comprehend its structure, and accurately access the relevant cells or passages of text in order to provide answers to the given questions. Savelka et al. [187] evaluated the effectiveness of GPT-3.5 models in answering multiple-choice questions (MCQs), particularly those involving code snippets from programming' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19231.87109375\n",
      "page_content='Some of the research works explored GLLMs for more challenging tasks in question answering like tabular question answering [180], knowledge-based complex question answering [178], multiple choice code question answering [187], multi-document question answering [189] and conversational question answering [193]. Srivastava et al. [180] evaluated the effectiveness of GPT-3 for question answering on tabular data in zero and few-shot settings. Here the model is prompted with unstructured passage text, tabular data in JSON format, examples (in the case of few-shot) and the question. The authors reported that GPT-3 displayed its ability to successfully locate the table, comprehend its structure, and accurately access the relevant cells or passages of text in order to provide answers to the given questions. Savelka et al. [187] evaluated the effectiveness of GPT-3.5 models in answering multiple-choice questions (MCQs), particularly those involving code snippets from programming' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19238.548828125\n",
      "page_content='Experiments on six text classification datasets demonstrate that the proposed approach consistently outperforms standard prompt tuning in zero-\n",
      "3We use stochastic sampling to introduce randomness to simulate the unbalanced distribution of labels in real-world scenarios.\n",
      "shot settings, with up to 19.7% improvement and 13.8% average improvement. More surprisingly, on IMDB and SST-2, our approach yields better performance than all few-shot baselines, indicating that the proposed annotation strategy can obtain high-quality training examples from unlabeled data.\n",
      "2.\tRelated Work' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19238.548828125\n",
      "page_content='Experiments on six text classification datasets demonstrate that the proposed approach consistently outperforms standard prompt tuning in zero-\n",
      "3We use stochastic sampling to introduce randomness to simulate the unbalanced distribution of labels in real-world scenarios.\n",
      "shot settings, with up to 19.7% improvement and 13.8% average improvement. More surprisingly, on IMDB and SST-2, our approach yields better performance than all few-shot baselines, indicating that the proposed annotation strategy can obtain high-quality training examples from unlabeled data.\n",
      "2.\tRelated Work' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19254.708984375\n",
      "page_content='3.4\tChatGPT and GPT-4\n",
      "GPT-3 models are capable of understanding and generating natural language, while GPT-3.5 models are capable of understanding and generating both natural language and code. However, both GPT-3 and GPT-3.5 models are not chat optimized. This drawback is addressed by ChatGPT (GPT-3.5-turbo) and GPT-4 [42] models. Open AI introduced ChatGPT in November 2022. With extraordinary conversational abilities, ChatGPT, ChatGPT has garnered millions of users within a few weeks of its launch. Following ChatGPT, Open AI released the GPT-4 model in March 2023, which can handle both text and image inputs. Apart from generating text with human-like fluency, these models further pushed the results in many natural language processing tasks. The performance of these models in downstream tasks and specific domains is discussed in detail in Sections 4 and 5.\n",
      "4\tPerformance of GLLMs in Downstream Tasks\n",
      "4.1\tText Classification' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19254.708984375\n",
      "page_content='3.4\tChatGPT and GPT-4\n",
      "GPT-3 models are capable of understanding and generating natural language, while GPT-3.5 models are capable of understanding and generating both natural language and code. However, both GPT-3 and GPT-3.5 models are not chat optimized. This drawback is addressed by ChatGPT (GPT-3.5-turbo) and GPT-4 [42] models. Open AI introduced ChatGPT in November 2022. With extraordinary conversational abilities, ChatGPT, ChatGPT has garnered millions of users within a few weeks of its launch. Following ChatGPT, Open AI released the GPT-4 model in March 2023, which can handle both text and image inputs. Apart from generating text with human-like fluency, these models further pushed the results in many natural language processing tasks. The performance of these models in downstream tasks and specific domains is discussed in detail in Sections 4 and 5.\n",
      "4\tPerformance of GLLMs in Downstream Tasks\n",
      "4.1\tText Classification' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19255.1484375\n",
      "page_content='human participants with extensive education and specialized training achieved a 68% accuracy rate, while the GPT-3.5 model achieved a lower accuracy rate of 50.3%. Gupta et al. [190] evaluated how effective ChatGPT is in answering questions from plastic surgery inservice training examination. The authors reported that ChatGPT achieves an accuracy of 54.96% by correctly answering 242 questions. Tanaka et al. [191] evaluated the performances of GLLMs like GPT-3.5 and GPT-4 in answering questions from the Japanese National Medical Licensing Examination (NMLE). Here the input includes sample examples, instructions to translate the question into English, and then summarizing the question before answering. The authors reported that GPT-4 achieves a score better than the minimum passing score, and further analysis showed that the incorrect answers are due to insufficient medical knowledge and insufficient information about the Japanese-specific medical system. Kasai et al. [195] reported' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19255.1484375\n",
      "page_content='human participants with extensive education and specialized training achieved a 68% accuracy rate, while the GPT-3.5 model achieved a lower accuracy rate of 50.3%. Gupta et al. [190] evaluated how effective ChatGPT is in answering questions from plastic surgery inservice training examination. The authors reported that ChatGPT achieves an accuracy of 54.96% by correctly answering 242 questions. Tanaka et al. [191] evaluated the performances of GLLMs like GPT-3.5 and GPT-4 in answering questions from the Japanese National Medical Licensing Examination (NMLE). Here the input includes sample examples, instructions to translate the question into English, and then summarizing the question before answering. The authors reported that GPT-4 achieves a score better than the minimum passing score, and further analysis showed that the incorrect answers are due to insufficient medical knowledge and insufficient information about the Japanese-specific medical system. Kasai et al. [195] reported' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19255.59765625\n",
      "page_content='Alec Radford, Karthik Narasimhan, Tim Salimans, Ilya Sutskever, et al. 2018. Improving language understanding by generative pre-training.\n",
      "Timo Schick and Hinrich Schütze. 2021a. Exploiting cloze-questions for few-shot text classification and natural language inference. In Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, pages 255–269, Online. Association for Computational Linguistics.\n",
      "Timo Schick and Hinrich Schütze. 2021b. It’s not just size that matters: Small language models are also few-shot learners. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics:\n",
      "Human Language Technologies, pages 2339– 2352, Online. Association for Computational Linguistics.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19255.59765625\n",
      "page_content='Alec Radford, Karthik Narasimhan, Tim Salimans, Ilya Sutskever, et al. 2018. Improving language understanding by generative pre-training.\n",
      "Timo Schick and Hinrich Schütze. 2021a. Exploiting cloze-questions for few-shot text classification and natural language inference. In Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, pages 255–269, Online. Association for Computational Linguistics.\n",
      "Timo Schick and Hinrich Schütze. 2021b. It’s not just size that matters: Small language models are also few-shot learners. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics:\n",
      "Human Language Technologies, pages 2339– 2352, Online. Association for Computational Linguistics.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19257.0703125\n",
      "page_content='In recent years, fine-tuning pre-trained language models (PLMs) with task-specific data has become a standard practice for various NLP tasks (Peters et al., 2018; Radford et al., 2018; Devlin et al., 2019; Lewis et al., 2020; Bao et al., 2020), such as text classification (Kowsari et al., 2019), machine translation (Zhu et al., 2020), and natural language inference (Bowman et al., 2015; Williams et al., 2018). However, fine-tuning requires sufficient downstream task data to train the extra random-initialized parameters (e.g., the classification head in text classification) that it introduces. This drawback limits the application of PLMs to tasks where sufficient labeled data are unavailable and has led to research on making PLMs perform better in low-resource scenarios. Proposed by GPT-3 (Brown et al., 2020) and PET (Schick and Schütze, 2021a), prompt tuning has shown effectiveness in low-resource scenarios by incorporating human prior knowledge into the PLM’s input. Prompt tuning' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19257.0703125\n",
      "page_content='In recent years, fine-tuning pre-trained language models (PLMs) with task-specific data has become a standard practice for various NLP tasks (Peters et al., 2018; Radford et al., 2018; Devlin et al., 2019; Lewis et al., 2020; Bao et al., 2020), such as text classification (Kowsari et al., 2019), machine translation (Zhu et al., 2020), and natural language inference (Bowman et al., 2015; Williams et al., 2018). However, fine-tuning requires sufficient downstream task data to train the extra random-initialized parameters (e.g., the classification head in text classification) that it introduces. This drawback limits the application of PLMs to tasks where sufficient labeled data are unavailable and has led to research on making PLMs perform better in low-resource scenarios. Proposed by GPT-3 (Brown et al., 2020) and PET (Schick and Schütze, 2021a), prompt tuning has shown effectiveness in low-resource scenarios by incorporating human prior knowledge into the PLM’s input. Prompt tuning' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19259.12890625\n",
      "page_content='GPT-1\tGPT-3\tInstructGPT\tGPT-4\n",
      "Dec.2015\n",
      "Open Al journey started\n",
      "Feb.2019\n",
      "Jun.2018\n",
      "May.2020\n",
      "Jul.2021\n",
      "Open Al journey continues\n",
      "Open Al founded\n",
      "GPT-2\n",
      "Codex\n",
      "ChatGPT\n",
      "Fig. 7: Open AI journey starting from GPT-1 to the latest GPT-4.\n",
      "GPT-3\n",
      "G PT-3.5\n",
      "ChatGPT\n",
      ". Raw\n",
      "ada\n",
      "text-adaSFT\n",
      "i i\tCode\n",
      "code-davinci-002\n",
      "■\t* । Raw\n",
      "babbage\n",
      "text-babbageSFT\n",
      "RLHF-Chat\n",
      "gpt-3.5-turbo\n",
      "curieRaw\n",
      "-SFT\n",
      "text-curie\n",
      "SFT\n",
      "text-davinci-002\n",
      "।\t.\t. Raw\n",
      "davinci\n",
      "text-davinciSFT\n",
      "RLHF\n",
      "text-davinci-003\n",
      "RLHF-Chat\n",
      "gpt-3.5-turbo-16k\n",
      ". _ RLHF-Chat gpt-4\n",
      "RLHF-Chat\n",
      "gpt-4-32k\n",
      "GPT-4\n",
      "Fig. 8: GPT-3 family large language models (GLLMs) starting from GPT-3 series to the latest GPT-4. Here, SFT stands for supervised fine-tuning, and RLHF stands for reinforcement learning from human feedback. Here, raw represents that the model is just pretrained and is not aligned using SFT or RLHF. Here, RLHF-Chat represents that the model is aligned using RLHF and optimized for chat.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19259.12890625\n",
      "page_content='GPT-1\tGPT-3\tInstructGPT\tGPT-4\n",
      "Dec.2015\n",
      "Open Al journey started\n",
      "Feb.2019\n",
      "Jun.2018\n",
      "May.2020\n",
      "Jul.2021\n",
      "Open Al journey continues\n",
      "Open Al founded\n",
      "GPT-2\n",
      "Codex\n",
      "ChatGPT\n",
      "Fig. 7: Open AI journey starting from GPT-1 to the latest GPT-4.\n",
      "GPT-3\n",
      "G PT-3.5\n",
      "ChatGPT\n",
      ". Raw\n",
      "ada\n",
      "text-adaSFT\n",
      "i i\tCode\n",
      "code-davinci-002\n",
      "■\t* । Raw\n",
      "babbage\n",
      "text-babbageSFT\n",
      "RLHF-Chat\n",
      "gpt-3.5-turbo\n",
      "curieRaw\n",
      "-SFT\n",
      "text-curie\n",
      "SFT\n",
      "text-davinci-002\n",
      "।\t.\t. Raw\n",
      "davinci\n",
      "text-davinciSFT\n",
      "RLHF\n",
      "text-davinci-003\n",
      "RLHF-Chat\n",
      "gpt-3.5-turbo-16k\n",
      ". _ RLHF-Chat gpt-4\n",
      "RLHF-Chat\n",
      "gpt-4-32k\n",
      "GPT-4\n",
      "Fig. 8: GPT-3 family large language models (GLLMs) starting from GPT-3 series to the latest GPT-4. Here, SFT stands for supervised fine-tuning, and RLHF stands for reinforcement learning from human feedback. Here, raw represents that the model is just pretrained and is not aligned using SFT or RLHF. Here, RLHF-Chat represents that the model is aligned using RLHF and optimized for chat.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19278.2890625\n",
      "page_content='Natural language queries can be used to provide more intuitive and user-friendly interfaces for users in a range of applications, including search engines, virtual assistants, and chatbots. [18]\n",
      "Natural Language Query consists of three key steps, which are as below in Table.1 :[20]\n",
      "Table 1. Three Key steps of Natural Language Query\n",
      "Goal\tWork\tUsage\n",
      "Rule-based Filtering\tQuickly exclude irrelevant data items using traditional rule-based methods such as keyword search on table names, column names, or metadata.\tFiltering tables to narrow down candidate items for further examination.\n",
      "Embeddingbased Similarity Search\tDiscover the most relevant items from the candidate items based on the similarity between the query embedding and the item embeddings learned using the representation learning approach. Return the top items whose embeddings are most similar to the query embedding.\tFinding the most similar items to the query in a highdimensional space, such as image or audio search.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kania和Mehta - 2023 - A Literature Review on Augmented Analytics and Natural Language Generation A Review of State of Art.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19278.2890625\n",
      "page_content='Natural language queries can be used to provide more intuitive and user-friendly interfaces for users in a range of applications, including search engines, virtual assistants, and chatbots. [18]\n",
      "Natural Language Query consists of three key steps, which are as below in Table.1 :[20]\n",
      "Table 1. Three Key steps of Natural Language Query\n",
      "Goal\tWork\tUsage\n",
      "Rule-based Filtering\tQuickly exclude irrelevant data items using traditional rule-based methods such as keyword search on table names, column names, or metadata.\tFiltering tables to narrow down candidate items for further examination.\n",
      "Embeddingbased Similarity Search\tDiscover the most relevant items from the candidate items based on the similarity between the query embedding and the item embeddings learned using the representation learning approach. Return the top items whose embeddings are most similar to the query embedding.\tFinding the most similar items to the query in a highdimensional space, such as image or audio search.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kania和Mehta - 2023 - A Literature Review on Augmented Analytics and Natural Language Generation A Review of State of Art.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19279.072265625\n",
      "page_content='[261]\tI. Gur, H. Furuta, A. Huang, M. Safdari, Y. Matsuo, D. Eck, and A. Faust, “A real-world webagent with planning, long context understanding, and program synthesis,” CoRR, vol. abs/2307.12856, 2023.\n",
      "[262]\tJ. Menick, M. Trebacz, V. Mikulik, J. Aslanides, H. F. Song, M. J. Chadwick, M. Glaese, S. Young, L. Campbell-Gillingham, G. Irving, and N. McAleese, “Teaching language models to support answers with verified quotes,” CoRR, vol. abs/2203.11147, 2022.\n",
      "[263]\tX. Shi, J. Liu, Y. Liu, Q. Cheng, and W. Lu, “Know where to go: Make LLM a relevant, responsible, and trustworthy searcher,” CoRR, vol. abs/2310.12443, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19279.072265625\n",
      "page_content='[261]\tI. Gur, H. Furuta, A. Huang, M. Safdari, Y. Matsuo, D. Eck, and A. Faust, “A real-world webagent with planning, long context understanding, and program synthesis,” CoRR, vol. abs/2307.12856, 2023.\n",
      "[262]\tJ. Menick, M. Trebacz, V. Mikulik, J. Aslanides, H. F. Song, M. J. Chadwick, M. Glaese, S. Young, L. Campbell-Gillingham, G. Irving, and N. McAleese, “Teaching language models to support answers with verified quotes,” CoRR, vol. abs/2203.11147, 2022.\n",
      "[263]\tX. Shi, J. Liu, Y. Liu, Q. Cheng, and W. Lu, “Know where to go: Make LLM a relevant, responsible, and trustworthy searcher,” CoRR, vol. abs/2310.12443, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19282.72265625\n",
      "page_content='[260]\tJ. Y. Khan and G. Uddin, “Automatic code documentation generation using gpt-3,” in Proceedings of the 37th IEEE/ACM International Conference on Automated Software Engineering, 2022, pp. 1–6.\n",
      "[261]\tJ. Leinonen, P. Denny, S. MacNeil, S. Sarsa, S. Bernstein, J. Kim, A. Tran, and A. Hellas, “Comparing code explanations created by students and large language models,” arXiv preprint arXiv:2304.03938, 2023.\n",
      "[262]\tX.-Y. Li, J.-T. Xue, Z. Xie, and M. Li, “Think outside the code: Brainstorming boosts large language models in code generation,” arXiv preprint arXiv:2305.10679, 2023.\n",
      "[263]\tJ. A. Prenner and R. Robbes, “Automatic program repair with openai’s codex: Evaluating quixbugs,” arXiv preprint arXiv:2111.03922, 2021.\n",
      "[264]\tM. L. Siddiq, J. C. S. Santos, R. H. Tanvir, N. Ulfat, F. A. Rifat, and V. C. Lopes, “Exploring the effectiveness of large language models in generating unit tests,” ArXiv, vol. abs/2305.00418, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19282.72265625\n",
      "page_content='[260]\tJ. Y. Khan and G. Uddin, “Automatic code documentation generation using gpt-3,” in Proceedings of the 37th IEEE/ACM International Conference on Automated Software Engineering, 2022, pp. 1–6.\n",
      "[261]\tJ. Leinonen, P. Denny, S. MacNeil, S. Sarsa, S. Bernstein, J. Kim, A. Tran, and A. Hellas, “Comparing code explanations created by students and large language models,” arXiv preprint arXiv:2304.03938, 2023.\n",
      "[262]\tX.-Y. Li, J.-T. Xue, Z. Xie, and M. Li, “Think outside the code: Brainstorming boosts large language models in code generation,” arXiv preprint arXiv:2305.10679, 2023.\n",
      "[263]\tJ. A. Prenner and R. Robbes, “Automatic program repair with openai’s codex: Evaluating quixbugs,” arXiv preprint arXiv:2111.03922, 2021.\n",
      "[264]\tM. L. Siddiq, J. C. S. Santos, R. H. Tanvir, N. Ulfat, F. A. Rifat, and V. C. Lopes, “Exploring the effectiveness of large language models in generating unit tests,” ArXiv, vol. abs/2305.00418, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19286.517578125\n",
      "page_content='Furthermore, to better facilitate the deployment of these RAG systems, some tools or frameworks are proposed [194, 255, 256]. For example, RETA-LLM [194] breaks down the whole complex generation task into several simple modules in the reader pipeline. These modules include a query rewriter module for refining query intents, a passage extraction module for aligning reference lengths with LLM limitations, and a fact verification module for confirming the absence of fabricated information in the generated answers. Jin et al. [257] release the FlashRAG toolkit for the reproduction and development of RAG research, which includes 32 pre-processed benchmark datasets and 14 state-of-the-art algorithms.\n",
      "6.6\tLimitations' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19286.517578125\n",
      "page_content='Furthermore, to better facilitate the deployment of these RAG systems, some tools or frameworks are proposed [194, 255, 256]. For example, RETA-LLM [194] breaks down the whole complex generation task into several simple modules in the reader pipeline. These modules include a query rewriter module for refining query intents, a passage extraction module for aligning reference lengths with LLM limitations, and a fact verification module for confirming the absence of fabricated information in the generated answers. Jin et al. [257] release the FlashRAG toolkit for the reproduction and development of RAG research, which includes 32 pre-processed benchmark datasets and 14 state-of-the-art algorithms.\n",
      "6.6\tLimitations' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19286.90625\n",
      "page_content='8\tDetecting GLLM Generated Text\n",
      "Overview. GLLMs demonstrated extraordinary humanlike capabilities to understand user queries, follow the instructions and then answer the user queries with high-quality content. Apart from responding to user queries, these models can also generate news articles, research papers, code and essays with human-like fluency. With the ability to generate text with human-like fluency, these models are widely adopted in a variety of real-world applications like writing assistants, coding assistants, chatbots, etc [428]. Although there is a lot of excitement about GLLMs and their applications in recent times, there are also growing concerns regarding the potential misuse of these models for illegal activities [429], such as fake news on social media platforms [430], [431], fake reviews on e-commerce websites [432], fake research\n",
      "4. https://crfm.stanford.edu/2023/03/13/alpaca.html\n",
      "5. https://lmsys.org/blog/2023-03-30-vicuna/' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19286.90625\n",
      "page_content='8\tDetecting GLLM Generated Text\n",
      "Overview. GLLMs demonstrated extraordinary humanlike capabilities to understand user queries, follow the instructions and then answer the user queries with high-quality content. Apart from responding to user queries, these models can also generate news articles, research papers, code and essays with human-like fluency. With the ability to generate text with human-like fluency, these models are widely adopted in a variety of real-world applications like writing assistants, coding assistants, chatbots, etc [428]. Although there is a lot of excitement about GLLMs and their applications in recent times, there are also growing concerns regarding the potential misuse of these models for illegal activities [429], such as fake news on social media platforms [430], [431], fake reviews on e-commerce websites [432], fake research\n",
      "4. https://crfm.stanford.edu/2023/03/13/alpaca.html\n",
      "5. https://lmsys.org/blog/2023-03-30-vicuna/' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19296.890625\n",
      "page_content='[300]\tX. Mei, C. Meng, H. Liu, Q. Kong, T. Ko, C. Zhao, M. D. Plumbley, Y. Zou, and W. Wang, “Wavcaps: A chatgpt-assisted weakly-labelled audio captioning dataset for audio-language multimodal research,” arXiv preprint arXiv:2303.17395, 2023.\n",
      "[301]\tD. Zhang, S. Li, X. Zhang, J. Zhan, P. Wang, Y. Zhou, and X. Qiu, “Speechgpt: Empowering large language models with intrinsic cross-modal conversational abilities,” arXiv preprint arXiv:2305.11000, 2023.\n",
      "[302]\tZ. Zhao, L. Guo, T. Yue, S. Chen, S. Shao, X. Zhu, Z. Yuan, and J. Liu, “Chatbridge: Bridging modalities with large language model as a language catalyst,” arXiv preprint arXiv:2305.16103, 2023.\n",
      "[303]\tM. Zheng, X. Su, S. You, F. Wang, C. Qian, C. Xu, and S. Albanie, “Can gpt-4 perform neural architecture search?” arXiv preprint arXiv:2304.10970, 2023.\n",
      "[304]\tY. Shen, K. Song, X. Tan, D. Li, W. Lu, and Y. Zhuang, “Hug-ginggpt: Solving ai tasks with chatgpt and its friends in hug-gingface,” arXiv preprint arXiv:2303.17580, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19296.890625\n",
      "page_content='[300]\tX. Mei, C. Meng, H. Liu, Q. Kong, T. Ko, C. Zhao, M. D. Plumbley, Y. Zou, and W. Wang, “Wavcaps: A chatgpt-assisted weakly-labelled audio captioning dataset for audio-language multimodal research,” arXiv preprint arXiv:2303.17395, 2023.\n",
      "[301]\tD. Zhang, S. Li, X. Zhang, J. Zhan, P. Wang, Y. Zhou, and X. Qiu, “Speechgpt: Empowering large language models with intrinsic cross-modal conversational abilities,” arXiv preprint arXiv:2305.11000, 2023.\n",
      "[302]\tZ. Zhao, L. Guo, T. Yue, S. Chen, S. Shao, X. Zhu, Z. Yuan, and J. Liu, “Chatbridge: Bridging modalities with large language model as a language catalyst,” arXiv preprint arXiv:2305.16103, 2023.\n",
      "[303]\tM. Zheng, X. Su, S. You, F. Wang, C. Qian, C. Xu, and S. Albanie, “Can gpt-4 perform neural architecture search?” arXiv preprint arXiv:2304.10970, 2023.\n",
      "[304]\tY. Shen, K. Song, X. Tan, D. Li, W. Lu, and Y. Zhuang, “Hug-ginggpt: Solving ai tasks with chatgpt and its friends in hug-gingface,” arXiv preprint arXiv:2303.17580, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19302.83984375\n",
      "page_content='# Unlabeled Data\tK Training Examples\t\t\t\n",
      "\t5\t10\t15\t20\n",
      "200\t82.0\t76.8\t71.9\t71.3\n",
      "400\t82.3\t83.1\t78.6\t73.7\n",
      "600\t81.8\t82.9\t83.5\t80.0\n",
      "800\t82.0\t82.3\t83.2\t82.8\n",
      "bias after training. The results are shown in Figure 4. Compared to the high probability of “business” and the low probability of “politics” before calibration, the probability distribution is more uniform across label words after training the model with our approach. Then we tabulated the model’s predictions on the test set on each label word, as shown in Table 4. We find that the number of examples with the label word “politics”, which are incorrectly predicted as “business”, drops from 1217 (underlined in Table 1(a)) to 252, contributing the most to accuracy improvement. Thus, the proposed approach can eliminate model bias on the label words and can reduce the number of examples with low-probability label words being misclassified as classes with high-probability label words.\n",
      "5.2.\tAnalysis of Unlabeled Data' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19302.83984375\n",
      "page_content='# Unlabeled Data\tK Training Examples\t\t\t\n",
      "\t5\t10\t15\t20\n",
      "200\t82.0\t76.8\t71.9\t71.3\n",
      "400\t82.3\t83.1\t78.6\t73.7\n",
      "600\t81.8\t82.9\t83.5\t80.0\n",
      "800\t82.0\t82.3\t83.2\t82.8\n",
      "bias after training. The results are shown in Figure 4. Compared to the high probability of “business” and the low probability of “politics” before calibration, the probability distribution is more uniform across label words after training the model with our approach. Then we tabulated the model’s predictions on the test set on each label word, as shown in Table 4. We find that the number of examples with the label word “politics”, which are incorrectly predicted as “business”, drops from 1217 (underlined in Table 1(a)) to 252, contributing the most to accuracy improvement. Thus, the proposed approach can eliminate model bias on the label words and can reduce the number of examples with low-probability label words being misclassified as classes with high-probability label words.\n",
      "5.2.\tAnalysis of Unlabeled Data' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19302.998046875\n",
      "page_content='scenarios. Schick and Schütze (2021b) finds that using different random seeds to select training data can result in significant performance fluctuations. Gao et al. (2021) incorporates training examples as demonstrations into the template and finds that the choice of demonstration examples is crucial for the final results. Zhao et al. (2021) observes that in GPT-3’s input, the number and order of the demonstration examples corresponding to each label can cause accuracy to vary from near chance to near state-of-the-art. To enhance the stability of fewshot training, we propose an annotation and refinement strategy to obtain training examples with high correlation to their classes from unlabeled data.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19302.998046875\n",
      "page_content='scenarios. Schick and Schütze (2021b) finds that using different random seeds to select training data can result in significant performance fluctuations. Gao et al. (2021) incorporates training examples as demonstrations into the template and finds that the choice of demonstration examples is crucial for the final results. Zhao et al. (2021) observes that in GPT-3’s input, the number and order of the demonstration examples corresponding to each label can cause accuracy to vary from near chance to near state-of-the-art. To enhance the stability of fewshot training, we propose an annotation and refinement strategy to obtain training examples with high correlation to their classes from unlabeled data.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19306.55078125\n",
      "page_content='Transfer learning draws inspiration from human beings, i.e., human beings can do new tasks without or with few examples just by reusing previously gained knowledge [60]. Figure 2 illustrates real-life examples of knowledge transfer (transfer learning). For example, a person who can cycle can learn to ride a bike quickly with less effort. This is because riding a cycle and a bike involves a lot of common things like handling the balance, etc. Similarly, a person familiar with C programming language can learn Python programming language easily. This is because both C and Python are programming languages and share many common concepts. So, due to the ability to reuse the existing knowledge and train the target models with limited data, transfer learning evolved as a promising learning paradigm and eventually played a crucial role in the evolution of advanced deep learning models like pretrained language models [1], [3] and the recent large language models. Overall, the advantages of' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19306.55078125\n",
      "page_content='Transfer learning draws inspiration from human beings, i.e., human beings can do new tasks without or with few examples just by reusing previously gained knowledge [60]. Figure 2 illustrates real-life examples of knowledge transfer (transfer learning). For example, a person who can cycle can learn to ride a bike quickly with less effort. This is because riding a cycle and a bike involves a lot of common things like handling the balance, etc. Similarly, a person familiar with C programming language can learn Python programming language easily. This is because both C and Python are programming languages and share many common concepts. So, due to the ability to reuse the existing knowledge and train the target models with limited data, transfer learning evolved as a promising learning paradigm and eventually played a crucial role in the evolution of advanced deep learning models like pretrained language models [1], [3] and the recent large language models. Overall, the advantages of' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19310.15625\n",
      "page_content='[454]\tS. M. Lundberg and S.-I. Lee, “A unified approach to interpreting model predictions,” Advances in neural information processing systems, vol. 30, 2017.\n",
      "[455]\tX. Chen, J. Ye, C. Zu, N. Xu, R. Zheng, M. Peng, J. Zhou, T. Gui, Q. Zhang, and X. Huang, “How robust is gpt-3.5 to predecessors? a comprehensive study on language understanding tasks,” arXiv preprint arXiv:2303.00293, 2023.\n",
      "[456]\tJ. Wang, X. Hu, W. Hou, H. Chen, R. Zheng, Y. Wang, L. Yang, H. Huang, W. Ye, X. Geng et al., “On the robustness of chat-gpt: An adversarial and out-of-distribution perspective,” arXiv preprint arXiv:2302.12095, 2023.\n",
      "[457]\tT. Y. Zhuo, Z. Li, Y. Huang, Y.-F. Li, W. Wang, G. Haffari, and F. Shiri, “On robustness of prompt-based semantic parsing with large pre-trained language model: An empirical study on codex,” arXiv preprint arXiv:2301.12868, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19310.15625\n",
      "page_content='[454]\tS. M. Lundberg and S.-I. Lee, “A unified approach to interpreting model predictions,” Advances in neural information processing systems, vol. 30, 2017.\n",
      "[455]\tX. Chen, J. Ye, C. Zu, N. Xu, R. Zheng, M. Peng, J. Zhou, T. Gui, Q. Zhang, and X. Huang, “How robust is gpt-3.5 to predecessors? a comprehensive study on language understanding tasks,” arXiv preprint arXiv:2303.00293, 2023.\n",
      "[456]\tJ. Wang, X. Hu, W. Hou, H. Chen, R. Zheng, Y. Wang, L. Yang, H. Huang, W. Ye, X. Geng et al., “On the robustness of chat-gpt: An adversarial and out-of-distribution perspective,” arXiv preprint arXiv:2302.12095, 2023.\n",
      "[457]\tT. Y. Zhuo, Z. Li, Y. Huang, Y.-F. Li, W. Wang, G. Haffari, and F. Shiri, “On robustness of prompt-based semantic parsing with large pre-trained language model: An empirical study on codex,” arXiv preprint arXiv:2301.12868, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19317.28125\n",
      "page_content='dialogue summarization. The proposed method leverages the GPT-3 model through multiple intermediate calls to extract medical entities from the conversations. In the final step of summarization, the extracted entities, task instructions and in-context examples help the GPT-3 model to generate high-quality summaries. Based on the evaluation of radiology reports simplified by Chat-GPT, Jeblick et al. [327] reported that ChatGPT-generated simplified radiology reports are not potentially harmful, complete and factually correct. However, further analysis reveals that some simplified reports contain factually incorrect sentences, potentially harmful paragraphs and a lack of essential medical findings.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19317.28125\n",
      "page_content='dialogue summarization. The proposed method leverages the GPT-3 model through multiple intermediate calls to extract medical entities from the conversations. In the final step of summarization, the extracted entities, task instructions and in-context examples help the GPT-3 model to generate high-quality summaries. Based on the evaluation of radiology reports simplified by Chat-GPT, Jeblick et al. [327] reported that ChatGPT-generated simplified radiology reports are not potentially harmful, complete and factually correct. However, further analysis reveals that some simplified reports contain factually incorrect sentences, potentially harmful paragraphs and a lack of essential medical findings.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19326.443359375\n",
      "page_content='7.3\tLimitations\n",
      "Though the aspect of static search agents has been thoroughly studied, the literature on dynamic search agents remains limited. Some agents may lack mechanisms for real-time fact-checking or verification against authoritative sources, leading to the potential dissemination of misinformation. Moreover, since LLMs are trained on data from the Internet, they may inadvertently perpetuate biases present in the training data. This can lead to biased or offensive outputs and may collect unethical content from the web. Finally, as LLMs process user queries, there are concerns regarding user privacy and data security, especially if sensitive or personal information is involved in the queries.\n",
      "8\tFuture Direction' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19326.443359375\n",
      "page_content='7.3\tLimitations\n",
      "Though the aspect of static search agents has been thoroughly studied, the literature on dynamic search agents remains limited. Some agents may lack mechanisms for real-time fact-checking or verification against authoritative sources, leading to the potential dissemination of misinformation. Moreover, since LLMs are trained on data from the Internet, they may inadvertently perpetuate biases present in the training data. This can lead to biased or offensive outputs and may collect unethical content from the web. Finally, as LLMs process user queries, there are concerns regarding user privacy and data security, especially if sensitive or personal information is involved in the queries.\n",
      "8\tFuture Direction' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19336.5703125\n",
      "page_content='Enhance Retrieval Through LMs Recent works have investigated using auto-regressive language models to generate intermediate targets for better retrieval (Cao et al., 2021; Bevilacqua et al., 2022) while identifier strings still need to be created. Other works consider “retrieving” the knowledge stored in the parameters of pre-trained language models by directly generating text (Petroni et al., 2019; Roberts et al., 2020). Some researchers (Mao et al., 2021; Anantha et al., 2021; Wang et al., 2023) utilize LM to expand the query and incorporate these pseudo-queries for enhanced retrieval while others choose to expand the document (Nogueira et al., 2019). Besides, LMs can also be exploited to provide references for retrieval targets. For instance, GENREAD (Yu et al., 2023) directly generates contextual documents for given questions.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Feng 等 - 2023 - Synergistic Interplay between Search and Large Language Models for Information Retrieval.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19336.5703125\n",
      "page_content='Enhance Retrieval Through LMs Recent works have investigated using auto-regressive language models to generate intermediate targets for better retrieval (Cao et al., 2021; Bevilacqua et al., 2022) while identifier strings still need to be created. Other works consider “retrieving” the knowledge stored in the parameters of pre-trained language models by directly generating text (Petroni et al., 2019; Roberts et al., 2020). Some researchers (Mao et al., 2021; Anantha et al., 2021; Wang et al., 2023) utilize LM to expand the query and incorporate these pseudo-queries for enhanced retrieval while others choose to expand the document (Nogueira et al., 2019). Besides, LMs can also be exploited to provide references for retrieval targets. For instance, GENREAD (Yu et al., 2023) directly generates contextual documents for given questions.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Feng 等 - 2023 - Synergistic Interplay between Search and Large Language Models for Information Retrieval.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19350.82421875\n",
      "page_content='ChatGPT exhibits better performances in emotion dialogue generation compared to emotion dialogue understanding. Chintagunta et al. [220] showed that the in-house model trained on GPT-3 generated summaries achieves performances comparable to when trained on human-generated summaries. Further, the in-house model trained on mixed summaries (human-generated and GPT-3 generated) achieves better performances than those trained on either one of the summaries.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19350.82421875\n",
      "page_content='ChatGPT exhibits better performances in emotion dialogue generation compared to emotion dialogue understanding. Chintagunta et al. [220] showed that the in-house model trained on GPT-3 generated summaries achieves performances comparable to when trained on human-generated summaries. Further, the in-house model trained on mixed summaries (human-generated and GPT-3 generated) achieves better performances than those trained on either one of the summaries.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19352.060546875\n",
      "page_content='is a learning paradigm which focuses on enhancing the performance of a group of tasks by leveraging the interconnections between the tasks and learning them simultaneously [63]. Unlike multi-task learning, which simultaneously learns all the tasks, transfer learning first learns the source task and then transfers the knowledge to the target task. In multitask learning, the focus is generally on all the tasks, while transfer learning focuses more on the target task [61].' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19352.060546875\n",
      "page_content='is a learning paradigm which focuses on enhancing the performance of a group of tasks by leveraging the interconnections between the tasks and learning them simultaneously [63]. Unlike multi-task learning, which simultaneously learns all the tasks, transfer learning first learns the source task and then transfers the knowledge to the target task. In multitask learning, the focus is generally on all the tasks, while transfer learning focuses more on the target task [61].' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19362.890625\n",
      "page_content='1In IR tasks, the relevance judgment illustrates the label of relevance between each pair of query and document, which is mainly used for supervised learning of an IR model.\n",
      "et al., 2020), has recently undergone substantial research. Relevant studies include improving training approach (Karpukhin et al., 2020; Xiong et al., 2021; Qu et al., 2021), distillation (Lin et al., 2021; Hofstätter et al., 2021) and task-specific pre-training (Izacard et al., 2022; Gao & Callan, 2021; Lu et al., 2021; Gao & Callan, 2022; Xiao et al., 2022) of dense retrieval models which significantly outperform sparse approaches.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Feng 等 - 2023 - Synergistic Interplay between Search and Large Language Models for Information Retrieval.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19362.890625\n",
      "page_content='1In IR tasks, the relevance judgment illustrates the label of relevance between each pair of query and document, which is mainly used for supervised learning of an IR model.\n",
      "et al., 2020), has recently undergone substantial research. Relevant studies include improving training approach (Karpukhin et al., 2020; Xiong et al., 2021; Qu et al., 2021), distillation (Lin et al., 2021; Hofstätter et al., 2021) and task-specific pre-training (Izacard et al., 2022; Gao & Callan, 2021; Lu et al., 2021; Gao & Callan, 2022; Xiao et al., 2022) of dense retrieval models which significantly outperform sparse approaches.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Feng 等 - 2023 - Synergistic Interplay between Search and Large Language Models for Information Retrieval.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19369.9140625\n",
      "page_content='Inspired by the success of pretrained language models like BERT, RoBERTa, ELECTRA, DeBERTa and T5 in the general domain, these models are also explored for domain-specific NLP tasks [1]. However, the performance of general domain models is limited as these models are pretrained on general domain texts [81], [89], and fine-tuning alone cannot provide enough domain knowledge [1]. So, the research community focused on\n",
      "developing domain-specific pretrained language models either by continual pretraining or pretraining from scratch [1], [3]. Currently, domain-specific pretrained language models achieve state-of-the-art results in most tasks in specific domains like healthcare, finance, legal, social media, etc.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19369.9140625\n",
      "page_content='Inspired by the success of pretrained language models like BERT, RoBERTa, ELECTRA, DeBERTa and T5 in the general domain, these models are also explored for domain-specific NLP tasks [1]. However, the performance of general domain models is limited as these models are pretrained on general domain texts [81], [89], and fine-tuning alone cannot provide enough domain knowledge [1]. So, the research community focused on\n",
      "developing domain-specific pretrained language models either by continual pretraining or pretraining from scratch [1], [3]. Currently, domain-specific pretrained language models achieve state-of-the-art results in most tasks in specific domains like healthcare, finance, legal, social media, etc.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19382.923828125\n",
      "page_content='Some of the research works explored GLLMs for data generation-based data augmentation in various text classification tasks [143], [409], [413], [414], [421], [423]. For example, Hartvigsen et al. [413] used GPT-3 with demonstration-based prompting to create a large-' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19382.923828125\n",
      "page_content='Some of the research works explored GLLMs for data generation-based data augmentation in various text classification tasks [143], [409], [413], [414], [421], [423]. For example, Hartvigsen et al. [413] used GPT-3 with demonstration-based prompting to create a large-' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19402.3125\n",
      "page_content='[352]\tY. Lan, Y. Wu, W. Xu, W. Feng, and Y. Zhang, “Chinese finegrained financial sentiment analysis with large language models,” arXiv preprint arXiv:2306.14096, 2023.\n",
      "[353]\tG. Fatouros, J. Soldatos, K. Kouroumali, G. Makridis, and D. Kyr-iazis, “Transforming sentiment analysis in the financial domain with chatgpt,” arXiv preprint arXiv:2308.07935, 2023.\n",
      "[354]\tM. Leippold, “Sentiment spin: Attacking financial sentiment with gpt-3,” Finance Research Letters, p. 103957, 2023.\n",
      "[355]\tP. Wiriyathammabhum, “Promptshots at the finnlp-2022 erai task: Pairwise comparison and unsupervised ranking,” in Proceedings of the Fourth Workshop on Financial Technology and Natural Language Processing (FinNLP), 2022, pp. 104–110.\n",
      "[356]\tA. Shah and S. Chava, “Zero is not hero yet: Benchmarking zero-shot performance of llms for financial tasks,” arXiv preprint arXiv:2305.16633, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19402.3125\n",
      "page_content='[352]\tY. Lan, Y. Wu, W. Xu, W. Feng, and Y. Zhang, “Chinese finegrained financial sentiment analysis with large language models,” arXiv preprint arXiv:2306.14096, 2023.\n",
      "[353]\tG. Fatouros, J. Soldatos, K. Kouroumali, G. Makridis, and D. Kyr-iazis, “Transforming sentiment analysis in the financial domain with chatgpt,” arXiv preprint arXiv:2308.07935, 2023.\n",
      "[354]\tM. Leippold, “Sentiment spin: Attacking financial sentiment with gpt-3,” Finance Research Letters, p. 103957, 2023.\n",
      "[355]\tP. Wiriyathammabhum, “Promptshots at the finnlp-2022 erai task: Pairwise comparison and unsupervised ranking,” in Proceedings of the Fourth Workshop on Financial Technology and Natural Language Processing (FinNLP), 2022, pp. 104–110.\n",
      "[356]\tA. Shah and S. Chava, “Zero is not hero yet: Benchmarking zero-shot performance of llms for financial tasks,” arXiv preprint arXiv:2305.16633, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19424.484375\n",
      "page_content='analyze large amounts of data and use natural language processing to generate text that mimics human writing. The resulting book can cover a wide range of topics, from fiction to non-fiction, and can be produced in various formats such as e-books or print-on-demand. However, the quality of machine-generated books varies widely, and they may contain errors or lack coherence and originality. A machine-generated book is a book that has been produced using artificial intelligence (AI) or machine learning algorithms, without direct human involvement in the writing process. These algorithms analyze large amounts of data and use natural language processing to generate text that mimics human writing. The resulting book can cover a wide range of topics, from fiction to non-fiction, and can be produced in various formats such as e-books or print-on-demand. However, the quality of machine-generated books varies widely, and they may contain errors or lack coherence and originality. Top of Form' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kania和Mehta - 2023 - A Literature Review on Augmented Analytics and Natural Language Generation A Review of State of Art.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19424.484375\n",
      "page_content='analyze large amounts of data and use natural language processing to generate text that mimics human writing. The resulting book can cover a wide range of topics, from fiction to non-fiction, and can be produced in various formats such as e-books or print-on-demand. However, the quality of machine-generated books varies widely, and they may contain errors or lack coherence and originality. A machine-generated book is a book that has been produced using artificial intelligence (AI) or machine learning algorithms, without direct human involvement in the writing process. These algorithms analyze large amounts of data and use natural language processing to generate text that mimics human writing. The resulting book can cover a wide range of topics, from fiction to non-fiction, and can be produced in various formats such as e-books or print-on-demand. However, the quality of machine-generated books varies widely, and they may contain errors or lack coherence and originality. Top of Form' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kania和Mehta - 2023 - A Literature Review on Augmented Analytics and Natural Language Generation A Review of State of Art.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19425.587890625\n",
      "page_content='LLMs like BloombergGPT on tasks like finance news classification and sentiment analysis. In the case of finance news classification, GPT-4 outperforms all other LLMs, including the domain-specific BloombergGPT model.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19425.587890625\n",
      "page_content='LLMs like BloombergGPT on tasks like finance news classification and sentiment analysis. In the case of finance news classification, GPT-4 outperforms all other LLMs, including the domain-specific BloombergGPT model.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19440.51171875\n",
      "page_content='Hirosawa et al. [339] investigated the effectiveness of ChatGPT for clinical diagnosis by evaluating its ability to generate accurate diagnosis lists for clinical vignettes with common chief complaints. Experimental results showed that ChatGPT can generate diagnosis lists with good accuracy. However, the accuracy rate of ChatGPT is still less than the accuracy rate of physicians. Wang et al. [333] evaluated the performance of the ChatGPT model in answering medical questions in the Chinese language. Here, ChatGPT is prompted with questions in both English and Chinese to avoid language barriers. Experimental results show that the performance of ChatGPT is much lower than the average performance of the medical students. For example, ChatGPT correctly answers 45.8% of questions, while the average answering\n",
      "rate of medical students is 67.9% in 2021.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19440.51171875\n",
      "page_content='Hirosawa et al. [339] investigated the effectiveness of ChatGPT for clinical diagnosis by evaluating its ability to generate accurate diagnosis lists for clinical vignettes with common chief complaints. Experimental results showed that ChatGPT can generate diagnosis lists with good accuracy. However, the accuracy rate of ChatGPT is still less than the accuracy rate of physicians. Wang et al. [333] evaluated the performance of the ChatGPT model in answering medical questions in the Chinese language. Here, ChatGPT is prompted with questions in both English and Chinese to avoid language barriers. Experimental results show that the performance of ChatGPT is much lower than the average performance of the medical students. For example, ChatGPT correctly answers 45.8% of questions, while the average answering\n",
      "rate of medical students is 67.9% in 2021.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19440.60546875\n",
      "page_content='Keywords Technical Language Processing · Failure Mode · Large Language Models · Maintenance\n",
      "1\tIntroduction\n",
      "The maintenance of assets plays a critical role in the safety and costs of industrial organisations. One of the key tasks within maintenance is failure mode identification. This task is done by reliability engineers to capture and code failure and other undesirable events. These failure mode codes, together with data such as the cost/ production/ service impact, safety and environmental consequence of the event are used to prioritise improvement work, update maintenance strategy and can assist product/ plant engineers to improve future design by updating their failure modes and effects analysis. Consistent and reproducible failure mode code assignment is difficult as the observation of each event are captured by field technicians in natural language. For example, consider the following maintenance work order texts:\n",
      "•\tpump runs for a while and trip\n",
      "•\tengin does not work' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Stewart 等 - 2023 - Large Language Models for Failure Mode Classification An Investigation.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19440.60546875\n",
      "page_content='Keywords Technical Language Processing · Failure Mode · Large Language Models · Maintenance\n",
      "1\tIntroduction\n",
      "The maintenance of assets plays a critical role in the safety and costs of industrial organisations. One of the key tasks within maintenance is failure mode identification. This task is done by reliability engineers to capture and code failure and other undesirable events. These failure mode codes, together with data such as the cost/ production/ service impact, safety and environmental consequence of the event are used to prioritise improvement work, update maintenance strategy and can assist product/ plant engineers to improve future design by updating their failure modes and effects analysis. Consistent and reproducible failure mode code assignment is difficult as the observation of each event are captured by field technicians in natural language. For example, consider the following maintenance work order texts:\n",
      "•\tpump runs for a while and trip\n",
      "•\tengin does not work' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Stewart 等 - 2023 - Large Language Models for Failure Mode Classification An Investigation.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19445.05859375\n",
      "page_content='5.2\tBaselines\n",
      "Methods without relevance judgment We consider several zero-shot retrieval models as our main baselines, because we do not involve any query-document relevance scores (denoted as w/o relevance judgment) in our setting. Particularly, we choose heuristic-based lexical retriever BM25 (Robertson & Zaragoza, 2009), and Contriever (Izacard et al., 2022) that is trained using unsupervised contrastive learning. We also compare our model with the state-of-the-art LLM-based retrieval model HyDE (Gao et al., 2023) which shares the exact same embedding spaces with Contriever but builds query vectors with LLMs.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Feng 等 - 2023 - Synergistic Interplay between Search and Large Language Models for Information Retrieval.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19445.05859375\n",
      "page_content='5.2\tBaselines\n",
      "Methods without relevance judgment We consider several zero-shot retrieval models as our main baselines, because we do not involve any query-document relevance scores (denoted as w/o relevance judgment) in our setting. Particularly, we choose heuristic-based lexical retriever BM25 (Robertson & Zaragoza, 2009), and Contriever (Izacard et al., 2022) that is trained using unsupervised contrastive learning. We also compare our model with the state-of-the-art LLM-based retrieval model HyDE (Gao et al., 2023) which shares the exact same embedding spaces with Contriever but builds query vectors with LLMs.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Feng 等 - 2023 - Synergistic Interplay between Search and Large Language Models for Information Retrieval.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19450.111328125\n",
      "page_content='We summarize representative passive reader approaches in Table 7, considering various aspects such as the backbone language models, the insertion point for retrieved references, the timing of using retrieval models, and the tuning strategy employed for LLMs.\n",
      "6.2\tActive Reader\n",
      "However, the passive reader-based approaches separate IR systems and generative language models. This signifies that LLMs can only submissively utilize references provided by IR systems and are unable to interactively engage with the IR systems in a manner akin to human interaction such as issuing queries to seek information.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19450.111328125\n",
      "page_content='We summarize representative passive reader approaches in Table 7, considering various aspects such as the backbone language models, the insertion point for retrieved references, the timing of using retrieval models, and the tuning strategy employed for LLMs.\n",
      "6.2\tActive Reader\n",
      "However, the passive reader-based approaches separate IR systems and generative language models. This signifies that LLMs can only submissively utilize references provided by IR systems and are unable to interactively engage with the IR systems in a manner akin to human interaction such as issuing queries to seek information.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19451.396484375\n",
      "page_content='to Thailand’s National Economic and Social Development Board (NESDB). Thai time is divided into five sections, with different names for each section of the day. The country’s primary religion is Theravada Buddhism, and important holidays include Thai New Year, or Songkran. Overall, the daily life of Thai people is diverse, vibrant and deeply rooted in their rich cultural heritage.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Feng 等 - 2023 - Synergistic Interplay between Search and Large Language Models for Information Retrieval.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19451.396484375\n",
      "page_content='to Thailand’s National Economic and Social Development Board (NESDB). Thai time is divided into five sections, with different names for each section of the day. The country’s primary religion is Theravada Buddhism, and important holidays include Thai New Year, or Songkran. Overall, the daily life of Thai people is diverse, vibrant and deeply rooted in their rich cultural heritage.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Feng 等 - 2023 - Synergistic Interplay between Search and Large Language Models for Information Retrieval.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19460.818359375\n",
      "page_content='Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Ves Stoyanov, and Luke Zettlemoyer. 2019. Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension. arXiv preprint arXiv:1910.13461.\n",
      "Xiang Lisa Li and Percy Liang. 2021. Prefix-tuning: Optimizing continuous prompts for generation. arXiv preprint arXiv:2101.00190.\n",
      "Yuxiao Lin, Yuxian Meng, Xiaofei Sun, Qinghong Han, Kun Kuang, Jiwei Li, and Fei Wu. 2021. Bertgcn: Transductive text classification by combining gcn and bert. arXiv preprint arXiv:2105.05727.\n",
      "Jiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan, Lawrence Carin, and Weizhu Chen. 2021. What makes good in-context examples for gpt-3? arXiv preprint arXiv:2101.06804.\n",
      "Pengfei Liu, Xipeng Qiu, and Xuanjing Huang. 2016. Recurrent neural network for text classification with multi-task learning. arXiv preprint arXiv:1605.05101.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19460.818359375\n",
      "page_content='Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Ves Stoyanov, and Luke Zettlemoyer. 2019. Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension. arXiv preprint arXiv:1910.13461.\n",
      "Xiang Lisa Li and Percy Liang. 2021. Prefix-tuning: Optimizing continuous prompts for generation. arXiv preprint arXiv:2101.00190.\n",
      "Yuxiao Lin, Yuxian Meng, Xiaofei Sun, Qinghong Han, Kun Kuang, Jiwei Li, and Fei Wu. 2021. Bertgcn: Transductive text classification by combining gcn and bert. arXiv preprint arXiv:2105.05727.\n",
      "Jiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan, Lawrence Carin, and Weizhu Chen. 2021. What makes good in-context examples for gpt-3? arXiv preprint arXiv:2101.06804.\n",
      "Pengfei Liu, Xipeng Qiu, and Xuanjing Huang. 2016. Recurrent neural network for text classification with multi-task learning. arXiv preprint arXiv:1605.05101.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19468.78515625\n",
      "page_content='[382]\tGPT-3.5\tText Summarization\tZS, FS\tGeneral\tEnglish\t-\n",
      "[383]\tChatGPT\tDetection of Stance, Topics, Relevance, General Frame and Policy Frame\tZS,FS\tSocial Media, News\tEnglish\tYes\n",
      "[324]\tGPT-3\tRadiology Text Simplification\tFS\tHealthcare\tEnglish\t-\n",
      "TABLE 17. Summary of research works exploring GLLMs for data labelling. Here, ’-’ represents that the paper doesn’t include a comparison between GLLMs and human annotators.\n",
      "an evaluator for natural language generation tasks in multilingual settings. The authors reported that GPT-4 tends to favour high scores and should be used carefully.\n",
      "7\tData Labelling and Data Augmentation Abilities of GLLMs\n",
      "7.1\tData Labelling' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19468.78515625\n",
      "page_content='[382]\tGPT-3.5\tText Summarization\tZS, FS\tGeneral\tEnglish\t-\n",
      "[383]\tChatGPT\tDetection of Stance, Topics, Relevance, General Frame and Policy Frame\tZS,FS\tSocial Media, News\tEnglish\tYes\n",
      "[324]\tGPT-3\tRadiology Text Simplification\tFS\tHealthcare\tEnglish\t-\n",
      "TABLE 17. Summary of research works exploring GLLMs for data labelling. Here, ’-’ represents that the paper doesn’t include a comparison between GLLMs and human annotators.\n",
      "an evaluator for natural language generation tasks in multilingual settings. The authors reported that GPT-4 tends to favour high scores and should be used carefully.\n",
      "7\tData Labelling and Data Augmentation Abilities of GLLMs\n",
      "7.1\tData Labelling' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19471.259765625\n",
      "page_content='INPUT & GOLD LABEL\tCLUES\tREASONING\n",
      "INPUT: johnnie to and wai ka fai are sure to find an enthusiastic audience among american action adventure buffs, but the film ’s interests may be too narrow to attract crossover viewers GOLD LABEL: Negative\t-\tPositive Clues: enthusiastic, action, The diagnostic reasoning process supporting the adventure.\tsentiment determination of the input is that the phrase -\tNegative Clues: narrow, crossover\t\"johnnie to and wai ka fai are sure to find an enthusiastic audience among american action adventure buffs\" suggests that the film is likely to be well-received by this specific demographic. However, the subsequent phrase \"but the film’s interests may be too narrow to attract crossover viewers\" implies that the film is unlikely to appeal to a broader audience, suggesting a negative sentiment. Therefore, the overall sentiment of the input is negative.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19471.259765625\n",
      "page_content='INPUT & GOLD LABEL\tCLUES\tREASONING\n",
      "INPUT: johnnie to and wai ka fai are sure to find an enthusiastic audience among american action adventure buffs, but the film ’s interests may be too narrow to attract crossover viewers GOLD LABEL: Negative\t-\tPositive Clues: enthusiastic, action, The diagnostic reasoning process supporting the adventure.\tsentiment determination of the input is that the phrase -\tNegative Clues: narrow, crossover\t\"johnnie to and wai ka fai are sure to find an enthusiastic audience among american action adventure buffs\" suggests that the film is likely to be well-received by this specific demographic. However, the subsequent phrase \"but the film’s interests may be too narrow to attract crossover viewers\" implies that the film is unlikely to appeal to a broader audience, suggesting a negative sentiment. Therefore, the overall sentiment of the input is negative.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19473.287109375\n",
      "page_content='DocIDs) relevant to the queries. In these generative retrieval methods, the knowledge of the document corpus is stored in the model parameters, eliminating the need for additional storage space for a separate index. Existing works have investigated' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19473.287109375\n",
      "page_content='DocIDs) relevant to the queries. In these generative retrieval methods, the knowledge of the document corpus is stored in the model parameters, eliminating the need for additional storage space for a separate index. Existing works have investigated' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19475.580078125\n",
      "page_content='Some of the research works focused on developing multi-model AI systems which can handle multiple tasks [289], [292], [293], [295], [299], [302]. As ChatGPT is trained on one data modality i.e., text data, ChatGPT can only handle text inputs and training models from scratch for vision-language tasks, is not a feasible option as it involves huge computation. So, Wu et al. [292] developed Visual ChatGPT based on ChatGPT and various visual foundation models to handle 22 vision language tasks. Bhattacharya et al. [299] proposed a novel three-' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19475.580078125\n",
      "page_content='Some of the research works focused on developing multi-model AI systems which can handle multiple tasks [289], [292], [293], [295], [299], [302]. As ChatGPT is trained on one data modality i.e., text data, ChatGPT can only handle text inputs and training models from scratch for vision-language tasks, is not a feasible option as it involves huge computation. So, Wu et al. [292] developed Visual ChatGPT based on ChatGPT and various visual foundation models to handle 22 vision language tasks. Bhattacharya et al. [299] proposed a novel three-' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19481.390625\n",
      "page_content='•\tImproving personalized search. Many existing LLM-based reranking methods mainly focus on the ad-hoc reranking task. However, by incorporating user-specific information, LLMs can also improve the effectiveness of the personalized reranking task. For example, by analyzing users’ search history, LLMs can construct accurate user profiles and rerank the search results accordingly, providing personalized results with higher user satisfaction.\n",
      "•\tAdapting to diverse ranking tasks. In addition to document reranking, there are also other ranking tasks, such as response ranking, evidence ranking, entity ranking and etc., which also belong to the universal information access system. Navigating LLMs towards adeptness in these diverse ranking tasks can be achieved through specialized methodologies, such as instruction tuning. Exploring this avenue holds promise as an intriguing and valuable research trajectory.\n",
      "8.4\tReader' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19481.390625\n",
      "page_content='•\tImproving personalized search. Many existing LLM-based reranking methods mainly focus on the ad-hoc reranking task. However, by incorporating user-specific information, LLMs can also improve the effectiveness of the personalized reranking task. For example, by analyzing users’ search history, LLMs can construct accurate user profiles and rerank the search results accordingly, providing personalized results with higher user satisfaction.\n",
      "•\tAdapting to diverse ranking tasks. In addition to document reranking, there are also other ranking tasks, such as response ranking, evidence ranking, entity ranking and etc., which also belong to the universal information access system. Navigating LLMs towards adeptness in these diverse ranking tasks can be achieved through specialized methodologies, such as instruction tuning. Exploring this avenue holds promise as an intriguing and valuable research trajectory.\n",
      "8.4\tReader' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19484.197265625\n",
      "page_content='•\tSpecial tokens: tokens that do not have semantic meaning. They are independent of the input and added for a certain purpose. e.g., <cls>, <mask>.\n",
      "Results are shown in Table 8. As can be seen, few-shot ICL with annotation words as label words achieves the best performances. It is also worth noting that we observe a significant performance\n",
      "9 GPT-3 generates the same label words for binary sentiment classification task.\n",
      "decrease when flipped words are used as label words in demonstrations.\n",
      "6.4\tThe influence of clues' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19484.197265625\n",
      "page_content='•\tSpecial tokens: tokens that do not have semantic meaning. They are independent of the input and added for a certain purpose. e.g., <cls>, <mask>.\n",
      "Results are shown in Table 8. As can be seen, few-shot ICL with annotation words as label words achieves the best performances. It is also worth noting that we observe a significant performance\n",
      "9 GPT-3 generates the same label words for binary sentiment classification task.\n",
      "decrease when flipped words are used as label words in demonstrations.\n",
      "6.4\tThe influence of clues' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19484.380859375\n",
      "page_content='7\tSearch Agent\n",
      "With the development of LLMs, IR systems are also facing new changes. Among them, developing LLMs as intelligent agents has attracted more and more attention. This conceptual shift aims to mimic human browsing patterns, thereby enhancing the capability of these models to handle complex retrieval tasks. Empowered by the advanced natural language understanding and generation capabilities of LLMs, these agents can autonomously search, interpret, and synthesize information from a wide range of sources.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19484.380859375\n",
      "page_content='7\tSearch Agent\n",
      "With the development of LLMs, IR systems are also facing new changes. Among them, developing LLMs as intelligent agents has attracted more and more attention. This conceptual shift aims to mimic human browsing patterns, thereby enhancing the capability of these models to handle complex retrieval tasks. Empowered by the advanced natural language understanding and generation capabilities of LLMs, these agents can autonomously search, interpret, and synthesize information from a wide range of sources.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19492.4453125\n",
      "page_content='Fg (s,k) ^ j 6 {entailment, contradiction, neutral}\n",
      "Knowledge is retained if the NLI result is classified as entailment. We can adjust the strength of the hypothesis based on the specific dataset. For single-hop questions, a stronger hypothesis can be set, requiring the knowledge to contain direct and explicit answer information. Conversely, for more complex multi-hop questions, we can set a weaker hypothesis, only requiring the knowledge to include information that possibly aids in answering the question. When valid knowledge is unavailable, a back-off strategy is invoked, where LLMs generate responses without the aid of external knowledge augmentation. The Knowledge Filter also employs the LoRA fine-tuning method [12] on the Gemma-2B model, offering enhanced applicability and adaptability compared to prompt-based approaches.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19492.4453125\n",
      "page_content='Fg (s,k) ^ j 6 {entailment, contradiction, neutral}\n",
      "Knowledge is retained if the NLI result is classified as entailment. We can adjust the strength of the hypothesis based on the specific dataset. For single-hop questions, a stronger hypothesis can be set, requiring the knowledge to contain direct and explicit answer information. Conversely, for more complex multi-hop questions, we can set a weaker hypothesis, only requiring the knowledge to include information that possibly aids in answering the question. When valid knowledge is unavailable, a back-off strategy is invoked, where LLMs generate responses without the aid of external knowledge augmentation. The Knowledge Filter also employs the LoRA fine-tuning method [12] on the Gemma-2B model, offering enhanced applicability and adaptability compared to prompt-based approaches.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Shi 等 - 2024 - Enhancing Retrieval and Managing Retrieval A Four-Module Synergy for Improved Quality and Efficienc.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19496.693359375\n",
      "page_content='[149]\tQ. Liu, B. Wang, N. Wang, and J. Mao, “Leveraging passage embeddings for efficient listwise reranking with large language models,” CoRR, vol. abs/2406.14848, 2024.\n",
      "[150]\tP. Liang, R. Bommasani, T. Lee, D. Tsipras, D. Soylu, M. Yasunaga, Y. Zhang, D. Narayanan, Y. Wu, A. Kumar, B. Newman, B. Yuan, B. Yan, C. Zhang, C. Cosgrove, C. D. Manning, C. Re´ , D. Acosta-Navas, D. A. Hudson, E. Zelikman, E. Durmus, F. Ladhak, F. Rong, H. Ren, H. Yao, J. Wang, K. Santhanam, L. J. Orr, L. Zheng, M. Yu¨ ksekgo¨ nu¨ l, M. Suzgun, N. Kim, N. Guha, N. S. Chatterji, O. Khattab, P. Henderson, Q. Huang, R. Chi, S. M. Xie, S. Santurkar, S. Gan-guli, T. Hashimoto, T. Icard, T. Zhang, V. Chaudhary, W. Wang, X. Li, Y. Mai, Y. Zhang, and Y. Koreeda, “Holistic evaluation of language models,” CoRR, vol. abs/2211.09110, 2022.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19496.693359375\n",
      "page_content='[149]\tQ. Liu, B. Wang, N. Wang, and J. Mao, “Leveraging passage embeddings for efficient listwise reranking with large language models,” CoRR, vol. abs/2406.14848, 2024.\n",
      "[150]\tP. Liang, R. Bommasani, T. Lee, D. Tsipras, D. Soylu, M. Yasunaga, Y. Zhang, D. Narayanan, Y. Wu, A. Kumar, B. Newman, B. Yuan, B. Yan, C. Zhang, C. Cosgrove, C. D. Manning, C. Re´ , D. Acosta-Navas, D. A. Hudson, E. Zelikman, E. Durmus, F. Ladhak, F. Rong, H. Ren, H. Yao, J. Wang, K. Santhanam, L. J. Orr, L. Zheng, M. Yu¨ ksekgo¨ nu¨ l, M. Suzgun, N. Kim, N. Guha, N. S. Chatterji, O. Khattab, P. Henderson, Q. Huang, R. Chi, S. M. Xie, S. Santurkar, S. Gan-guli, T. Hashimoto, T. Icard, T. Zhang, V. Chaudhary, W. Wang, X. Li, Y. Mai, Y. Zhang, and Y. Koreeda, “Holistic evaluation of language models,” CoRR, vol. abs/2211.09110, 2022.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19496.8203125\n",
      "page_content='ing those text retrieval systems, in which query-document relevance is commonly measured by their matching score.3 Given that IR systems operate on extensive repositories, the efficiency of retrieval algorithms becomes of paramount importance. To improve the user experience, the retrieval performance is enhanced from both the upstream (query reformulation) and downstream (reranking and reading) perspectives. As an upstream technique, query reformulation is designed to refine user queries so that they are more effective at retrieving relevant documents [10, 11]. With the recent surge in the popularity of conversational search, this technique has received increasing attention. On the downstream side, reranking approaches are developed to further adjust the document ranking [12–14]. In contrast to the retrieval stage, reranking is performed only on a limited set of relevant documents, already retrieved by the retriever. Under this circumstance, the emphasis is placed on achieving higher' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19496.8203125\n",
      "page_content='ing those text retrieval systems, in which query-document relevance is commonly measured by their matching score.3 Given that IR systems operate on extensive repositories, the efficiency of retrieval algorithms becomes of paramount importance. To improve the user experience, the retrieval performance is enhanced from both the upstream (query reformulation) and downstream (reranking and reading) perspectives. As an upstream technique, query reformulation is designed to refine user queries so that they are more effective at retrieving relevant documents [10, 11]. With the recent surge in the popularity of conversational search, this technique has received increasing attention. On the downstream side, reranking approaches are developed to further adjust the document ranking [12–14]. In contrast to the retrieval stage, reranking is performed only on a limited set of relevant documents, already retrieved by the retriever. Under this circumstance, the emphasis is placed on achieving higher' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19499.20703125\n",
      "page_content='[371]\tR. Bommasani, P. Liang, and T. Lee, “Holistic evaluation of language models,” Annals of the New York Academy of Sciences, 2023.\n",
      "[372]\tA. Srivastava, A. Rastogi, A. Rao, A. A. M. Shoeb, A. Abid, A. Fisch, A. R. Brown, A. Santoro, A. Gupta, A. Garriga-Alonso et al., “Beyond the imitation game: Quantifying and extrapolating the capabilities of language models,” Transactions on Machine Learning Research, 2023.\n",
      "[373]\tF. Gilardi, M. Alizadeh, and M. Kubli, “Chatgpt outperforms crowd-workers for text-annotation tasks,” arXiv preprint arXiv:2303.15056, 2023.\n",
      "[374]\tX. He, Z. Lin, Y. Gong, A. Jin, H. Zhang, C. Lin, J. Jiao, S. M. Yiu, N. Duan, W. Chen et al., “Annollm: Making large language models to be better crowdsourced annotators,” arXiv preprint arXiv:2303.16854, 2023.\n",
      "[375]\tP. To¨ rnberg, “Chatgpt-4 outperforms experts and crowd workers in annotating political twitter messages with zero-shot learning,” arXiv preprint arXiv:2304.06588, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19499.20703125\n",
      "page_content='[371]\tR. Bommasani, P. Liang, and T. Lee, “Holistic evaluation of language models,” Annals of the New York Academy of Sciences, 2023.\n",
      "[372]\tA. Srivastava, A. Rastogi, A. Rao, A. A. M. Shoeb, A. Abid, A. Fisch, A. R. Brown, A. Santoro, A. Gupta, A. Garriga-Alonso et al., “Beyond the imitation game: Quantifying and extrapolating the capabilities of language models,” Transactions on Machine Learning Research, 2023.\n",
      "[373]\tF. Gilardi, M. Alizadeh, and M. Kubli, “Chatgpt outperforms crowd-workers for text-annotation tasks,” arXiv preprint arXiv:2303.15056, 2023.\n",
      "[374]\tX. He, Z. Lin, Y. Gong, A. Jin, H. Zhang, C. Lin, J. Jiao, S. M. Yiu, N. Duan, W. Chen et al., “Annollm: Making large language models to be better crowdsourced annotators,” arXiv preprint arXiv:2303.16854, 2023.\n",
      "[375]\tP. To¨ rnberg, “Chatgpt-4 outperforms experts and crowd workers in annotating political twitter messages with zero-shot learning,” arXiv preprint arXiv:2304.06588, 2023.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19505.767578125\n",
      "page_content='Adina Williams, Nikita Nangia, and Samuel Bowman. 2018. A broad-coverage challenge corpus for sentence understanding through inference. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers), pages 1112–1122, New Orleans, Louisiana. Association for Computational Linguistics.\n",
      "Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Russ R Salakhutdinov, and Quoc V Le. 2019. Xlnet: Generalized autoregressive pretraining for language understanding. In Advances in Neural Information Processing Systems, volume 32. Curran Associates, Inc.\n",
      "Ningyu Zhang, Luoqiu Li, Xiang Chen, Shumin Deng, Zhen Bi, Chuanqi Tan, Fei Huang, and Huajun Chen. 2022. Differentiable prompt makes pre-trained language models better fewshot learners. In International Conference on Learning Representations.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19505.767578125\n",
      "page_content='Adina Williams, Nikita Nangia, and Samuel Bowman. 2018. A broad-coverage challenge corpus for sentence understanding through inference. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers), pages 1112–1122, New Orleans, Louisiana. Association for Computational Linguistics.\n",
      "Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Russ R Salakhutdinov, and Quoc V Le. 2019. Xlnet: Generalized autoregressive pretraining for language understanding. In Advances in Neural Information Processing Systems, volume 32. Curran Associates, Inc.\n",
      "Ningyu Zhang, Luoqiu Li, Xiang Chen, Shumin Deng, Zhen Bi, Chuanqi Tan, Fei Huang, and Huajun Chen. 2022. Differentiable prompt makes pre-trained language models better fewshot learners. In International Conference on Learning Representations.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19511.81640625\n",
      "page_content='Table 7: The impact of model bias in XLNet-large on predicting the next word.\n",
      "Next Word\tPrediction of Next Word\t\t\t\n",
      "\tpolitics\tsports\tbusiness\ttechnology\n",
      "politics\t1651\t6\t52\t191\n",
      "sports\t255\t623\t118\t904\n",
      "business\t129\t27\t1343\t401\n",
      "technology\t54\t2\t16\t1828\n",
      "ists in all three models and different models show various distributions of model bias. Moreover, after correcting the model bias with our approach, we measure the model bias again on AG’s News using the same unlabeled data and template. As shown in Table 6(b), the model bias of all three models is nearly uniformly distributed, which demonstrates the effectiveness of our method.\n",
      "5.5.\tApplicability beyond Classification' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19511.81640625\n",
      "page_content='Table 7: The impact of model bias in XLNet-large on predicting the next word.\n",
      "Next Word\tPrediction of Next Word\t\t\t\n",
      "\tpolitics\tsports\tbusiness\ttechnology\n",
      "politics\t1651\t6\t52\t191\n",
      "sports\t255\t623\t118\t904\n",
      "business\t129\t27\t1343\t401\n",
      "technology\t54\t2\t16\t1828\n",
      "ists in all three models and different models show various distributions of model bias. Moreover, after correcting the model bias with our approach, we measure the model bias again on AG’s News using the same unlabeled data and template. As shown in Table 6(b), the model bias of all three models is nearly uniformly distributed, which demonstrates the effectiveness of our method.\n",
      "5.5.\tApplicability beyond Classification' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhao 等 - Correcting Language Model Bias for Text Classification in True Zero-Shot Learning.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19529.7265625\n",
      "page_content='TABLE 6. Summary of research works exploring GLLMs for various dialogue tasks. Here ZS represents zero-shot, and FS represents few-shot.\n",
      "[228], [229].\n",
      "Research works exploring GLLMs for dialogue tasks. The research community explored GLLMs like GPT-3, GPT-3.5 and ChatGPT for various dialogue tasks like dialogue summarization [157], [220], [221] , dialogue question answering [224], emotion dialogue understanding and generation [219], dialogue state tracking [218], dialogue generation [132], and dialogue discourse analysis [223]. Some of the research works explored LLMs for the evaluation of dialogue tasks [222]. Most of the research works focused on general domain and English language datasets, except a few research works which focused on the medical domain [220] and languages like Chinese [223], [224]. Table 6 presents a summary of research works exploring GLLMs for various dialogue tasks.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19529.7265625\n",
      "page_content='TABLE 6. Summary of research works exploring GLLMs for various dialogue tasks. Here ZS represents zero-shot, and FS represents few-shot.\n",
      "[228], [229].\n",
      "Research works exploring GLLMs for dialogue tasks. The research community explored GLLMs like GPT-3, GPT-3.5 and ChatGPT for various dialogue tasks like dialogue summarization [157], [220], [221] , dialogue question answering [224], emotion dialogue understanding and generation [219], dialogue state tracking [218], dialogue generation [132], and dialogue discourse analysis [223]. Some of the research works explored LLMs for the evaluation of dialogue tasks [222]. Most of the research works focused on general domain and English language datasets, except a few research works which focused on the medical domain [220] and languages like Chinese [223], [224]. Table 6 presents a summary of research works exploring GLLMs for various dialogue tasks.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19548.744140625\n",
      "page_content='Comparison with existing surveys. The existing survey papers provide a review of large language models [44] and the relevant concepts like in-context learning [45], evaluation [46], [47], alignment with human values [48], [49], safety and trustworthiness [50], reasoning [51], challenges and applications [52], LLM compression [53] and multi-modal LLMs [54]. For example, Zhao et al. [44] are the first to provide a comprehensive of large language models. Unlike Zhao et al. [44], the other existing survey papers focus on specific concepts of LLMs. For example, the survey papers written by Dong et al. [45], Chang et al. [46], Wang et al. [48] and Huang et al. [51] focus on in-context learning, evaluation of LLMs, alignment of LLMs with human values and reasoning ability of LLMs respectively. Similarly, the survey papers written by Yin et al. [54] and Huan et al. [50] provide a review of multi-modal LLMs and the safety and trustworthiness of LLMs, respectively. However, there is no existing' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19548.744140625\n",
      "page_content='Comparison with existing surveys. The existing survey papers provide a review of large language models [44] and the relevant concepts like in-context learning [45], evaluation [46], [47], alignment with human values [48], [49], safety and trustworthiness [50], reasoning [51], challenges and applications [52], LLM compression [53] and multi-modal LLMs [54]. For example, Zhao et al. [44] are the first to provide a comprehensive of large language models. Unlike Zhao et al. [44], the other existing survey papers focus on specific concepts of LLMs. For example, the survey papers written by Dong et al. [45], Chang et al. [46], Wang et al. [48] and Huang et al. [51] focus on in-context learning, evaluation of LLMs, alignment of LLMs with human values and reasoning ability of LLMs respectively. Similarly, the survey papers written by Yin et al. [54] and Huan et al. [50] provide a review of multi-modal LLMs and the safety and trustworthiness of LLMs, respectively. However, there is no existing' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19551.55078125\n",
      "page_content='document corpus. (2) More model parameters often bring better performance. (3) Introducing synthetic queries generated from documents to expand training samples could significantly enhance the retrieval performance.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19551.55078125\n",
      "page_content='document corpus. (2) More model parameters often bring better performance. (3) Introducing synthetic queries generated from documents to expand training samples could significantly enhance the retrieval performance.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19556.712890625\n",
      "page_content='Luyu Gao, Xueguang Ma, Jimmy Lin, and Jamie Callan. Precise zero-shot dense retrieval without relevance labels. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 1762–1777, Toronto, Canada, July 2023. Association for Computational Linguistics. doi: 10.18653/v1/2023.acl-long.99. URL https://aclanthology. org/2023.acl-long.99.\n",
      "Manas Gaur, Kalpa Gunaratna, Vijay Srinivasan, and Hongxia Jin. Iseeq: Information seeking question generation using dynamic meta-information retrieval and knowledge graphs. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 36, pp. 10672–10680, 2022.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Feng 等 - 2023 - Synergistic Interplay between Search and Large Language Models for Information Retrieval.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19556.712890625\n",
      "page_content='Luyu Gao, Xueguang Ma, Jimmy Lin, and Jamie Callan. Precise zero-shot dense retrieval without relevance labels. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 1762–1777, Toronto, Canada, July 2023. Association for Computational Linguistics. doi: 10.18653/v1/2023.acl-long.99. URL https://aclanthology. org/2023.acl-long.99.\n",
      "Manas Gaur, Kalpa Gunaratna, Vijay Srinivasan, and Hongxia Jin. Iseeq: Information seeking question generation using dynamic meta-information retrieval and knowledge graphs. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 36, pp. 10672–10680, 2022.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Feng 等 - 2023 - Synergistic Interplay between Search and Large Language Models for Information Retrieval.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19571.076171875\n",
      "page_content='[92]\tV. Sanh, L. Debut, J. Chaumond, and T. Wolf, “Distilbert, a distilled version of bert: smaller, faster, cheaper and lighter,” arXiv preprint arXiv:1910.01108, 2019.\n",
      "[93]\tX. Jiao, Y. Yin, L. Shang, X. Jiang, X. Chen, L. Li, F. Wang, and Q. Liu, “Tinybert: Distilling bert for natural language understanding,” in Findings of the Association for Computational Linguistics: EMNLP 2020, 2020, pp. 4163–4174.\n",
      "[94]\tZ. Sun, H. Yu, X. Song, R. Liu, Y. Yang, and D. Zhou, “Mobile-bert: a compact task-agnostic bert for resource-limited devices,” in Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, 2020, pp. 2158–2170.\n",
      "[95]\tW. Wang, F. Wei, L. Dong, H. Bao, N. Yang, and M. Zhou, “Minilm: Deep self-attention distillation for task-agnostic compression of pre-trained transformers,” arXiv preprint arXiv:2002.10957, 2020.\n",
      "[96]\tI. Beltagy, M. E. Peters, and A. Cohan, “Longformer: The long-document transformer,” arXiv preprint arXiv:2004.05150, 2020.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19571.076171875\n",
      "page_content='[92]\tV. Sanh, L. Debut, J. Chaumond, and T. Wolf, “Distilbert, a distilled version of bert: smaller, faster, cheaper and lighter,” arXiv preprint arXiv:1910.01108, 2019.\n",
      "[93]\tX. Jiao, Y. Yin, L. Shang, X. Jiang, X. Chen, L. Li, F. Wang, and Q. Liu, “Tinybert: Distilling bert for natural language understanding,” in Findings of the Association for Computational Linguistics: EMNLP 2020, 2020, pp. 4163–4174.\n",
      "[94]\tZ. Sun, H. Yu, X. Song, R. Liu, Y. Yang, and D. Zhou, “Mobile-bert: a compact task-agnostic bert for resource-limited devices,” in Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, 2020, pp. 2158–2170.\n",
      "[95]\tW. Wang, F. Wei, L. Dong, H. Bao, N. Yang, and M. Zhou, “Minilm: Deep self-attention distillation for task-agnostic compression of pre-trained transformers,” arXiv preprint arXiv:2002.10957, 2020.\n",
      "[96]\tI. Beltagy, M. E. Peters, and A. Cohan, “Longformer: The long-document transformer,” arXiv preprint arXiv:2004.05150, 2020.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Kalyan - 2023 - A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19572.466796875\n",
      "page_content='every n generated tokens). In this manner, when generating the text about the university career of Barack Obama, the LLM can receive additional documents as supplementary materials. This need for additional references highlights the necessity for multiple retrieval iterations to ensure robustness in subsequent answer generation. Notably, RETRO [23] introduces a novel approach incorporating cross-attention between the generating texts and the references within the Transformer attention calculation, as opposed to directly embedding references into the input texts of LLMs. Since it involves additional cross-attention modules in the Transformer ’s structure, RETRO trains this model from scratch.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19572.466796875\n",
      "page_content='every n generated tokens). In this manner, when generating the text about the university career of Barack Obama, the LLM can receive additional documents as supplementary materials. This need for additional references highlights the necessity for multiple retrieval iterations to ensure robustness in subsequent answer generation. Notably, RETRO [23] introduces a novel approach incorporating cross-attention between the generating texts and the references within the Transformer attention calculation, as opposed to directly embedding references into the input texts of LLMs. Since it involves additional cross-attention modules in the Transformer ’s structure, RETRO trains this model from scratch.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Zhu 等 - 2024 - Large Language Models for Information Retrieval A Survey.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19573.294921875\n",
      "page_content='This is an overall sentiment classifier for movie reviews. Classify the overall SENTIMENT of the INPUT as Positive or Negative.\n",
      "INPUT: noyce films it more as a shocking history lesson than as drama.\n",
      "SENTIMENT: Let's think step-by-step. The input states that the films are \"more\" something than something else. This implies that the films are at least somewhat of the first thing mentioned. In this case, the films are more of a \"shocking history lesson\" than \"drama\". This implies that the sentiment is positive, as the films are more of a history lesson than drama. The overall sentiment is Positive.\n",
      "INPUT: press the delete key\n",
      "SENTIMENT: Let's think step-by-step. The input does not provide any context or opinion, so it is impossible to determine the sentiment. Therefore, the overall sentiment is Neutral. ^\n",
      "(b)\n",
      "This is an overall sentiment classifier for movie reviews.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n",
      "========================================================================================================================================================================================================\n",
      "该文档相似度为: 19573.294921875\n",
      "page_content='This is an overall sentiment classifier for movie reviews. Classify the overall SENTIMENT of the INPUT as Positive or Negative.\n",
      "INPUT: noyce films it more as a shocking history lesson than as drama.\n",
      "SENTIMENT: Let's think step-by-step. The input states that the films are \"more\" something than something else. This implies that the films are at least somewhat of the first thing mentioned. In this case, the films are more of a \"shocking history lesson\" than \"drama\". This implies that the sentiment is positive, as the films are more of a history lesson than drama. The overall sentiment is Positive.\n",
      "INPUT: press the delete key\n",
      "SENTIMENT: Let's think step-by-step. The input does not provide any context or opinion, so it is impossible to determine the sentiment. Therefore, the overall sentiment is Neutral. ^\n",
      "(b)\n",
      "This is an overall sentiment classifier for movie reviews.' metadata={'source': 'd:\\\\待办\\\\D40视频\\\\LLM\\\\D03Base\\\\data\\\\Sun 等 - 2023 - Text Classification via Large Language Models.txt'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = []\n",
    "query = \"What is prompt?\"\n",
    "docs = db.similarity_search_with_score(query, k = len(documents))\n",
    "for doc in docs:\n",
    "    metadata = doc[0].metadata\n",
    "    data.append({\"Content\": doc[0].page_content, \n",
    "                 \"Similarity Score\": doc[1],\n",
    "                 \"Sourcd Path\": metadata.get('source', '')})\n",
    "\n",
    "    print(\"=\"*200)\n",
    "    print(\"该文档相似度为:\",doc[1])\n",
    "    print(doc[0])\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_excel(\"result.xlsx\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 运行方法4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_community.llms import Tongyi\n",
    "\n",
    "retriever = db.as_retriever()\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "model = Tongyi(model=\"qwen-turbo\", temperature=0.7)\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join([d.page_content for d in docs])\n",
    "\n",
    "chain = (\n",
    "    {\"context\":retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the provided context, \"prompt\" refers to a technique used in machine learning, specifically in the context of prompt learning with Pre-Trained Language Models (PLMs). A prompt is a method that involves framing a task as a prediction problem where the model is given some contextual information (the prompt) and asked to predict a specific output, such as a label or answer to a question. The effectiveness of this approach depends on the model\\'s ability to correctly fill in or predict the right label or response based on the given prompt. \\n\\nHowever, the term \"prompt\" in your question could also refer to the examples provided for different types of prompts like few-shot, zero-shot, and brainstorm prompts which are used to elicit specific responses from PLMs. These prompts are designed to help the model understand and generate appropriate outputs for various tasks without extensive training or additional data. \\n\\nSo, in summary, a \"prompt\" is a form of input designed to guide a PLM toward generating or predicting a particular kind of output relevant to a given task or question.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"What is prompt?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
